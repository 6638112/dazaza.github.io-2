<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>一个新的protobuf发电机 A new ProtoBuf generator for Go</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">A new ProtoBuf generator for Go<br/>一个新的protobuf发电机 </h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2021-06-04 02:31:59</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2021/6/aaf3eb06887a519cdb14d83a7506e54d.png"><img src="http://img2.diglog.com/img/2021/6/aaf3eb06887a519cdb14d83a7506e54d.png" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>Although the main interface between applications and a Vitess database is through the MySQL protocol, Vitess is a large and complex distributed system, and all the communication between the different services in a Vitess cluster is performed through  GRPC.</p><p>虽然应用程序和Vitess数据库之间的主要界面是通过MySQL协议，但Vitess是一个大而复杂的分布式系统，并且通过GRPC执行VITESS集群中的不同服务之间的所有通信。</p><p> Because of this, all service boundaries and messages between Vitess&#39; systems are specified using Protocol Buffers. The history of Vitess&#39; integration with Protocol Buffers is rather involved: We have been using and keeping up to date with the  Go Protocol Buffers package since its earliest releases, up until May last year, when Google  released a new Go API for Protocol Buffers, which is not backwards compatible with the previous Go package.</p><p> 因此，所有服务边界和Vitess＆＃39之间的消息;使用协议缓冲区指定系统。 Vitess＆＃39的历史;与协议缓冲区的集成相同涉及：自从最早的发布以来，我们一直在使用并保持最新与Go Protocol Buffers封装，直到去年5月，当谷歌发布了用于协议缓冲区的新GO API时，这不是向后兼容的使用之前的Go Package。</p><p> There are several reasons why we didn’t jump at the chance of upgrading to the new API right away: the upgrade is non-trivial, particularly for a project as large as Vitess; it does not provide any tangible benefits to us, since our use of Protocol Buffers is quite basic, and we don’t use reflection anywhere in our codebase; and most importantly: it implies a very significant performance regression.</p><p> 我们立即升级到新API的机会有几个原因：升级是非琐碎的，特别是对于像玻璃体一样大的项目;它没有向我们提供任何有形的好处，因为我们使用协议缓冲区是非常基本的，并且我们不会在我们的代码库中的任何地方使用反射;最重要的是：它意味着一个非常重要的性能回归。</p><p> Although the new (un)marshaling code in ProtoBuf APIv2 is  not measurably slower than the one in APIv1 (it is, in fact, mostly equivalent), Vitess hasn’t been using the APIv1 codecs for a while. Earlier this year, we introduced the Gogo ProtoBuf compiler to our codebase, with really impressive performance results.</p><p> 虽然Protobuf APIV2中的新（UN）编程代码不会比APIV1中的一个慢得多（但实际上，大多数等价物），Vitess尚未使用API​​V1编解码器一段时间。今年早些时候，我们将Gogo Protobuf编译器介绍给我们的Codebase，具有令人印象深刻的性能结果。</p><p> For those who are not aware of it,  Gogo ProtoBuf is a  fork of the original ProtoBuf APIv1 that includes a custom code generator with optional support for many performance related features. The most notable of them, and the one we enabled for Vitess, is the generation of fully unrolled marshaling and unmarshaling code for all the messages in the codebase. This is a very significant performance boost compared to marshaling using the default codecs in ProtoBuf APIv1, which are fully implemented using reflection at runtime. Having static code that can be compiled ahead of time results in much lower CPU usage and measurably shorter response times for our most demanding RPC calls.</p><p> 对于那些不了解的人，Gogo Protobuf是原始Protobuf APIV1的叉子，包括一个自定义代码生成器，可选支持许多性能相关的功能。它们中最值得注意的是，我们为Vitess启用的那个是为代码库中的所有消息产生完全展开的蒙太展和解码代码。与使用Protobuf APIV1中的默认编解码器进行默认编解码器相比，这是一个非常重要的性能提升，这在运行时使用反射完全实现。具有可以提前编译的静态代码会导致CPU使用率的大量使用率和最令人难以置信的RPC呼叫的响应时间更低。</p><p> Despite the positive results of introducing the Gogo ProtoBuf compiler to our codebase, there was something rather concerning about the optimization: the Gogo project is currently unmaintained and  actively looking for new ownership. The main reason for this is the release of the ProtoBuf APIv2: Gogo ProtoBuf is a fork of the APIv1 compiler, so updating it to support APIv2 would essentially mean a full rewrite of the project, just like APIv2 is a full rewrite of APIv1. The maintainers of Gogo, understandably, were not up to the gigantic task.</p><p> 尽管将Gogo Protobuf编译器引入我们的Codebase的结果，但有些关于优化的东西：Gogo项目目前没有积极寻找新的所有权。这是主要原因是Protobuf APIV2的发布：Gogo Protobuf是APIV1编译器的叉子，因此将其更新为支持APIV2将是一个完整的重写项目，就像APIV2是APIV1的完整重写一样。 Gogo的维护者，可理解的是，无法达到巨大的任务。</p><p> Hence, it was clear to us that introducing Gogo ProtoBuf generated code in Vitess would be a very short-lived optimization: as soon as we decided to upgrade our project to ProtoBuf APIv2, we’d have to drop Gogo altogether and go back to the default reflection-based (un)marshaler, but we still took the plunge, making sure to use as few Gogo-exclusive features as possible to make the eventual upgrade less painful.</p><p> 因此，我们很清楚，在Vitess中引入Gogo Protobuf生成的代码将是一个非常短暂的优化：一旦我们决定将我们的项目升级到Protobuf APIV2，我们必须完全丢弃Gogo并回到基于默认的反射（联合国）母校，但我们仍然脱颖而出，确保尽可能少的Gogo专用特征来使最终升级更痛苦。 </p><p> Was this a bad idea? Maybe. Earlier this month we decided to attempt upgrading Vitess to ProtoBuf APIv2, mostly to find out how hard would the process be, and how large the performance regression when removing Gogo’s autogenerated code. The upgrade didn’t go without its  hiccups, but we managed to get Vitess working with the new API and the test suite fully green after a couple of weeks of effort.</p><p>这是一个坏主意吗？也许。本月早些时候，我们决定尝试将Vitess升级到Protobuf APIV2，主要是为了了解过程是多么努力，以及删除Gogo的自动化代码时的性能回归程度如何。升级没有没有打嗝，但我们设法在几周的努力之后，我们设法使用新的API和测试套件全面使用。</p><p> The results of our benchmarks, however, were discouraging.  AreWeFastYet, our nightly benchmark system, detected a very significant increase in CPU usage during all benchmarking runs: up to 19%, resulting in lowering the total throughput of of the system by roughly 3%.</p><p> 然而，我们的基准的结果令人沮丧。我们的夜间基准系统是在所有基准测试期间检测到CPU使用率的非常大幅增加：高达19％，导致系统的总吞吐量降低约3％。</p><p>  We try  really hard to never regress performance between Vitess releases, so we started evaluating our options to perform this upgrade and leaving behind the ProtoBuf APIv1 package (now deprecated) and the Gogo ProtoBuf compiler (now unmaintained) while keeping Vitess as fast as it was.</p><p>  我们真的很难在Vitess版本之间恢复性能，因此我们开始评估我们的选项来执行此升级并留下Protobuf APIV1封装（现在已被弃用）以及Gogo Protobuf编译器（现在不明意），同时保持Vitess尽可能快地保持Vitess 。</p><p>  The most obvious choice that occured to us was picking up ownership of Gogo ProtoBuf, but its maintainers were right: upgrading it to APIv2 is a massive undertaking. We don’t have the staffing capacity to commit to upgrading  and owning such project indefinitely.</p><p>  最明显的选择是借鉴我们的Gogo Protobuf的所有权，但它的维护者是对的：将其升级到APIV2是一个大规模的事业。我们没有人员配备能力，以无限期地升级和拥有此类项目。</p><p> So instead, we’ve attempted to build a ProtoBuf compiler that fulfills our performance needs while learning from the lessons of Gogo ProtoBuf:  vtprotobuf is a ProtoBuf compiler for Go that generates highly optimized (un)marshaling code for APIv2, whilst being (hopefully) easier to maintain in the long term.</p><p> 所以，我们试图建立一个protobuf编译器，同时从Gogo protobuf的课程中学习了我们的性能需求：Vtprotobuf是一个Protobuf编译器，用于GoIV2的高度优化（UN）编号，同时（希望）在长期内更容易维护。</p><p> The  vtprotobuf compiler makes a different design choice compared to Gogo ProtoBuf: it is not a fork of the APIv2 compiler, but an independent plug-in that runs  alongside the upstream compiler for APIv2 and generates the optimized code as opt-in helpers. This is a trade-off because it means that we cannot implement some of the optimizations that Gogo supports, like making message fields non-nullable, or aliasing the generated types in the generated ProtoBuf messages. These are Gogo ProtoBuf features that some Go projects have used successfuly to reduce the amount of garbage generated when handling Protocol Buffer messages, but Vitess has never opted-in into those, so it didn’t make sense for us to port them to our APIv2 generator.</p><p> 与Gogo Protobuf相比，VTProtobuf编译器会产生不同的设计选择：它不是APIV2编译器的叉子，而是一个独立的插件，它与APIV2的上游编译器一起运行，并将优化的代码作为opt-in enders一起运行。这是一个权衡，因为它意味着我们无法实现Gogo支持的一些优化，例如使消息字段不可以，或别名生成的Protobuf消息中的生成类型。这些是Gogo Protobuf功能，一些Go项目已经使用成功来减少处理协议缓冲区消息时生成的垃圾量，但Vitess从未选择过那些，因此我们对我们的APIV2港口没有意义发电机。</p><p> Instead, by focusing solely on highly optimized marshaling and unmarshaling code,  vtprotobuf can be implemented in a tiny codebase that depends only on the public and stable   google.golang.org/protobuf/compiler/protogen package from APIv2, while the original APIv2 code generator runs alongside it and generates the actual ProtoBuf messages and associated metadata for reflection.</p><p> 相反，通过专注于高度优化的元帅和解体代码，VTProtobuf可以在一个小写字母中实现，只依赖于公共和稳定的Google.golang.org/protobuf/compiler/protogen包，而原始的apiv2代码生成器伴随它并生成实际的Protobuf消息和相关元数据以进行反射。 </p><p> We believe this is a solid trade-off that will make  vtprotobuf very easy to maintain in the long run and that ensures that we’re always playing nice with any changes performed upstream, since we no longer carry our own fork.</p><p>我们相信这是一个坚实的权衡，它将使VTProtobuf从长远来看很容易维持，确保我们总是在上游进行的任何变化都很好的，因为我们不再携带自己的叉子。</p><p> The first beta version of   vtprotobuf is now publicly available : it supports optimized code generation for marshaling, unmarshaling and sizing. The resulting codegen is based on the original implementation in Gogo ProtoBuf, but it is fully adapted to ProtoBuf APIv2 messages and has received numerous micro-optimizations that make it run as fast or faster in all our benchmarks. Furthermore, we’ve also implemented a new feature which is not available in the original Gogo ProtoBuf compiler: memory pooling.</p><p> 第一个Beta版本的VTPROTOBUF现在可公开可用：它支持用于元帅，单声道和大小的优化代码。得到的Codegen基于Gogo Protobuf中的原始实现，但它完全适合Protobuf APIV2消息，并且已经接收了许多微优化，使其在所有基准中的快速或更快地运行。此外，我们还实现了一个新功能，在原始Gogo Protobuf编译器中不可用：内存池。</p><p>  There are two main reasons for the overall poor performance of Protocol Buffers in Go: the reliance on reflection for marshaling and unmarshaling, and the overhead of memory allocation.</p><p>  在GO期间的总体性能差的总体性能有两种主要原因：依赖于拼警和解体的反射，以及内存分配的开销。</p><p> The first issue with reflection is handled by  vtprotobuf by generating optimized code to perform serialization and deserialization for each specific message. The second issue is much harder to fix.</p><p> 通过生成优化的代码来处理具有反射的第一个问题，以对每个特定消息执行序列化和反序列化的序列化和反序列化。第二个问题更难解决。</p><p> Other ProtoBuf implementations, like C++, work around the memory allocation issues by using memory arenas: large memory blocks that can be used to allocate memory with a bump-pointer allocator (extremely efficient) and that can be freed all at once. This is a pattern that works beautifully in the typical request-response RPC system where Protocol Buffers are commonly used. Arenas are, however, unfeasible to implement in Go because it is a garbage collected language.</p><p> 其他protobuf实现，如c ++，通过使用内存arenas解决内存分配问题：大的内存块，可用于分配带有凸点指针分配器（非常有效）的内存，并且可以立即释放。这是一种在典型请求 - 响应RPC系统中起作用的模式，其中常用于协议缓冲区。然而，竞技场是不可行的，因为它是垃圾收集的语言。</p><p> The Gogo ProtoBuf compiler works around the issue by allowing users to opt-in into  fewer pointer fields in their generated message structs, something which reduces the overall number of allocations at the expense of ergonomics (it’s hard to tell whether nested messages are missing or not) and backwards incompatibility with upstream ProtoBuf generated messages. As explained earlier, we’ve opted  not to modify the generated message structs at all, as to not carry a whole fork of the ProtoBuf Go generator, so this is not an option for us.</p><p> Gogo Protobuf编译器通过允许用户在其生成的消息结构中选择更少的指针字段，从而减少了牺牲了人体工程学的分配数量（很难判断嵌套消息是否丢失） ）和向后兼容上游Protobuf生成的消息。如前所述，我们选择不完全修改生成的消息结构，因为不携带Protobuf的整个叉子去生成器，因此这不是我们的选择。</p><p> Hence, the next best option are memory pools for individual objects, and this is the functionality that  vtprotobuf now provides. When enabling the  pool feature in  protoc-gen-go-vtproto, we can mark individual ProtoBuf messages so they’re always allocated off a memory pool when being unmarshaled. The marked messages receive a helper method so they can be directly returned to the memory pool when they’re no longer needed, and a specialized  Reset implementation that zeros them out whilst making sure to keep as much underlying memory around as possible (e.g. in nested slices, maps and objects) so that retrieving those objects from the memory pool later on results in fewer allocations when unmarshaling.</p><p> 因此，下一个最佳选择是单个对象的内存池，这是VTPROTOBUF现在提供的功能。在Protoc-Gen-Go-Vtproto中启用池功能时，我们可以标记单个Protobuf消息，因此它们始终在单个解体后的内存池中分配。标记的消息接收辅助方法，以便在不再需要时可以直接返回到内存池，以及零零的特殊重置实现，同时确保保持尽可能多的底层内存（例如，嵌套切片，映射和对象），以便稍后从内存池中检索这些对象，导致解体时的分配较少。 </p><p> Memory pooling is far from a performance silver bullet: many ProtoBuf messages are too small to benefit from pooling at all, and some have so much nested complexity that the overhead of recursively pooling its fields defeats the optimization in the first place. Furthermore, the Go programming language provides no capabilities in its type system to safely manage these pooled objects. If not used very carefully, it’s very easy to corrupt memory and cause data races with pooled ProtoBuf messages.</p><p>内存池远离性能银弹远非：许多Protobuf消息太小，无法从池中受益，有些具有如此多的嵌套复杂性，即递归汇集其字段的开销首先击败优化。此外，Go编程语言在其类型系统中提供了无法安全地管理这些池对象的功能。如果没有非常仔细使用，它很容易损坏内存并导致带有池的Protobuf消息的数据比赛。</p><p> Despite its limitations, we have found that memory pooling is an extremely effective optimization in Vitess. When used well in APIs where it makes sense, it becomes significantly faster than the custom Gogo ProtoBuf messages without pointer fields, with average unmarshaling times for large messages being competitive with C++ arena-based unmarshaling. Let’s see a practical example now!</p><p> 尽管有其局限性，但我们发现内存池是Vitess中非常有效的优化。当在API中使用井有意义，它比没有指针字段的自定义Gogo Protobuf消息变得明显快，具有普通的Monforshing时代，对于基于C ++基于竞技场的解析，大型消息竞争。我们现在看到一个实用的例子！</p><p>  Vitess&#39; replication engine, VReplication, is one of the most RPC-heavy paths in a Vitess cluster. It is a powerful and versatile MySQL replication engine, capable of keeping copies of tables in sync between distinct Vitess keyspaces and materializing partial views of tables. Whenever we commit changes or optimizations that affect GRPC or ProtoBuf marshaling, we pay very close attention to their impact on the replication subsystem. Since the whole replication process is performed through GRPC, and in production deployments the replicated tables are often massive (terabytes), any performance regressions in this path often result in real world time increases that range between minutes and hours.</p><p>  Vitess＆＃39;复制引擎，抗匹配，是Vitess集群中最常规的重型路径之一。它是一个强大而多功能的MySQL复制引擎，能够在不同的Vitess键空间之间保持同步中的表副本，并换算表的偏见视图。每当我们提交影响GRPC或PROTOBUF编组的更改或优化时，我们都会非常关注它们对复制子系统的影响。由于整个复制过程通过GRPC执行，并且在生产部署中，复制的表通常是大规模的（terabytes），因此该路径中的任何性能回归通常会导致真实的世界时间在分钟和小时之间增加范围。</p><p> To measure the impact of ProtoBuf changes in our replication process, we’ve built a synthetic stress test that performs a full replication of a large MySQL table between two Vitess keyspaces. This is a realistic example that exercises the most expensive part of the replication process: the initial copy of all row data between the two Vitess tablets.</p><p> 为了测量Protobuf变化在复制过程中的影响，我们建立了一个合成压力测试，在两个Vitess键之间执行了一个大型MySQL表的全部复制。这是一个现实的示例，其练习复制过程的最昂贵的部分：两个Vitess片剂之间所有行数据的初始副本。</p><p> As a baseline for our performance measurements, we’re going to perform the replication using an old Vitess commit, where we were still using ProtoBuf APIv1 but without any of the Gogo ProtoBuf optimizations.</p><p> 作为我们的性能测量的基线，我们将使用旧的Vitess提交来执行复制，我们仍在使用protobuf apiv1但没有任何Gogo Protobuf优化。</p><p> The flame graph in the  destination tablet of the Vitess cluster clearly shows the source of RPC overhead:</p><p> Vitess集群目的地平板电脑中的火焰图清楚地显示了RPC开销的来源：</p><p>  The reflection-based unmarshal code is not particularly efficient, but the vast majority of time is actually spent allocating memory for the contents of the individual rows being streamed. We spend a total of  7.47 CPU seconds in unmarshaling overhead through the whole benchmark.</p><p>  基于反射的解压缩代码并不是特别有效，但绝大多数时间实际上是为正在流式传输的单个行的内容分配内存。通过整个基准测试，我们共度7.47秒在解体开销中进行了7.47秒。 </p><p> Let’s compare this to the same replication process with ProtoBuf APIv1, but using the Gogo ProtoBuf generated unmarshaling code. Since we’re only interested in the faster (un)marshal code, we don’t need to modify our  .proto files to enable the optimizations. We can simply replace the default  protoc-gen-go generator with  protoc-gen-gofast, provided by the Gogo project:</p><p>让我们将其与Protobuf APIV1进行比较相同的复制过程，但使用Gogo Protobuf生成的解码代码。由于我们只对更快（UN）铭牌代码感兴趣，因此我们不需要修改我们的.proto文件以启用优化。我们可以简单地用Gogo项目提供的Protoc-Gen-Gofast更换默认的Protoc-Go-Go Gen Gen Geacer：</p><p>  No further changes are need to enjoy the benefits of the optimization. Let’s see its impact on unmarshal overhead by running the benchmark again:</p><p>  没有进一步的变化需要享受优化的好处。让我们通过再次运行基准来看看它对解体开销的影响：</p><p>  With all the reflection-based code replaced with optimized, pre-generated unmarshaling code, we can see that the overhead of actually  parsing the ProtoBuf messages has been greatly reduced. We’re no longer calling into the  proto package, and instead we’re using the specialized  Marshal method in the  VStreamRowsResponse struct to perform the unmarshaling. Most of the CPU time is now spent in allocating memory for the row data. In total, we’re now spending  4.24 CPU seconds in unmarshal overhead.</p><p>  通过使用所有基于反射的代码替换为优化的预先生成的解码代码，我们可以看到实际解析Protobuf消息的开销已经大大减少。我们不再呼入ProTO包，而是我们在vstreamRowsResponse结构中使用专门的rsshal方法来执行解体。现在，大多数CPU时间都在分配行数据的内存中。总的来说，我们现在在解压开销中支出4.24 CPU秒。</p><p> Let’s now see what performance looks like once we’ve upgraded Vitess to ProtoBuf APIv2. We’re going to need to remove the  protoc-gen-gofast generator from Gogo ProtoBuf and replace it with the new APIv2 Generator. Also note that now the GRPC generator runs on its own, instead of being a plug-in passed to the default generator.</p><p> 我们现在看看我们升级到Protobuf APIV2后看起来像什么表现。我们需要从Gogo Protobuf中删除Protoc-Gen-Gofast发电机，并用新的APIV2发电机替换它。另请注意，现在GRPC生成器自己运行，而不是将传递传递给默认生成器。</p><p>  With the optimized Gogo code now gone, we’re expecting a performance regression. Let’s find out how bad it is in practice:</p><p>  通过现已消失的优化Gogo代码，我们期待性能回归。让我们找出实践中有多糟糕：</p><p>  Oh no! We’re back at square one. The overhead of using reflection is back, and although the new reflection-based parser in ProtoBuf APIv2 is slightly faster than the one in V1, the total overhead of unmarshaling is massive compared to our Gogo ProtoBuf unmarshaling code. We’re now spending  7.17 CPU seconds.</p><p>  不好了！我们回到了广场。使用反射的开销是回来的，尽管Protobuf APIV2中的新反射的解析器略微比V1中的一个稍慢，但与我们的Gogo Protobuf解码代码相比，解马语的总开销是大量的。我们现在花了7.17秒。</p><p> Let’s enable the optimized code generation of  vtprotobuf. We need to run the  protoc-gen-go-vtproto generator  alongside the  protoc-gen-go and  protoc-gen-go-grpc generators:</p><p> 让我们启用vtprotobuf的优化代码生成。我们需要与Protoc-Gen-Go和Protoc-Gen-Go-Grpc发电机一起运行Protoc-Gen-Go-VTProto发生器： </p><p>  It is not enough to simply generate the optimized marshaling and unmarshaling helpers for our ProtoBuf messages. We need to opt our RPC framework into using those by injecting a specific codec. The  vtprotobuf README has  instructions for different Go RPC frameworks, including GRPC.</p><p>只需为我们的protobuf消息生成优化的ressshaling和解体求助者是不够的。我们需要通过注入特定编解码器来选择我们的RPC框架。 Vtprotobuf Readme具有不同的GO RPC框架的说明，包括GRPC。</p><p> When running the benchmark again, we’re hoping to see performance very similar to Gogo ProtoBuf, but working on top of APIv2 ProtoBuf messages:</p><p> 再次运行基准时，我们希望看到与Gogo Protobuf非常相似的性能，但在APIV2 Protobuf消息的顶部工作：</p><p>  This is great. Reflection usage is now gone, and we can see how GRPC calls directly into our specialized  UnmarshalVT helpers for each ProtoBuf message. There’s still the fixed overhead of memory allocation, but we’re spending  4.15 CPU seconds in unmarshal overhead now. We’re slightly faster than with Gogo ProtoBuf, and we’re unmarshaling into forward-compatible APIv2 ProtoBuf messages.</p><p>  这很棒。反射使用现已走了，我们可以看到GRPC如何直接呼叫我们的专门用于每个Protobuf消息的助手助手。内存分配仍然存在固定的开销，但我们现在正在开销中的4.15 CPU秒。我们比Gogo Protobuf略微快，我们我们是未分校进入前向兼容的APIV2 Protobuf消息。</p><p> We could very easily stop here, since we’ve successfully upgraded Vitess to use ProtoBuf APIv2 without having a performance regression, but we want to go one step further. The  VStreamRows RPC call in the VReplication process is an ideal use case for  memory pooling.</p><p> 我们可以很容易地停止这里，因为我们已经成功地升级了Vitess来使用Protobuf APIV2而不具有性能回归，但我们希望进一步走一步。 vReplication过程中的vStreamRows RPC呼叫是内存池的理想用例。</p><p> To enable memory pooling, we add the  pool feature to our  protoc-gen-go-vtproto invocation, and specify which objects need to be memory pooled. For now, we’re just focusing on the  Row and  VStreamRowsResponse messages that are used in VReplication. To specify which messages must be pooled, we can use ProtoBuf extensions like  Gogo ProtoBuf does, but in order to keep our  .proto files free of foreign dependencies, we’ve also added the option to configure pooling directly as commandline flags.</p><p> 要启用内存池，我们将池功能添加到ProToc-Gen-Go-Vtproto调用，并指定池中需要存储的对象。目前，我们只关注vReplication中使用的行和vstreamrowsresponse消息。要指定必须池的邮件，我们可以使用像gogo protobuf等protobuf扩展，但为了保留我们的.proto文件，但我们还添加了直接配置池作为Commandline标志的选项。</p><p>  Once the pooling helpers for our messages have been generated, we must update the calling code to ensure we’re pooling the messages from the stream. For this specific  VStreamRows API, Vitess already provides a callback-based abstraction behind the stream, so fetching and returning the messages from the pool is very easy to implement, assuming that receivers of the  send(r) callback do not keep the message around – which they don’t.</p><p>  一旦生成了我们的消息的池申请人，我们必须更新调用代码以确保我们从流中汇集邮件。对于此特定的VStreamRows API，Vitess已经在流后面提供了基于回调的抽象，因此从池中获取和返回消息非常易于实现，假设发送（R）回调的接收器不会保持消息 - 他们没有。</p><p>  With these trivial changes in place, we can run our replication benchmark again and look at the overhead of unmarshaling the rows:</p><p>  通过这些微不足道的变化，我们可以再次运行我们的复制基准并查看未制作行的开销： </p><p>  No, I did not screw up when cropping the flame graph. Once we enable memory pooling for  VStreamRowsResponse objects, the unmarshaling code no longer needs to allocate memory for the underlying  Row data. We’re spending  0.63 CPU seconds in unmarshaling now, because we just keep re-using the same few  Response objects over and over again while copying rows from the source Vitess tablet.</p><p>不，当裁剪火焰图时，我没有搞砸。一旦我们为vstreamRowsResponse对象启用内存池，就不再需要为基础行数据分配内存。我们现在在解释的CPU秒中花费0.63 CPU秒，因为我们只是在从源VITESS平板电脑复制行的同时又一次地重新使用相同的响应对象。</p><p> The impact of the memory pooling optimization is clearly visible when graphed against the CPU usage of all the different ProtoBuf code generators:</p><p> 在针对所有不同Protobuf代码生成器的CPU使用情况下绘制时，内存池优化的影响清晰可见：</p><p>   Protocol Buffers performance in Go is a hard subject, which has only become much more complex with the release of the ProtoBuf APIv2 and the deprecation of Gogo ProtoBuf, the best recipe we’ve had in the past to reduce the CPU usage of the marshaling &amp; unmarshaling overhead in our RPCs.</p><p>   协议缓冲区的性能在GO中是一个艰难的主题，它只与Protobuf APIV2发布的遗传更复杂，并且Gogo Protobuf的弃用，我们过去的最佳配方，以减少Marshaling＆amp的CPU使用情况;在我们的RPCS中解开开销。</p><p> There are many open-source and proprietary Go projects that are either stuck in ProtoBuf APIv1 (because they rely on Gogo ProtoBuf) or that have upgraded to APIv2 and suffered a performance regression. We know that  vtprotobuf is not able to handle all the use cases that Gogo ProtoBuf did, but we’re hoping it’ll enable many projects to migrate to ProtBuf APIv2 without suffering a serious performance penalty, like we’ve done in Vitess, and result in a more unified and more performant Go ecosystem.</p><p> 有许多开源和专有的Go项目，可以卡在Protobuf APIV1中（因为它们依赖于Gogo Protobuf）或已升级到APIV2并遭受性能回归。我们知道VTPROTOBUF无法处理Gogo Protobuf所做的所有用例，但我们希望它能够使许多项目迁移到Protbuf APIV2而不会遭受严重的表现惩罚，就像我们在Vitess中所做的那样，并且导致更统一和更有表现的GO生态系统。</p><p> We’re actively testing the beta of  vtprotobuf in the Vitess  master branch already, and we’re hoping to ship the optimized codegen as the default for our next major Vitess release. Please feel free to try it out on your own projects and report any performance regressions or incompatibilities.</p><p> 我们已经积极测试Vitess Master分支中VTProtobuf的Beta，我们希望将优化的Codegen作为我们的下一个主要玻璃体发布的默认值运送。请随时尝试自己的项目，并报告任何性能回归或不兼容。 </p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://vitess.io/blog/2021-06-03-a-new-protobuf-generator-for-go/">https://vitess.io/blog/2021-06-03-a-new-protobuf-generator-for-go/</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/protobuf/">#protobuf</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/谷歌/">#谷歌</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy;2012-2021 diglog.com </div></div></body></html>