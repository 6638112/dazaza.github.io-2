<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>在不停机的情况下将大型Heroku Postgres实例迁移到AWS Aurora</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">在不停机的情况下将大型Heroku Postgres实例迁移到AWS Aurora</h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2020-11-13 01:01:55</div><div class="page_narrow text-break page_content"><p>In this article I discuss a general process I used recently to migrate a large multi-terabyte Heroku Postgres Database from the Heroku Platform to Amazon Aurora Postgres on a live Heroku based application architecture with near zero downtime and builtin failovers during the process. Not only did this migration save significant costs associated with running a large managed Postgres instance it also resulted in increased scalability and flexibility of parameter turing and other management abilities afforded by AWS RDS.</p><p>在本文中，我讨论了我最近使用的一个通用流程，该流程将一个大型的多TB Heroku Postgres数据库从Heroku平台迁移到基于Heroku的实时应用程序架构上的Amazon Aurora Postgres，在此过程中几乎没有宕机和内置故障转移。此迁移不仅节省了与运行大型托管Postgres实例相关的大量成本，还提高了参数图灵以及AWS RDS提供的其他管理功能的可扩展性和灵活性。</p><p>            The Heroku Postgres Migration to AWS Aurora Postgres Architecture and Process Flow diagram above shows at a high level what the Heroku Postgres Data Layer Architecture for a typical Premium Level Service with High Availability plus a Read Replica for load balancing Read heavy apps. Then on the right is the migration target goal within the AWS platform boundary annotated with the sequence of steps used to migrate the data to the end Aurora Postgres instance.</p><p>上面的Heroku Postgres迁移到AWS Aurora Postgres架构和流程流程图从较高层面展示了Heroku Postgres数据层架构对于具有高可用性的典型高级服务以及用于负载平衡读取繁重应用的读取副本的作用。然后右边是AWS平台边界内的迁移目标，标注了将数据迁移到最终Aurora Postgres实例所需的步骤序列。</p><p>  Before I get into discussing the constraints that I&#39;ve experienced and found noteworthy I would like to put forth an important disclaimer. The Heroku platform is a phenominally innovative service that has paved the way for developing countless extremely useful and profitable apps and services by lowering the barrier to entry. Many, if not most, apps will not hit the constraints that I point out below which necessitate a migration of their data layer off the platform.</p><p>在我开始讨论我所经历并发现值得注意的限制之前，我想提出一个重要的免责声明。Heroku平台是一项名义上的创新服务，通过降低进入门槛，为开发无数极其有用和有利可图的应用和服务铺平了道路。许多(如果不是大多数)应用程序不会达到我在下面指出的限制，这些限制需要将它们的数据层迁移出平台。</p><p>  Heroku can be costly, perhaps for good reasons, because they aleviate much of the sysops / devops investment and dev time costs of maintaining and scaling services like Postgres</p><p>Heroku的成本可能很高，这或许是有充分理由的，因为它们省去了维护和扩展Postgres等服务所需的大部分sysop/devop投资和开发时间成本。</p><p>  Heroku Postgres locks down the majority of the Postgres parameters that are often necessary to tune for large enterprise level, high throughput, Postgres usage</p><p>Heroku Postgres锁定了Postgres的大部分参数，这些参数通常是针对大型企业级、高吞吐量、Postgres使用情况进行调优所必需的。</p><p>  Heroku Postgres monitoring falls well short of many of the other options, particularly AWS RDS, which becomes very important for large enterprise grade applications</p><p>Heroku Postgres监控远远不及许多其他选项，尤其是AWS RDS，这对大型企业级应用程序来说变得非常重要。</p><p>  Heroku Postgres does not allow Postgres superuser or Replication User roles so migration options become limited</p><p>Heroku Postgres不允许Postgres超级用户或复制用户角色，因此迁移选项受到限制。</p><p>  Postgres pg_dump / pg_restore is not a viable option for large databases of a terabyte and up because of the amount of time it requires to run and the inheritly implies down time or data loss if used as an option with isn&#39;t possible for most applications</p><p>Postgres PG_DUMP/PG_RESTORE对于TB及以上的大型数据库来说不是一个可行的选项，因为它需要运行的时间很长，而且如果将其作为选项与ISN一起使用，则必然会导致停机或数据丢失，这对大多数应用程序来说都是不可能的</p><p>      To faciltate this discussion I&#39;ve provided a silly app that is deployable to Heroku and built using the Django web framework which simply generates random numbers and quotes scraped from the web.</p><p>为了便于讨论，我提供了一个愚蠢的应用，可以部署到Heroku上，并使用Django web框架构建，它只需生成随机数字和从网络上抓取的报价。</p><p>          which gave the following output but, note you&#39;re output will give a different app name and url</p><p>它给出了以下输出，但请注意，重新输出将给出不同的应用程序名称和url。</p><p>                        Open the app in your default browser with the following (replace -a intense-headland-79519 with your app name).</p><p>使用以下命令在默认浏览器中打开该应用程序(将-a tenent-Headland-79519替换为您的应用程序名称)。</p><p>            In the Real World for this process to work you need to request Heroku Data Support team to establish continuous WAL log shipping to an AWS S3 bucket along with a base physical backup using the  WAL-E Python based library. Rather than bothering Heroku&#39;s Data Support team for this demo and to allow readers to fully reproduce the demo I will simply mimic this step with my own AWS EC2 instance running Postgres 11 and shipping a continuous archive to my own AWS S3 bucket.</p><p>在现实世界中，要使此流程正常运行，您需要请求Heroku数据支持团队建立到AWS S3存储桶的连续Wal日志传送，以及使用基于Wal-E Python的库的基本物理备份。为了不麻烦Heroku的数据支持团队进行此演示，并允许读者完整地复制演示，我只需使用我自己的运行Postgres 11的AWS EC2实例来模拟这一步骤，并将一个连续的归档文件发送到我自己的AWS S3存储桶中。</p><p>          sudo yum update -ysudo amazon-linux-extras install epel -ysudo amazon-linux-extras install postgresql11 -ysudo yum install postgresql-server postgresql-contrib python3 lzop pv -ycurl https://bootstrap.pypa.io/get-pip.py -o get-pip.pysudo python3 get-pip.pysudo python3 -m pip install envdir wal-e[aws]</p><p>Sudo yum更新-ySudo Amazon-Linux-Extras Install Epel-ySudo Amazon-linux-额外安装postgresql11-ySudo yum安装PostgreSQL-SERVER PostgreSQL-contrib python3 lzop pv-yCurl https://bootstrap.pypa.io/get-pip.py-o get-pip.pySudo python3 get-pin.pySudo python3-m pip安装envdir wal-e[AWS]。</p><p>      $ lsblkNAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTxvda 202:0 0 8G 0 disk└─xvda1 202:1 0 8G 0 part /xvdb 202:16 0 16G 0 disk</p><p>$isblk名称：最小RM尺寸RO类型MOUNTPOINTXVDA 202：0 0 8G 0磁盘└─xvda1 202：1 0 8G 0部件/Xvdb 202：16 0 16G 0磁盘。</p><p>                            sudo mkdir -p /etc/wal-e/envsudo chown -R ec2-user:ec2-user /etc/wal-eecho &#34;INSERT-VALUE-HERE&#34; &gt; /etc/wal-e/env/AWS_ACCESS_KEY_IDecho &#34;REGION-HERE&#34; &gt; /etc/wal-e/env/AWS_REGIONecho &#34;INSERT-VALUE-HERE&#34; &gt; /etc/wal-e/env/AWS_SECRET_ACCESS_KEYecho &#34;S3-BUCKET-FOLDER-URL-HERE&#34; &gt; /etc/wal-e/env/WALE_S3_PREFIXsudo chown -R postgres:postgres /etc/wal-esudo chmod -R 755 /etc/wal-e/env</p><p>Sudo mkdir-p/etc/wale/envSudo Chown-R EC2-User：EC2-User/ETC/Wal-eECHO&#34；INSERT-VALUE-HERE&34；&gt；/etc/wal-e/env/AWS_ACCESS_KEY_IDEcho&#34；Region-此处&gt；/etc/wal-e/env/aws_RegionECHO&#34；INSERT-VALUE-HERE&34；&gt；/etc/wal-e/env/AWS_SECRET_ACCESS_KEYEcho&#34；S3-存储桶-文件夹-URL-here&#34；&gt；/etc/wal-e/env/Wale_S3_PrefixSudo Chown-R Postgres：postgres/etc/wal-eSudo chmod-R 755/etc/wal-e/env。</p><p>            listen_addresses = &#39;*&#39; or your apps specific IPwal_level = replicaarchive_mode = onarchive_command = &#39;envdir /etc/wal-e/env wal-e wal-push %p&#39;archive_timeout = 60</p><p>LISTEN_ADDRESS=&#39；*&#39；或您的应用程序特定IPWAL_LEVEL=复本ARCHIVE_MODE=ONARCHIVE_COMMAND=&#39；envdir/etc/wal-e/env wal-e wal-ush%p&#39；ARCHIVE_TIMEOUT=60</p><p>              sudo systemctl daemon-reloadsudo systemctl start postgresqlsudo systemctl status postgresqlsudo systemctl enable postgresql</p><p>Sudo system ctl后台进程-重新加载Sudo system ctl启动PostgreSQLSUDO系统控制状态PostgreSQLSudo system ctl启用PostgreSQL。</p><p>                      Replace the DATABASE_URL config variable to point to the newly spun up EC2 Postgres instance mimicing Heroku Postgres</p><p>替换DATABASE_URL配置变量以指向新启动的模仿Heroku Postgres的EC2 Postgres实例。</p><p>        At this point you&#39;ll want to register a new user and generate some more test data to migrate. You could also use pg_dump / pg_restore to transfer any existing data from Heroku Postgres to this new EC2 Postgres instance being used to mimic Heroku Postgres</p><p>此时，您将希望注册一个新用户并生成更多要迁移的测试数据。您还可以使用PG_DUMP/PG_RESTORE将任何现有数据从Heroku Postgres传输到这个用于模拟Heroku Postgres的新EC2 Postgres实例。</p><p>      As a personal preference I like to wrap potentially long running commands in shell scripts so I can explicitly echo out when things begin and end then to protect against SSH connections from timing out during potentially long running processes I use nohup with backgrounding.</p><p>作为个人偏好，我喜欢将可能长时间运行的命令包装在Shell脚本中，这样我就可以显式地回显事情开始和结束的时间，然后为了防止SSH连接在可能长时间运行的进程期间超时，我使用了带后台的nohup。</p><p>              After the push finishes I should be able to verify that the backup has been pushed with the following command.</p><p>推送完成后，我应该能够使用以下命令验证备份是否已推送。</p><p>    At this point I have an EC2 Instance with Postgres installed mimicing Heroku Postgres and continuously shipping backups and WAL to S3.</p><p>此时，我有一个安装了Postgres的EC2实例，它模仿Heroku Postgres并持续将备份和WAL传送到S3。</p><p>    In the real world this is where you will start, that is by creating your log shipped replica loaded from data in S3 in the form of a physical base backup and WAL files. The Heroku Data Support team will likely provide you with S3 creds for WAL-E in the form of Heroku config variables which you can view running the following.</p><p>在现实世界中，您将从这里开始，即以物理基础备份和WAL文件的形式创建从S3中的数据加载的日志装运副本。Heroku数据支持团队可能会以Heroku配置变量的形式为您提供Wal-E的S3证书，您可以运行以下命令查看这些变量。</p><p>    For this demo I will be using the following specs for and EC2 VPS. You will need to tailor this to your needs and budget. My suggestion is to use a EC2 instance size ideally larger than your current Heroku Postgres instance.</p><p>在本演示中，我将对和EC2 VPS使用以下规格。你需要根据你的需要和预算来调整。我的建议是使用EC2实例大小，最好比您当前的Heroku Postgres实例大。</p><p>          sudo yum update -ysudo amazon-linux-extras install epel -ysudo amazon-linux-extras install postgresql11 -ysudo yum install postgresql-server postgresql-contrib python3 lzop -ycurl https://bootstrap.pypa.io/get-pip.py -o get-pip.pysudo python3 get-pip.pysudo python3 -m pip install envdir wal-e[aws]</p><p>Sudo yum更新-ySudo Amazon-Linux-Extras Install Epel-ySudo Amazon-linux-额外安装postgresql11-ySudo yum安装PostgreSQL-服务器PostgreSQL-contrib python3 lzop-yCurl https://bootstrap.pypa.io/get-pip.py-o get-pip.pySudo python3 get-pin.pySudo python3-m pip安装envdir wal-e[AWS]。</p><p>      $ lsblkNAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTxvda 202:0 0 8G 0 disk└─xvda1 202:1 0 8G 0 part /xvdb 202:16 0 16G 0 disk</p><p>$isblk名称：最小RM尺寸RO类型MOUNTPOINTXVDA 202：0 0 8G 0磁盘└─xvda1 202：1 0 8G 0部件/Xvdb 202：16 0 16G 0磁盘。</p><p>                            Use the AWS S3 credentials provided by Heroku to create environment variables in a directory to be used by WAL-E and envdir libraries for pulling down the backup and WAL files.</p><p>使用Heroku提供的AWS S3凭证在目录中创建环境变量，wal-E和envdir库使用该环境变量来下载备份和wal文件。</p><p>  sudo mkdir -p /etc/wal-e/envsudo chown -R ec2-user:ec2-user /etc/wal-eecho &#34;INSERT-VALUE-HERE&#34; &gt; /etc/wal-e/env/AWS_ACCESS_KEY_IDecho &#34;REGION-HERE&#34; &gt; /etc/wal-e/env/AWS_REGIONecho &#34;INSERT-VALUE-HERE&#34; &gt; /etc/wal-e/env/AWS_SECRET_ACCESS_KEYecho &#34;S3-BUCKET-FOLDER-URL-HERE&#34; &gt; /etc/wal-e/env/WALE_S3_PREFIXsudo chown -R postgres:postgres /etc/wal-esudo chmod -R 755 /etc/wal-e/env</p><p>Sudo mkdir-p/etc/wale/envSudo Chown-R EC2-User：EC2-User/ETC/Wal-eECHO&#34；INSERT-VALUE-HERE&34；&gt；/etc/wal-e/env/AWS_ACCESS_KEY_IDEcho&#34；Region-此处&gt；/etc/wal-e/env/aws_RegionECHO&#34；INSERT-VALUE-HERE&34；&gt；/etc/wal-e/env/AWS_SECRET_ACCESS_KEYEcho&#34；S3-存储桶-文件夹-URL-here&#34；&gt；/etc/wal-e/env/Wale_S3_PrefixSudo Chown-R Postgres：postgres/etc/wal-eSudo chmod-R 755/etc/wal-e/env。</p><p>  Once the above environment variable files have been created it is helpful to test WAL-E by listing the available backups with the following command.</p><p>一旦创建了上述环境变量文件，通过使用以下命令列出可用的备份来测试WAL-E是很有帮助的。</p><p>      I use the following bash script named wal-e-fetch-backup.sh to wrap the WAL-E call to pull the base backup from S3 because it enables me to track how long it takes and utilize nohup to guard against an SSH connection timeout.</p><p>我使用以下名为wal-e-fetch-backup.sh的bash脚本包装wal-E调用，以便从S3提取基本备份，因为它使我能够跟踪需要多长时间，并利用nohup防止SSH连接超时。</p><p>  #!/bin/bashecho &#34;starting wal-e backup-fetch&#34;started=`date +%s`envdir /etc/wal-e/env wal-e backup-fetch --blind-restore /database LATESTended=`date +%s`duration=$((ended - started))echo &#34;wal-e backup-fetch completed after $duration seconds&#34;</p><p>#！/bin/bashEcho&#34；正在启动Wal-e Backup-Fetch&#34；开始日期=`日期+%s`Envdir/etc/wal-e/env wal-e备份-获取--盲恢复/数据库最新结束=`日期+%s`持续时间=$((结束-开始))Echo&#34；Wal-e备份-回迁在$Duration秒&#34；之后完成。</p><p>        There are a few config settings that need updated in order to faciliate this replica to be used as a source for Streaming Replication to a failover EC2 Postgres instance as well as be a source for Logical Replication to Aurora Postgres.</p><p>需要更新一些配置设置，以便将此副本用作到故障转移EC2 Postgres实例的流复制的源，以及用作到Aurora Postgres的逻辑复制的源。</p><p>  listen_address = &#39;*&#39;hot_standby = ondata_directory = &#39;/database&#39;wal_level = logicalmax_wal_senders = 10max_replication_slots = 10wal_keep_segments=1000wal_sender_timeout=60</p><p>LISTEN_ADDRESS=&#39；*&#39；HOT_STANDBY=ONDATA_DIRECTORY=&#39；/DATABASE&#39；WAL_LEVEL=逻辑MAX_WAL_SENDERS=10最大复制插槽数=10WAL_KEEP_SECTIONS=1000WAL_SENDER_TIMEOUT=60。</p><p>    In order to allow the app user, pguser, to connect to the EC2 Postgres Log Shipped Replica as well as the postgres user to connect from the Streamed Replica I must enable md5 password authentication for pguser and trusted auth for the postgres user from the EC2 Streamed Replica&#39;s IP address. The trusted auth for the postgres user from the failover Streamed Replica is necessary because Heroku will not have a replication user with a password you can connect with and ideally you want the Streamed Replica available immediately upon promoting the Log Shipped Replica.</p><p>为了允许应用程序用户pguser连接到EC2 Postgres日志发送副本，以及postgres用户从流副本连接，我必须从EC2流副本的IP地址为pguser启用MD5密码身份验证，为postgres用户启用可信身份验证。来自故障转移流副本的postgres用户的受信任身份验证是必要的，因为Heroku没有可以连接的密码的复制用户，理想情况下，您希望流副本在升级日志传送副本后立即可用。</p><p>  Additionally, I also add another password based auth entry for the Aurora rds_replication user that will be used to perform Logical Replication.</p><p>此外，我还为Aurora rds_Replication用户添加了另一个基于密码的身份验证条目，该条目将用于执行逻辑复制。</p><p>  # &#34;local&#34; is for Unix domain socket connections onlylocal all all trust# IPv4 local connections:host pgdb pguser 0.0.0.0/0 md5host all rds_replication 0.0.0.0/0 md5host all postgres IP-ADDRESS-HERE/32 trusthost all all 127.0.0.1/32 trust# IPv6 local connections:host all all ::1/128 trust# Allow replication connections from localhost, by a user with the# replication privilege.host replication postgres IP-ADDRESS-HERE/32 trusthost replication rds_replication 0.0.0.0/0 md5local replication all trusthost replication all 127.0.0.1/32 trusthost replication all ::1/128 trust</p><p>#&#34；本地&#34；仅适用于Unix域套接字连接本地所有信任#IPv4本地连接：主机pgdb pguser 0.0.0.0/0 md5托管所有rds_Replication 0.0.0.0/0 MD5托管所有Postgres IP地址-此处/32信任托管所有127.0.0.1/32信任#IPv6本地连接：托管所有：：1/128信任#允许从本地主机复制连接，由具有#复制权限。主机复制Postgres IP地址-此处/32信任主机复制rds_Replication 0.0.0.0/0 MD5本地复制所有信任主机复制所有127.0.0.1/32信任主机复制全部：：1/128信任。</p><p>    The recovery.conf file specifies that the WAL-E program should be used to pull WAL files from S3 and continuously restore them to the latest recovery timeline.</p><p>Recovery.conf文件指定应使用WAL-E程序从S3提取WAL文件，并将其持续恢复到最新的恢复时间表。</p><p>      To manage the postgresql install I use a systemd service file at /etc/systemd/system/postgresql.service with a PGDATA environment variable indicating the database cluster to be managed is in the /database directory.</p><p>要管理PostgreSQL安装，我使用了一个位于/etc/systemd/system/postgresql.service的systemd服务文件和一个PGDATA环境变量，该变量指示要管理的数据库集群位于/database目录中。</p><p>      sudo systemctl daemon-reloadsudo systemctl start postgresqlsudo systemctl status postgresqlsudo systemctl enable postgresql</p><p>Sudo system ctl后台进程-重新加载Sudo system ctl启动PostgreSQLSUDO系统控制状态PostgreSQLSudo system ctl启用PostgreSQL。</p><p>  After starting the postgresql service you will be able to see WAL files being pulled in and restored by watching the Postgresql logs.</p><p>启动PostgreSQL服务后，通过查看PostgreSQL日志，您将能够看到WAL文件被拉入和恢复。</p><p>      As mentioned previously, I felt it would be a good idea to have an immediately available WAL Streamed Replica as a Hot Standby to failover in the event the promoted Log Shipped Replica fails to gaurentee the application remains viable during the migration. Of course, should that happen the Logical Replication to Aurora would need restarted from using the WAL Streamed Replica as a source.</p><p>如前所述，我觉得让立即可用的WAL流副本作为热备份是一个好主意，以便在升级的日志传送副本无法确保应用程序在迁移期间保持可用时进行故障切换。当然，如果发生这种情况，需要使用Wal流副本作为源重新启动到Aurora的逻辑复制。</p><p>  The infrastructure for this EC2 Instance should be the same as that used for the EC2 Log Streamed Replica.</p><p>此EC2实例的基础架构应与EC2日志流副本使用的基础架构相同。</p><p>        sudo yum update -ysudo amazon-linux-extras install epel -ysudo amazon-linux-extras install postgresql11 -ysudo yum install postgresql-server postgresql-contrib python3 lzop pv -ycurl https://bootstrap.pypa.io/get-pip.py -o get-pip.pysudo python3 get-pip.pysudo python3 -m pip install envdir wal-e[aws]</p><p>Sudo yum更新-ySudo Amazon-Linux-Extras Install Epel-ySudo Amazon-linux-额外安装postgresql11-ySudo yum安装PostgreSQL-SERVER PostgreSQL-contrib python3 lzop pv-yCurl https://bootstrap.pypa.io/get-pip.py-o get-pip.pySudo python3 get-pin.pySudo python3-m pip安装envdir wal-e[AWS]。</p><p>      $ lsblkNAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTxvda 202:0 0 8G 0 disk└─xvda1 202:1 0 8G 0 part /xvdb 202:16 0 16G 0 disk</p><p>$isblk名称：最小RM尺寸RO类型MOUNTPOINTXVDA 202：0 0 8G 0磁盘└─xvda1 202：1 0 8G 0部件/Xvdb 202：16 0 16G 0磁盘。</p><p>                            In order to replicate the database cluster for this Streaming Replica I use the pg_basebackup utility that comes with the install of Postgres 11 by directly connecting to the Log Streamed Replica. Similar to other commands I wrap this call to pg_basebackup in a shell script named physical_backup.sh shown below.</p><p>为了复制这个流副本的数据库集群，我使用了Postgres 11安装附带的pg_base备份实用程序，方法是直接连接到日志流副本。与其他命令类似，我将这个对pg_base备份的调用包装在名为Physical_backup.sh的Shell脚本中，如下所示。</p><p>  #!/bin/bashecho &#34;starting physical backup&#34;started=`date +%s`pg_basebackup -h IP-ADDRESS-HERE -D /database --progress --verboseended=`date +%s`duration=$((ended - started))echo &#34;physical backup completed after $duration seconds&#34;</p><p>#！/bin/bashECHO&#34；开始物理备份&#34；开始日期=`日期+%s`Pg_base备份-h IP地址-此处-D/数据库--进度--详细结束=`日期+%s`持续时间=$((结束-开始))ECHO&#34；物理备份在$DATION秒&#34；之后完成。</p><p>  Then run it with nohup as a background process to guard against an SSH connection timeout since this may potentially execute for an extended period of time.</p><p>然后使用nohup将其作为后台进程运行，以防止SSH连接超时，因为这可能会执行一段较长的时间。</p><p>      Can either reuse the restored postgresql.conf file that got pulled over from the Log Shipped Replica in the last step for pull the default one by just initializing the default Postgresql directory.</p><p>只需初始化默认PostgreSQL目录，即可重复使用在上一步中从Log Shipping复制副本拉回的恢复的postgresql.conf文件，以拉入默认的Postgresql.conf文件。</p><p>      Again, its important to at least make sure that the app user, pguser in this demo, can connect via password auth in case you have to fail over to this instance.</p><p>同样，重要的是至少要确保应用程序用户(在此演示中为pguser)可以通过密码auth进行连接，以防您必须故障转移到此实例。</p><p>      This recovery.conf file is different from the one used in the Log Shipped Replica because it tells Postgres to directly connect to the Log Shipped Replica to suck in WAL transactions opposed to reading them from a shared storage device such as S3 or similar.</p><p>此Recovery.conf文件与Log Shipping复制副本中使用的文件不同，因为它告诉Postgres直接连接到Log Shipping复制副本以吸收WAL事务，而不是从共享存储设备(如S3或类似设备)读取它们。</p><p>      Just like the Log Shipped Replica I again use an identical systemd postgresql service file to manage the service.</p><p>就像Log Shift副本一样，我再次使用相同的systemd PostgreSQL服务文件来管理该服务。</p><p>      sudo systemctl daemon-reloadsudo systemctl start postgresqlsudo systemctl status postgresqlsudo systemctl enable postgresql</p><p>Sudo system ctl后台进程-重新加载Sudo system ctl启动PostgreSQLSUDO系统控制状态PostgreSQLSudo system ctl启用PostgreSQL。</p><p>  Remember, you can check the Postgresql logs to verify WAL is being retrieved from the Log Shipped Replica.</p><p>请记住，您可以检查PostgreSQL日志，以验证是否正在从Log Shipping副本中检索WAL。</p><p>      Alright, at this stage of the journey the EC2 Postgres Log Shipped Read Only Replica is promoted allowing it to start receiving writes as well as reads and the Heroku app&#39;s database is switched to the newly promoted EC2 Postgres. This is the first, or intermediate, database switch necessary to get the Heroku app off Heroku Postgres. Switching the primary database to the EC2 Postgres instance is necessary so that the EC2 Postgres instance can be used for logical replication to Aurora Postgres via Logical Replication and the Publisher / Subscriber paradigm that comes along with it but, a publication cannot be created on a Read Only (aka Hot Standby) Replica so it must be promoted to a Primary database and capture the new writes from the Heroku app during this phase of Logical Replication to Aurora Postgres.</p><p>好的，在旅途的这个阶段，EC2 Postgres Log发运的只读副本被升级，允许它开始接收写入和读取，Heroku应用程序的数据库切换到新升级的EC2 Postgres。这是从Heroku Postgres上获取Heroku应用程序所需的第一个或中间数据库切换。有必要将主数据库切换到EC2 Postgres实例，以便EC2 Postgres实例可以用于通过逻辑复制和随之而来的发布者/订阅者范例向Aurora Postgres进行逻辑复制，但是不能在只读(也称为热备份)副本上创建发布，因此必须将其提升为主数据库，并在此阶段从Heroku应用程序捕获到Aurora Postgres的新写入。</p><p>  Procedure for Establishing the Promoting the EC2 Postgres Log Shipped Replica and Switching Heroku&#39;s App DB</p><p>建立升级EC2 Postgres日志发运副本和切换Heroku的应用数据库的步骤。</p><p>      2) Promote the EC2 Postgres Log Shipped Replica  * this is ran on the EC2 VPS</p><p>2)升级EC2 Postgres日志发运副本*这在EC2 VPS上运行</p><p>    3) Flip the Database URL on the App via Environment Variable  To repoint the App to the newly promoted database I used a completely separate environment variable named `AURORA_MASTER_DATABASE_URL` and in the code where the database connection is established I simply check for the existance of this variable and selectively connect using it over the standard Heroku DATABASE_URL variable.</p><p>3)通过环境变量翻转App上的Database URL将App重定向到新升级的数据库我使用了一个完全独立的环境变量，名为`AURORA_MASTER_DATABASE_URL`，在建立数据库连接的代码中，我只需检查该变量是否存在，并通过标准Heroku DATABASE_URL变量有选择地使用它进行连接。</p><p>  For example, in my demo app for this article, which again is Django, the looks like this.</p><p>例如，在本文的演示应用程序(也是Django)中，看起来是这样的。</p><p>    The specific commands for setting the Heroku environment variable is shown below (again this is ran locally). You&#39;ll also notice that I do an explicit restart of the Dyno&#39;s after setting the environment variable which is a good idea to ensure that every dyno restarts and gets the environment variable update.</p><p>设置Heroku环境变量的具体命令如下所示(同样是在本地运行)。您还会注意到，我在设置环境变量后显式重新启动Dyno，这是确保每个dyno重新启动并获得环境变量更新的好主意。</p><p>        Ok at this point the Heroku app is no longer utilizing the Heroku Postgres Database service and is fully on the AWS Platform but, the end goal is to be back on a Managed Database Service which is Aurora Postgres. Of cource, if your end goal is simply to migrate to an EC2 Instance running Postgres then you could stop here.</p><p>好的，目前Heroku应用程序不再使用Heroku Postgres数据库服务，完全基于AWS平台，但最终目标是重新使用托管数据库服务，即Aurora Postgres。当然，如果您的最终目标只是迁移到运行Postgres的EC2实例，那么您可以到此为止。</p><p>    Ok at this point Logical Replication needs to be setup to utilize Publications (aka Replication Slots) on the newly Promoted EC2 Postgres instance along with Subscriptions on the Aurora Postgres RDS Service.</p><p>好的，此时需要设置逻辑复制以利用新升级的EC2 Postgres实例上的发布(也称为复制插槽)以及Aurora Postgres RDS服务上的订阅。</p><p>      A user, which already exists on the Aurora instance, named rds_replication needs to be created on the EC2 Postgres instance that is now serving as the Master which will be used to connect to via the Aurora instance to execute Logical Replication via the pub/sub replication slot that will be created shortly.</p><p>需要在现在充当Master的EC2 Postgres实例上创建名为rds_Replication的用户，该用户已存在于Aurora实例上，该实例将用于通过Aurora实例连接到该实例，以通过即将创建的发布/订阅复制插槽执行逻辑复制。</p><p>            Once the subscription is created Aurora will connect to the EC2 Postgres instance and Logical Replication will commence. The Logical Replication will transpire in two phases: (i) an initial table synchronization occurs as a transaction wrapped COPY statement to pull over the tables current data then (ii) change data capture occurs whereby on going writes are propagated to the subscriber of the Logical Replication.</p><p>创建订阅后，Aurora将连接到EC2 Postgres实例，并开始逻辑复制。逻辑复制将分两个阶段进行：(I)初始表同步作为事务包装复制语句发生，以拉出表的当前数据，然后(Ii)发生改变数据捕获，由此在进行中的写入被传播到逻辑复制的订阅者。</p><p>    If you are migrating a large amount of data you will want to increase the max_sync_workers_per_subscription parameter of the Aurora Cluster Parameter group along with the max_worker_processes and max_logical_replication_workers. See the  Postgres docs for more details.</p><p>如果要迁移大量数据，则需要增加Aurora群集参数组的max_sync_Worker_per_SUBSCRIPTION参数以及max_Worker_Processing和max_logic_Replication_Worker参数。有关详细信息，请参阅Postgres文档。</p><p>  Logical Replication also does not replicate Sequences which typically back primary keys. This can be mitigated by updating the start values for each sequence immediately after turning off Logical Replication and before the final Heroku App is switched to Aurora.</p><p>逻辑复制也不复制通常支持主键的序列。这可以通过在关闭逻辑复制之后、最终Heroku应用程序切换到Aurora之前立即更新每个序列的起始值来缓解。</p><p>  The initial table synchronization step may fail one or more times for very large tables (10s to 100s of millions of rows) but, it will automatically restart and in my experience they have always succeeded.</p><p>对于非常大的表(10到100行数百万行)，初始表同步步骤可能会失败一次或多次，但它会自动重新启动，根据我的经验，它们总是成功的。</p><p>    Ok, moving on to the home stretch, in this section you wait until the replication is fully synchronized and replication lag is minimized to an acceptable level (ideally zero) then kill the subscription, update the sequences, and switch the Heroku app to Aurora Postgres.</p><p>好的，接下来进入最后阶段，在这一部分中，您将等待复制完全同步，复制延迟降至可接受的水平(理想情况下为零)，然后终止订阅，更新序列，并将Heroku应用程序切换到Aurora Postgres。</p><p>      Postgres provides a view named  pg_stat_replication which provides useful information on the state of on going replication whereby one row is dedicated to each replication event. In this demo example there are two entries in the table (i) one for the Streaming Replica and (ii) another for the Logical Replication to Aurroa. Probably the most important rows fields of this view are write_lag, flush_lag, and replay_lag which show the amount of time in which replication is falling behind. The ideal values for these fields are null which mean there is no lag.</p><p>Postgres提供了一个名为PG_STAT_REPLICATION的视图，该视图提供有关正在进行的复制状态的有用信息，其中一行专用于每个复制事件。在此演示示例中，表中有两个条目(I)一个用于流副本，(Ii)另一个用于向Aurroa的逻辑复制。该视图中最重要的行字段可能是WRITE_LAG、FLUSH_LAG和REPLAY_LAG，它们显示复制落后的时间量。这些字段的理想值为空，这意味着没有延迟。</p><p>  So on the Master EC2 Postgres server you can query this table to evaluate the progress.</p><p>因此，在Master EC2 Postgres服务器上，您可以查询该表来评估进度。</p><p>    You should also check the postgresql log from Aurora in CloudWatch and make sure all the tables finish their initial synchronization phase.</p><p>您还应该在CloudWatch中检查来自Aurora的PostgreSQL日志，并确保所有表都完成了初始同步阶段。</p><p>              As I mentioned previously Logical Replication does not properly migrate sequences so if a new record were to be attempted to be inserted into one of the tables on Aurora a collision error will occur because all the primary key values will be starting at 1 even though table data already exists. I alleviate this problem by using a SQL function to query each primary key&#39;s tables (that utilize a sequence) to find the max primary key value and restart the sequence value to that max value plus some offset.</p><p>正如我前面提到的，逻辑复制不会正确迁移序列，因此如果尝试将新记录插入Aurora上的某个表中，则会发生冲突错误，因为即使表数据已经存在，所有主键值都将从1开始。我通过使用SQL函数查询每个主键的表(利用序列)来找到最大主键值，并重新启动序列值，使其达到最大值加上一定的偏移量，从而缓解了这个问题。</p><p>  For this demo app I have the following SQL script named alter_sequences.sql which accomplishes just that.</p><p>对于这个演示应用程序，我有一个名为Alter_Sequences.sql的SQL脚本，它可以实现这一点。</p><p>  CREATE OR REPLACE FUNCTION alter_sequence(seq TEXT, select_sql TEXT) RETURNS void LANGUAGE plpgsql PARALLEL UNSAFE AS $$DECLARE max_pk INTEGER; new_seq_id INTEGER; seq_id_offset INTEGER := 9000;BEGIN EXECUTE select_sql INTO max_pk; new_seq_id = max_pk + seq_id_offset; RAISE NOTICE &#39;Max PK=% and new Seq Val=% from SQL=%&#39;, max_pk, new_seq_id, select_sql; PERFORM setval(seq, new_seq_id);END; $$;BEGIN;SELECT alter_sequence(&#39;public.auth_group_id_seq&#39;, &#39;SELECT MAX(id) FROM public.auth_group&#39;);SELECT alter_sequence(&#39;public.auth_group_permissions_id_seq&#39;, &#39;SELECT MAX(id) FROM public.auth_group_permissions&#39;);SELECT alter_sequence(&#39;public.auth_permission_id_seq&#39;, &#39;SELECT MAX(id) FROM public.auth_permission&#39;);SELECT alter_sequence(&#39;public.auth_user_groups_id_seq&#39;, &#39;SELECT MAX(id) FROM public.auth_user_groups&#39;);SELECT alter_sequence(&#39;public.auth_user_id_seq&#39;, &#39;SELECT MAX(id) FROM public.auth_user&#39;);SELECT alter_sequence(&#39;public.auth_user_user_permissions_id_seq&#39;, &#39;SELECT MAX(id) FROM public.auth_user_user_permissions&#39;);SELECT alter_sequence(&#39;public.core_randonumba_id_seq&#39;, &#39;SELECT MAX(id) FROM public.core_randonumba&#39;);SELECT alter_sequence(&#39;public.django_admin_log_id_seq&#39;, &#39;SELECT MAX(id) FROM public.django_admin_log&#39;);SELECT alter_sequence(&#39;public.django_content_type_id_seq&#39;, &#39;SELECT MAX(id) FROM public.django_content_</p><p>CREATE OR REPLACE函数ALTER_SEQUENCE(seq text，SELECT_SQL text)返回void语言plpgsql并行不安全作为$$申报MAX_PK整数；New_seq_id整数；SEQ_ID_OFFSET整数：=9000；开始执行SELECT_SQL INTO max_pk；New_seq_id=max_pk+seq_id_offset；从SQL=%&#39；，max_pk，new_seq_id，select_sql；提出通知&#39；最大主键=%，新序号=%，新序号=%执行setval(seq，new_seq_id)；结束；$$；开始；SELECT alter_sequence(&#39；public.auth_group_id_seq&#39；，&#39；SELECT MAX(Id)from Public。auth_group&#39；)；SELECT alter_sequence(&#39；public.auth_group_permissions_id_seq&#39；，&#39；SELECT MAX(Id)from Public。auth_group_permises&#39；)；选择alter_sequence(&#39；public.auth_permission_id_seq&#39；，&#39；从Public中选择Max(Id)。auth_permission&#39；)；SELECT alter_sequence(&#39；public.auth_user_groups_id_seq&#39；，&#39；SELECT MAX(Id)from Public。auth_User_Groups&#39；)；SELECT alter_sequence(&#39；public.auth_user_id_seq&#39；，&#39；SELECT MAX(Id)from Public。auth_user&#39；)；选择ALTER_SEQUENCE(&#39；Public.auth_user_user_permissions_id_seq&#39；，&#39；从发布中选择MAX(Id)。auth_user_user_permises&#39；)；SELECT alter_sequence(&#39；public.core_randonumba_id_seq&#39；，&#39；从公共核心选择MAX(Id)。core_randonumba&#39；)；选择alter_sequence(&#39；public.django_admin_log_id_seq&#39；，&#39；从Public中选择Max(Id)。django_admin_log&#39；)；从alter_sequence(&#39；public.django_content_type_id_seq&#39；，中选择最大(Id)。django_Content_。</p><p>......</p><p>.</p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://thecodinginterface.com/blog/heroku-postgres-migration-to-aurora/">https://thecodinginterface.com/blog/heroku-postgres-migration-to-aurora/</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/停机/">#停机</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/large/">#large</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/postgres/">#postgres</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/美国/">#美国</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/谷歌/">#谷歌</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/linux/">#linux</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/程序/">#程序</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy; 2020 diglog.com </div></div></body></html>