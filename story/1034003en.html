<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>结构化并发</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">结构化并发</h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2020-11-09 17:38:08</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2020/11/c69e448af5523c385129a6f111544fe3.jpg"><img src="http://img2.diglog.com/img/2020/11/c69e448af5523c385129a6f111544fe3.jpg" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>TL;DR:  “Structured concurrency” refers to a way to structure async computations so that child operations are guaranteed to complete before their parents, just the way a function is guaranteed to complete before its caller. This sounds simple and boring, but in C++ it’s anything but. Structured concurrency — most notably, C++20 coroutines — has profound implications for the correctness and the simplicity of async architecture. It brings the  Modern C++ style to our async programs by making async lifetimes correspond to ordinary C++ lexical scopes, eliminating the need for reference counting to manage object lifetime.</p><p>TL；DR：“结构化并发”指的是一种构建异步计算结构的方法，如此一来，子操作保证在父操作之前完成，就像函数保证在调用者之前完成一样。这听起来简单乏味，但在C++中却并非如此。结构化并发--最引人注目的是C++20协程--对异步架构的正确性和简单性有着深远的影响。它为我们的异步程序带来了现代C++风格，使异步生命周期与普通的C++词法作用域相对应，不再需要引用计数来管理对象生命周期。</p><p>  Back in the 1950’s, the nascent computing industry discovered structured programming: that high-level programming languages with lexical scopes, control structures, and subroutines resulted in programs that were far easier to read, write, and maintain than programming at the assembly level with test-and-jump instructions and  goto. The advance was such a quantum leap that nobody talks about structured programming anymore; it’s just “programming”.</p><p>早在20世纪50年代，新生的计算机业就发现了结构化编程：具有词法作用域、控制结构和子例程的高级编程语言产生的程序比使用测试跳转指令和GOTO的汇编级编程更易于阅读、编写和维护。这一进步是一个巨大的飞跃，以至于没有人再谈论结构化编程；它只是一种“编程”。</p><p> C++, more so than any other language, leverages structured programming to the hilt. The semantics of object lifetime mirror — and are tied to — the strict nesting of scopes; i.e., the  structure of your code. Function activations nest, scopes nest, and object lifetimes nest. Objects’ lifetimes end with a scope’s closing curly brace, and objects are destroyed in the reverse order of their construction to preserve the strict nesting.</p><p>与任何其他语言相比，C++更充分地利用了结构化编程。对象生存期的语义反映了作用域的严格嵌套，也就是代码的结构。函数激活嵌套、作用域嵌套和对象生存期嵌套。对象的生命周期以作用域的右大括号结束，并且对象以与其构造相反的顺序被销毁，以保持严格的嵌套。</p><p> The Modern C++ programming style is built on this structured foundation. Objects have  value semantics — they behave like the ints — and resources are cleaned up in destructors deterministically, which guarantees structurally that resources aren’t used after their lifetimes have ended. This is  very important.</p><p>现代C++编程风格就是建立在这种结构化的基础上的。对象具有值语义-它们的行为类似于int-并且资源在析构函数中被确定性地清理，这从结构上保证了资源在其生命周期结束后不会被使用。这是非常重要的。</p><p> When we abandon this strict nesting of scopes and lifetimes — say, when we reference count an object on the heap, or when we use the singleton pattern — we are fighting against the strengths of the language rather than working with them.</p><p>当我们放弃这种严格的作用域和生存期嵌套时-例如，当我们引用堆上的对象计数时，或者当我们使用单例模式时-我们是在与语言的优势抗争，而不是与它们合作。</p><p>  Writing correct programs in the presence of concurrency is far more difficult than in single-threaded code. There are lots of reasons for this. One reason is that threads, like singletons and dynamically allocated objects, scoff at your puny nested scopes. Although you can use the Modern C++ style  within a thread, when logic and lifetimes are scattered across threads, the hierarchical structure of your program is lost. The tools we use to manage complexity in single-threaded code — in particular, nested lifetimes tied to nested scopes — simply don’t translate to async code.</p><p>在并发性存在的情况下编写正确的程序要比在单线程代码中困难得多。造成这种情况的原因有很多。原因之一是线程，就像单例和动态分配的对象一样，嘲笑你的微不足道的嵌套作用域。虽然您可以在线程中使用现代C++风格，但当逻辑和生命周期分散在线程之间时，程序的层次结构就会丢失。我们用来管理单线程代码复杂性的工具--特别是绑定到嵌套作用域的嵌套生命周期--根本不能转换为异步代码。</p><p> To see what I mean, let’s look at what happens when we take a simple synchronous function and make it asynchronous.</p><p>为了理解我的意思，让我们看看当我们采用一个简单的同步函数并将其设为异步函数时会发生什么。</p><p>  doThing() is simple enough. It declares some local state, calls a helper, then returns some result. Now imagine that we want to make both functions async, maybe because they take too long. No problem, let’s use Boost futures, which support continuation chaining:</p><p>Dothing()非常简单。它声明一些本地州，调用帮助器，然后返回一些结果。现在想象一下，我们想要使这两个函数同步，可能是因为它们花费的时间太长。没问题，让我们使用Boost Futures，它支持延续链接：</p><p> boost::future&lt;void&gt; computeResult(State &amp; s);boost::future&lt;int&gt; doThing() { State s; auto fut = computeResult(s); return fut.then( [&amp;](auto&amp;&amp;) { return s.result; }); // OOPS}</p><p>Boost：：Future&lt；void&gt；ComputeResult(State&amp；s)；Boost：：Future&lt；int&gt；dothing(){State s；Auto Fut=ComputeResult(S)；Return Fut.Then([&amp；](AUTO&amp；&amp；){return s.Result；})；//oops}。</p><p> If you’ve programmed with futures before, you’re probably screaming,  “Nooooo!” The  .then() on the last line queues up some work to run after  computeResult() completes.  doThing() then returns the resulting future. The trouble is, when  doThing() returns, the lifetime of the  State object ends,  and the continuation is still referencing it. That is now a dangling reference, and will likely cause a crash.</p><p>如果你以前用期货编程，你可能会尖叫，“不！”最后一行上的.Then()将一些工作排入队列，以便在culteResult()完成后运行。Dothing()然后返回结果的未来。问题是，当dothing()返回时，State对象的生命周期结束，而Continue仍在引用它。这现在是一个悬而未决的参考，很可能会导致崩盘。</p><p> What has gone wrong? Futures let us compute with results that aren’t available yet, and the Boost flavor lets us chain continuations. But the continuation is a separate function with a separate scope. We often need to share data across those separate scopes. No more tidy nested scopes, no more nested lifetimes. We have to manage the lifetime of the state manually, something like this:</p><p>哪里出了问题？期货让我们可以计算出目前还不能得到的结果，Boost风格让我们可以链接延续。但Continue是一个单独的函数，具有单独的作用域。我们经常需要在这些独立的作用域之间共享数据。不再有整洁的嵌套作用域，不再有嵌套的生存期。我们必须手动管理状态的生命周期，如下所示：</p><p> boost::future&lt;void&gt;computeResult(shared_ptr&lt;State&gt; s); // addref // the stateboost::future&lt;int&gt; doThing() { auto s = std::make_shared&lt;State&gt;(); auto fut = computeResult(s); return fut.then( [s](auto&amp;&amp;) { return s.result; }); // addref // the state}</p><p>Boost：：future&lt；void&gt；computeResult(shared_ptr&lt；State&gt；s)；//addref//状态Boost：：Future&lt；int&gt；dothing(){AUTO s=std：：Make_Shared&lt；State&gt；()；AUTO FUT=ComputeResult；Return Fut.Then([s](AUTO&amp；&amp；){Return s.Result；})；//addref//状态}。</p><p> Since both async operations refer to the state, they both need to share responsibility to keep it alive.</p><p>由于这两个异步操作都涉及状态，因此它们都需要分担责任来保持状态。</p><p> Another way to think about this is:  what is the lifetime of this asynchronous computation? It starts when  doThing() is called, but it doesn’t end until the continuation — the lambda passed to  future.then() — returns.  There is no lexical scope that corresponds to that lifetime. And that is the source of our woes.</p><p>思考这个问题的另一种方式是：这种异步计算的生命周期是多少？它在调用dothing()时开始，但直到延续(传递给Future的lambda)返回时才结束。没有与该生命周期相对应的词汇作用域。这就是我们悲哀的根源。</p><p>  The story gets more complicated yet when we consider executors. Executors are handles to executions contexts that let you schedule work onto, say, a thread or thread pool. Many codebases have some notion of an executor, and some let you schedule things with a delay or with some other policy. This lets us do cool things, like move a computation from an IO thread pool to a CPU thread pool, or retry an async operation with a delay. Handy, but like  goto it is a very low-level control structure that tends to obfuscate rather than clarify.</p><p>当我们考虑遗嘱执行者时，故事就变得更加复杂了。Executor是执行上下文的句柄，它允许您在线程或线程池上调度工作。许多代码库都有一些执行者的概念，有些代码库允许您用延迟或其他策略来安排事情。这让我们可以做一些很酷的事情，比如将计算从IO线程池转移到CPU线程池，或者延迟重试异步操作。很方便，但就像Goto一样，它是一个非常低级的控制结构，容易混淆而不是澄清。</p><p> For instance, I recently came across an algorithm that uses executors and callbacks (called Listeners here) that retries the async allocation of some resource. Below is a greatly abridged version. It is described after the break.</p><p>例如，我最近遇到了一种算法，它使用执行器和回调(这里称为侦听器)来重试某些资源的异步分配。下面是一个大大删节的版本。这是在休息后描述的。</p><p> // This is a continuation that gets invoked when// the async operation completes:struct Manager::Listener : ListenerInterface { shared_ptr&lt;Manager&gt; manager_; executor executor_; size_t retriesCount_; void onSucceeded() override { /* ...yay, allocation succeeded... */ } void onFailed() override { // When the allocation fails, post a retry // to the executor with a delay auto alloc = [manager = manager_]() { manager-&gt;allocate(); }; // Run &#34;alloc&#34; at some point in the future: executor_.execute_after( alloc, 10ms * (1 &lt;&lt; retriesCount_)); }};// Try asynchronously allocating some resource// with the above class as a continuationvoid Manager::allocate() { // Have we already tried too many times? if (retriesCount_ &gt; kMaxRetries) { /* ...notify any observers that we failed */ return; } // Try once more: ++retriesCount_; allocator_.doAllocate( make_shared&lt;Listener&gt;( shared_from_this(), executor_, retriesCount_));}</p><p>//这是一个在//异步操作完成时调用的延续：struct Manager：：Listener：ListenerInterface{Shared_PTR&lt；Manager&gt；Manager_；Executor Executor_；Size_t RetriesCount_；void onSuccemon()Override{/*...yay，分配成功...。*/}void onFailed()Override{//当分配失败时，向执行器发送重试//并延迟自动分配=[MANAGER=MANAGER_](){MANAGER-&&gt;；ALLOCATE()；}；//在将来的某个时候运行：EXECUTOR_.EXECUTE_AFTER(ALLOC，10ms*(1&lt；&lt；RetriesCount_))；}}；//尝试异步分配某些资源//将上面的类作为Continuationvoid Manager：：Allocate(){//我们是否已经尝试了太多次？If(RetriesCount_&gt；kMaxRetries){/*...通知任何观察者我们失败了*/return；}//重试：++RetriesCount_；allocator_.doAllocate(make_Shared&lt；Listener&gt；(Shared_From_This()，Executor_，RetriesCount_))；}(Made_Shared&lt；Listener&gt；(Shared_From_This()，Executor_，RetriesCount_))。</p><p> The  allocate() member function first checks to see if the operation has already been retried too many times. If not it calls a helper  doAllocate() function, passing in a callback to be notified on either success or failure. On failure, the handler posts deferred work to the executor, which will call  allocate() back, thus retrying the allocation with a delay.</p><p>ALLOCATE()成员函数首先检查操作是否已经重试了太多次。如果不是，它调用帮助器doAllocate()函数，传递一个回调来通知成功或失败。失败时，处理程序将延迟的工作提交给Executor，后者将回调Alalate()，从而延迟地重试分配。</p><p> This is a heavily stateful and rather circuitous async algorithm. The logic spans many functions and several objects, and the control and data flow is not obvious. Note the intricate ref-counting dance necessary to keep the objects alive. Posting the work to an executor makes it even harder. Executors in this code have no notion of continuations, so errors that happen during task execution have nowhere to go. The  allocate() function can’t signal an error by throwing an exception if it wants any part of the program to be able to recover from the error. Error handling must be done manually and out-of-band. Ditto if we wanted to support cancellation.</p><p>这是一种高度有状态且相当迂回的异步算法。逻辑跨越多个功能和多个对象，控制和数据流不明显。请注意，保持物品存活所必需的复杂的参考计数舞蹈。将工作发布给遗嘱执行人会让这件事变得更加困难。这段代码中的执行器没有延续的概念，因此在任务执行期间发生的错误无处可去。如果ALLOCATE()函数希望程序的任何部分能够从错误中恢复，则它不能通过抛出异常来发出错误信号。错误处理必须手动和带外完成。如果我们想要支持取消，情况也是如此。</p><p> This is  unstructured concurrency: we queue up async operations in an  ad hoc fashion; we chain dependent work, use continuations or “strand” executors to enforce sequential consistency; and we use strong and weak reference counts to keep data alive until we are certain it’s no longer needed. There is no formal notion of task A being a child of task B, no way to enforce that child tasks complete before their parents, and no one place in the code that we can point to and say, “Here is the algorithm.”</p><p>这是非结构化并发：我们以特别的方式将异步操作排队；我们链接依赖的工作，使用延续或“串”执行器来强制顺序一致性；我们使用强引用计数和弱引用计数来保持数据存活，直到我们确定不再需要它为止。没有任务A是任务B的子任务的正式概念，也没有办法强制该子任务在其父任务之前完成，并且代码中没有一个地方可以让我们指向并说，“这就是算法。”</p><p> If you don’t mind the analogy, the hops through the executor are a bit like  goto statements that are non-local in both time and space: “Jump to this point in the program,  X milliseconds from now, on this particular thread.”</p><p>如果您不介意这个类比，通过执行器的跳跃有点像在时间和空间上都是非本地的goto语句：“跳到程序中的这一点，从现在起X毫秒，在这个特定的线程上。”</p><p> That non-local discontinuity makes it hard to reason about correctness and efficiency. Scale unstructured concurrency up to whole programs handling lots of concurrent real-time events, and the incidental complexity of manually handling out-of-band asynchronous control and data flow, controlling concurrent access to shared state, and managing object lifetime becomes overwhelming.</p><p>这种非局部的不连续性使得人们很难对正确性和效率进行推理。将非结构化并发扩展到处理大量并发实时事件的整个程序，手动处理带外异步控制和数据流、控制对共享状态的并发访问以及管理对象生存期的附带复杂性变得难以承受。</p><p>  Recall that in the early days of computing, unstructured programming styles rapidly gave way to structured styles. With the addition of coroutines to C++, we are seeing a similar phase shift happening today to our asynchronous code. If we were to rewrite the above retry algorithm in terms of coroutines (using Lewis Baker’s popular  cppcoro library), it might look something like this:</p><p>回想一下，在计算的早期，非结构化编程风格迅速让位于结构化风格。随着C++中增加了协同程序，我们看到今天的异步代码也发生了类似的相移。如果我们根据协程(使用Lewis Baker流行的cppcoro库)重写上述重试算法，它可能如下所示：</p><p> // Try asynchronously allocating some resource// with retry:cppcoro::task&lt;&gt; Manager::allocate() { // Retry the allocation up to kMaxRetries // times: for (int retriesCount = 1; retriesCount &lt;= kMaxRetries; ++retriesCount) { try { co_await allocator_.doAllocate(); co_return; // success! } catch (...) {} // Oops, it failed. Yield the thread for a // bit and then retry: co_await scheduler_.schedule_after( 10ms * (1 &lt;&lt; retriesCount)); } // Error, too many retries throw std::runtime_error( &#34;Resource allocation retry count exceeded.&#34;);}</p><p>//尝试异步分配某些资源//WITH RETRY：cppcoro：：TASK&lt；&gt；Manager：：ALLOCATE(){//重试最多kMaxRetries//次：For(int riresesCount=1；riresesCount&lt；=kMaxRetries；++RetriesCount){try{co_await allocator_.doAllocate()；co_return；//Success！}Catch(...){}//O。释放线程以获取//位，然后重试：co_aWait Scheduler_.Schedule_After(10ms*(1&lt；&lt；RetriesCount))；}//错误，重试次数太多，抛出std：：run_error(&#34；资源分配重试计数已超出。&#34；)；}</p><p> Aside: This replaces the  executor_ with a  scheduler_ that implements cppcoro’s  DelayedScheduler concept.</p><p>旁白：这用实现cppcoro的DelayedScheduler概念的Scheduler_替换了Executor_。</p><p>  The state (like  retriesCount) can be maintained in local variables instead of as members of objects that need to be ref-counted.</p><p>可以在局部变量中维护状态(就像RetriesCount一样)，而不是作为需要引用计数的对象的成员。</p><p>  We are guaranteed structurally that the async call to  allocator_.doAllocate() completes before this function continues executing.</p><p>从结构上保证，在此函数继续执行之前，将完成对allocator_.doAllocate()的异步调用。</p><p> Point (4) has profound implications. Consider the trivial example from the beginning of the article. The following re-implementation in terms of coroutines is perfectly safe:</p><p>第(4)点影响深远。考虑一下本文开头的这个微不足道的例子。以下在协程方面的重新实现是完全安全的：</p><p>  The above code is safe because we know that  computeResult completes before  doThing is resumed and thus before  s is destructed.</p><p>上面的代码是安全的，因为我们知道ComputeResult在恢复执行之前完成，因此在s被销毁之前完成。</p><p> With structured concurrency, it is perfectly safe to pass local variables by reference to child tasks that are immediately awaited.</p><p>使用结构化并发，通过引用立即等待的子任务来传递局部变量是完全安全的。</p><p>  Taking a structured approach to concurrency, where the lifetime of concurrent operations is strictly nested within the lifetime of resources that it uses and is tied to program scopes, allows us to avoid needing to use garbage collection techniques like  shared_ptr to manage lifetime. This can lead to code that is more efficient, requiring fewer heap-allocations and fewer atomic reference-counting operations, as well as code that is easier to reason about and is less bug-prone. However, one implication of this approach is that it means that we must always join and wait for child operations before the parent operation can complete. We can no longer just detach from those child operations and let the resources get cleaned up automatically when their ref-counts drop to zero. To avoid having to wait unnecessarily long times for child operations whose results are no longer needed, we need a mechanism to be able to cancel those child operations so that they complete quickly. Thus the structured concurrency model requires deep support for cancellation to avoid introducing unnecessary latency.</p><p>采用结构化的并发方法(其中并发操作的生存期严格嵌套在它使用的资源的生存期内，并与程序作用域绑定)允许我们避免使用诸如SHARED_PTR之类的垃圾收集技术来管理生存期。这可以产生更高效的代码，需要更少的堆分配和原子引用计数操作，以及更容易推理和不容易出错的代码。然而，这种方法的一个含义是，它意味着在父操作可以完成之前，我们必须始终联接并等待子操作。我们不能再简单地从那些子操作中分离出来，让资源在引用计数降至零时自动清理。为了避免不必要的长时间等待其结果不再需要的子操作，我们需要一种能够取消这些子操作的机制，以便它们能够快速完成。因此，结构化并发模型需要对取消提供深度支持，以避免引入不必要的延迟。</p><p> Note that we rely on structured lifetime and structured concurrency every time we pass a local variable to a child coroutine by reference. We must ensure that the child coroutine has completed and is no longer using that object before the parent coroutine exits the scope of that local variable and destroys it.</p><p>请注意，每次通过引用将局部变量传递给子协程时，我们都依赖结构化生存期和结构化并发性。我们必须确保子协程在父协程退出该局部变量的作用域并销毁它之前已经完成并且不再使用该对象。</p><p>  When I talk about “structured concurrency,” I am not just talking about coroutines — although that is its most obvious manifestation. To see what I mean, let’s talk briefly about what coroutines  are and what they  are not. In particular, there is nothing inherently concurrent about C++ coroutines at all! They are really just a way to get the compiler to carve your function up into callbacks for you.</p><p>当我谈到“结构化并发”时，我说的不仅仅是协程--尽管这是它最明显的表现。为了理解我的意思，让我们简要地讨论一下什么是协程，什么不是协程。特别是，C++协程根本没有本质上的并发性！它们实际上只是让编译器将您的函数分割为回调函数的一种方式。</p><p>   What does  co_await here mean? The trite answer is: it means whatever the author of  cppcoro::task&lt;&gt; wants it to mean (within certain bounds). The fuller answer is that  co_await suspends the current coroutine, bundles up the rest of the coroutine (here, the statement  co_return s.result;) as a continuation, and passes it to the awaitable object (here, the  task&lt;&gt; returned by  computeResult(s)). That awaitable will typically store it somewhere so it can be invoked later, when the child task completes. That’s what  cppcoro::task&lt;&gt; does, for instance.</p><p>在这里等待是什么意思？老生常谈的答案是：无论cppcoro：：task&lt；&gt；的作者希望它是什么意思(在一定范围内)，它都意味着什么。更完整的答案是，co_await挂起当前的协程，捆绑协程的其余部分(这里是语句co_return s.result；)，并将其传递给可等待的对象(这里是culteResult(S)返回的任务&lt；&gt；)。该可等待对象通常会将其存储在某个位置，以便以后子任务完成时可以调用它。例如，cppcoro：：Task&lt；&gt；就是这样做的。</p><p> In other words, the  task&lt;&gt; type and the coroutines language feature conspire together to layer “structured concurrency” on top of boring ol’ callbacks. That’s it. That’s the magic. It’s all just callbacks, but callbacks in a very particular pattern, and it is that pattern that makes this “structured.” The pattern ensures that child operations complete before parents, and that property is what brings the benefits.</p><p>换句话说，任务类型和协程语言特性共同作用，在无聊的回调之上加了一层“结构化并发”。就这样。这就是魔力。这一切都只是回调，但回调是一种非常特殊的模式，正是这种模式使这种“结构化”。该模式确保子操作在父操作之前完成，而该属性才是带来好处的因素。</p><p> Once we recognize that structured concurrency is really just callbacks in a particular pattern, we realize that we can achieve structured concurrency  without coroutines. Programming with callbacks is nothing new, of course, and the patterns can be codified into a library and made reusable. That’s what  libunifex does. If you follow C++ standardization, it is also what the sender/receiver abstraction from  the Executors proposal does.</p><p>一旦我们认识到结构化并发实际上只是特定模式中的回调，我们就会意识到我们可以在没有协程的情况下实现结构化并发。当然，使用回调进行编程并不是什么新鲜事，并且可以将模式编码到库中并使其可重用。这就是libunifex所做的。如果您遵循C++标准化，这也是执行者提案中的发送者/接收者抽象所做的事情。</p><p> Using libunifex as a basis for structured concurrency, we can write the example above as follows:</p><p>使用libunifex作为结构化并发的基础，我们可以编写以下示例：</p><p> unifex::any_sender_of&lt;&gt; computeResult(State &amp; s);auto doThing() { return unifex::let_with( // Declare a &#34;local variable&#34; of type State: [] { return State{}; }, // Use the local to construct an async task: [](State &amp; s) { return unifex::transform( computeResult(s), [&amp;] { return s.result; }); });}</p><p>Unifex：：any_sender_of&lt；&gt；ComputeResult(State&amp；s)；auto dothing(){return unifex：：let_with(//声明类型为State：[]{return State{}；}的局部变量)，//使用本地构造一个异步任务：[](State&amp；s){return unifex：：Transform(ComputeResult)，[&amp；]{。</p><p> Why would anybody write that when we have coroutines? You would certainly need a good reason, but I can think of a few. With coroutines, you have an allocation when a coroutine is first called, and an indirect function call each time it is resumed. The compiler can sometimes eliminate that overhead, but sometimes not. By using callbacks directly — but in a structured concurrency pattern — we can get many of the benefits of coroutines without the tradeoffs.</p><p>当我们有协同程序的时候为什么会有人这么写呢？你当然需要一个很好的理由，但我能想到几个。使用协程，在第一次调用协程时有一个分配，每次恢复时都有一个间接函数调用。编译器有时可以消除这种开销，但有时不能。通过直接使用回调(但采用结构化并发模式)，我们可以在不进行权衡的情况下获得协程的许多好处。</p><p> That style of programming makes a different tradeoff, however: it is far harder to write and read than the equivalent coroutine. I think that &gt;90% of all async code in the future should be coroutines simply for maintainability. For hot code, selectively replace coroutines with the lower-level equivalent, and let the benchmarks be your guide.</p><p>然而，这种编程风格做出了不同的取舍：它比同等的协程程序更难写和读。我认为未来90%的异步代码应该仅仅是为了可维护性而使用协程。对于热代码，有选择地用较低级别的等价物替换协程，并让基准作为您的指南。</p><p>  I mention above that coroutines aren’t inherently concurrent; they’re just a way of writing callbacks. Coroutines are inherently sequential in nature and the laziness of  task&lt;&gt; types — where a coroutine starts suspended and doesn’t start executing until it is awaited — means that we can’t use it to introduce concurrency in the program. Existing  future-based code often assumes that the operation has already started eagerly, introducing  ad hoc concurrency that you need to be careful to prune back. That forces you to re-implement concurrency patterns over and over in an  ad hoc fashion.</p><p>我在上面提到过，协程本身并不是并发的；它们只是编写回调的一种方式。协程本质上是顺序的，而任务&lt；&gt；类型的懒惰--协程开始挂起，等待之后才开始执行--意味着我们不能用它来在程序中引入并发性。现有的基于未来的代码通常假定操作已经急切地开始，从而引入了临时并发，您需要小心地将其删减。这迫使您以特别的方式一遍又一遍地重新实现并发模式。</p><p> With structured concurrency, we codify concurrency patterns into reusable algorithms to introduce concurrency in a structured way. For instance, if we have a bunch of  tasks and would like to wait until they have all completed and return their results in a  tuple, we pass them all to the  cppcoro::when_all and  co_await the result. (Libunifex also has a  when_all algorithm.)</p><p>通过结构化并发，我们将并发模式编码为可重用的算法，以结构化的方式引入并发。例如，如果我们有一系列任务，并且希望等到它们全部完成并以元组形式返回结果，我们会将它们全部传递给cppcoro：：When_all并等待结果。(Libunifex也有WHEN_ALL算法。)。</p><p> At present, neither cppcoro nor libunifex has a  when_any algorithm, so you can’t launch a bunch of concurrent operations and return when the  first one completes. It’s a very important and interesting foundational algorithm, though. To maintain the guarantees of structured concurrency, when the first child task completes,  when_any should request cancellation on all the other tasks  and then wait for them all to finish. The utility of this algorithm depends upon all async operations in your program responding promptly to cancellation requests, which demonstrates just how important deep support for cancellation is in modern async programs.</p><p>目前，cppcoro和libunifex都没有WHEN_ANY算法，因此不能启动多个并发操作并在第一个操作完成时返回。不过，这是一个非常重要和有趣的基础算法。为了保持结构化并发的保证，当第一个子任务完成时，When_any应该请求取消所有其他任务，然后等待它们全部完成。该算法的效用取决于程序中的所有异步操作是否能迅速响应取消请求，这表明在现代异步程序中，对取消的深度支持是多么重要。</p><p>  So far, I’ve discussed what structured concurrency is and why it matters. I haven’t discussed how we get there. If you are already using coroutines to write async C++, then congrats. You may keep enjoying the benefits of structured concurrency, perhaps with a deeper understanding and appreciation for  why coroutines are so transformative.</p><p>到目前为止，我已经讨论了什么是结构化并发以及它为什么重要。我还没有讨论我们是如何做到这一点的。如果您已经在使用协程来编写异步C++，那么恭喜您。您可能会继续享受结构化并发的好处，也许会对协程为什么如此具有变革性有更深入的理解和欣赏。</p><p> For codebases that lack structured concurrency, deep support for cancellation, or maybe even an abstraction for asynchrony, the job is hard. It may even start with  introducing complexity in order to carve out an island in which the surrounding code provides the guarantees that structured concurrency patterns require. This includes, for instance, creating the  impression of prompt cancellation of scheduled work, even when the underlying execution contexts don’t offer that directly. That added complexity can be isolated in a layer, and the islands of structured concurrency can be built on top. Then the simplifying work can begin, taking future- or callback-style code and converting them to coroutines, teasing out parent/child relationships, ownership, and lifetime.</p><p>对于缺乏结构化并发性、缺乏对取消的深度支持，甚至缺乏对异步的抽象的代码库来说，这项工作非常困难。它甚至可以从引入复杂性开始，以便开辟出一个孤岛，在该孤岛中，周围的代码提供结构化并发模式所需的保证。例如，这包括给人一种即时取消预定工作的印象，即使底层执行上下文不直接提供这一功能。增加的复杂性可以隔离在一个层中，并且可以在上面构建结构化并发孤岛。然后可以开始简化工作，获取未来或回调样式的代码并将其转换为协程，梳理出父/子关系、所有权和生命周期。</p><p>  Adding  co_await makes a synchronous function asynchronous, without disturbing the structure of the computation. The async operation being awaited necessarily completes before the calling function does, just like ordinary function calls. The revolution is:  nothing changes. Scopes and lifetimes still nest as they always have, except now the scopes are discontinuous in time. With raw callbacks and futures, that structure is lost.</p><p>添加co_aWait会使同步函数成为异步函数，而不会干扰计算结构。与普通函数调用一样，等待的异步操作必须在调用函数完成之前完成。这场革命是：什么都不会改变。作用域和生命周期仍然像往常一样嵌套，只是现在作用域在时间上是不连续的。有了原始的回调和期货，这种结构就会消失。</p><p> Coroutines, and structured concurrency more generally, bring the advantages of the Modern C++ style — value semantics, algorithm-driven design, clear ownership semantics with deterministic finalization — into our async programming. It does that because it ties async lifetimes back to ordinary C++ lexical scopes. Coroutines carve our async functions up into callbacks at suspension points, callbacks that get called in a very specific pattern to maintain that strict nesting of scopes, lifetimes, and function activations.</p><p>协程，以及更一般的结构化并发，将现代C++风格的优势--值语义、算法驱动的设计、具有确定性终结的清晰所有权语义--带入我们的异步编程中。它之所以这样做，是因为它将异步生命周期与普通的C++词法作用域联系在一起。协程将我们的异步函数划分为挂起点处的回调，这些回调以一种非常特定的模式被调用，以维护作用域、生存期和函数激活的严格嵌套。</p><p> We sprinkle  co_await in our code and we get to continue using all our familiar idioms: exceptions for error handling, state in local variables, destructors for releasing resources, arguments passed by value or by reference, and all the other hallmarks of good, safe, and idiomatic Modern C++.</p><p>我们在代码中散布了co_await，并且继续使用我们熟悉的所有习惯用法：错误处理的异常、局部变量中的状态、释放资源的析构函数、通过值或引用传递的参数，以及所有其他良好、安全和惯用的现代C++的特征。</p><p>   If you want to hear more about structured concurrency in C++, be sure to check out  Lewis Baker’s CppCon talk from 2019 about it.</p><p>如果您想更多地了解C++中的结构化并发，请务必查看Lewis Baker的CppCon Talk from 2019关于它的文章。</p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://ericniebler.com/2020/11/08/structured-concurrency/">https://ericniebler.com/2020/11/08/structured-concurrency/</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/结构化/">#结构化</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/协程/">#协程</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/美国/">#美国</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/谷歌/">#谷歌</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/linux/">#linux</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/程序/">#程序</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy; 2020 diglog.com </div></div></body></html>