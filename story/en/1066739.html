<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>AI芯片公司的细分 A Breakdown of AI Chip Companies</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">A Breakdown of AI Chip Companies<br/>AI芯片公司的细分 </h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2021-06-19 02:42:35</div><div class="page_narrow text-break page_content"><p>I see something similar happening in AI chip companies that I do in self driving cars. You have many wildly overcapitalized companies that have 0 product market fit, never mind revenue or profit.</p><p>我看到我在自动驾驶汽车的AI芯片公司中发生了类似的事情。您有许多疯狂的过度传奇的公司，有0个产品市场的适合，从不介意收入或利润。</p><p> Not a single one of these companies has a product I can buy! The current leader in AI chips is unquestionably NVIDIA, and they have a card I can buy. So that leaves the question, are the companies banking on a stupid business model, or do they just not have anything? I tend to think it’s the latter. Remember: Unless it’s a from company with a track record like Apple, secrecy is just cover for “we don’t have shit”</p><p> 这些公司不是一个我可以购买的产品！ AI Chips的当前领导人毫无疑问，我可以买一张卡片。所以留下了这个问题，是公司银行在一个愚蠢的商业模式，还是他们没有任何东西？我倾向于认为这是后者。记住：除非是来自苹果这样的轨道记录的公司，秘密只是掩盖“我们没有狗屎”</p><p>     Here is a  Technical Report on the Graphcore IPU Architecture. It looks insanely hard to program for. And while they have a buy now button, it links to a contact us form. If a company has a contact us form gating sales, it means that their product isn’t actually competitive in the market if you did the research yourself, but they are hoping a sales guy will wrongly convince you otherwise.</p><p>     以下是GraphCore IPU架构的技术报告。它看起来很难努力。虽然他们现在有购买按钮，但它链接到联系我们的表格。如果公司有联系我们的表格门控销售，这意味着他们的产品在自己的研究中实际上并不竞争力，但他们希望销售人员将错误地说服你。</p><p> While I had to get to the 7th page of the report to find the problem, it’s the same mistake as the Cell SPE. They rely on a many core chip with a custom weird communications protocol. You want to try to maintain fast code for that? Game devs hated the SPE, why wouldn’t ML devs hate this?</p><p> 虽然我必须到达第7页的报告来查找问题，但它与细胞SPE相同。他们依靠许多核心芯片，具有自定义奇怪的通信协议。您想尝试保留快速代码吗？游戏devs讨厌spe，为什么不讨厌这个？</p><p>  They seem to get the idea right, or at least match what I would do with a single big core running at around 1 GHz. Here is their  Technical Report. I have heard that they get the details wrong though, and the fact that they are still adversing their ResNet-50 performance (a 2015 era network) speaks to that.</p><p>  他们似乎可以获得正确的想法，或者至少匹配我将与在左右1个GHz的单一大核心相匹配。这是他们的技术报告。我听说他们得到了细节的错误，而且他们仍然对他们的resnet-50绩效（2015年的时代网络）发表讲话。</p><p> The problem is obvious on the first page of report, the same mistake as Itanium, “But this approach places a heavy burden on the compiler, which must comprehend the twin pulses of instruction flow and data flow while optimizing function-unit utilization. The compiler must schedule all data movement, manage the memory and function units, and even manually fetch instructions.” This push it to static software strategy has never worked in the history of computer architecture.</p><p> 问题在第一个报告页面上是显而易见的，同样的错误作为鼬，但这种方法对编译器造成了沉重的负担，这必须理解指令流量和数据流的双脉冲，同时优化功能单元利用率。编译器必须计划所有数据移动，管理内存和功能单位，甚至手动获取指令。“这将其推动到静态软件策略从未在计算机架构的历史中工作过。</p><p> I’ll leave with one more sentence from the report, “The memory units also store VLIW instructions, which are 2,304 (144x16) bytes wide” For reference, RISC-V instructions are 4 bytes wide. Hope you like fitting 7 instructions in your 16kB icache!</p><p> 我将从报告中再次句刑，“内存单位还存储VLIW指令，这些指令是2,304（144x16）字节宽”参考，RISC-V指令是4字节宽。希望您喜欢在16KB的ICACH中拟合7条说明！ </p><p>  Their chip is called Grayskull, and there’s almost no information published on this architechture, and I was told the only way to get a demo would be to sign something promising to not say anything bad about it. That doesn’t inspire much (read: any) confidence in it being good, I’m nice if people are honest and transparent, less nice if they aren’t. But now that  Jim Keller is there, perhaps there is hope.</p><p>他们的芯片被称为Grayskull，几乎没有关于这个拱形发布的信息，我被告知获得演示的唯一方法是签署有希望的东西，不要对它说什么不对。这不会激发更多的（阅读：任何）对它的信心，如果人们是诚实和透明的，那么如果他们不是那么好。但现在吉姆凯勒在那里，也许有希望。</p><p>  WE MAKE  BIG CHIP! CHIP REALLY BIG! BIG MUST BE GOOD BECAUSE BIG! BIG CHIP MEAN BIG INVESTMENT! Good luck controlling 400,000 cores in any sane way.</p><p>  我们制作大芯片！芯片真的很大！大必须是好的，因为很大！大芯片意味着大投资！祝你在任何理智的方式控制400,000个核心。</p><p>     The king of AI chips. The 3090 isn’t even a bad deal! The problem is the 5x overpriced A100, and the facts that, one, they have a monopoly, and two, the chips are still mainly designed as gaming GPUs with AI as an afterthought. While the 432 Tensor Cores have an insane number of FLOPS (8x4x4 = 128 FMAs each), it’s almost  impossible to keep them fed from memory, or even cache, and in reality performance is 10x worse. (this is where we get our 10x speed from)</p><p>     AI芯片之王。 3090甚至不是一个不好的交易！问题是5X价格过高的A100，而且，一个，一个，他们有垄断和二，筹码仍然主要被设计为与AI作为事后的游戏GPU。虽然432张核心核心有一个疯狂的絮凝物（8x4x4 = 128 fmas），但几乎不可能让他们从内存中喂食，甚至缓存，并且在现实性能中达到10倍。 （这是我们从中获得10倍的速度）</p><p>  The TPU is based around TensorFlow. While it does work with PyTorch, it is really meant to have things compiled and laid out in RAM in specific ways. This is the “push it to software” pattern that I see fail over and over, while it may work for an organization like Google, it’s not practical for a normal organization trying to do ML. Hence why Google doesn’t sell the TPUs, they sell services that can use them in their cloud. Nobody wants custom weird services that lock you in to Google, and this is why they are losing to AWS and Azure in the cloud space.</p><p>  TPU基于Tensorflow。虽然它与Pytorch合作，但它真的意味着以特定方式在RAM中编制和布局。这是“将其推动到软件”模式，我看到一遍又一遍地失败，而它可能为像谷歌这样的组织工作，这对于试图做ML的普通组织并不实用。因此，为什么谷歌不销售TPU，他们销售可以在云中使用它们的服务。没有人想要锁定你的自定义奇怪的服务，这就是为什么他们在云空间中失去AWS和Azure的原因。</p><p> The best documentation I could find  is here, along with  this presentation on the changes from v2 to v3. It seems they have very large 2D arrays, 128x128 (reduced in v2 from 256x256 in v1). And VLIW instructions (at least only 322-bit), pushing all the complexity into a compiler.</p><p> 我可以找到的最好的文档在这里，以及此演示文稿从V2到V3的更改。似乎它们具有非常大的2D阵列，128x128（在v1中的256x256中减少了V2）。和VLIW指令（至少只有322位），将所有复杂性推入编译器中。</p><p> The  TPUv4 docs are out, and they look okay. Wish I could buy one. They also are  using ML to do layout for the TPUv5.</p><p> TPUv4文档出来，它们看起来还不错。希望我能买一送一个。它们也使用ML为TPUv5进行布局。</p><p>  Similar downsides to NVIDIA, but with much less investment in the software side. I don’t know anyone who uses these to train. From twitch chat: “ROCm = please use kernel version 5.4.1.4.12.44.1 and only 5.4.1.4.12.44.1” aka unusable in practice.</p><p>  与NVIDIA类似的缺点，但在软件方面的投资少得多。我不知道任何用这些用来训练的人。来自抽搐聊天：“rocm =请使用内核版本5.4.1.4.12.44.1，只有5.4.1.4.12.44.1”在实践中不可用。 </p><p>  The  Huawei Ascend910 made it on the list for MLPerf 0.7, so I included it here, even though I can’t buy the chips or use them it seems. They  seem to use a 16x16x16 matrix unit, not a bad choice. But it only supports FP16, which is a software hassle for training. Found  more info here, it seems similarish to the Apple Neural Engine.</p><p>Huawei ascend910在Mlperf 0.7的列表中制作，所以我在这里包括在这里，即使我不能购买筹码或似乎使用它们。它们似乎使用了16x16x16矩阵单元，而不是一个糟糕的选择。但它只支持FP16，这是一个用于训练的软件麻烦。在此发现更多信息，似乎是苹果神经发动机的样子。</p><p>    Our goal would be to beat NVIDIA and build training chips that are 10x faster at training (because we have the cache bandwidth to feed our tensor cores) and cost 10x less (because we aren’t overcharging and can omit all the GPU silicon). Same D2C business model, just with purpose built hardware for ML training instead of shoehorning it into a gaming device.</p><p>    我们的目标是击败NVIDIA并在培训快10倍的培训芯片（因为我们有缓存带宽来喂养我们的张量核心），并且减少10倍（因为我们没有过充电，并且可以省略所有GPU硅）。相同的D2C商业模式，只有目的的内置硬件，用于ML培训，而不是将其俯冲到游戏设备。</p><p> I’ve been working on  an extension to RISC-V that includes a 32x32x32 matrix multiply unit, and a few other wide vector style instructions. I would support only the TF32 datatype (19 bits), so it would well with training out of the box without gradient scaling (which is really a ton of software complexity to hack the larger floating point range into FP16). While training with smaller datatypes is possible, it’s super annoying!</p><p> 我一直在研究RISC-V的扩展，其中包括32x32x32矩阵乘以单位，以及其他一些宽边矢量样式指令。我只支持TF32数据类型（19位），因此在没有梯度缩放的盒子中训练会很好（这是一个真正大量的软件复杂性，以便将较大的浮点范围重新进入FP16）。虽然有了较小的数据类型的培训，但它非常讨厌！</p><p> A lesson that seems to be forgotten over and over again is that VLIW doesn’t work (Itanium) and fancy multicore doesn’t work (Cell SPE). You have to make a chip people love to program in hardware! Otherwise, you push it to software and it never happens. How is that Itanium compiler coming along?</p><p> 似乎一遍又一遍地被遗忘的课程是VLIW不起作用（Itanium），并且花哨的多核不起作用（Cell SPE）。你必须让芯片人喜欢在硬件上进行编程！否则，您将它推向软件，它永远不会发生。 Itanium编译器怎么样？</p><p> I’ve been learning computer architecture lately, I wrote a  RISC-V core in a day. I think the idea is a single RISC-V core with a really wide decode path and good out of order support. The M1 has a  630 element reorder buffer, we won’t even need this much to keep our MACs fed. While the argument against this sort of architecture is that it uses power, this is only a problem in massive multicore designs! If your basic instruction is a 32x32x32 matmul (65k FLOPS), this will be dwarfed by the power used by the FMACs. I don’t think the branch predictor needs to be that good either, ML code is straightforward loops, and it’s identical every run through.</p><p> 我最近一直在学习电脑架构，我一天写了一个RISC-V核心。我认为这个想法是一个单一的RISC-V核心，具有非常宽的解码路径，并且良好的顺序支持。 M1有一个630个元素重新排序缓冲区，我们甚至不会需要这么多来保持我们的Macs喂养。虽然针对这种架构的论证是它使用权力，但这只是大量多核设计中的问题！如果您的基本指令是32x32x32 Matmul（65k拖鞋），则将通过FMACS使用的功率赋予。我不认为分支预测因子需要是良好的，ml代码是直接的循环，并且每次运行都是相同的。</p><p> One of the biggest problems with non NVIDIA training solutions is terrible software support. This isn’t because it’s hard to write, it’s because it’s hard to write with performance for the weird architecture chips these companies came up with. Since this chip is a single core, wide decode path superscalar, writing the code should be very easy, even to support all of PyTorch with decent performance.</p><p> 非NVIDIA培训解决方案的最大问题之一是可怕的软件支持。这不是因为它很难写，这是因为它很难用这些公司提出的奇怪建筑筹码的表演。由于此芯片是单核，广泛的解码路径超标，写入代码应该很容易，甚至支持所有具有体现性能的Pytorch。</p><p> Cherry One: My first step would be to write open source Verilog implementing this core that can run in the  S7t-VG6, the  Xilinx Alveo, or the  FK33. According to my initial benchmarks, assuming 1 instruction per cycle and 1 GHz clock speed, this would comfortably outperform a 3090. This FPGA card costs $7500, so it wouldn’t be cost effective to use, but this is the comma NEO of AI chips, it will be adopted by hobbyists. (raise nothing for this stage, just open source code and hype building)</p><p> 樱桃一步：我的第一步是写入开源Verilog实现可以在S7T-VG6，Xilinx Alveo或FK33中运行的此核心。根据我的初始基准，假设每周期1指令和1个GHz时钟速度，这会令人舒服地优于3090.这个FPGA卡的费用为7500美元，因此使用这是逗号的逗号，它将被爱好者采用。 （对于这个阶段而言，只要开源代码和炒作建设） </p><p> Cherry Two: My second step would be to do a 10k unit tapeout of this chip as an ASIC (I’m hearing $5M for a reasonable 12nm process node). 1 core, 20MB SRAM, PCIe Gen3 x16, no onboard big RAM (use host), 75W TDP. Due to not requiring a supported car, I think the audience for this card would be much broader than the comma EON, more similar to the Oculus DK1. After selling the 10k cards at $1,000 each, this company would already be profitable! (raise $10M on $50M for this stage, verification and tapeout)</p><p>樱桃二：我的第二步是做这个芯片的10K单位的磁带作为ASIC（我听到合理的12nm过程节点的500万美元）。 1核心，20MB SRAM，PCIe Gen3 X16，无板载大RAM（使用主机），75W TDP。由于不需要支持的汽车，我认为这张卡的观众将比逗号EON更广泛，更类似于Oculus DK1。在每次1,000美元销售10K卡后，该公司将是有利可图的！ （为此阶段，验证和磁带筹集5000万美元）</p><p> Cherry Three: My third step would be to build a serious version of this chip on a modern (&lt;= 5nm) process node, perhaps $50M for the tapeout. 16 core (with  NCCL style primitives), 320MB SRAM (20MB per core, isolated), PCIe Gen4 x16, a modern GPU-style DDR interface, 300W TDP. Sell this card for $2,000, and I suspect quickly cloud demand would come from the correct direction, which is bottom up! One of these cards should outperform a  DGX A100, a $199k machine. This is a 100x price improvement. At this point, we would win the AI chip market, even against NVIDIA’s next generation. (raise $100M on $500M for this stage, serious verification and tapeout)</p><p> 樱桃三：我的第三步是在现代（＆lt; = 5nm）的过程节点上建立一个严肃的这个芯片版本，也许是磁带50米。 16核心（带NCCL样式原语），320MB SRAM（每核，隔离20MB，隔离），PCIe Gen4 X16，现代GPU式DDR接口，300W TDP。以2000美元的价格出售此卡，我怀疑迅速云需求来自正确的方向，这是底部的！其中一个卡应该优于一个高达199万台机器的DGX A100。这是100倍的价格改进。此时，我们将赢得AI芯片市场，即使是针对NVIDIA的下一代。 （在此阶段为500米筹集1000万美元，严重验证和磁带）</p><p> At this point, we flip the company for at least $1B to anyone but NVIDIA, and they will be highly financially motivated to continue to sell cards D2C (similar to the Facebook Oculus sale). Should be an easy sell with a 10x revenue multiple, assuming we sell 50k Cherry Three cards. The company has achieved three purposes:</p><p> 此时，我们将公司投入至少1亿美元，除了NVIDIA，他们将在高度经济上有动力继续销售卡D2C（类似于Facebook Oculus销售）。应该是一款轻松的销售，有10倍的收入多倍，假设我们销售了50k樱桃三张牌。该公司已实现三种目的：</p><p> Made a competitor to NVIDIA in ML, forcing them to stop charging a 10x premium.</p><p> 为ML的NVIDIA制作了竞争对手，强迫他们停止收取10倍的保费。</p><p> I think this is doable in 3 years. The first card (FPGA) would only have tinygrad support, but it’s enough for benchmarking training of all modern ML models, EfficientNet, YOLO, and Transformers. The open source community will help drive great PyTorch support by the time the second card comes out, judging from how much was contributed to tinygrad, and how people added all the car support to openpilot in the comma EON era.</p><p> 我认为这是3年的可行。第一张牌（FPGA）只有TinyGrad支持，但它足以对所有现代ML型号，效率，YOLO和变压器的基准测试培训。开源社区将通过第二张卡出来的时间来帮助推动大型的Pytorch支持，从为Tinygrad贡献多少，以及人们如何在逗号EON时代向OpenPilot添加所有汽车支持。</p><p> After I have the benchmarking done and confirm I can get 3090 levels of performance from the FPGA card, I will consider incorporating this company and raising money. Only investors who are aligned with overall value creation in the world would be allowed to invest. See  more info about the business plan.</p><p> 在完成基准测试并确认我可以从FPGA卡获得3090级绩效之后，我将考虑纳入这家公司并提高资金。只允许与世界上总体价值创造一致的投资者投资。查看有关业务计划的更多信息。</p><p> If you are interested in working at Cherry Computer, start  contributing to tinygrad. It still needs full support for the RISK architecture (the RISC-V vector extensions) and better benchmarks. This should be approachable for someone new, see the updated TODO section. I’m working on the Verilog for the core itself in  twitchcore, but on the tinygrad side is a better place to start for now.</p><p> 如果您有兴趣在樱桃计算机工作，请开始为Tinygrad提供贡献。它仍然需要全力支持风险架构（RISC-V矢量扩展）和更好的基准。这应该适合某人新的，请参阅更新的Todo部分。我正在努力在Twitchcore中为核心本身工作，但在TinyGrad Side是一个更好的开始。 </p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://geohot.github.io//blog/jekyll/update/2021/06/13/a-breakdown-of-ai-chip-companies.html">https://geohot.github.io//blog/jekyll/update/2021/06/13/a-breakdown-of-ai-chip-companies.html</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/芯片/">#芯片</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/ai/">#ai</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/谷歌/">#谷歌</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy;2012-2021 diglog.com </div></div></body></html>