<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>学习状态抽象以进行长期规划Learning State Abstractions for Long-Horizon Planning</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">Learning State Abstractions for Long-Horizon Planning<br/>学习状态抽象以进行长期规划</h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2020-11-21 23:28:16</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2020/11/cd6d2fe9adf30da81075bf015a9703bd.png"><img src="http://img2.diglog.com/img/2020/11/cd6d2fe9adf30da81075bf015a9703bd.png" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>Many tasks that we do on a regular basis, such as navigating a city, cooking ameal, or loading a dishwasher, require planning over extended periods of time.Accomplishing these tasks may seem simple to us; however, reasoning over longtime horizons remains a major challenge for today’s Reinforcement Learning (RL)algorithms. While unable to plan over long horizons, deep RL algorithms excelat learning policies for short horizon tasks, such as robotic grasping,directly from pixels. At the same time, classical planning methods such asDijkstra’s algorithm and A$^*$ search can plan over long time horizons, butthey require hand-specified or task-specific abstract representations of theenvironment as input.</p><p>我们定期执行的许多任务（例如，游览城市，烹饪食品或装载洗碗机）需要计划较长的时间。对我们来说，完成这些任务似乎很简单；但是，长期的推理仍然是当今强化学习（RL）算法的主要挑战。深度RL算法虽然无法长距离规划，但在直接针对像素的短距离任务（例如机器人抓取）方面具有出色的学习策略。同时，经典的计划方法（例如Dijkstra的算法和A $ ^ * $搜索）可以在很长的时间范围内进行计划，但是它们需要人工指定或特定于任务的抽象环境表示作为输入。</p><p> To achieve the best of both worlds, state-of-the-art visual navigation methodshave applied classical search methods to learned graphs. In particular, SPTM [2]and SoRB [3] use a replay buffer of observations as nodes in a graph and learna parametric distance function to draw edges in the graph. These methods havebeen successfully applied to long-horizon simulated navigation tasks that weretoo challenging for previous methods to solve.</p><p> 为了实现两全其美，最先进的视觉导航方法已将经典搜索方法应用于学习的图。特别是，SPTM [2]和SoRB [3]使用观察的重播缓冲区作为图中的节点，并学习参数距离函数以在图中绘制边缘。这些方法已经成功地应用于长期水平的模拟导航任务，这对于以前的方法来说太难了。</p><p> Nevertheless, these methods are still limited because they are highly sensitiveto errors in the learned graph. Even a single faulty edge acts like a wormholein the graph topology that planning algorithms try to exploit, which makesexisting methods that combine graph search and RL extremely brittle. Forexample, if an artificial agent navigating a maze thinks that two observationson either side of a wall are nearby, its plans will involve transitions thatcollide into the wall. Adopting a simple model that assumes a constantprobability $p$ of each edge being faulty, we see that the expected number offaulty edges is $p|E| = O(|V|^2)$. In other words,  errors in the graph scalequadratically with the number of nodes in the graph.</p><p> 然而，这些方法仍然受到限制，因为它们对学习的图形中的错误高度敏感。规划算法试图利用图拓扑中的单个虫害边缘都像虫洞，这使得将图搜索和RL相结合的现有方法非常脆弱。例如，如果在迷宫中行进的人工代理认为在墙壁的两侧有两个观察员在附近，则其计划将涉及碰撞到墙壁的过渡。通过采用一个简单模型，假设每个边的恒定概率$ p $是有缺陷的，我们看到有缺陷的边的预期数目为$ p | E |。 = O（| V | ^ 2）$。换句话说，图中的错误与图中节点的数量成正比。</p><p>  We could do a lot better if we could minimize the errors in the graph. But how?Graphs over observations in both simulated and real-world environments can beprohibitively large, making it challenging to even identify which edges arefaulty. To minimize errors in the graph, then, we desire sparsity; we want tokeep a minimal set of nodes that is sufficient for planning. If we have a wayto aggregate similar observations into a single node in the graph, we canreduce the number of errors and improve the accuracy of our plans. The keychallenge is to aggregate observations in a way that respects temporalconstraints. If observations are similar in appearance but actually far away,then they should be aggregated into different nodes.</p><p>  如果我们可以最大程度地减少图中的误差，我们可以做得更好。但是，在模拟和现实环境中，观察结果的图形可能会非常大，这甚至很难确定哪些边缘存在故障。为了最大程度地减少图中的误差，我们需要稀疏性。我们希望保留足以进行规划的最少节点集。如果我们有办法将类似的观察结果汇总到图中的单个节点中，则可以减少错误数量并提高计划的准确性。关键挑战在于以尊重时间约束的方式汇总观察结果。如果观察的外观相似但实际上相距较远，则应将其汇总到不同的节点中。</p><p>  So how can we sparsify our graph while guaranteeing that the graph remainsuseful for planning? Our key insight is a novel merging criterion called two-way consistency. Two-way consistency can be viewed as a generalization ofvalue irrelevance to the goal-conditioned setting. Intuitively, two-way consistencymerges nodes (i) that can be interchanged as starting states and (ii) that can beinterchanged as goal states.</p><p>  那么，如何在保证图仍然可用于计划的同时稀疏图呢？我们的主要见识是一种称为双向一致性的新颖合并准则。双向一致性可以看作是与目标条件设置无关的值的概括。直观上，双向一致性合并了可以作为起始状态互换的节点（i）和可以作为目标状态互换的节点（ii）。</p><p>  For an example of two-way consistency, consider the above figure. Supposeduring our node merging procedure we ask: can we merge the nodes with pink andorange bottles according to two-way consistency? First, we note that movingfrom the blue bottle to the pink bottle requires roughly the same work asmoving from the blue bottle to the orange bottle. So the nodes with pink andorange bottles satisfy criterion (ii) because they can be interchanged as goalstates. However, while it is possible to start from the pink bottle and move tothe blue bottle, if we instead start at the orange bottle, the orange bottlewill fall to the floor and crash! So the nodes with pink and orange bottlesfail criterion (i) because they cannot be interchanged as starting states.</p><p>有关双向一致性的示例，请考虑上图。假设我们的节点合并过程是：是否可以根据双向一致性将节点与粉红色和橙色的瓶子合并？首先，我们注意到从蓝色的瓶子移到粉红色的瓶子所需的工作与从蓝色的瓶子移到橙色的瓶子大致相同。因此带有粉红色和橙色瓶子的节点满足条件（ii），因为它们可以作为目标状态互换。但是，虽然可以从粉红色的瓶子开始移动到蓝色的瓶子，但是如果我们改为从橙色的瓶子开始，橙色的瓶子将掉在地上并崩溃！因此，具有粉色和橙色瓶子的节点将无法通过标准（i），因为它们不能作为起始状态互换。</p><p> In practice, we can’t expect to encounter two nodes that can be perfectlyinterchanged. Instead, we merge nodes that can be interchanged up to athreshold parameter $\tau$. By increasing $\tau$, we can make the resultinggraph as sparse as we’d like. Crucially, *we prove in the paper that mergingaccording to two-way consistency preserves the graph’s quality up to an errorterm that scales only linearly with the merging threshold $\tau$.</p><p> 实际上，我们不能期望遇到两个可以完美互换的节点。相反，我们合并可以互换的节点，直到阈值参数$ \ tau $。通过增加$ \ tau $，我们可以根据需要使结果图稀疏。至关重要的是，*我们在论文中证明，按照双向一致性进行合并可将图形的质量保留到一个误差项，误差项仅与合并阈值$ \ tau $成线性比例关系。</p><p> Our motivation for sparsity, discussed above, is robustness: we expect smallergraphs to have fewer errors. Furthermore, our main theorem tells us that we canmerge nodes according to two-way consistency while preserving the graph’squality. Experimentally, though, are the resulting sparse graphs more robust?</p><p> 上面讨论的稀疏性的动机是鲁棒性：我们期望较小的图具有较少的错误。此外，我们的主定理告诉我们，可以在保持图质量的同时，根据双向一致性合并节点。不过，从实验上来说，所得的稀疏图是否更健壮？</p><p> To test the robustness of Sparse Graphical Memory to errors in learned distancemetrics, we thinned the walls in the PointEnv mazes of [3]. While PointEnv is asimple environment with $(x, y)$ coordinate observations, thinning the walls isa major challenge for parametric distance functions; any error in the learneddistance function will cause faulty edges across the walls that destroy thefeasibility of plans. For this reason, simply thinning the maze walls is enoughto break the previous state-of-the-art [3] resulting in a 0% success rate.</p><p> 为了测试稀疏图形内存对学习的距离度量中的错误的鲁棒性，我们对[3]的PointEnv迷宫中的壁进行了细化。虽然PointEnv是具有$（x，y）$坐标观测值的简单环境，但是使壁变薄是参数距离函数的主要挑战。 Learneddistance函数中的任何错误都将导致穿过墙的错误边缘，从而破坏计划的可行性。因此，仅使迷宫壁变薄就足以打破以前的最新技术[3]，成功率为0％。</p><p> How does Sparse Graphical Memory fare? With many fewer edges, it becomestractable to perform self-supervised cleanup: the agent can step through theenvironment to detect and remove faulty edges from its graph. The below figureillustrates the results of this process. While the dense graph shown in red hasmany faulty edges, sparsity and self-supervised cleanup, shown in green,overcome errors in the learned distance metric, leading to a 100% success rate.</p><p> 稀疏图形记忆如何发挥作用？使用更少的边缘，执行自我监督的清理变得很容易：代理可以逐步穿越环境以检测并从其图形中删除有缺陷的边缘。下图说明了此过程的结果。红色显示的密集图具有许多错误的边缘，而绿色显示的稀疏性和自我监督的清理克服了学习距离度量中的错误，从而获得了100％的成功率。</p><p>  We see a similar trend in experiments with visual input. In both ViZDoom [4]and SafetyGym [5] – maze navigation tasks that require planning from rawimages – Sparse Graphical Memory consistently improves the success of baselinemethods including SoRB [3] and SPTM [2].</p><p>在视觉输入实验中，我们看到了类似的趋势。在ViZDoom [4]和SafetyGym [5]中–需要从原始图像进行规划的迷宫导航任务–稀疏图形内存始终如一地提高了基线方法（包括SoRB [3]和SPTM [2]）的成功率。</p><p> In addition to containing fewer errors, Sparse Graphical Memory also results inmore optimal plans. On a ViZDoom maze navigation task [4], we find that SGMrequires significantly less steps to reach the final goal across easy, medium,and hard maze tasks, meaning that the agent follows a shorter path to the finaldestination.</p><p> 除了包含更少的错误外，稀疏图形内存还可以产生更多的最佳计划。在ViZDoom迷宫导航任务[4]上，我们发现SGM在完成简单，中等和困难的迷宫任务时只需很少的步骤即可达到最终目标，这意味着代理遵循一条较短的路线到达终点。</p><p>  Overall, we found that state aggregation with two-way consistency resulted insubstantially more robust plans over the prior state-of-the-art. Whilepromising, many open questions and challenges remain for combining classicalplanning with learning-based control. Some of the questions we’re thinkingabout are - how can we extend these methods beyond navigation to manipulationdomains? As the world is not static, how should we build graphs over changingenvironments? How can two-way consistency be utilized beyond the scope ofgraphical-based planning methods? We are excited about these future directionsand hope our theoretical and experimental findings prove useful to otherresearchers investigating control over extended time horizons.</p><p>  总的来说，我们发现具有双向一致性的状态聚合导致的计划比现有技术要强得多。尽管很有希望，但将经典计划与基于学习的控制相结合仍然存在许多悬而未决的问题和挑战。我们正在考虑的一些问题-如何将这些方法从导航扩展到操纵域？由于世界不是一成不变的，我们应该如何在不断变化的环境上建立图表？在基于图形的计划方法范围之外，如何利用双向一致性？我们对这些未来的方向感到兴奋，并希望我们的理论和实验结果对其他研究延长时间范围的控制的研究者有用。</p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://bair.berkeley.edu/blog/2020/11/20/sgm/">https://bair.berkeley.edu/blog/2020/11/20/sgm/</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/状态/">#状态</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/state/">#state</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/计划/">#计划</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/分享/">#分享</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy; 2020 diglog.com </div></div></body></html>