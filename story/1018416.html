<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>语义分词指南</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">语义分词指南</h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2020-08-16 07:21:15</div><div class="story_img_container"><a href="http://img.diglog.com/img/2020/8/ec18c5f155f618ff50425424e4d6c68e.jpeg"><img src="http://img.diglog.com/img/2020/8/ec18c5f155f618ff50425424e4d6c68e.jpeg" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>深度学习在将图像作为数据处理时非常成功，目前正处于在多个用例上比人类工作得更好的阶段。人类最感兴趣用计算机视觉解决的最重要的问题是图像分类、目标检测和分割，它们的难度从高到低依次是图像分类、目标检测和分割。</p><p>在普通的图像分类任务中，我们只对获取图像中存在的所有对象的标签感兴趣。在对象检测中，我们进一步尝试了解图像中存在的所有对象，以及在边界框的帮助下对象存在的位置。图像分割通过试图准确地找出图像中对象的精确边界，将图像分割带到了一个新的水平。</p><p>在本文中，我们将通过图像分割这一概念，讨论相关用例、实现结果所涉及的不同神经网络架构、度量标准和数据集来探索。</p><p>我们知道图像只不过是像素的集合。图像分割是将图像中的每个像素归类到某个类别的过程，因此可以认为是每个像素的分类问题。有两种类型的分段技术。</p><p>语义分割：-语义分割是对属于特定标签的每个像素进行分类的过程。对于同一对象的不同实例，它没有什么不同。例如，如果图像中有2只猫，则语义分割会为这两只猫的所有像素赋予相同的标签。</p><p>实例分割：实例分割与语义分割的不同之处在于，它为图像中特定对象的每个实例提供唯一的标签。从上图可以看出，所有3只狗都被分配了不同的颜色，即不同的标签。有了语义分割，所有它们都将被分配相同的颜色。</p><p>所以我们现在要谈到需要这种算法的地方。</p><p>谷歌画像模式：-在很多用例中，将前景与背景分开是绝对必要的。例如，在谷歌的肖像模式中，我们可以看到背景变得模糊，而前景保持不变，以获得凉爽的效果</p><p>YouTube Stories：-谷歌最近发布了一个YouTube Stories专题，让内容创作者在创作故事的同时展示不同的背景。</p><p>虚拟化妆：-在图像分割的帮助下，现在可以使用虚拟唇膏。</p><p>4.虚拟试穿：-衣服的虚拟试穿是一个有趣的功能，可以在商店里使用专门的硬件创建3D模型。但是，通过深度学习和图像分割，仅使用一张2D图像就可以获得同样的效果。</p><p>视觉图像搜索：-将衣服分割出来的想法也被用于电子商务中的图像检索算法。例如，Pinterest/Amazon允许您上传任何图片，并通过分割布料部分进行图像搜索来获取相关外观相似的产品。</p><p>自动驾驶汽车：-自动驾驶汽车需要对周围环境的全面了解，达到像素级的完美水平。因此，使用图像分割来识别车道和其他必要信息。</p><p>在深度学习出现之前，经典的机器学习技术如支持向量机、随机森林、K-均值聚类等都被用来解决图像分割问题。但是，就像大多数与图像相关的问题陈述一样，深度学习已经全面优于现有技术，并且现在已经成为处理语义分割的一种规范。让我们回顾一下用来解决这个问题的技术。</p><p>CNN的一般架构由几个卷积和汇聚层组成，后面是几个完全连接的层。2014年发布的《完全卷积网络》(Full Convolutional Network)的论文认为，最终的完全连接层可以被认为是进行覆盖整个地区的1x1卷积。</p><p>因此，最终的致密层可以由卷积层代替，从而获得相同的结果。但现在这样做的好处是输入的大小不再需要固定。当涉及密集层时，输入的大小受到限制，因此，当必须提供不同大小的输入时，必须调整其大小。但是通过用卷积代替致密层，这种约束就不存在了。</p><p>此外，当提供更大尺寸的图像作为输入时，生成的输出将是一个特征地图，而不是像正常输入大小的图像那样只是一个类输出。另外，观察到的最终特征图的行为表示所需类的热图，即在特征图中突出显示对象的位置。由于特征图的输出是所需对象的热图，因此对于我们的分割用例来说，它是有效的信息。</p><p>由于所执行的卷积集合，在输出层获得的特征地图是向下采样的，因此我们希望使用插值技术对其进行向上采样。双线性上采样是可行的，但本文提出使用带反卷积的学习上采样，它甚至可以学习非线性上采样。</p><p>网络的下采样部分称为编码器，上采样部分称为解码器。这是我们在许多体系结构中都会看到的一种模式，即用编码器减小尺寸，然后用解码器进行上采样。在理想的情况下，我们不希望使用池进行下采样，并始终保持相同的大小，但这会导致大量的参数，并且在计算上是不可行的。</p><p>虽然获得了不错的输出结果，但观察到的输出是粗糙和不平滑的。其原因是由于使用卷积图层进行32次下采样而导致最终要素图层处的信息丢失。现在，对于网络来说，使用这些小小的信息进行32倍的上采样变得非常困难。这种体系结构称为FCN-32。</p><p>针对这一问题，本文提出了另外两种体系结构FCN-16、FCN-8。在fcn-16中，来自前一个池层的信息与最终的特征地图一起使用，因此现在网络的任务是学习16倍上采样，这比fcn-32更好。FCN-8试图通过包含来自更多以前的池层的信息来使其更好。</p><p>U-Net建立在从上面开始的完全卷积网络之上。它是为了医学目的而建造的，用来发现肺部或大脑中的肿瘤。它还包括编码器和解码器，编码器将输入图像下采样为特征映射，解码器使用学习的反卷积层将特征映射上采样为输入图像大小。</p><p>U-Net体系结构的主要贡献是快捷连接。我们在上面的FCN中看到，由于我们对图像进行下采样，作为编码器的一部分，我们丢失了很多信息，这些信息在编码器部分很难恢复。FCN尝试通过在最终要素图层之前从池化图层获取信息来解决此问题。</p><p>U-Net为解决这一信息丢失问题提供了一种新的途径。如上图所示，它建议将信息从编码器中对应的下采样层发送到解码器中的每个上采样层，从而捕获更精细的信息，同时也保持较低的计算量。由于编码器开始处的层具有更多的信息，它们将通过提供与输入图像相对应的精细细节来支持解码器的上采样操作，从而极大地提高了结果。本文还建议使用一种新的损失函数，我们将在下面讨论这一点。</p><p>来自谷歌的一组研究人员的Deeplab已经提出了多种技术来改进现有的结果，并以更低的计算成本获得更好的输出。作为研究的一部分，建议的3项主要改进是。</p><p>1)阿特罗斯卷积2)阿特罗斯空间金字塔合并3)条件随机场的使用以提高最终输出让我们来讨论一下这些。</p><p>FCN方法的主要问题之一是由于连续的池操作而过度缩减规模。由于一系列的合并，输入图像被下采样32x，然后再被上采样以得到分割结果。向下采样32倍会导致信息丢失，这对于在分段任务中获得良好的输出是非常关键的。此外，由于在形成学习的上采样中涉及附加参数，因此将卷积去卷积到上采样32倍是计算和存储器昂贵的操作。</p><p>本文提出使用Atrus卷积或孔卷积或膨胀卷积来帮助理解使用相同数量的参数的大背景。</p><p>膨胀卷积的工作原理是通过附加零(称为空洞)来填充参数之间的间隙来增加滤波器的大小。填充在过滤器参数之间的孔/零的数量由项扩张率来表示。当速率等于1时，它只是正常的卷积。当RATE等于2时，在每隔一个参数之间插入一个零，使过滤器看起来像一个5x5卷积。现在，它能够在具有3x3卷积参数的情况下获得5x5卷积的上下文。类似地，对于速率3，接收字段变为7x7。</p><p>在Deeplab中，最后的池化层被替换为具有跨度1而不是2，从而将向下采样率保持在仅为8倍。然后应用一系列的Atrus卷积来捕获更大的上下文。为了训练，将输出标记的掩码向下采样8倍以比较每个像素。对于推断，双线性上采样用于产生相同大小的输出，这在较低的计算/存储成本下给出了足够好的结果，因为双线性上采样不需要任何参数，而不是用于上采样的反卷积。</p><p>空间金字塔池是SPPNet中引入的一个概念，用于从要素地图捕获多尺度信息。在引入SPP之前，需要提供不同分辨率的输入图像，并将计算出的特征映射组合在一起来获取多尺度信息，但这需要较多的计算量和时间。利用空间金字塔集合，可以用一幅输入图像捕获多尺度信息。</p><p>使用SPP模块，网络产生尺寸为1x1(即间隙)、2x2和4x4的3个输出。这些值通过转换为一维向量来连接，从而捕获多个尺度的信息。使用SPP的另一个优点是可以提供任何大小的输入图像。</p><p>ASPP采用了融合不同尺度信息的概念，并将其应用于Atrus卷积。将输入与不同的扩张率进行卷积，并将它们的输出融合在一起。</p><p>可以看出，输入与扩张率为6、12、18和24的3×3滤波器卷积，而输出由于大小相同而级联在一起。1x1卷积输出也被添加到融合输出。为了还提供全局信息，在上采样之后还将间隙输出加到上面。3x3的熔断输出是不同的放大输出，1x1和间隙输出通过1x1卷积得到所需的通道数。</p><p>由于需要分割的图像在输入中可以是任意大小，来自ASPP的多尺度信息有助于改进结果。</p><p>池化是一种有助于减少神经网络中参数数量的操作，但它也带来了不变性。不变性是指神经网络的质量不受输入中轻微平移的影响。由于通过汇集获得的这一特性，神经网络获得的分割输出是粗略的，并且边界没有被具体定义。</p><p>针对这一问题，本文提出使用图形模型CRF。条件随机场操作后处理步骤，并尝试改进生成的结果以定义整形器边界。它的工作原理是不仅根据像素的标签对其进行分类，而且还根据其他像素标签对其进行分类。从上图可以看出，经过CRF后，神经网络产生的粗边界更加细化。</p><p>Deeplab-v3引入了批量归一化，并在RESNET块的每一层内建议扩张率乘以(1，2，4)。本文还提出了在ASPP模块中加入图像级特征，这是本文讨论的ASPP模块的一部分。</p><p>Deeplab-v3+建议使用解码器，而不是普通的双线性向上采样16倍。解码器从U-Net等体系结构使用的解码器中获取提示，从编码层获取信息以改善结果。编码器输出使用双线性上采样进行4倍上采样，并与编码器的特征级联，编码器在执行3x3卷积后再次上采样4倍。此方法比直接16倍向上采样产生更好的结果。此外，还提出了用改进的Xception结构代替RESNET作为编码器的一部分，并在Atrus卷积的基础上使用了深度可分离卷积，以减少计算量。</p><p>I)分类II)本地化分类网络被创建为对平移和旋转不变，因此不重视位置信息，而本地化涉及获得位置的准确细节。因此，这两项任务本质上是矛盾的。大多数分割算法更注重局部化，即上图中的第二个，因此忽略了全局上下文。在这项工作中，作者提出了一种既重视分类任务又不丢失定位信息的方法</p><p>作者建议通过使用大型内核作为网络的一部分来实现这一点，从而实现密集连接，从而获得更多信息。这是在GCN块的帮助下实现的，如上图所示。GCN块可以被认为是k×k卷积滤波器，其中k可以是大于3的数字。为了减少参数的数量，k×k滤波器被进一步分割成1xk和kx1、kx1和1xk块，然后求和。因此，通过增加值k，捕获了更大的上下文。</p><p>此外，作者还提出了一种类似于RESNET中看到的残差块的边界加细块，它由一个捷径连接和一个剩余连接组成，并将它们相加得到结果。可以观察到，具有边界细化块可以改善分割边界处的结果。结果表明，GCN块提高了距离目标中心较近的像素的分类精度，说明了由于捕获了远距离上下文而带来的改善，而边界细化块则有助于提高靠近边界的像素的分类精度。</p><p>Deeplab系列使用ASPP让多个感受野使用不同的ATHROS卷积速率捕获信息。虽然ASPP在改进结果分割方面有很大的用处，但由于体系结构的原因，也存在一些固有的问题。在ASPP中，不同的并行层之间没有信息共享，从而影响了每层核的泛化能力。而且，由于每层迎合不同的训练样本集合(较小的对象对应较小的ATROS速率，而较大的对象对应较大的ATHROS速率)，因此每个平行层的数据量将较少，从而影响总体的概括性。此外，网络中的参数数量随着参数数量的增加而线性增加，因此可能导致过拟合。</p><p>为了解决这些问题，作者提出了一种新的网络结构，称为核共享信源卷积(KSAC)。如上图所示，ASPP不是每个并行层都有不同的内核，而是共享单个内核，从而提高了网络的泛化能力。当膨胀率为6、12和18时，用KSAC代替ASPP可节省62%的参数。</p><p>使用KSAC结构的另一个优点是参数的数量与所使用的扩张率的数量无关。因此，我们可以在不增加模型大小的情况下添加尽可能多的费率。ASPP在速率为6、12、18时提供最佳结果，但当速率为6、12、18、24时，精度会降低，这表明可能存在过拟合。但是KSAC的精确度仍然有很大的提高，说明泛化能力增强了。</p><p>该核共享技术还可以被视为特征空间中的增强，因为相同的核在多个速率上被应用。类似于输入增强如何产生更好的结果，在网络中执行的特征增强应该有助于提高网络的表示能力。</p><p>对于自动驾驶汽车、机器人等用例，需要对观察到的视频进行实时分割。到目前为止讨论的体系结构在很大程度上是为精确而不是速度而设计的。因此，如果在视频上以每帧为基础应用它们，结果将会非常慢。</p><p>此外，通常在视频中，连续帧之间的场景有很多重叠，这可以用来提高结果和速度，如果在每帧的基础上进行分析，这些结果和速度是不会出现在画面中的。使用这些提示，让我们讨论专门为视频设计的体系结构</p><p>时空FCN提出将FCN与LSTM相结合进行视频分割。我们已经知道如何使用FCN来提取用于分割图像的特征。LSTM是一种能够捕捉时间序列信息的神经网络。STFCN结合了FCN和LSTM的能力，既能捕获空间信息，又能捕获时间信息。</p><p>从上图可以看出，STFCN由FCN、空时模块和反卷积组成。由FCN生成的特征地图被发送到时空模块，该模块也具有来自上一帧的模块的输入。基于这两个输入的模块捕获除了空间信息之外的时间信息，并使用类似于在FCN中所做的那样，使用反卷积将其向上采样到图像的原始大小。</p><p>由于FCN和LSTM作为STFCN的一部分共同工作，因此网络是端到端可训练的，并且性能优于单帧分割方法。*有类似的方法，其中LSTM被GRU取代，但捕捉空间和时间信息的概念是相同的。</p><p>本文提出利用相邻帧间的光流作为额外的输入来提高分割效果。</p><p>建议的方法可以作为插件嵌入到任何标准体系结构中。发挥作用的关键因素是NetWarp模块。为了计算分割图，计算当前帧和前一帧之间的光流，即Ft，并通过FlowCNN得到Λ(Ft)。这个过程被称为流变换。该值通过WARP模块传递，该WARP模块还将通过网络计算的中间层的特征地图作为输入。这给出了扭曲的特征地图，然后将其与当前层的中间特征地图相结合，并对整个网络进行端到端的训练。该架构在CamVid和CitysSees视频基准数据集上取得了SOTA结果。</p><p>本文提出利用视频中的语义信息相对于像素级信息变化较慢的事实来提高神经网络在视频分割任务中的执行速度。因此，与开始层相比，最终层中的信息变化速度要慢得多。论文提出了不同的时代要求。</p><p>上图表示中层pool4和深层l的变化率比较。</p><p>.</p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://nanonets.com/blog/semantic-image-segmentation-2020/">https://nanonets.com/blog/semantic-image-segmentation-2020/</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/分词/">#分词</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/semantic/">#semantic</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/分割/">#分割</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/谷歌/">#谷歌</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy;2012-2021 diglog.com </div></div></body></html>