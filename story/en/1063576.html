<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>在实践中很少拍摄学习：GPT-NEO＆'HUGGINGFACE'加速推理API Few-Shot Learning in Practice: GPT-Neo & 'HuggingFace' Accelerated Inference API</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">Few-Shot Learning in Practice: GPT-Neo & 'HuggingFace' Accelerated Inference API<br/>在实践中很少拍摄学习：GPT-NEO＆'HUGGINGFACE'加速推理API </h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2021-06-05 02:58:42</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2021/6/5c5513aee074a0f4b419b0118de6a9c0.png"><img src="http://img2.diglog.com/img/2021/6/5c5513aee074a0f4b419b0118de6a9c0.png" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>In many Machine Learning applications, the amount of available labeled data is a barrier to producing a high-performing model. The latest developments in NLP show that you can overcome this limitation by providing a few examples at inference time with a large language model - a technique known as Few-Shot Learning. In this blog post, we&#39;ll explain what Few-Shot Learning is, and explore how a large language model called GPT-Neo, and the 🤗 Accelerated Inference API, can be used to generate your own predictions.</p><p>在许多机器学习应用中，可用标记数据的量是产生高性能模型的障碍。 NLP的最新进展表明，您可以通过提供具有大语言模型的推理时间的几个例子来克服这种限制 - 一种称为少量学习的技术。在这个博客文章中，我们＆＃39; ll解释了很少拍摄的学习，并探索称为gpt-neo的大型语言模型和🤗加速推理API，可用于生成自己的预测。</p><p>   Few-Shot Learning refers to the practice of feeding a machine learning model with a very small amount of training data to guide its predictions, like a few examples at inference time, as opposed to standard fine-tuning techniques which require a relatively large amount of training data for the pre-trained model to adapt to the desired task with accuracy.</p><p>   少量学习是指用非常少量的训练数据喂养机器学习模型的做法，以指导其预测，例如推理时间的几个例子，而不是需要相对大量的标准微调技术预先训练模型的培训数据，以准确性适应所需的任务。</p><p> This technique has been mostly used in computer vision, but with some of the latest Language Models, like  EleutherAI GPT-Neo and  OpenAI GPT-3, we can now use it in Natural Language Processing (NLP).</p><p> 这种技术主要用于计算机愿景，但与一些最新的语言模型，如Eleutherai GPT-Neo和Openai GPT-3，我们现在可以在自然语言处理（NLP）中使用它。</p><p> In NLP, Few-Shot Learning can be used with Large Language Models, which have learned to perform a wide number of tasks implicitly during their pre-training on large text datasets. This enables the model to generalize, that is to understand related but previously unseen tasks, with just a few examples.</p><p> 在NLP中，很少拍摄的学习可以与大型语言模型一起使用，这已经学会了在他们在大型文本数据集的预训练期间隐含地执行广泛的任务。这使得模型概括，即要了解相关但以前看不见的任务，只有几个例子。</p><p>  Task Description: A short description of what the model should do, e.g. &#34;Translate English to French&#34;</p><p>  任务说明：简短描述模型应该做的事情，例如＆＃34;将英语翻译为法语＆＃34;</p><p> Examples: A few examples showing the model what it is expected to predict, e.g. &#34;sea otter =&gt; loutre de mer&#34;</p><p> 示例：一些例子，显示了预期预测的模型，例如预期。 ＆＃34;海獭=＆gt; loutre de mer＆＃34;</p><p> Prompt: The beginning of a new example, which the model should complete by generating the missing text, e.g. &#34;cheese =&gt; &#34;</p><p> 提示：通过生成丢失的文本，例如，该模型的开头，例如，该模型应该完成。 ＆＃34;奶酪=＆gt; ＆＃34; </p><p>  Creating these few-shot examples can be tricky, since you need to articulate the “task” you want the model to perform through them. A common issue is that models, especially smaller ones, are very sensitive to the way the examples are written.</p><p>创建这些几张镜头示例可能很棘手，因为您需要阐明“任务”，因此您希望模型通过它们执行。常见问题是模型，尤其更小的模型对描述的方式非常敏感。</p><p> An approach to optimize Few-Shot Learning in production is to learn a common representation for a task and then train task-specific classifiers on top of this representation.</p><p> 一种优化生产中的少量学习的方法是学习任务的共同表示，然后在此表示的顶部培训特定于特定于特定于特定的分类器。</p><p> OpenAI showed in the  GPT-3 Paper that the few-shot prompting ability improves with the number of language model parameters.</p><p> Openai在GPT-3纸上显示，几次射击提示能力随着语言模型参数的数量而改进。</p><p>  Let&#39;s now take a look at how at how GPT-Neo and the 🤗 Accelerated Inference API can be used to generate your own Few-Shot Learning predictions!</p><p>  Let＆＃39;现在看看如何使用GPT-NEO和🤗加速推理API来生成您自己的少量学习预测！</p><p>   GPT⁠-⁠Neo is a family of transformer-based language models from  EleutherAI based on the GPT architecture.  EleutherAI&#39;s primary goal is to train a model that is equivalent in size to GPT⁠-⁠3 and make it available to the public under an open license.</p><p>   GPT⁠-⁠neo是一系列来自Eleutherai的基于变压器的语言模型，基于GPT架构。 eleutherai＆＃39;初级目标是培训一个相当于尺寸的模型，以便在公开许可下向公众提供。</p><p> All of the currently available GPT-Neo checkpoints are trained with the Pile dataset, a large text corpus that is extensively documented in ( Gao et al., 2021). As such, it is expected to function better on the text that matches the distribution of its training text; we recommend keeping this in mind when designing your examples.</p><p> 所有当前可用的GPT-NEO检查点都接受了桩数据集，这是一个广泛记录的大文本语料库（Gao等，2021）。因此，预计将在与其培训文本分配匹配的文本上更好地运行;我们建议在设计示例时牢记这一点。</p><p>   The  Accelerated Inference API is our hosted service to run inference on any of the 10,000+ models publicly available on the 🤗 Model Hub, or your own private models, via simple API calls. The API includes acceleration on CPU and GPU with  up to 100x speedup compared to out of the box deployment of Transformers.</p><p>   加速推理API是我们的托管服务，以通过简单的API调用在「模型集线器上公开可用的10,000多种型号中的任何10,000多种型号的推理。 API包括CPU和GPU的加速，与OFFORMERERE的盒子部署相比，高速增速。 </p><p> To integrate Few-Shot Learning predictions with  GPT-Neo in your own apps, you can use the 🤗 Accelerated Inference API with the code snippet below. You can find your API Token  here, if you don&#39;t have an account you can get started  here.</p><p>要在您自己的应用程序中与GPT-Neo集成了几秒钟学习预测，您可以使用下面的代码片段的🤗加速推理API。如果您没有账户，您可以在此处找到您的API令牌，您可以在此处开始。</p><p> import json import requestsAPI_TOKEN =  &#34;&#34;  def  ( payload= &#39;&#39;,parameters= None,options={ &#39;use_cache&#39;:  False}): API_URL =  &#34;https://api-inference.huggingface.co/models/EleutherAI/gpt-neo-2.7B&#34; headers = { &#34;Authorization&#34;:  f&#34;Bearer  {API_TOKEN}&#34;} body = { &#34;inputs&#34;:payload, &#39;parameters&#39;:parameters, &#39;options&#39;:options} response = requests.request( &#34;POST&#34;, API_URL, headers=headers, data= json.dumps(body))  try: response.raise_for_status()  except requests.exceptions.HTTPError:  return  &#34;Error:&#34;+ &#34; &#34;.join(response.json()[ &#39;error&#39;])  else:  return response.json()[ 0][ &#39;generated_text&#39;]parameters = {  &#39;max_new_tokens&#39;: 25,  # number of generated tokens  &#39;temperature&#39;:  0.5,  # controlling the randomness of generations  &#39;end_sequence&#39;:  &#34;###&#34;  # stopping sequence for generation}prompt= &#34;....&#34;  # few-shot promptdata = query(prompt,parameters,options)</p><p> 导入JSON Import RequestSapi_Token =＆＃34;＆＃34; def（payload =＆＃39;＆＃39;，parameters = none，选项= {＆＃39; use_cache＆＃39 ;: false}）：api_url =＆＃34; https：//api-inference.huggingface.co /models/eleutherai/gpt-neoge.7b&#34;标题= {＆＃34;授权＆＃34 ;: f＆＃34;持票人{api_token}＆＃34;} body = {＆＃34;输入＆＃34;：有效载荷，＆＃39;参数＆＃39;：参数， ＆＃39;选项＆＃39;：选项} response} response = requests.request（＆＃34; post and＃34; api_url，headers =标题，data = json.dumps（body））尝试：response.raise_for_status（）除请求之外.Exceptions.httperror：返回＆＃34;错误：＆＃34; +＆＃34; ＆＃34; .join（response.json（）[＆＃39;错误＆＃39;]）else：return response.json（）[0] [＆＃39;生成_text＆＃39; parameters = {＆＃39 ; max_new_tokens＆＃39 ;: 25，生成的令牌的数量和＃39;温度＆＃39 ;: 0.5，＃控制几代人的随机性＆＃39; end_sequence＆＃39 ;:＆＃34; ###＆＃34; ＃停止生成序列}提示=＆＃34; ....＆＃34; ＃少量拍摄提示=查询（提示，参数，选项）</p><p>   Here are some practical insights, which help you get started using  GPT-Neo and the 🤗 Accelerated Inference API.</p><p>   以下是一些实用的见解，帮助您使用GPT-NEO和🤗加速推理API开始。</p><p> Since  GPT-Neo (2.7B) is about 60x smaller than  GPT-3 (175B), it does not generalize as well to zero-shot problems and needs 3-4 examples to achieve good results. When you provide more examples  GPT-Neo understands the task and takes the  end_sequence into account, which allows us to control the generated text pretty well.</p><p> 由于GPT-Neo（2.7b）小于GPT-3（175b），因此它不概括为零射击问题，并且需要3-4个例子来实现良好的结果。当您提供更多示例时，GPT-neo了解任务并将End_sequence占用，这允许我们控制生成的文本。</p><p>  The hyperparameter  End Sequence,  Token Length &amp;  Temperature can be used to control the  text-generation of the model and you can use this to your advantage to solve the task you need. The  Temperature controlls the randomness of your generations, lower temperature results in less random generations and higher temperature results in more random generations.</p><p>  封闭式计结束序列，令牌长度＆amp;温度可用于控制模型的文本生成，并且您可以将此用于解决您所需的任务。温度控制几代随机性，较低的温度导致随机的几代，更高的温度导致更多随机的几代。</p><p>  In the example, you can see how important it is to define your hyperparameter. These can make the difference between solving your task or failing miserably.</p><p>  在该示例中，您可以看到定义HyperParameter有多重要。这些可以在解决任务或恶作剧失败之间产生差异。</p><p>   Few-Shot Learning is a powerful technique but also presents unique pitfalls that need to be taken into account when designing uses cases.To illustrate this, let&#39;s consider the default  Sentiment Analysis setting provided in the widget. After seeing three examples of sentiment classification, the model makes the following predictions 4 times out of 5, with  temperature set to 0.1:</p><p>   很少拍摄的学习是一种强大的技术，但也呈现了在设计使用情况时需要考虑的独特陷阱。要示出此操作，请＆＃39; s考虑窗口小部件中提供的默认情绪分析设置。在看到三个情绪分类的例子之后，模型使以下预测值为5的4次，温度设定为0.1： </p><p>  What could go wrong? Imagine that you are using sentiment analysis to aggregate reviews of products on an online shopping website: a possible outcome could be that items useful to people with disabilities would be automatically down-ranked - a form of automated discrimination. For more on this specific issue, we recommend the ACL 2020 paper  Social Biases in NLP Models as Barriers for Persons with Disabilities. Because Few-Shot Learning relies more directly on information and associations picked up from pre-training, it makes it more sensitive to this type of failures.</p><p>什么可能出错？想象一下，您正在使用情感分析在网上购物网站上的产品汇总审查：可能的结果可以是对残疾人有用的物品将自动排放 - 一种自动歧视的形式。有关此具体问题的更多信息，我们建议将ACL 2020纸张社会偏见作为残疾人的障碍。由于少量学习更直接依赖于从预训练中拾取的信息和关联，因此它使其对这种类型的故障更敏感。</p><p>   Make sure people know which parts of their user experience depend on the outputs of the ML system</p><p>   确保人们知道其用户体验的哪些部分取决于ML系统的输出</p><p>  Provide a mechanism for users to give feedback on the model decision, and to override it</p><p>  提供了一种机制，让用户对模型决定提供反馈，并覆盖它</p><p> What needs most to be avoided is to use the model to automatically make decisions for, or about, a user, without opportunity for a human to provide input or correct the output. Several regulations, such as  GDPR in Europe, require that users be provided an explanation for automatic decisions made about them.</p><p> 最需要避免的是使用该模型来自动为用户自动做出决策，而不为人类提供输入或更正输出的机会。欧洲的若干法规（如GDPR）要求用户提供关于对其作出的自动决策的解释。</p><p>  To use GPT-Neo or any Hugging Face model in your own application, you can  start a free trial of the 🤗 Accelerated Inference API.If you need help mitigating bias in models and AI systems, or leveraging Few-Shot Learning, the 🤗 Expert Acceleration Program can  offer your team direct premium support from the Hugging Face team.</p><p>  要在您自己的应用程序中使用GPT-neo或任何拥抱面部模型，您可以开始自由试验的🤗加速推理API.IF您需要帮助缓解模型和AI系统的偏见，或利用少量学习，🤗专家加速计划可以从拥抱面部团队提供您的团队直接的优质支持。 </p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://huggingface.co/blog/few-shot-learning-gpt-neo-and-inference-api">https://huggingface.co/blog/few-shot-learning-gpt-neo-and-inference-api</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/学习/">#学习</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/learning/">#learning</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/模型/">#模型</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/谷歌/">#谷歌</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy;2012-2021 diglog.com </div></div></body></html>