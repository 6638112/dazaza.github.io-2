<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>OpenAI的新AI模型从文本中绘制图像 OpenAI's New AI Model Draws Images From Text</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">OpenAI's New AI Model Draws Images From Text<br/>OpenAI的新AI模型从文本中绘制图像 </h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2021-01-07 10:58:53</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2021/1/9bb78d54e6e3147eb1b4b9bea2ffbb8b.jpg"><img src="http://img2.diglog.com/img/2021/1/9bb78d54e6e3147eb1b4b9bea2ffbb8b.jpg" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>Stay on top of the latest market trends and economic insights with the Axios Markets newsletter. Sign up for free.</p><p>借助Axios Markets时事通讯，掌握最新的市场趋势和经济见解。免费注册。</p><p>    The machine learning company OpenAI is developing models  that improve computer vision and can produce original images from a text prompt.</p><p>    机器学习公司OpenAI正在开发可改善计算机视觉并可以从文本提示生成原始图像的模型。</p><p> Why it matters: The new models are the latest steps in ongoing  efforts to create machine learning systems that exhibit elements of general intelligence, while performing tasks that are actually useful in the real world — without breaking the bank on computing power.</p><p> 为何重要：新模型是不断努力的最新步骤，以创建具有通用情报元素的机器学习系统，同时执行在现实世界中实际有用的任务，而不会动摇计算能力。</p><p> What&#39;s happening: OpenAI today is announcing two new systems that attempt to do for images what its landmark GPT-3 model did last year for text generation.</p><p> 发生了什么：OpenAI今天宣布了两个新系统，这些系统试图对图像进行处理，这是其具有里程碑意义的GPT-3模型去年为生成文本所做的。</p><p> DALL-E is a neural network that can &#34;take any text and make an image out of it,&#34; says Ilya Sutskever, OpenAI co-founder and chief scientist. That includes concepts it would never have encountered in training, like the drawing of an anthropomorphic daikon radish walking a dog shown above.</p><p> DALL-E是一种神经网络，可以“提取任何文本并从中提取图像，” OpenAI联合创始人兼首席科学家Ilya Sutskever说。其中包括训练中从未遇到过的概念，例如上图所示的拟人化萝卜萝卜walking狗的图画。</p><p> Flashback: DALL-E operates somewhat similarly to GPT-3, the  huge transformer model that can generate original passages of text based on a short prompt.</p><p> 闪回：DALL-E的操作与GPT-3类似，后者是巨大的变形模型，可以根据简短提示生成原始文本段落。</p><p> CLIP, the other new neural network, &#34;can take any set of visual categories and instantly create very strong and reliable visually classifiable text descriptions,&#34; says Sutskever, improving on existing computer vision techniques with less training and expensive computational power.</p><p> CLIP，另一个新的神经网络，可以采用任何视觉类别集，并立即创建非常强大和可靠的视觉可分类文字描述，＆＃34; Sutskever说，以较少的培训和昂贵的计算能力改进了现有的计算机视觉技术。 </p><p> What they&#39;re saying: &#34;Last year, we were able to make substantial progress on text with GPT-3, but the thing is that the world isn&#39;t just built on text,&#34; says Sutskever. &#34;This is a step towards the grander goal of building a neural network that can work in both images and text.&#34;</p><p>他们在说什么：去年，我们能够在使用GPT-3的文本上取得实质性的进步，但事实是，世界并非仅建立在文本之上， Sutskever说。 ＆＃34;这是朝着建立可以同时处理图像和文本的神经网络这一宏伟目标迈出的一步。</p><p> How it works: DALL-E — a name OpenAI picked as a portmanteau of the surrealist artist Salvador Dali and the fatally cute Pixar robot WALL-E — is the model that jumps out because it aims to fulfill the Star Trek dream of simply being able to tell a computer, using regular language, what to create.</p><p> 工作原理：DALL-E（OpenAI被选为超现实主义艺术家Salvador Dali和致命可爱的皮克斯机器人WALL-E的肖像）是跳出来的模型，因为它旨在实现“星际迷航”的梦想：告诉计算机使用常规语言创建什么。</p><p> For example: Enter the prompt &#34;a can of soup that has the word &#39;skynet&#39; on it&#34; and you&#39;ll get images like the one below.</p><p> 例如：输入提示“一罐汤”，其中有单词“天窗”。在它上然后您将获得如下图所示的图像。</p><p>  &#34;It can take unrelated concepts that are nothing alike and put them together into a functional object,&#34; says Aditya Ramesh, the leader of the DALL-E team.</p><p>  ＆＃34;可以将不相干的无关概念放到一个功能对象中， DALL-E小组负责人Aditya Ramesh说。</p><p> CLIP can identify images with comparatively little training, allowing it to caption pictures it encounters.</p><p> CLIP只需很少的训练就可以识别图像，从而可以为遇到的图像添加字幕。</p><p> The model&#39;s real advantage is its efficiency, which is becoming a bigger issue in the field as the  computational cost of training machine learning models only grows.</p><p> 该模型的真正优势在于它的效率，这随着训练机器学习模型的计算成本的增长而在领域内变得越来越重要。</p><p> Yes, but: Like GPT-3, the new models are far from perfect, with DALL-E, in particular, dependent on exactly how the text prompt is phrased if it&#39;s to be able to generate a coherent image.</p><p> 是的，但是：与GPT-3一样，新模型也远非完美，特别是DALL-E取决于是否能够生成连贯图像的文本提示的确切用语方式。 </p><p> The bottom line: Artificial general intelligence may be getting closer, one doodle at a time.</p><p>底线：人工智能可能越来越近，一次涂鸦。 </p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://www.axios.com/openai-artificial-intelligence-model-images-dall-e-5c977633-81cd-450c-8ce5-a30e5f0e90e7.html">https://www.axios.com/openai-artificial-intelligence-model-images-dall-e-5c977633-81cd-450c-8ce5-a30e5f0e90e7.html</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/模型/">#模型</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/ai/">#ai</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/图像/">#图像</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/分享/">#分享</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy; 2020 diglog.com </div></div></body></html>