<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>神经元通过预测未来的活动来学习Neurons learn by predicting future activity</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">Neurons learn by predicting future activity<br/>神经元通过预测未来的活动来学习</h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2022-02-17 10:35:37</div><div class="page_narrow text-break page_content"><p>Understanding how the brain learns may lead to machines with human-like intellectual capacities. It was previously proposed that the brain may operate on the principle of predictive coding. However, it is still not well understood how a predictive system could be implemented in the brain. Here we demonstrate that the ability of a single neuron to predict its future activity may provide an effective learning mechanism. Interestingly, this predictive learning rule can be derived from a metabolic principle, whereby neurons need to minimize their own synaptic activity (cost) while maximizing their impact on local blood supply by recruiting other neurons. We show how this mathematically derived learning rule can provide a theoretical connection between diverse types of brain-inspired algorithm, thus offering a step towards the development of a general theory of neuronal learning. We tested this predictive learning rule in neural network simulations and in data recorded from awake animals. Our results also suggest that spontaneous brain activity provides ‘training data’ for neurons to learn to predict cortical dynamics. Thus, the ability of a single neuron to minimize surprise—that is, the difference between actual and expected activity—could be an important missing element to understand computation in the brain.</p><p>了解大脑如何学习可能会导致机器具有人类一样的智能能力。此前有人提出，大脑可以根据预测编码的原理运作。然而，预测系统是如何在大脑中实现的，目前尚不清楚。在这里，我们证明了单个神经元预测其未来活动的能力可能提供了一种有效的学习机制。有趣的是，这种预测性学习规则可以从代谢原理中推导出来，根据代谢原理，神经元需要最小化自身的突触活动（成本），同时通过招募其他神经元来最大化对局部血液供应的影响。我们展示了这种数学推导的学习规则如何在不同类型的大脑启发算法之间提供理论联系，从而为神经元学习的一般理论的发展提供了一个步骤。我们在神经网络模拟和清醒动物记录的数据中测试了这种预测性学习规则。我们的结果还表明，自发的大脑活动为神经元学习预测皮质动力学提供了“训练数据”。因此，单个神经元将惊喜最小化的能力，即实际活动和预期活动之间的差异，可能是理解大脑中计算的一个重要缺失元素。</p><p>     Neuroscience is at the stage biology was at before Darwin. It has a myriad of detailed observations but no single theory explaining the connections between all of those observations. We do not even know if such a brain theory should be at the molecular level or at the level of brain regions, or at any scale between. However, looking at deep neural networks, which have achieved remarkable results in tasks ranging from cancer detection to self-driving cars, may provide useful insights. Although such networks may have different inputs and architectures, most of their impressive behaviour can be understood in terms of the underlying common learning algorithm, called backpropagation  1.</p><p>神经科学正处于生物学在达尔文之前的阶段。它有无数详细的观察结果，但没有单一的理论解释所有这些观察结果之间的联系。我们甚至不知道这样的大脑理论应该是在分子水平上，还是在大脑区域的水平上，或者在两者之间的任何尺度上。然而，深入研究在癌症检测到自动驾驶汽车等任务中取得显著成果的深层神经网络可能会提供有用的见解。尽管这类网络可能有不同的输入和结构，但它们的大多数令人印象深刻的行为都可以通过底层的通用学习算法（称为反向传播1）来理解。</p><p> A better understanding of the learning algorithm(s) used by the brain could thus be central to developing a unifying theory of brain function. There are two main approaches to investigating learning mechanisms in the brain: (1) experimental, where persistent changes in neuronal activity are induced by a specific intervention  2, and (2) computational, where algorithms are developed to achieve specific computational objectives while still satisfying selected biological constraints  3, 4. In this Article we explore an additional option—(3) theoretical derivation—where a learning rule is derived from basic cellular principles, that is, from maximizing the metabolic energy of a cell. Using this approach, we found that maximizing the energy balance by a neuron leads to a predictive learning rule, where a neuron adjusts its synaptic weights to minimize surprise—that is, the difference between actual and predicted activity. Interestingly, this derived learning rule has a direct relation to some of the most promising biologically inspired learning algorithms, like predictive coding and temporal difference learning (see below), and Hebbian-based rules can be seen as a special case of our predictive learning rule ( Discussion). Thus, our approach may provide a theoretical connection between multiple brain-inspired algorithms and may offer a step towards the development of a unified theory of neuronal learning.</p><p>因此，更好地理解大脑使用的学习算法可能是发展统一的大脑功能理论的核心。有两种主要的方法来研究大脑中的学习机制：（1）实验性的，神经元活动的持续变化是由特定的干预引起的；（2）计算性的，算法的开发是为了实现特定的计算目标，同时仍然满足选定的生物约束3,4。在这篇文章中，我们探索了另一个选项—（3）理论推导，其中学习规则源自基本的细胞原理，即最大化细胞的代谢能量。使用这种方法，我们发现最大化神经元的能量平衡会产生一种预测性学习规则，在这种规则中，神经元会调整其突触权重，以最小化惊喜，即实际活动和预测活动之间的差异。有趣的是，这种衍生的学习规则与一些最有前途的生物启发学习算法有直接关系，比如预测编码和时间差分学习（见下文），基于Hebbian的规则可以被视为我们预测学习规则的特例（讨论）。因此，我们的方法可能在多个大脑启发算法之间提供理论联系，并可能为神经元学习的统一理论的发展提供一个步骤。</p><p> There are multiple lines of evidence suggesting that the brain operates as a predictive system  5, 6, 7, 8, 9, 10. However, it remains controversial as to how exactly predictive coding could be implemented in the brain  4. Most of the proposed mechanisms involve specially designed neuronal circuits with ‘error units’ to allow for comparing expected and actual activity  11, 12, 13, 14. Those models assume a predictive circuit, but we propose an alternative, where there is an internal predictive model within a neuron. As many basic properties of neurons are highly conserved throughout evolution  15, 16, 17, we suggest that a single neuron using a predictive learning rule could provide an elementary unit from which a variety of predictive brains may be built.</p><p>有多条证据表明，大脑作为一个预测系统运行5、6、7、8、9、10。然而，如何在大脑中实现精确的预测编码仍然存在争议。大多数提出的机制都涉及专门设计的带有“错误单元”的神经元电路，以便比较预期和实际活动11、12、13、14。这些模型假设了一个预测电路，但我们提出了一个替代方案，即在神经元内有一个内部预测模型。由于神经元的许多基本属性在整个进化过程中高度保守15、16、17，我们认为，使用预测性学习规则的单个神经元可以提供一个基本单元，从中可以构建各种预测性大脑。</p><p> Interestingly, our predictive learning rule can also be obtained by modifying a temporal difference learning algorithm to be more biologically plausible. Temporal difference learning is one of the most promising ideas about how backpropagation-like algorithms could be implemented in the brain. It is based on using differences in neuronal activity to approximate top-down error signals  4, 18, 19, 20, 21, 22, 23, 24. A typical example of such algorithms is contrastive Hebbian learning  25, 26, 27, which was proven to be equivalent to backpropagation under certain assumptions  28. Contrastive Hebbian learning requires networks to have reciprocal connections between hidden and output layers, which allows activity to propagate in both directions (Fig.  1a). The learning consists of two separate phases. First, in the ‘free phase’, a sample stimulus is continuously presented to the input layer and the activity propagates through the network until the dynamics converge to an equilibrium (the activity of each neuron achieves a steady-state level). In the second ‘clamped phase’, in addition to presenting a stimulus to the input, the output neurons are also held clamped at values representing the stimulus category (for example, 0 or 1), and the network is again allowed to converge to an equilibrium. For each neuron, the difference between activity in the clamped ( \({\hat {x}}\)) and free ( \({\check{x}}\)) phases is used to modify the synaptic weights ( w) according to the equation</p><p>有趣的是，我们的预测学习规则也可以通过修改时间差分学习算法来获得，使其在生物学上更合理。关于如何在大脑中实现类似反向传播的算法，时间差分学习是最有前途的想法之一。它基于神经元活动的差异来近似自上而下的错误信号4、18、19、20、21、22、23、24。这种算法的一个典型例子是对比Hebbian学习25、26、27，在某些假设28下，这被证明相当于反向传播。对比赫布式学习要求网络在隐藏层和输出层之间具有相互联系，这允许活动在两个方向上传播（图1a）。学习包括两个独立的阶段。首先，在“自由阶段”，一个样本刺激持续呈现给输入层，活动通过网络传播，直到动力学收敛到平衡（每个神经元的活动达到稳态水平）。在第二个“钳制阶段”，除了向输入呈现刺激外，输出神经元也被钳制在代表刺激类别的值上（例如，0或1），网络再次被允许收敛到平衡。对于每个神经元，钳制（\（{hat{x}}\）和自由（\（{check{x}}\）阶段的活动之间的差异用于根据方程式修改突触重量（w）</p><p>  where  i and  j are indices of pre- and post-synaptic neurons respectively, and  α is a small number representing the learning rate. Intuitively, this can be seen as adjusting weights to push each neuron’s activity in the free phase closer to the desired activity represented by the clamped phase. The obvious biological plausibility issue with this algorithm is that it requires the neuron to experience exactly the same stimulus twice in two separate phases, and that the neuron needs to ‘remember’ its activity from the previous phase. Our predictive learning rule provides a solution to this problem by predicting the free-phase steady-state activity, thus eliminating the requirement for two separate stimulus presentations.</p><p>其中i和j分别是突触前和突触后神经元的指数，α是代表学习率的一个小数字。直观地说，这可以被视为调整权重，使自由期的每个神经元的活动更接近钳制期所代表的期望活动。这种算法明显的生物学合理性问题是，它要求神经元在两个不同阶段经历两次完全相同的刺激，并且神经元需要“记住”前一阶段的活动。我们的预测学习规则通过预测自由相稳态活动来解决这个问题，从而消除了对两个单独刺激呈现的要求。</p><p> a, Schematic of the network. Note that activity propagates back and forth between hidden and output layers.  b, Sample neuron activity in the free phase in response to different stimuli (marked with shades of blue). The free-phase responses are used to train a linear model to predict a steady-state activity from the activity at earlier time steps (marked by the shaded area; see main text for details). The bottom traces show the duration of the inputs, and dots represent predicted activity.  c, Activity of a neuron in response to a new stimulus with the network output clamped. Initially, the network receives only the input signal (free phase), but, after a few steps, the output signal is also presented (clamped phase, bottom black trace). The red dot represents the steady-state free-phase activity predicted from the initial activity (the shaded region). For comparison, the dashed line shows a neuron’s activity in the free phase if the output is not clamped. Synaptic weights ( w) are adjusted in proportion to the difference between steady-state activity in the clamped phase ( \({\hat {x}}\)) and the predicted free-phase activity ( \({\tilde {x}}\)).</p><p>a、 网络示意图。请注意，活动在隐藏层和输出层之间来回传播。b、 在自由期对不同刺激（以蓝色阴影标记）做出反应的神经元活动样本。自由相响应用于训练线性模型，以根据早期时间步的活动预测稳态活动（用阴影区域标记；详情见正文）。底部的轨迹显示输入的持续时间，点表示预测的活动。c、 神经元在网络输出被钳制的情况下对新刺激作出反应的活动。最初，网络只接收输入信号（自由相位），但经过几步之后，输出信号也会出现（钳制相位，底部黑色轨迹）。红点代表从初始活动（阴影区域）预测的稳态自由相活动。为了进行比较，虚线显示了在输出未被钳制的情况下，神经元在自由期的活动。突触重量（w）根据钳制期的稳态活动（\（{hat{x}}\）和预测的自由期活动（\（{tilde{x}}\）之间的差异成比例调整。</p><p> For clarity here, first we will describe how our predictive learning rule can be obtained by modifying the contrastive Hebbian learning algorithm. Next, we will validate the predictive learning rule in simulation and in data recorded from awake animals, and we will show how our results shed new light on the function of spontaneous activity. The details of derivation of the learning rule by maximizing the neuron energy balance will be presented at the end.</p><p>为了清楚起见，首先我们将描述如何通过修改对比Hebbian学习算法来获得预测学习规则。接下来，我们将在模拟和清醒动物记录的数据中验证预测性学习规则，并展示我们的结果如何为自发活动的功能提供新的启示。最后将详细介绍通过最大化神经元能量平衡来推导学习规则的过程。</p><p> As mentioned earlier, the contrastive Hebbian learning algorithm requires a network to converge to steady-state equilibrium in two separate learning phases, so exactly the same stimulus has to be presented twice. However, this is unlikely to be the case in the actual brain. Here we propose to solve this problem by combining both activity phases into one, which is inspired by sensory processing in the cortex. For example, in visual areas, when presented with a new picture, there is initially bottom-up-driven activity containing mostly visual attributes of the stimulus (for example, contours). This is then followed by top-down modulation containing more abstract information, such as ‘this object is a member of category  x’ or ‘this object is novel’ (Supplementary Fig.  1). Accordingly, our algorithm first runs only the initial part of the free phase, which represents bottom-up stimulus-driven activity, and then, after a few steps, the network output is clamped, corresponding to top-down modulation.</p><p>如前所述，对比Hebbian学习算法要求网络在两个独立的学习阶段收敛到稳态平衡，因此必须两次呈现完全相同的刺激。然而，实际大脑中不太可能出现这种情况。在这里，我们建议通过将两个活动阶段合并为一个阶段来解决这个问题，这是受到皮层感觉处理的启发。例如，在视觉区域中，当呈现一张新图片时，最初会有自下而上的驱动活动，其中主要包含刺激的视觉属性（例如轮廓）。随后是包含更多抽象信息的自上而下调制，例如“该对象是类别x的成员”或“该对象是新颖的”（补充图1）。因此，我们的算法首先只运行自由阶段的初始部分，这代表了自下而上的刺激驱动活动，然后，经过几步之后，网络输出被钳制，对应于自上而下的调制。</p><p> The novel insight here is that the initial bottom-up activity is enough to allow neurons to predict the steady-state part of the free-phase activity, and the mismatch between the predicted free phase and the clamped phase can then be used as a teaching signal. To implement this idea in our model, for each neuron, activity during 12 initial time steps of the free phase ( \({\check{x}_{(1)}}\), ...,  \({\check{x}_{(12)}}\)) was used to predict its steady-state activity at time step 120,  \({\check{x}_{(120)}}\) (Fig.  1b). Specifically, we first presented sample stimuli in the free phase to train a linear model, such that  \({\check{x}_{(120)}\approx{\tilde {x}} = {\lambda _{(1)} \check{x}_{(1)}, + \ldots + \lambda _{(12)} \check{x}_{(12)} + {b}}}\), where  \({\tilde {x}}\) denote predicted activity,  λ and  b correspond to coefficients and offset term of the least-squares model, and terms in brackets correspond to time steps. Next, a new set of stimuli was used for which the free phase was run only for the first 12 steps, and from step 13 the network output was clamped (Fig.  1c). The above least-squares model was then applied to predict the free-phase steady-state activity for each neuron, and the weights were updated based on the difference between predicted and clamped activity ( Methods). Thus, to modify the synaptic weights, in equation ( 1) we replace the activity in the free phase with predicted activity ( \({\tilde {x}}\)):</p><p>这里的新见解是，初始自底向上的活动足以让神经元预测自由相活动的稳态部分，并且预测的自由相和钳制相之间的失配可以用作教学信号。为了在我们的模型中实现这个想法，对于每个神经元，在自由期的12个初始时间步（\（{check{x}{u{（1）}\）内的活动， ...,  \（{check{x}{（12）}}\）用于预测其在时间步120的稳态活动，\（{check{x}{（120）}\）（图1b）。具体地说，我们首先提出了自由阶段的样本刺激来训练线性模型，例如\（{check{x}{（120）}\approx{tilde{x}={\lambda{（1）}\check{x}{（1）}，+\ldots+\lambda{（12）}\check{x}{（12）{b}），其中\（{tilde{x}）表示预测的活动，λ和b对应于最小二乘模型的系数和偏移项，括号中的项对应于时间步长。接下来，使用一组新的刺激物，仅在前12个步骤中运行自由相，并从步骤13开始钳制网络输出（图1c）。然后应用上述最小二乘模型预测每个神经元的自由相稳态活动，并根据预测和钳制活动之间的差异更新权重（方法）。因此，为了修改突触重量，在方程式（1）中，我们用预测的活动（\（{tilde{x}}\）替换自由期的活动：</p><p>  However, the problem is that this equation implies that a neuron needs also to know the predicted activity of all its presynaptic neurons ( \({\tilde {x}_{i}}\)), which may not be realistic. To solve this problem, we replaced ( \({\tilde {x}_{i}}\)) by the actual presynaptic activity in the clamped phase ( \({\hat {x}_{i}}\)), which we validated in network simulations (see the next section). This change leads to the following simplified synaptic plasticity rule (equation ( 3)):</p><p>然而，问题是，这个等式意味着一个神经元还需要知道其所有突触前神经元的预测活动（\（{tilde{x}{i}\），这可能是不现实的。为了解决这个问题，我们用钳制阶段的实际突触前活动（\（{hat{x}{i}}）代替（\（{tilde{x}}{i}]），我们在网络模拟中验证了这一点（见下一节）。这种变化导致以下简化的突触可塑性规则（方程式（3））：</p><p> $${\Delta {w}_{ij}} = {\alpha ({\hat {x}_{i}}{\hat {x}_{j}} - {\hat {x}_{i}}{\tilde {x}_{j}})} = {\alpha {\hat {x}_{i}}({\hat {x}_{j}} - {\tilde {x}_{j}})}.$$</p><p>$${\Delta{w}{ij}={\alpha（{\hat{x}}{i}}{\hat{x}}{j}-{\hat{x}{i}{i}{\tilde{x}{j}}}={\alpha{hat{x}{i}{j}{$$</p><p> Thus, to modify the synaptic weights, a neuron only compares its actual activity ( \({\hat {x}_{j}}\)) with its predicted activity ( \({\tilde {x}_{j}}\)), and applies this difference in proportion to each input contribution ( \({\hat {x}_{i}}\)).</p><p>因此，为了修改突触权重，神经元只会将其实际活动（\（{hat{x}{j}）与其预测活动（\（{tilde{x}{uj}）进行比较，并将此差异按比例应用于每个输入贡献（\（{hat{x}{uj}]）。</p><p>  To test if the predictive learning rule can be used to solve standard machine learning tasks, we created the following simulation. The neural network had 784 input units, 1,000 hidden units and 10 output units, and it was trained on a handwritten digit recognition task (MNIST  29; Supplementary Fig.  2 and  Methods). This network achieved 1.9% error rate, which is similar to neural networks with comparable architecture trained with the backpropagation algorithm  29. This demonstrates that the network with the predictive learning rule can solve challenging nonlinear classification tasks.</p><p>为了测试预测学习规则是否可以用于解决标准的机器学习任务，我们创建了以下模拟。该神经网络有784个输入单元、1000个隐藏单元和10个输出单元，并在手写数字识别任务上进行训练（MNIST 29；补充图2和方法）。该网络实现了1.9%的错误率，这与使用反向传播算法29训练的具有类似结构的神经网络相似。这表明，具有预测学习规则的网络可以解决具有挑战性的非线性分类任务。</p><p> To verify that the neurons could correctly predict future free-phase activity, we took a closer look at sample neurons. Figure  2a presents the activity of all ten output neurons in response to an image of a sample digit after the first epoch of training. During time steps 1–12, only the input signal was presented and the network was running in the free phase. At time step 13, the output neurons were clamped, with the activity of nine neurons set to 0 and the activity of one neuron, representing the correct image class, set to 1. For comparison, this figure also shows the activity of the same neurons without clamped outputs (free phase). It illustrates that, after about 50 steps in the free phase, the network achieves a steady state, with predicted activity closely matching. When the network is fully trained, it still takes about 50 steps for the network dynamics in the free phase to converge to a steady state (Fig.  2b). Note that, although all units initially increase their activity at the beginning of the free phase, they later converge close to 0, except the one unit representing the correct category. Again, predictions made from the first 12 steps during the free phase closely matched the actual steady-state activity. The hidden units also converged to a steady state after about 50 steps. Figure  2c illustrates the response of one representative hidden neuron to five sample stimuli. Because hidden units experience the clamped signal only indirectly, through synapses from output neurons, their steady-state activity is not bound to converge only to 0 or 1, as in the case of output neurons. Actual and predicted steady-state activity for hidden neurons is presented in Fig.  2d. The average correlation coefficient between predicted and actual free-phase activity was  R = 1 ± 0.0001 s.d. (averaged across 1,000 hidden neurons in response to 200 randomly selected test images). Note that we always used a cross-validation approach, where we trained a predictive model for each neuron on a subset of the data and applied that model to new examples, which were then used for updating the weights ( Methods). Thus, neurons were able to successfully generalize their predictions to new unseen stimuli. The network error rates for the training and test datasets are shown in Fig.  2e. This demonstrates that the predictive learning rule worked well, and each neuron accurately predicted its future activity.</p><p>为了验证神经元能够正确预测未来的自由相活动，我们仔细观察了样本神经元。图2a显示了在第一次训练后，所有十个输出神经元对样本数字图像的反应。在时间步长1–12期间，仅显示输入信号，网络在空闲阶段运行。在时间步13，输出神经元被钳制，九个神经元的活动设置为0，代表正确图像类别的一个神经元的活动设置为1。为了进行比较，该图还显示了没有钳制输出（自由相）的相同神经元的活动。它表明，在自由阶段大约50步后，网络达到稳定状态，预测的活动密切匹配。当网络完全训练时，自由阶段的网络动力学仍需要大约50步才能收敛到稳定状态（图2b）。请注意，尽管所有单位最初在自由阶段开始时都会增加其活动，但它们后来会收敛到接近0，但代表正确类别的一个单位除外。同样，自由阶段前12步的预测与实际的稳态活动非常吻合。隐藏单元在大约50步后也收敛到稳定状态。图2c显示了一个具有代表性的隐藏神经元对五种样本刺激的反应。因为隐藏单元只能通过输出神经元的突触间接感受钳制信号，所以它们的稳态活动不一定像输出神经元那样只收敛到0或1。隐藏神经元的实际和预测稳态活动如图2d所示。预测自由相活度与实际自由相活度之间的平均相关系数为R = 1. ± 0.0001 s、 d.（对随机选择的200张测试图像进行1000个隐藏神经元的平均反应）。请注意，我们总是使用交叉验证方法，在这种方法中，我们根据数据子集为每个神经元训练一个预测模型，并将该模型应用于新的示例，然后用于更新权重（方法）。因此，神经元能够成功地将他们的预测推广到新的看不见的刺激。训练和测试数据集的网络错误率如图2e所示。这表明预测性学习规则运行良好，每个神经元都能准确预测其未来的活动。</p><p> a, Activity of ten output neurons in response to a sample stimulus at the beginning of network training. The grey shaded area indicates the extent of the free phase (time steps 1–12). Solid red lines show activity of the neurons clamped at step 13. For comparison, dashed lines represent the free-phase activity if the output neurons had not been clamped. Dots show the predicted steady-state activity in the free phase based on initial activity (from steps 1–12).  b, Activity of the same neurons after network training. Note that the free-phase and predicted activities converged to the desired clamped activity.  c, Activity of a representative neuron in the hidden layer in response to five different stimuli after network training. Solid and dashed lines represent clamped and free phases, respectively, and dots show predicted activity.  d, Predicted versus actual free-phase activity. For clarity, only every 10th hidden neuron out of 1,000 is shown, in response to 20 sample images. Different colours represent different neurons, but some neurons may share the same colour due to the limited number of colours. The distribution of points along the diagonal shows that the predictions are accurate.  e, Decrease in error rate across training epochs. Yellow and green lines denote learning curves for the training and test datasets, respectively. Note that, in each epoch, we only used 2% of 60,000 training examples.</p><p>a、 在网络训练开始时，十个输出神经元对样本刺激的反应。灰色阴影区域表示自由阶段的范围（时间步长1–12）。红色实线显示在第13步被钳制的神经元的活动。为了进行比较，虚线表示输出神经元未被钳制时的自由相活动。圆点表示根据初始活性（步骤1-12）预测的自由相稳态活性。b、 网络训练后相同神经元的活动。请注意，自由相和预测的活动收敛到所需的钳制活动。c、 网络训练后，隐层中代表性神经元对五种不同刺激的反应。实线和虚线分别表示固定相和自由相，点表示预测的活性。d、 预测自由相活动与实际自由相活动。为了清晰起见，在1000个隐藏神经元中，只有每10个被显示，以回应20个样本图像。不同的颜色代表不同的神经元，但由于颜色的数量有限，一些神经元可能共享相同的颜色。点沿对角线的分布表明预测是准确的。e、 在不同的训练时期，错误率降低。黄线和绿线分别表示训练和测试数据集的学习曲线。请注意，在每个时代，我们只使用了60000个培训示例中的2%。</p><p>  We also tested the predictive learning rule in multiple other network architectures, which were designed to reflect additional aspects of biological neuronal networks. First, we introduced a constraint that 80% of the hidden neurons were excitatory and the remaining 20% had only inhibitory outputs. This follows observations that biological neurons release either excitatory or inhibitory neurotransmitters, not both (Dale’s law  30), and that ~80% of cortical neurons are excitatory. The network with this architecture achieved an error rate of 2.66% (Supplementary Fig.  3a). We also tested our algorithm in a network without symmetric weights, which resulted in a performance similar to the original network (1.96%, Supplementary Fig.  3b). Moreover, we implemented the predictive learning rule in a network with spiking neurons, which again achieved a similar error rate of 2.46% (Supplementary Fig.  4). Our predictive learning rule was further tested in a deep convolutional network (Fig.  3a), the architecture of which has been shown to resemble neuronal processing in the visual system  31, 32. Using this convolutional network, we tested our algorithm on a more challenging dataset for biologically inspired algorithms: CIFAR-10  33. This dataset consists of colour images representing ten different classes (for example, aeroplanes, cars, birds and cats). We achieved an error rate of 20.03%, which was comparable with that achieved training the same network using a backpropagation through time (BPTT) algorithm (Fig.  3b; details are provided in the  Methods and code to reproduce the results is available at  https://github.com/ykubo82/bioCHL/tree/master/conv). Altogether, this shows that our predictive learning rule performs well in a variety of biologically motivated network architectures.</p><p>我们还在多个其他网络架构中测试了预测学习规则，这些架构旨在反映生物神经元网络的其他方面。首先，我们引入了一个约束，即80%的隐藏神经元是兴奋性的，剩下的20%只有抑制性输出。这是因为观察到生物神经元释放兴奋性或抑制性神经递质，而不是两者都释放（Dale定律30），约80%的皮层神经元是兴奋性的。采用这种结构的网络实现了2.66%的错误率（补充图3a）。我们还在一个没有对称权重的网络中测试了我们的算法，其性能与原始网络类似（1.96%，补充图3b）。此外，我们在一个带有尖峰神经元的网络中实现了预测学习规则，再次获得了2.46%的类似错误率（补充图4）。我们的预测学习规则在深度卷积网络中得到了进一步测试（图3a），其结构已被证明类似于视觉系统31、32中的神经元处理。利用这个卷积网络，我们在一个更具挑战性的数据集上测试了我们的算法，该数据集是受生物启发的算法：CIFAR-10 33。该数据集由代表十个不同类别（例如飞机、汽车、鸟类和猫）的彩色图像组成。我们实现了20.03%的错误率，与使用时间反向传播（BPTT）算法训练同一网络的错误率相当（图3b；方法和代码中提供了详细信息，重现结果可在https://github.com/ykubo82/bioCHL/tree/master/conv)总之，这表明我们的预测学习规则在各种生物动机的网络架构中表现良好。</p><p> a, Depiction of our convolutional (Conv.) network architecture ( Methods).  b, Learning curve for the convolutional network trained using the predictive (Pred.) learning rule (green) and, for comparison, learning curves for the same network trained using BPTT. The red line shows a learning curve for BPTT using the same learning rates as in our predictive model (red line; LR: 0.4, 0.028, 0.025), BPTT with a learning rate of 0.1 for all layers (yellow line) and BPTT with a learning rate of 0.2 for all layers (violet line). This shows that, on CIFAR-10, the performance of the deep network using our predictive learning rule was comparable with that of BPTT.</p><p>a、 描述我们的卷积（Conv.）网络架构（方法）。b、 使用预测（Pred.）训练的卷积网络的学习曲线学习规则（绿色）和使用BPTT训练的同一网络的学习曲线，用于比较。红线显示了BPTT的学习曲线，使用与我们的预测模型相同的学习率（红线；LR:0.4,0.028,0.025），BPTT所有层的学习率为0.1（黄线），BPTT所有层的学习率为0.2（紫线）。这表明，在CIFAR-10上，使用我们的预测学习规则的深度网络的性能与BPTT相当。</p><p>  To test whether real neurons could also predict their future activity, we analysed neuronal recordings from the auditory cortex in awake rats ( Methods). As stimuli we presented six tones, each 1 s long and interspersed by 1 s of silence, repeated continuously for over 20 min. ( Supplementary Information). For each of the six tones we separately calculated the average onset and offset response, giving us 12 different activity profiles for each neuron (Fig.  4a). For each stimulus, the activity in the 15–25 ms time window was used to predict average future activity within the 30–40 ms window. We used 12-fold cross-validation, whereby responses from 11 stimuli were used to train the least-squares model, which was then applied to predict neuron activity for the one remaining stimulus. This procedure was repeated 12 times for each neuron. The average correlation coefficient between actual and predicted activity was  R = 0.36 ± 0.05 s.e.m. (averaged across 55 cells from four animals; Fig.  4b). The distributions of correlation coefficients for individual neurons were significantly different from 0 ( t-test  P &lt; 0.0001; all tests were two-sided; inset, Fig.  4b). This shows that neurons have predictable dynamics and, from an initial neuronal response, their future activity can be estimated.</p><p>为了测试真实神经元是否也能预测其未来的活动，我们分析了清醒大鼠听觉皮层的神经元记录（方法）。作为刺激，我们呈现了六个音调，每个音调1 它很长，中间有1个 持续20多次的沉默 min.（补充信息）。对于六个音调中的每一个，我们分别计算了平均起始和偏移反应，为每个神经元提供了12种不同的活动模式（图4a）。对于每个刺激，15-25分钟的活动 ms时间窗用于预测30-40年内的平均未来活动 window女士。我们使用12倍交叉验证，其中来自11个刺激的反应用于训练最小二乘模型，然后应用最小二乘模型预测剩余刺激的神经元活动。这个过程对每个神经元重复12次。实际活性和预测活性之间的平均相关系数为R = 0.36 ± 0.05 s.e.m.（四只动物55个细胞的平均值；图4b）。单个神经元的相关系数分布与0显著不同（t检验P &书信电报； 0.0001; 所有测试都是双向的；插图，图4b）。这表明神经元具有可预测的动力学，并且，从最初的神经元反应，可以估计它们未来的活动。</p><p> a, Response of a representative neuron to different stimuli. For visualization, only 5 out of 12 responses are shown. The grey shaded area indicates the time window that was used to predict future activity. Dots show the predicted average activity in the 30–40 ms time window. Colours correspond to different stimuli.  b</p><p>a、 代表性神经元对不同刺激的反应。为了可视化，12个响应中只有5个显示出来。灰色阴影区域表示用于预测未来活动的时间窗口。圆点显示了30-40年的预测平均活动 ms时间窗口。颜色对应不同的刺激。B</p><p>......</p><p>......</p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/预测/">#预测</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/learn/">#learn</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/神经元/">#神经元</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/谷歌/">#谷歌</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy;2012-2021 diglog.com </div></div></body></html>