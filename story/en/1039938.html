<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>我希望有人告诉我有关Tensor计算库的信息 What I Wish Someone Had Told Me About Tensor Computation Libraries</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">What I Wish Someone Had Told Me About Tensor Computation Libraries<br/>我希望有人告诉我有关Tensor计算库的信息 </h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2020-12-16 05:02:50</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2020/12/32690c137a79d52b5546cb9e31ac2013.png"><img src="http://img2.diglog.com/img/2020/12/32690c137a79d52b5546cb9e31ac2013.png" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>In this blog post, we’ll break down what tensor computation libraries actually are, and how they differ. We’ll take a detailed look at some popular libraries, and end with an observation on the future of Theano in the context of contemporary tensor computation libraries.</p><p>在此博客文章中，我们将分解张量计算库的实际含义以及它们之间的区别。我们将详细介绍一些流行的库，最后以当代张量计算库为背景对Theano的未来进行观察。</p><p> I get confused with tensor computation libraries (or computational graph libraries, or symbolicalgebra libraries, or whatever they’re marketing themselves as these days).</p><p> 我对张量计算库（或计算图库，或符号代数库，或当今它们正在推销的任何内容）感到困惑。</p><p> I was first introduced to PyTorch and TensorFlow and, having no other reference, thought they wereprototypical examples of tensor computation libraries. Then I learnt about Theano - an older andless popular project, but different from PyTorch and TensorFlow and better in some meaningful ways.This was followed by JAX, which seemed to be basically NumPy with more bells and whistles (althoughI couldn’t articulate what exactly they were). Then came  the announcement by the PyMC developersthat Theano would have a new JAXbackend.</p><p> 我最初被介绍给PyTorch和TensorFlow，并且在没有其他参考的情况下认为它们是张量计算库的典型示例。然后我了解了Theano-一个较旧且流行的项目，但与PyTorch和TensorFlow有所不同，并且在一些有意义的方式上有所改进.JAX之后是它，它基本上是NumPy，带有更多的花哨功能（尽管我无法确切说明他们是）。然后，PyMC开发人员宣布Theano将拥有一个新的JAXbackend。</p><p>  Similar to  my previous post on the anatomy of probabilistic programmingframeworks, I’ll first discuss tensor computationlibraries in general - what they are and how they can differ from one another. Then I’ll discusssome libraries in detail, and finally offer an observation on the future of Theano in the context ofcontemporary tensor computation libraries.</p><p>  与我之前关于概率编程框架剖析的帖子类似，我将首先讨论一般的张量计算库-它们是什么以及它们之间的区别。然后，我将详细讨论一些库，最后在当代张量计算库的背景下对Theano的未来进行观察。</p><p>   They run the computation itself (duh), but also run “related” computations that either (a)  usethe computational graph, or (b) operate  directly on the computational graph itself, A good example of the latter is optimizing the computation itself: think symbolicsimplifications (e.g.  xy/x = y) or modifications for numerical stability (e.g.   log(1 + x)for small values of  x).</p><p>   他们运行计算本身（duh），但也运行“相关”计算，它们要么（a）使用计算图，要么（b）直接对计算图本身进行操作，后者的一个很好的例子是优化计算本身：思考符号简化（例如xy / x = y）或数字稳定性的修改（例如，对于小x值，为log（1 + x））。</p><p> And they provide “best execution” for the computation: whether it’s changing the execution by JIT(just-in-time) compiling it, by utilizing special hardware (GPUs/TPUs), by vectorizing thecomputation, or in any other way.</p><p> 而且它们为计算提供了“最佳执行”：无论是通过JIT（即时）编译来更改执行，通过利用特殊硬件（GPU / TPU），通过对计算进行矢量化还是以任何其他方式来改变执行。</p><p>  As an aside: I realize that the name “tensor computation library” is too broad, and that thecharacterization above precludes some libraries that might also justifiably be called “tensorcomputation libraries”. Better names might be “graph computation library” (although that might getmixed up with libraries like   networkx) or “computational graph managementlibrary” or even “symbolic tensor algebra libraries”.</p><p>  顺便说一句：我意识到“张量计算库”的名称太宽泛，并且上面的特征排除了一些可能被合理地称为“张量计算库”的库。更好的名称可能是“图形计算库”（尽管可能与networkx之类的库混在一起）或“计算图管理库”，甚至是“符号张量代数库”。 </p><p> So for the avoidance of doubt, here is a list of libraries that this blog post is  not about:</p><p>因此，为避免疑问，以下是此博客文章所不涉及的库列表：</p><p> NumPy and SciPy These libraries don’t have a concept of a computational graph - they’re more like a toolbox offunctions, called from Python and executed in C or Fortran.</p><p> NumPy和SciPy这些库没有计算图的概念-它们更像是一个函数工具箱，从Python调用并在C或Fortran中执行。</p><p> However, this might be a controversial distinction - as we’ll see later, JAX also doesn’t buildan explicit computational graph either, and I definitely want to include JAX as a “tensorcomputation library”…  ¯\_(ツ)_/¯</p><p> 但是，这可能是一个有争议的区别-正如我们稍后将要看到的，JAX也没有建立显式的计算图，我当然想将JAX包含为“张量计算库”…\ _（ツ）_ /</p><p> Numba and Cython These libraries provide best execution for code (and in fact some tensor computation libraries,such as Theano, make good use them), but like NumPy and SciPy, they do not actually manage thecomputational graph itself.</p><p> Numba和Cython这些库为代码提供了最佳执行（实际上，一些张量计算库（例如Theano）很好地利用了它们），但是像NumPy和SciPy一样，它们实际上并不管理计算图本身。</p><p> Keras, Trax, Flax and PyTorch-Lightning These libraries are high-level wrappers around tensor computation libraries - they basicallyprovide abstractions and a user-facing API to utilize tensor computation libraries in afriendlier way.</p><p> Keras，Trax，Flax和PyTorch-Lightning这些库是张量计算库的高级包装-它们基本上提供抽象和面向用户的API，以更友好的方式利用张量计算库。</p><p>   All three aforementioned goals are ambitious undertakings with sophisticated solutions, so itshouldn’t be surprising to learn that decisions in pursuit on goal can have implications for (oreven incur a trade-off with!) other goals. Here’s a list of common differences along all three axes:</p><p>   上述所有三个目标都是具有复杂解决方案的雄心勃勃的事业，因此，了解追求目标的决定可能会对其他目标产生影响（甚至要进行权衡！）也就不足为奇了。以下是所有三个轴上的共同差异列表：</p><p> Tensor computation libraries can differ in how they represent the computational graph, and how itis built. Static or dynamic graphs: do we first define the graph completely and then inject data to run(a.k.a. define-and-run), or is the graph defined on-the-fly via the actual forward computation(a.k.a. define-by-run)? TensorFlow 1.x was (in)famous for its static graphs, which made users feel like they were“working with their computational graph through a keyhole”, especially when  compared toPyTorch’s dynamic graphs.</p><p> 张量计算库在如何表示计算图以及如何构建方面可以有所不同。静态图或动态图：首先要完全定义图，然后将数据注入以运行（又称为“定义并运行”），还是通过实际的正向计算即时定义图（即按运行来定义）？ ？ TensorFlow 1.x以其静态图而闻名，这使用户感到“正在通过锁孔处理计算图”，尤其是与PyTorch的动态图相比时。 </p><p> Lazy or eager execution: do we evaluate variables as soon as they are defined, or only when adependent variable is evaluated? Usually, tensor computation libraries either choose to supportdynamic graphs with eager execution, or static graphs with lazy execution - for example, TensorFlow 2.0 supports both modes.</p><p>懒惰或渴望执行：是在定义变量后立即评估变量，还是仅在评估自变量时才评估变量？通常，张量计算库要么选择支持急切执行的动态图，要么选择支持懒惰执行的静态图-例如，TensorFlow 2.0支持这两种模式。</p><p> Interestingly, some tensor computation libraries (e.g.  Thinc) don’t evenconstruct an explicit computational graph: they represent it as  chained higher-orderfunctions.</p><p> 有趣的是，某些张量计算库（例如Thinc）甚至没有构造明确的计算图：它们将其表示为链接的高阶函数。</p><p> Tensor computation libraries can also differ in what they want to use the computational graph for - for example, are we aiming to do things that basically amount to running thecomputational graph in a “different mode”, or are we aiming to modify the computational graphitself? Obviously, how you represent the computational graph and what you want to use it for are veryrelated questions! For example, if you want to be able to represent aribtrary computation as agraph, you’ll have to handle control flow like if-else statements or for-loops - this leads tocommon gotchas with  using Python for-loops inJAXor needing to use   torch.nn.ModuleList in for-loops withPyTorch.</p><p> Tensor计算库在使用计算图的目的上也可能有所不同-例如，我们的目标是基本上完成以“不同模式”运行计算图的事情，还是目标是自己修改计算图？显然，如何表示计算图以及要将其用于什么是非常相关的问题！例如，如果您希望能够将aribtrary计算形式表示为图形，则必须处理诸如if-else语句或for-loops之类的控制流-这导致在JAX中使用Python for-loops或需要使用手电筒导致常见问题。使用PyTorch在for循环中使用nn.ModuleList。</p><p> Some tensor computation libraries (e.g.  Theano and it’sfork,  Theano-PyMC) aim to  optimizethe computational graphitself, for which an explicit graph is necessary.</p><p> 一些张量计算库（例如Theano和itfork的Theano-PyMC）旨在优化计算图形本身，为此必须有一个明确的图形。</p><p> Finally, tensor computation libraries can also differ in how they execute code. All tensor computation libraries run on CPU, but the strength of GPU and TPU support is a majordifferentiator among tensor computation libraries.</p><p> 最后，张量计算库在执行代码方面也可能有所不同。所有张量计算库都在CPU上运行，但是GPU和TPU支持的强度是张量计算库之间的主要区别。</p><p> Another differentiator is how tensor computation libraries compile code to be executed onhardware. For example, do they use JIT compilation or not? Do they use “vanilla” C or CUDAcompilers, or  the XLA compiler for machine-learning specificcode?</p><p> 另一个区别是张量计算库如何编译要在硬件上执行的代码。例如，他们是否使用JIT编译？他们是否使用“原始” C或CUDA编译器，或XLA编译器来进行机器学习的特定代码？</p><p>  Having outlined the basic similarities and differences of tensor computation libraries, I thinkit’ll be helpful to go through several of the popular libraries as examples. I’ve tried to link tothe relevant documentation where possible.  1</p><p>  概述了张量计算库的基本相似之处和不同之处之后，我认为以几种流行的库为例会很有帮助。我试图尽可能地链接到相关文档。 1个 </p><p>  How is the computational graph represented and built? PyTorch dynamically builds (and eagerly evaluates) an explicit computational graph. For moredetail on how this is done, check out  the PyTorch docs on autogradmechanics.</p><p>计算图如何表示和构建？ PyTorch动态构建（并热切评估）一个明确的计算图。有关如何完成此操作的更多详细信息，请查看有关autogradmechanics的PyTorch文档。</p><p> For more on how PyTorch computational graphs, see   jdhao’s introductory blog post oncomputational graphs inPyTorch.</p><p> 有关PyTorch计算图的更多信息，请参见jdhao在PyTorch中有关计算图的介绍性博客文章。</p><p> What is the computational graph used for? To quote the  PyTorch docs, “PyTorch is anoptimized tensor library for deep learning using GPUs and CPUs” - as such, the main focus is on autodifferentiation.</p><p> 计算图是用来做什么的？引用PyTorch文档，“ PyTorch是一个优化的张量库，用于使用GPU和CPU进行深度学习” –因此，主要重点是自动区分。</p><p>  How is the computational graph represented and built? Instead of building an explicit computational graph to compute gradients, JAX simply supplies a grad() that returns the gradient function of any supplied function. As such, there istechnically no concept of a computational graph - only pure (i.e. stateless andside-effect-free) functions and their gradients.</p><p>  计算图如何表示和构建？无需构建显式的计算图来计算梯度，JAX只需提供grad（）即可返回任何提供的函数的梯度函数。因此，从技术上讲，没有计算图的概念，只有纯（即无状态和无副作用）函数及其梯度。</p><p> PyTorch builds up a graph as you compute the forward pass, and one call to  backward() onsome “result” node then augments each intermediate node in the graph with the gradient of theresult node with respect to that intermediate node. JAX on the other hand makes you expressyour computation as a Python function, and by transforming it with  grad() gives you agradient function that you can evaluate like your computation function — but instead of theoutput it gives you the gradient of the output with respect to (by default) the firstparameter that your function took as input.</p><p> 当您计算前向通过时，PyTorch会建立一个图，然后在某个“结果”节点上调用向后（），然后使用结果节点相对于该中间节点的梯度来扩大图中的每个中间节点。另一方面，JAX使您可以将您的计算表达为Python函数，并通过用grad（）对其进行转换，可以像计算函数一样为您提供一个可以评估的梯度函数-但是，与输出相比，它为您提供了相对于输出的梯度（默认）函数输入的第一个参数。</p><p> What is the computational graph used for? According to the  JAX quickstart,JAX bills itself as “NumPy on the CPU, GPU, and TPU, with great automatic differentiation forhigh-performance machine learning research”. Hence, its focus is heavily onautodifferentiation.</p><p> 计算图是用来做什么的？根据JAX快速入门，JAX自称为“ NumPy在CPU，GPU和TPU上具有出色的自动差异性，可用于高性能机器学习研究”。因此，它的重点是自动分化。</p><p> How does the library ensure “best execution” for computation? JAX uses XLA to compile and run your NumPy code on […] GPUs and TPUs. Compilation happensunder the hood by default, with library calls getting just-in-time compiled and executed. ButJAX even lets you just-in-time compile your own Python functions into XLA-optimized kernels[…] Compilation and automatic differentiation can be composed arbitrarily […]</p><p> 该库如何确保计算的“最佳执行”？ JAX使用XLA在[…] GPU和TPU上编译和运行您的NumPy代码。默认情况下，编译是在后台进行的，并且库调用会及时进行编译和执行。但是，JAX甚至可以让您及时将自己的Python函数编译为XLA优化的内核[…]编译和自动区分可以任意组合[…] </p><p> For more detail on JAX’s four-function API ( grad,  jit,  vmap and  pmap), see Alex Minaar’s overview of how JAX works.</p><p>有关JAX的四功能API（grad，jit，vmap和pmap）的更多详细信息，请参阅Alex Minaar关于JAX的工作原理的概述。</p><p>  Note: the  original Theano (maintained by MILA) has been discontinued, and the PyMC developers have forked theproject:  Theano-PyMC (soon to be renamed Aesara). I’lldiscuss both the original and forked projects below.</p><p>  注意：原始的Theano（由MILA维护）已经停产，并且PyMC开发人员已分叉了该项目：Theano-PyMC（即将重命名为Aesara）。我将在下面讨论原始项目和分支项目。</p><p> What is the computational graph used for? Theano is unique among tensor computation libraries in that it places more emphasis onreasoning about the computational graph itself. In other words, while Theano has  strongsupport forautodifferentiation,running the computation and computing gradients isn’t the be-all and end-all: Theano has anentire module for  optimizing the computational graphitself, and makes it fairlystraightforward to compile the Theano graph to different computational backends (by default,Theano compiles to C or CUDA, but it’s straightforward to compile to JAX).</p><p> 计算图是用来做什么的？ Theano在张量计算库中是唯一的，因为它更加强调计算图本身的合理性。换句话说，尽管Theano对自动微分功能有强大的支持，但运行计算和计算梯度并不是一劳永逸的事情：Theano具有用于优化计算图形本身的anentire模块，并且可以很容易地将Theano图编译为不同的计算结果后端（默认情况下，Theano编译为C或CUDA，但是直接编译为JAX很简单）。</p><p> Theano is often remembered as a library for deep learning research, but it’s so much more thanthat!</p><p> Theano通常被认为是进行深度学习研究的图书馆，但不仅如此！</p><p> How does the library ensure “best execution” for computation? The original Theano used the GCC C compiler for CPU computation, and the NVCC CUDA compiler forGPU computation.</p><p> 该库如何确保计算的“最佳执行”？最初的Theano使用GCC C编译器进行CPU计算，并使用NVCC CUDA编译器进行GPU计算。</p><p> The Theano-PyMC fork project  will use JAX as abackend,which can utilize CPUs, GPUs and TPUs as available.</p><p> Theano-PyMC fork项目将使用JAX作为后端，可以利用可用的CPU，GPU和TPU。</p><p>  Finally, a quick observation on static graphs and the niche that Theano fills that other tensorcomputation libraries do not. I had huge help from  Thomas Wiecki and Brandon Willard with this section.</p><p>  最后，快速观察静态图和Theano填补的其他张量计算库所没有的生态位。在这一部分，我得到了Thomas Wiecki和Brandon Willard的大力帮助。 </p><p> There’s been a consistent movement in most tensor computation libraries away from static graphs (ormore precisely, statically  built graphs): PyTorch and TensorFlow 2 both support dynamicallygenerated graphs by default, and JAX forgoes an explicit computational graph entirely.</p><p>大多数张量计算库中的静态图形（或更确切地说，是静态生成的图形）始终保持一致：PyTorch和TensorFlow 2默认都支持动态生成的图形，而JAX完全放弃了显式的计算图形。</p><p> This movement is understandable - building the computational graph dynamically matches people’sprogramming intuition much better. When I write  z = x + y, I don’t mean  “I want to register a sumoperation with two inputs, which is waiting for data to be injected” - I mean  “I want to computethe sum of  x and  y“. The extra layer of indirection is not helpful to most users, who just wantto run their tensor computation at some reasonable speed.</p><p> 这种运动是可以理解的-动态地建立计算图可以更好地匹配人们的编程直觉。当我写z = x + y时，我的意思不是“我想用两个输入注册一个求和运算，正在等待数据注入”-我的意思是“我想计算x和y的和”。额外的间接层对大多数只希望以合理速度运行张量计算的用户没有帮助。</p><p>  Having an explicit representation of the computational graph is immensely useful for certain things,even if it makes the graph harder to work with. You can modify the graph (e.g. graph optimizations,simplifications and rewriting), and you can reason about and analyze the graph. Having thecomputation as an actual  object helps immeasurably for tasks where you need to think about thecomputation itself, instead of just blindly running it.</p><p>  明确表示计算图对于某些事物非常有用，即使它使该图更难使用。您可以修改图形（例如图形优化，简化和重写），并且可以推理和分析图形。将计算作为实际对象，对您需要考虑计算本身而不是盲目运行的任务有不可估量的帮助。</p><p> On the other hand, with dynamically generated graphs, the computational graph is never actuallydefined anywhere: the computation is traced out on the fly and behind the scene. You can no longerdo anything interesting with the computational graph: for example, if the computation is slow, youcan’t reason about  what parts of the graph are slow. The end result is that you basically have tohope that the framework internals are doing the right things, which they might not!</p><p> 另一方面，对于动态生成的图，计算图实际上从未在任何地方定义：计算是在运行中和在幕后进行的。您无法再对计算图做任何有趣的事情：例如，如果计算很慢，就无法推断出图的哪些部分很慢。最终结果是，您基本上必须希望框架内部执行正确的操作，而他们可能做不到！</p><p> This is the niche that Theano (or rather, Theano-PyMC/Aesara) fills that other contemporary tensorcomputation libraries do not: the promise is that if you take the time to specify your computationup front and all at once, Theano can optimize the living daylight out of your computation - whetherby graph manipulation, efficient compilation or something else entirely - and that this is somethingyou would only need to do once.</p><p> 这是Theano（或更确切地说，Theano-PyMC / Aesara）填补了其他当代张量计算库所不能满足的利基市场：承诺是，如果您花时间在前面指定您的计算并且全部一次，Theano可以优化生活日光无需进行任何计算-无论是通过图形操作，高效编译还是完全通过其他方式进行-只需执行一次即可。</p><p>  Some readers will notice the conspicuous lack of TensorFlow from this list - its exclusion isn’t out of malice, merely a lack of time and effort to do the necessary research to do it justice. Sorry.  ↩</p><p>  一些读者会注意到，此列表中明显缺少TensorFlow-排除TensorFlow并非出于恶意，只是缺乏时间和精力来进行必要的研究以使其公正。抱歉。 ↩</p><p>     Subscribe to my newsletter!My thoughts on what I&#39;m reading and learning, delivered once every two weeks. More information  here.Newsletter archive  here.</p><p>     订阅我的新闻通讯！每两周发表一次的关于阅读和学习内容的想法。这里有更多信息。这里有新闻通讯存档。 </p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://eigenfoo.xyz/tensor-computation-libraries/">https://eigenfoo.xyz/tensor-computation-libraries/</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/tensor/">#tensor</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/计算/">#计算</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/分享/">#分享</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy; 2020 diglog.com </div></div></body></html>