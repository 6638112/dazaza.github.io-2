<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>让我们用GPU构建一个高性能的模糊器</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">让我们用GPU构建一个高性能的模糊器</h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2020-10-23 00:41:01</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2020/10/af62daf8ef2bb0719075fe04e35ad4e0.jpeg"><img src="http://img2.diglog.com/img/2020/10/af62daf8ef2bb0719075fe04e35ad4e0.jpeg" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>TL;DR: Can we use GPUs to get 10x performance/dollar when fuzzing embedded software in the cloud? Based on our preliminary work, we think the answer is yes!</p><p>TL；DR：在云中模糊化嵌入式软件时，我们是否可以使用GPU获得10倍的性能/美元？根据我们的初步工作，我们认为答案是肯定的！</p><p> Fuzzing is a software testing technique that supplies programs with many randomized inputs in an attempt to cause unexpected behavior. It’s an important, industry-standard technique responsible for the discovery of many security vulnerabilities and the prevention of many more. However, fuzzing well takes time, and fuzzing embedded software presents additional challenges.</p><p>模糊是一种软件测试技术，它为程序提供许多随机化的输入，试图导致意想不到的行为。它是一项重要的行业标准技术，负责发现许多安全漏洞并预防更多漏洞。然而，很好地模糊化需要时间，并且模糊化嵌入式软件带来了额外的挑战。</p><p> Embedded platforms are not designed for the instrumentation and high-throughput computation required to find bugs via fuzzing. Without access to source code, practical fuzzing of such platforms requires an emulator, which is slow, or many physical devices, which are often impractical.</p><p>嵌入式平台不是为通过模糊查找错误所需的工具和高通量计算而设计的。在不访问源代码的情况下，此类平台的实际模糊化需要速度较慢的仿真器，或者需要许多物理设备，而这通常是不切实际的。</p><p> Most fuzzing approaches have used conventional CPU architectures or emulators, but we decided to use other commodity hardware to tackle this problem—in particular, GPUs. The recent boom in machine learning has driven down the off-peak price of GPUs and made massive GPU computing capacity readily available from all major cloud providers. GPUs are very good at executing tasks in parallel, and fuzzing is an easily parallelizable problem.</p><p>大多数模糊方法都使用传统的CPU架构或仿真器，但我们决定使用其他商用硬件来解决这个问题-特别是GPU。最近机器学习的繁荣压低了GPU的非高峰价格，并使所有主要的云提供商都可以轻松获得巨大的GPU计算能力。GPU非常擅长并行执行任务，而模糊化是一个很容易并行化的问题。</p><p> In this blog post, I’ll walk you through the design and implementation of this massively parallel GPU-based fuzzer. So far, we’ve implemented an execution engine that can achieve 5x more executions/second/dollar than libFuzzer—and there’s much more room for optimization.</p><p>在这篇博客文章中，我将带你完成这个基于GPU的大规模并行模糊器的设计和实现。到目前为止，我们已经实现了一个执行引擎，它可以实现比libFuzzer多5倍的执行/秒/美元-而且还有更大的优化空间。</p><p>   Fuzzing aims to generate unexpected inputs to a program and cause undesired behaviors (e.g., crashes or memory errors). The most commonly used fuzzers are coverage-guided fuzzers, which focus on finding inputs that cause new code coverage (such as executing a function that wasn’t executed before) to explore edge cases that may crash the program.</p><p>模糊的目的是向程序生成意外的输入，并导致不想要的行为(例如，崩溃或内存错误)。最常用的模糊器是覆盖率引导的模糊器，它专注于查找导致新代码覆盖的输入(例如执行以前没有执行过的函数)，以探索可能导致程序崩溃的边缘情况。</p><p>    To do this, fuzzers run many different randomized inputs through the target program. This task is easily parallelizable, as each input can be executed independently of the others.</p><p>为此，模糊器通过目标程序运行许多不同的随机输入。此任务很容易并行化，因为每个输入都可以独立于其他输入执行。</p><p> GPUs are fairly cheap; it costs $0.11/hour for a pre-emptible Tesla T4 on Google Cloud. Also, GPUs are really good at executing many things in parallel—a Tesla T4 can context-switch between over 40,000 threads and can simultaneously execute 2,560 of them in parallel—and, as mentioned, fuzzing is a naturally parallelizable problem. Using thousands of threads, we should theoretically be able to test thousands of different inputs at the same time.</p><p>GPU相当便宜；在Google Cloud上购买一辆可抢占的特斯拉T4的价格是0.11美元/小时。此外，GPU非常擅长并行执行许多事情-特斯拉T4可以在40,000多个线程之间进行上下文切换，并可以同时执行其中的2,560个线程-如上所述，模糊是一个自然可以并行化的问题。使用数千个线程，理论上我们应该能够同时测试数千个不同的输入。</p><p>  In short, running code on GPUs is very different from running code on CPUs in a few critical ways.</p><p>简而言之，在几个关键方面，在GPU上运行代码与在CPU上运行代码有很大的不同。</p><p> First, a GPU cannot directly execute x86/aarch64/etc. instructions, as GPUs have their own instruction set. Our goal is to fuzz embedded software for which no source code is available. With only a binary in hand, we have no easy way of generating GPU assembly to run.</p><p>首先，GPU不能直接执行x86/aarch64/等指令，因为GPU有自己的指令集。我们的目标是模糊没有源代码的嵌入式软件。由于手头只有一个二进制文件，我们没有简单的方法来生成要运行的GPU程序集。</p><p> Second, a GPU has no operating system. Traditional parallel fuzzers  launch multiple processes that can execute inputs separately without interfering with other processes. If an input causes one process to crash, other processes will be unaffected. GPUs have no notion of processes or address space isolation, and any memory violation will cause the entire fuzzer to crash, so we need to find some way to isolate the parallel instances of the program being fuzzed.</p><p>其次，GPU没有操作系统。传统的并行模糊器可以启动多个进程，这些进程可以单独执行输入，而不会干扰其他进程。如果输入导致一个进程崩溃，其他进程不会受到影响。GPU没有进程或地址空间隔离的概念，任何内存违规都会导致整个Fuzzer崩溃，因此我们需要找到某种方法来隔离正在Fuzize的程序的并行实例。</p><p> Additionally, without an operating system, there’s no one home to answer system calls, which enable a program to open files, use the network, and so on. System calls must be emulated or relayed back to the CPU to be executed by the host operating system.</p><p>此外，如果没有操作系统，就没有人在家应答系统调用，这些调用使程序能够打开文件、使用网络等。系统调用必须被仿真或中继回CPU才能由主机操作系统执行。</p><p> Finally, GPU memory is hard to manage well. GPUs have complicated memory hierarchies with several different types of memory, and each has different ease-of-use and performance characteristics. Performance is highly dependent on memory access patterns, and controlling when and how threads access memory can make or break an application. Additionally, there isn’t much memory to go around, making it even more difficult to properly manage memory layout and access patterns. Having 16GB of device memory might sound impressive, but splitting it between 40,000 threads of execution leaves each thread with a paltry 419 KiB.</p><p>最后，GPU内存很难管理好。GPU具有复杂的内存层次结构，具有几种不同类型的内存，并且每种内存都具有不同的易用性和性能特征。性能高度依赖于内存访问模式，控制线程访问内存的时间和方式可以决定应用程序的成败。此外，没有太多内存可供分配，这使得正确管理内存布局和访问模式变得更加困难。拥有16 GB的设备内存听起来可能令人印象深刻，但将其分配给40,000个执行线程，每个线程只有微不足道的419 KiB。</p><p>  There are many obstacles to building a working GPU fuzzer, but none of them are insurmountable.</p><p>要构建一个可以工作的GPU模糊器有很多障碍，但没有一个是不可逾越的。</p><p>  First, let’s see if we can get  aarch64 binaries running on the GPU.</p><p>首先，让我们看看是否可以在GPU上运行aarch64二进制文件。</p><p> As mentioned, we want to fuzz embedded binaries (e.g., ARMv7, aarch64, etc.) on the GPU. NVIDIA GPUs use a different instruction set architecture called PTX (“Parallel Thread eXecution”), so we cannot directly execute the binaries we want to fuzz. A common solution to this problem is to emulate an embedded CPU, but developing a CPU emulator for GPUs would likely be an expensive investment that would perform poorly. Another alternative is to translate binaries to PTX so they can execute directly on the GPU without emulation.</p><p>如前所述，我们希望模糊化嵌入式二进制文件(例如，ARMv7、aarch64等)。在GPU上。NVIDIA GPU使用一种不同的指令集架构，称为PTX(“并行线程执行”)，因此我们不能直接执行我们想要模糊的二进制文件。这个问题的一个常见解决方案是仿真嵌入式CPU，但是为GPU开发CPU仿真器可能是一项昂贵的投资，而且性能会很差。另一种选择是将二进制文件转换为PTX，这样它们就可以直接在GPU上执行，而无需仿真。</p><p> Trail of Bits has developed a binary translation tool called  Remill that we can use to do this. Remill “lifts” binaries to LLVM IR (intermediate representation), which can then be retargeted and compiled to any architecture supported by the LLVM project. It just so happens that LLVM supports emitting LLVM IR as PTX code, which is perfect for our purposes.</p><p>TRAIL of BITS已经开发了一个叫做REMILL的二进制翻译工具，我们可以用它来做这件事。Remill将二进制文件“提升”到LLVMIR(中间表示)，然后可以重定目标并编译到LLVM项目支持的任何架构。碰巧LLVM支持将LLVM IR作为PTX代码发出，这非常适合我们的目的。</p><p>  Say we have this simple example function, which sets w19 to 0, adds 5, and returns the result:</p><p>假设我们有这个简单的示例函数，它将w19设置为0，加5，然后返回结果：</p><p>  We can pass the bytes for these instructions to Remill, which produces LLVM IR that models the original program executing on an ARM processor:</p><p>我们可以将这些指令的字节传递给Remill，它会生成LLVM IR，对在ARM处理器上执行的原始程序进行建模：</p><p>  Then, with some optimizations, we can have LLVM compile the above LLVM IR to PTX assembly:</p><p>然后，通过一些优化，我们可以让LLVM将上面的LLVM IR编译为PTX程序集：</p><p>  Finally, we can load this PTX into a GPU and execute it as if we’d had access to the source code in the first place.</p><p>最后，我们可以将此PTX加载到GPU中并执行它，就像我们首先可以访问源代码一样。</p><p>  As mentioned earlier, GPUs have no operating system to provide isolation between processes. We need to implement address space isolation so multiple instances of the fuzzed program can access the same set of memory addresses without interfering with each other, and we need to detect memory safety errors in the target program.</p><p>如前所述，GPU没有操作系统来提供进程之间的隔离。我们需要实现地址空间隔离，以便模糊化程序的多个实例可以访问同一组内存地址，而不会相互干扰，并且需要检测目标程序中的内存安全错误。</p><p> Remill replaces all memory access in the original program with calls to the special functions read_memory and write_memory. By providing these functions, we can implement a software memory management unit that  fills in for the missing OS functionality and mediates memory accesses.</p><p>Remill将原始程序中的所有内存访问替换为对特殊函数read_memory和write_memory的调用。通过提供这些功能，我们可以实现一个软件内存管理单元，它可以填补缺失的操作系统功能，并调解内存访问。</p><p>  For example, consider this function that takes a pointer and increments the integer it points to:</p><p>例如，考虑以下函数，该函数接受一个指针并递增其指向的整数：</p><p>  Remill translates this assembly into the following IR containing a read_memory call, an add instruction, and a write_memory call:</p><p>Remill将此程序集转换为以下IR，其中包含READ_MEMORY调用、ADD指令和WRITE_MEMORY调用：</p><p>  By providing __remill_read_memory_32 and __remill_write_memory_32 functions, we can give each thread its own virtual address space. In addition, we can validate memory access and intercept invalid access before it crashes the entire fuzzer.</p><p>通过提供__REMILL_READ_MEMORY_32和__REMILL_WRITE_MEMORY_32函数，我们可以为每个线程提供自己的虚拟地址空间。此外，我们还可以验证内存访问，并在无效访问使整个模糊器崩溃之前拦截它。</p><p> Remember, though, that 16GB of device memory is actually not much when shared across 40,000 threads. To conserve memory, we can use copy-on-write strategies in our MMU; threads share the same memory until one of the threads writes to memory, at which point that memory is copied. Conserving memory this way has been a surprisingly effective strategy.</p><p>不过，请记住，如果跨40,000个线程共享，16 GB的设备内存实际上并不多。为了节省内存，我们可以在MMU中使用写入时复制策略；线程共享相同的内存，直到其中一个线程写入内存，此时该内存被复制。以这种方式保存内存是一种令人惊讶的有效策略。</p><p>  Wonderful—we have something that works! We can take a binary program, translate it to LLVM, convert it to PTX, mix in an MMU, and run the result on thousands of GPU threads in parallel.</p><p>太棒了--我们有一些管用的东西！我们可以获取一个二进制程序，将其转换为LLVM，将其转换为PTX，混入一个MMU，然后在数千个GPU线程上并行运行结果。</p><p>  But how well are we meeting our goal of building a fuzzer that achieves 10x performance per dollar when compared to other fuzzers?</p><p>但是，我们如何实现我们的目标，建立一个模糊，达到10倍的性能每美元与其他模糊的比较呢？</p><p> Evaluating fuzzers is a very tricky business, and there have been many papers published about how to effectively compare them. Our fuzzer is still too young to properly evaluate, since we are still missing critical fuzzer components such as a mutator to generate new inputs to the program. To measure executor performance only, we can look at how quickly our fuzzer runs inputs through the target program (in executions/second). By normalizing the cost of the compute hardware (GPUs are more expensive than the CPUs on which other fuzzers run), we can compare executions/second/$.</p><p>评估Fuzzer是一件非常棘手的事情，已经发表了很多关于如何有效地比较它们的论文。我们的模糊器还太年轻，还不能正确评估，因为我们仍然缺少关键的模糊器组件，如变频器，以生成程序的新输入。要仅测量执行器性能，我们可以查看Fuzzer通过目标程序运行输入的速度(以执行/秒为单位)。通过标准化计算硬件的成本(GPU比运行其他模糊器的CPU更贵)，我们可以比较执行/秒/$。</p><p> What should we fuzz in our benchmarking tests? The  BPF packet filtering code from libpcap seems like a good candidate for a few reasons:</p><p>在我们的基准测试中，我们应该模糊什么？出于以下几个原因，libpcap中的BPF数据包过滤代码似乎是一个很好的候选代码：</p><p> It implements a complicated state machine that is too difficult for humans to reason about, making it a good candidate for fuzzing.</p><p>它实现了一个复杂的状态机，人类很难对其进行推理，这使得它成为模糊化的一个很好的候选者。</p><p> BPF components have had bugs in the past,  so this is a realistic target that we might want to fuzz.</p><p>BPF组件在过去有过错误，所以这是一个我们可能想要模糊的现实目标。</p><p> Let’s write a test application that takes a packet from the fuzzer and runs a complicated BPF filter program on it:</p><p>让我们编写一个测试应用程序，该应用程序从Fuzzer获取数据包并在其上运行复杂的BPF过滤器程序：</p><p>  This test program doesn’t do a whole lot, but it does exercise complicated logic and requires a good amount of memory access.</p><p>这个测试程序没有做很多事情，但是它确实执行了复杂的逻辑，并且需要大量的内存访问。</p><p> To evaluate our fuzzer, we can compare it to  libFuzzer, a fast and widely used fuzzer. This isn’t an entirely fair comparison. On one hand, libFuzzer solves an easier problem: It fuzzes using the test program’s source code, whereas our fuzzer translates and instruments a binary compiled for a different architecture. Source code is often unavailable in security research. On the other hand, libFuzzer is performing mutation to generate new inputs, which we are not doing. While obviously imperfect, this comparison will work well enough to provide order-of-magnitude estimates.</p><p>要评价我们的模糊器，我们可以把它与libFuzzer相比较，libFuzzer是一种应用广泛的快速模糊器。这不是一个完全公平的比较。一方面，libFuzzer解决了一个更简单的问题：它使用测试程序的源代码进行模糊处理，而我们的Fuzzer则翻译并检测为不同架构编译的二进制代码。在安全研究中，源代码通常是不可用的。另一方面，libFuzzer正在执行突变以生成新的输入，而我们没有这样做。虽然显然不完美，但这种比较将足够好地提供数量级的估计。</p><p> I ran this comparison using Google Compute Engine 8-core N1 instances ($0.379998/hour for non-preemptible instances at time of writing) and a Tesla T4 GPU ($0.35/hour at time of writing).</p><p>我使用Google Compute engine 8核N1实例(撰写本文时不可抢占实例的价格为0.379998美元/小时)和Tesla T4GPU(撰写本文时价格为0.35美元/小时)进行了比较。</p><p> Unfortunately, our fuzzer doesn’t compare so well against libFuzzer. libFuzzer achieves 5.2M execs/s/$, and our fuzzer only achieves 361K execs/s/$.</p><p>不幸的是，我们的绒毛器比不上libFuzzer。LibFuzzer可以达到520万个execs/s/$，而我们的Fuzzer只能达到361k个execs/s/$。</p><p>    Before we start optimizing performance, we should profile the fuzzer to get a better sense of how it’s performing. Nvidia’s  Nsight Compute profiler helps explain hardware utilization and performance bottlenecks.</p><p>在我们开始优化性能之前，我们应该分析一下Fuzzer，以便更好地了解它的性能。NVIDIA的NSight Compute Profiler有助于解释硬件利用率和性能瓶颈。</p><p>  From the profile, we can see that the GPU is only using 3% of its compute capacity. Most of the time, the GPU compute hardware is sitting idle, not doing anything.</p><p>从配置文件中，我们可以看到GPU只使用了其计算能力的3%。大多数情况下，GPU计算硬件处于闲置状态，什么也不做。</p><p> This generally happens because of high memory latency: The GPU is waiting for memory reads/writes to complete. However, this isn’t happening because our fuzzer needs to access too much memory; the profile shows that the GPU is only using 45% of its available memory bandwidth. Rather, we must be accessing memory very inefficiently. Each memory access is taking a long time and not providing enough data for computation.</p><p>这通常是因为内存延迟较高：GPU正在等待内存读/写完成。然而，这并没有发生，因为我们的Fuzzer需要访问太多的内存；配置文件显示GPU只使用了其可用内存带宽的45%。相反，我们访问内存的效率肯定非常低。每次存储器访问都需要很长时间，并且没有提供足够的数据用于计算。</p><p> To fix this problem, we need a better understanding of a GPU’s execution model.</p><p>要解决这个问题，我们需要更好地理解GPU的执行模型。</p><p> GPU threads execute in groups of 32 called a warp. All threads in a warp execute together in a parallel multiprocessor, and they run in lockstep, i.e., they run the same instruction at the same time.</p><p>GPU线程以32个为一组执行，称为扭曲。WARP中的所有线程在并行多处理器中一起执行，并且它们以锁步方式运行，即它们同时运行相同的指令。</p><p> When threads read or write memory, the memory accesses happen in 128-byte blocks. If the 32 threads in the warp try to read memory that lies in the same 128-byte block, then the hardware will only need to request one block (one “transaction”) from the memory bus.</p><p>当线程读取或写入内存时，内存访问以128字节的块为单位进行。如果WARP中的32个线程试图读取位于同一128字节块中的内存，那么硬件将只需要从内存总线请求一个块(一个“事务”)。</p><p> However, if the threads each read memory addresses from different blocks, the hardware may need to make 32 separate memory transactions, which are often serialized. This leads to the behavior we found in the profile: The compute hardware is almost always idle because it has to wait for so many memory transactions to complete. The memory bandwidth utilization doesn’t appear quite as bad because many 128-byte chunks are being read, but only four or eight bytes out of each chunk are actually used, so much of the used bandwidth is wasted.</p><p>然而，如果每个线程都从不同的块读取存储器地址，则硬件可能需要进行32个单独的存储器事务，这些事务通常是串行化的。这导致了我们在配置文件中发现的行为：计算硬件几乎总是空闲的，因为它必须等待如此多的内存事务才能完成。内存带宽利用率看起来并不是很差，因为正在读取许多128字节的区块，但每个区块中只有4或8个字节被实际使用，因此浪费了大量使用的带宽。</p><p>  Currently, we allocate separate memory for each thread, so when a thread accesses memory, it very rarely falls into the same 128-byte chunk as a different thread. We can change that by allocating a slab of memory for a warp (32 threads), and interleaving the threads’ memory within that warp. This way, when threads need to access a value from memory, their values are all next to each other, and the GPU can fulfill these memory reads with a single memory transaction.</p><p>目前，我们为每个线程分配单独的内存，因此当一个线程访问内存时，它很少落入与不同线程相同的128字节块中。我们可以通过为一个扭曲(32个线程)分配一个内存片，并在该扭曲内交织线程的内存来改变这一点。这样，当线程需要访问内存中的值时，它们的值都是相邻的，并且GPU可以通过单个内存事务来完成这些内存读取。</p><p>  Trying this out, we find that performance improves by an order of magnitude! Clearly, it’s extremely important to be aware of memory access patterns when programming for GPUs.</p><p>尝试一下，我们发现性能提高了一个数量级！显然，在为GPU编程时了解内存访问模式是极其重要的。</p><p>   Re-running the profiler, we can see that we are getting much better compute utilization (33%, up from 3%), but we are still nowhere near full utilization. Can we do better?</p><p>重新运行性能分析器，我们可以看到，我们的计算利用率有了很大提高(33%，高于3%)，但我们仍远未达到完全利用率。我们能做得更好吗？</p><p>  Continuing our examination of memory usage patterns, let’s look at the type of memory used. Nvidia GPUs have several kinds of memory located in different physical places, but the easiest type to use is called “unified memory,” which automatically transfers data between different physical locations on our behalf. We have been using this because it doesn’t require us to think much about where bytes are being physically stored, but it can lead to performance bottlenecks if mismanaged, since data will be transferred between physical memory locations inefficiently.</p><p>继续检查内存使用模式，让我们看看使用的内存类型。NVIDIA GPU有几种位于不同物理位置的内存，但最容易使用的类型称为“统一内存”，它代表我们在不同物理位置之间自动传输数据。我们一直在使用它，因为它不需要我们过多地考虑字节的物理存储位置，但是如果管理不当可能会导致性能瓶颈，因为数据将在物理内存位置之间低效传输。</p><p> Since we are still seeing very high memory latency, let’s take a closer look at these transfers.</p><p>由于我们仍然看到非常高的内存延迟，让我们更仔细地看看这些传输。</p><p> Our simple fuzzer is working in “rounds”: if the GPU can run 40,000 threads, we pass 40,000 inputs to the GPU, and each thread fuzzes an input before we launch the next round. In between rounds, we reset the memory used (e.g., coverage tracking data structures and memory used by the program being fuzzed). However, this results in significant data transfers between the GPU and the CPU in between each round, as memory is paged back to the CPU, reset, and then paged back to the GPU. While these transfers are happening, the GPU is doing nothing. Additional latency is incurred as the GPU waits for the CPU to launch the next round.</p><p>我们的简单模糊器是“轮次”工作的：如果GPU可以运行40,000个线程，我们将40,000个输入传递给GPU，每个线程在我们启动下一轮之前对一个输入进行模糊处理。在两轮之间，我们重置使用的内存(例如，被模糊化的程序使用的覆盖范围跟踪数据结构和内存)。然而，这会导致GPU和CPU之间在每轮之间进行大量数据传输，因为内存会被分页回CPU、重置，然后再分页回GPU。当这些传输正在进行时，GPU什么也不做。当GPU等待CPU启动下一轮时，会产生额外的延迟。</p><p>  We can improve this setup by doing a single launch of the GPU code and avoiding synchronicity between the CPU and GPU. Much of the data doesn’t need to be in unified memory; we can allocate global memory on the GPU instead, then asynchronously transfer data to the CPU when we need to send information about fuzzing progress (e.g., which inputs are causing crashes). In this way, when a thread finishes fuzzing an input, it can reset the memory and proceed to the next input without data transfer overhead and without waiting on the CPU.</p><p>我们可以通过单次启动GPU代码并避免CPU和GPU之间的同步来改进此设置。许多数据不需要在统一内存中；相反，我们可以在GPU上分配全局内存，然后在需要发送有关Fuzization进度的信息(例如，哪些输入导致崩溃)时将数据异步传输到CPU。这样，当线程完成对输入的模糊化时，它可以重置内存并继续进行下一个输入，而不需要数据传输开销，也不需要等待CPU。</p><p>  This achieves a speedup of almost another order of magnitude! Now, the fuzzer is about five times faster per dollar than libFuzzer.</p><p>这几乎实现了另一个数量级的加速！现在，一美元比libFuzzer快五倍左右。</p><p>  It’s extremely promising—although our fuzzer lacks a mutation engine and can’t handle system calls, exceeding libFuzzer’s performance to this degree suggests that fuzzing using GPUs may be extremely useful for certain applications.</p><p>这是非常有前途的--尽管我们的Fuzzer缺少突变引擎并且不能处理系统调用，但是超过libFuzzer如此程度的性能表明使用GPU的Fuzze对于某些应用程序可能非常有用。</p><p>  Although we are close to our performance goal for this test program, the project still has a long way to go. Hardware utilization remains low, so there’s room for more optimization.</p><p>虽然我们已经接近这个测试程序的性能目标，但是这个项目还有很长的路要走。硬件利用率仍然较低，因此还有进一步优化的空间。</p><p> In addition, we need to build support for handling system calls, which may have a significant performance impact when fuzzing I/O-heavy applications. We also need to build the mutation engine before this fuzzer can be useful, although this problem is much better understood than building the execution engine.</p><p>此外，我们需要构建对处理系统调用的支持，这在模糊化I/O繁重的应用程序时可能会对性能产生重大影响。在这个Fuzzer有用之前，我们还需要构建突变引擎，尽管这个问题比构建执行引擎更容易理解。</p><p> Still, we’re very excited to be getting such promising results in such early stages of development. We look forward to an order of magnitude improvement in fuzzing embedded binaries.</p><p>尽管如此，我们仍然非常兴奋能在如此早期的开发阶段获得如此有希望的结果。我们期待在模糊化嵌入式二进制文件方面有一个数量级的改进。</p><p> We would love to hear your thoughts on this work! Contact us at  ryan@reberhardt.com or  artem@trailofbits.com.</p><p>我们很想听听您对这项工作的看法！联系我们：ryan@reberhardt.com或artem@trailofbits.com。</p><p> Finally, a big “thank you” goes to Artem Dinaburg for the initial design of this system and for mentoring me throughout this project. Also, thank you to Peter Goodman for giving design feedback and debugging suggestions.</p><p>最后，我要向Artem Dinaburg致以极大的感谢，感谢他对这个系统的初步设计，以及在整个项目过程中对我的指导。同时，感谢Peter Goodman提供设计反馈和调试建议。</p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://blog.trailofbits.com/2020/10/22/lets-build-a-high-performance-fuzzer-with-gpus/">https://blog.trailofbits.com/2020/10/22/lets-build-a-high-performance-fuzzer-with-gpus/</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/性能/">#性能</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/gpu/">#gpu</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/high/">#high</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/内存/">#内存</a></button></div></div><div class="shadow p-3 mb-5 bg-white rounded clearfix"><div class="container"><div class="row"><div class="col-sm"><div><a target="_blank" href="/story/1030523.html"><img src="http://img2.diglog.com/img/2020/10/thumb_201285ce3299b458b607b1e1c0b9f4d5.png" class="img-fluid" onerror="this.style.display='none'"></a></div><div class="item_title"><a target="_blank" href="/story/1030523.html">自PostgreSQL 8.3以来的TPC-H性能</a></div><span class="my_story_list_date">2020-10-22 20:49</span></div><div class="col-sm"><div><a target="_blank" href="/story/1030389.html"><img src="http://img2.diglog.com/img/2020/10/thumb_c1481866f8ac975e5bd0efeda6491de0.jpg" class="img-fluid" onerror="this.style.display='none'"></a></div><div class="item_title"><a target="_blank" href="/story/1030389.html">HPE表示，它已获得1.6亿美元的欧盟资金，用于在芬兰建造一台超级计算机，理论上最高性能为550千万亿次浮点运算</a></div><span class="my_story_list_date">2020-10-22 9:10</span></div><div class="col-sm"><div><a target="_blank" href="/story/1030198.html"><img src="http://img2.diglog.com/img/2020/10/thumb_77e67b9c577f57adddd96d1254075163.jpg" class="img-fluid" onerror="this.style.display='none'"></a></div><div class="item_title"><a target="_blank" href="/story/1030198.html">亚马逊的露娜在早期接入：没有强大的连接，流媒体性能可能参差不齐，iOS网络应用支持还不错，频道组竖井游戏选择</a></div><span class="my_story_list_date">2020-10-21 7:6</span></div><div class="col-sm"><div><a target="_blank" href="/story/1030065.html"><img src="http://img2.diglog.com/img/2020/10/thumb_391944c6fc1dec30cf240953a4bb7542.jpg" class="img-fluid" onerror="this.style.display='none'"></a></div><div class="item_title"><a target="_blank" href="/story/1030065.html">中等大小文本对PostgreSQL性能的惊人影响</a></div><span class="my_story_list_date">2020-10-20 22:47</span></div></div></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/美国/">#美国</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/谷歌/">#谷歌</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/linux/">#linux</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/程序/">#程序</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy; 2020 diglog.com </div></div></body></html>