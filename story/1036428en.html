<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>数字化旧的8mm胶带Digitizing Old 8mm Tapes</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">Digitizing Old 8mm Tapes<br/>数字化旧的8mm胶带</h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2020-11-25 05:59:35</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2020/11/7716878903f8890b32b7b39426e85ebd.png"><img src="http://img2.diglog.com/img/2020/11/7716878903f8890b32b7b39426e85ebd.png" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>It’s astounding to think back and consider how much technological progress has occurred in just the past 15 years. Most folks today carry a smartphone in their pocket everywhere they go, and a great many of those smartphones have powerful cameras built in capable of recording multiple hours in high definition. Pair this ability with low-cost video editing software— some of which comes at no cost at all—and far more people today have the tools to practice shooting, editing, compositing, and rendering professional-looking videos on a modest budget.</p><p>回顾过去，思考过去15年中发生了多少技术进步，真是令人惊讶。如今，大多数人随处携带口袋中的智能手机，其中许多智能手机都内置了功能强大的相机，能够以高清晰度记录多个小时。将此功能与低成本视频编辑软件（其中有一些完全免费）结合使用，如今，越来越多的人掌握了以适度的预算练习拍摄，编辑，合成和渲染具有专业外观的视频的工具。</p><p> My personal experience with photography began around age 7 shooting on  110 film using a small “spy” camera I got as a gift. My dad’s  Sony CCD-V5 was bulky, heavy, and probably expensive when he bought it around 1987, so he was reluctant to let me or my sister operate it under his supervision, let alone borrow it to make our own films by ourselves. As a consequence, my sister and I kept ourselves entertained by making audio recordings on much cheaper audio cassette hardware and tapes—we produced an episodic “radio show” starring our stuffed animals long before the podcast was invented. Though my sister and I took good care of our audio equipment, Dad stuck to his guns when it came to who got to use the camcorder, but he would sometimes indulge us when we had a full production planned, scripted, and rehearsed.  Video8 tapes were expensive, too, and for the most part Dad reserved their use for important events like concerts, school graduations, birthdays, and family holidays.</p><p> 我个人的摄影经验始于7岁左右，当时我使用礼物作为礼物的小型“间谍”相机拍摄110张胶卷。我父亲的索尼CCD-V5体积大，笨重，并且在1987年左右购买时很昂贵，因此他不愿意让我或姐姐在他的监督下操作它，更不用说借用它自己制作自己的电影了。结果，我和我姐姐在便宜得多的录音带硬件和磁带上录音，使自己保持了娱乐—在播客发明出来之前，我们就制作了由动物填充物主演的偶发性“广播节目”。尽管我和姐姐都很好地照顾了我们的音频设备，但是当涉及到谁要使用便携式摄录机时，爸爸还是坚持了下来，但是当我们计划好完整的制作，排练和排练时，他有时会沉迷于我们。 Video8磁带也很昂贵，在大多数情况下，爸爸将其保留用于重要活动，例如音乐会，学校毕业，生日和家庭假期。</p><p>  I went off to college and spent a  lot of time lurking the  originaltrilogy.com forums. It was here that not only did I learn a lot about the making and technical background of the Star Wars films (a topic I could blog about ad nauseum), but I also picked up a lot about video editing, codecs, post-production techniques, and preservation. OT.com was and still is home to a community of video hobbyists and professionals, most of whom share a common love for the  unreleased “original unaltered” versions of the Star Wars trilogy. As such, many tips were/are shared as to how to produce the best “fan preservations” of Star Wars and other classic films given the materials available, sacrificing the least amount of quality.</p><p>  我去上大学，花了很多时间潜入originaltrilogy.com论坛。在这里，我不仅学到了很多有关《星球大战》电影的制作和技术背景的知识（我可以在博客上发表有关广告恶作剧的话题），而且还学到了很多有关视频编辑，编解码器和后期制作技术的知识。 ，并保存。 OT.com曾经是，现在仍然是一个视频爱好者和专业人士社区的住所，其中大多数人对未发行的“星球大战”三部曲“原始且未更改”版本有着共同的爱好。因此，在可用的材料下，如何制作出《星球大战》和其他经典电影的最佳“粉丝保护品”，分享了许多技巧，却牺牲了最少的质量。</p><p> I bought my dad a  Sony HDR-CX100 camcorder some years ago to supplement his by that time affinity for digital still cameras—he took it to Vienna and Salzburg soon after and has since transitioned to shooting digital video mostly on his iPhone. But the 8mm tapes chronicling my family’s milestones over the first 25 years of my life continued to sit, undisturbed, in my folks’ cool, dry basement. My dad has recordings on them going as far back as 1988 that I’ve found so far. These recordings are over 30 years old, so the tapes must be at least that age.</p><p> 几年前，我为爸爸买了一台Sony HDR-CX100摄录机，以补充他对数码相机的兴趣。他不久后将它带到了维也纳和萨尔茨堡，此后转为主要在他的iPhone上拍摄数码视频。但是，记录我人生头25年的里程碑的8毫米录像带继续安稳地坐在人们凉爽干燥的地下室中。我父亲有关于他们的录音，可以追溯到我发现的1988年。这些录音已有30多年的历史，因此磁带必须至少是该年龄。</p><p> 8mm video tape  does not last forever, but making analog copies of video tape incurs generational loss each time a copy is dubbed. On the other hand, a digital file can be copied as many times as one wants without any quality loss. All I need is the right capture hardware, appropriate capture software, enough digital storage, and a way to play back the source tapes, and I can preserve one lossless digital capture of each tape indefinitely. The last 8mm camcorder my dad bought—a  Sony CCD-TR917—still has clean, working heads and can route playback of our existing library of tapes through its S-video and stereo RCA outputs. This provides me with the best possible quality given how they were originally shot.</p><p> 8mm的录像带不会永远持续下去，但是每次复制一个录像带时，制作录像带的模拟副本都会造成世代的损失。另一方面，数字文件可以被复制多次，而不会造成质量损失。我所需要的就是正确的捕获硬件，合适的捕获软件，足够的数字存储以及一种回放源磁带的方法，并且我可以无限期地保留每个磁带的无损数字捕获。我父亲最后购买的8毫米便携式摄像机– Sony CCD-TR917 –仍然具有清洁的工作头，并且可以通过S视频和立体声RCA输出路由我们现有的磁带库。鉴于最初的拍摄方式，这为我提供了最好的质量。</p><p>  Generally with modern analog-to-digital preservation, you want to losslessly capture the raw source at a reasonably high sample rate with as little processing done to the source material as possible, from the moment it hits the playback heads to the instant it’s written to disk. Any cleanup can be done in post-production software; in fact, as digital restoration technology improves, it is ideal to have a raw, lossless original available to revisit with improved techniques. For this project, I am using my dad’s aforementioned  Sony CCD-TR917 camcorder attached directly to the S-video and stereo audio inputs of a  Blackmagic Intensity Pro PCIe card. The capturing PC is running Debian Linux and is plugged into the same circuit as the camcorder to avoid possible ground loop noise.</p><p>  通常，对于现代的模数保存，您希望以合理的高采样率无损捕获原始资源，而对原始材料的处理尽可能少，从其到达播放磁头的那一刻到写入该刻的那一刻。磁盘。任何清理都可以在后期制作软件中完成；实际上，随着数字恢复技术的改进，理想的情况是拥有原始的，无损的原件，以便通过改进的技术进行重新访问。对于这个项目，我使用的是我父亲提到的Sony CCD-TR917便携式摄像机，该摄像机直接连接到Blackmagic Intensity Pro PCIe卡的S视频和立体声音频输入。捕获PC运行的是Debian Linux，并插入了与摄像机相同的电路中，以避免可能的接地环路噪声。</p><p> Since my Debian box is headless, I’m not interested in bringing up a full X installation just to grab some videos. Therefore I use the open source, command-line based  bmdtools suite—specifically bmdcapture—to do the raw captures from my Intensity Pro card. I do have to pull down the  DeckLink SDK in order to build bmdcapture, which does have some minor X-related dependencies, but I have to pull down the DeckLink software anyway for Linux drivers. I invoke the following from a shell before starting playback on the camcorder:</p><p> 由于我的Debian盒子是无头的，因此我不想为了获取一些视频而进行完整的X安装。因此，我使用基于命令行的开源bmdtools套件（特别是bmdcapture）来进行Intensity Pro卡的原始捕获。我确实必须下拉DeckLink SDK才能构建bmdcapture，bmdcapture确实具有一些与X相关的小依赖性，但是无论如何我都必须下拉DeckLink软件以用于Linux驱动程序。在开始在便携式摄像机上播放之前，我从外壳调用以下内容：</p><p> $ ./bmdcapture -C 0 -m 0 -M 4 -A 1 -V 6 -d 0 -n 230000 -f &lt;output&gt;.nut</p><p>$ ./bmdcapture -C 0 -m 0 -M 4 -A 1 -V 6 -d 0 -n 230000 -f  .nut</p><p>  -m 0: Capture using mode 0; that is, 525i59.94 NTSC, or 720×486 pixels at 29.97 FPS</p><p>  -m 0：使用模式0捕获；即525i59.94 NTSC或720×486像素（29.97 FPS）</p><p> -M 4: Set a queue size of up to 4GB. Without this, bmdcapture can run out of memory before the entire tape is captured to disk.</p><p> -M 4：将队列大小设置为最大4GB。如果不这样做，在将整个磁带捕获到磁盘之前，bmdcapture可能会耗尽内存。</p><p> -A 1: Use the “Analog (RCA or XLR)” audio input. In my case, stereo RCA.</p><p> -A 1：使用“模拟（RCA或XLR）”音频输入。就我而言，是立体声RCA。</p><p> -V 6: Use the “S-Video” video input. The S-video input on the Intensity Pro is provided as  an RCA pair for chroma (“B-Y In”) and luma/sync (“Y In”);  an adapter cable is necessary to convert to the standard miniDIN-4 connector.</p><p> -V 6：使用“ S-Video”视频输入。 Intensity Pro上的S视频输入以色度（“ B-Y In”）和亮度/同步（“ Y In”）的RCA对的形式提供；必须使用适配器电缆才能转换为标准miniDIN-4连接器。</p><p> -d 0: Fill in dropped frames with a black frame. The Sony CCD-TR917 has a built-in  TBC (which I leave enabled since I don’t own a separate TBC), but owing to the age of the tapes, there is an occasional frame drop.</p><p> -d 0：用黑框填充掉的帧。 Sony CCD-TR917具有内置的TBC（由于我没有单独的TBC，我将其启用），但是由于磁带的使用年限，偶尔会掉落帧。</p><p> -n 230000: Capture 230000 frames. At 29.97 FPS, that’s almost 7675 seconds, which is a little over two hours. Should be enough even for full tapes.</p><p> -n 230000：捕获230000帧。在29.97 FPS时，将近7675秒，这是两个多小时。即使是完整的磁带也应该足够了。</p><p> -f &lt;output&gt;.nut: Write to  &lt;output&gt;.nut in the  NUT container format by default, substituting the tape’s label for  &lt;output&gt;. The  README.md provided with bmdtools suggests sticking with the default, and since FFmpeg has no trouble converting from NUT and I’ve had no trouble capturing to that format, I leave the output file format alone.</p><p>-f  .nut：默认情况下，以NUT容器格式写入 .nut，用磁带的标签代替。 bmdtools随附的README.md建议使用默认设置，并且由于FFmpeg从NUT转换没有问题，并且我也没有捕获到该格式的麻烦，因此我不理会输出文件格式。</p><p> Once I have my lossless capture, I compress the .nut file using bzip2, getting the file size down to up to a quarter of the original size depending on how much of the tape is filled. I then create parity data on the .bz2 archive  using the par2 utility, and put my compressed capture and parity files somewhere safe for long-term archival storage. 🙂</p><p> 进行无损捕获后，我将使用bzip2压缩.nut文件，根据填充的磁带量，将文件大小减小到原始大小的四分之一。然后，我使用par2实用程序在.bz2归档文件上创建奇偶校验数据，并将压缩的捕获和奇偶校验文件放在安全的位置以进行长期归档存储。 🙂</p><p> My Windows-based Intel NUC is where I do most of my video post-production work. It lacks a PCIe slot, so I can’t capture there, but that’s fine because at this point my workflow is purely digital and I only have to worry about moving files around. My tools of choice here are AviSynth 2.6 and VirtualDub 1.10.4, but since AviSynth/VirtualDub are designed to work with AVI containers, I first convert my capture from the NUT container to the AVI container using FFmpeg:</p><p> 我基于Windows的Intel NUC是我大部分视频后期制作工作的地方。它没有PCIe插槽，所以我不能在那儿捕捉，但这很好，因为此时我的工作流程是纯数字的，我只需要担心文件移动。我在这里选择的工具是AviSynth 2.6和VirtualDub 1.10.4，但是由于AviSynth / VirtualDub设计用于AVI容器，因此我首先使用FFmpeg将捕获内容从NUT容器转换为AVI容器：</p><p>   -i &lt;output&gt;.nut: Use  &lt;output&gt;.nut as the input file. FFmpeg is smart and will auto-detect its file format when opened.</p><p>   -i  .nut：使用 .nut作为输入文件。 FFmpeg很聪明，打开后会自动检测其文件格式。</p><p> -vcodec copy: Copy the video stream from the input file’s container to the output file’s container; do not re-encode.</p><p> -vcodec复制：将视频流从输入文件的容器复制到输出文件的容器；不要重新编码。</p><p> -acodec copy: Likewise for the audio stream, copy from the input file’s container to the output file; do not re-encode.</p><p> -acodec copy：同样，对于音频流，从输入文件的容器复制到输出文件；不要重新编码。</p><p> &lt;output&gt;.avi: Write to  &lt;output&gt;.avi, again substituting my tape’s label for  &lt;output&gt; in both the input and output filenames.</p><p>  .avi：写入 .avi，再次用磁带的标签替换输入和输出文件名中的。</p><p>  Now that I have an AVI source file, I can open it in VirtualDub. Owing to its namesake, VirtualDub’s interface is reminiscent of a dual cassette deck ready to “dub” from one container to another. It isn’t as user-friendly as, say, Premiere or Resolve when it comes to editing and compositing, but what it lacks in usability it gains in flexibility. In particular, VirtualDub is designed to run a designated range of source video through one or more “filters,” encoding to one of several output codecs available at the user’s discretion via Video for Windows and/or DirectShow. If no filters are applied, VirtualDub can trim a video (and its audio)  without re-encoding—great for preparing source footage clips for later editing or other processing.</p><p>现在有了AVI源文件，可以在VirtualDub中打开它。由于具有相同的名称，VirtualDub的界面让人想起了一个双盒式录音带，可以将其从一个容器“复制”到另一个容器。在编辑和合成方面，它不像Premiere或Resolve那样方便用户使用，但是它缺乏可用性，因此具有灵活性。特别是，VirtualDub旨在通过一个或多个“过滤器”运行指定范围的源视频，并根据用户的意愿通过Windows Video和/或DirectShow编码为几种输出编解码器之一。如果未应用过滤器，则VirtualDub可以修整视频（及其音频）而无需重新编码-非常适合准备源素材片段，以供以后编辑或其他处理。</p><p>  Though the Sony CCD-TR917 has a built-in video noise reduction feature, I explicitly turn it off before capturing, because one of the filters I have for VirtualDub is  “Neat Video” by ABSoft. It’s the temporal version of their  “Neat Image” Photoshop filter for still images, which I used most recently to prepare a number of stills for Richard Moss’s  The Secret History of Mac Gaming. It’s a very intelligent program that has a lot of knobs and dials to really tune in the noise profile you want to filter out, so I was equally delighted to find that ABSoft’s magic works on videos too. Luckily they offer a plugin built to work with VirtualDub, so I didn’t hesitate to buy it as a sure improvement over the mid-90s noise reduction technology built in to the camcorder.</p><p>  尽管Sony CCD-TR917具有内置的视频降噪功能，但我在捕获之前会先将其关闭，因为我为VirtualDub配备的滤镜之一是ABSoft的“ Neat Video”。这是他们用于静止图像的“ Neat Image” Photoshop滤镜的临时版本，我最近用它来为Richard Moss的《 Mac游戏的秘密历史》准备许多静止图像。这是一个非常智能的程序，它具有许多旋钮和转盘，可以真正调出您要过滤的噪声轮廓，因此，我同样高兴地发现ABSoft的魔力也可以在视频上使用。幸运的是，他们提供了一个可与VirtualDub一起使用的插件，因此，我毫不犹豫地购买了它，以确保对90年代中期摄录一体机内置的降噪技术的改进。</p><p> Most of the aforementioned features can be done in high-end NLE applications such as  Resolve—indeed I have used Resolve to edit several video projects of my own. What makes VirtualDub the “killer app” for me is its use of Windows’s built-in video playback library, and therefore its ability to work with AviSynth scripts. AviSynth is a library that can be installed on Windows PCs that grants the ability to interpret AviSynth “script” files (with the .avs extension) as AVI files anywhere Windows is prompted to play one using its built-in facilities. The basic  AviSynth scripting language is procedural, without loops or conditionals, but it does retain the ability to work with multiple variables at runtime and organize frequently-called sequences into subroutines. Its most common use is to form a filter chain starting with one or more source clips, ending with a final output clip. When “played back,” the filter chain is evaluated for each frame, but this is transparent to Windows, which instead just sees a complete movie as though it’s already rendered to an AVI container.</p><p> 前面提到的大多数功能都可以在高端NLE应用程序（例如Resolve）中完成，实际上我已经使用Resolve编辑了自己的多个视频项目。对我来说，使VirtualDub成为“杀手级应用”的原因是它使用了Windows的内置视频播放库，因此能够使用AviSynth脚本。 AviSynth是一个可以安装在Windows PC上的库，它具有将AviSynth“脚本”文件（带有.avs扩展名）解释为AVI文件的任何功能，可以在任何提示Windows使用其内置功能播放Windows文件的地方播放。基本的AviSynth脚本语言是过程性的，没有循环或条件的，但它确实保留了在运行时使用多个变量并将经常调用的序列组织到子例程中的能力。它最常见的用途是形成一个过滤链，从一个或多个源片段开始，到最后一个输出片段结束。当“播放”时，将针对每个帧评估滤镜链，但这对Windows是透明的，Windows只会看到完整的电影，就像已经将其渲染到AVI容器一样。</p><p> Combined with VirtualDub, AviSynth allows me to write tiny scripts to do trims and conversions with frame-accurate precision, then render these edits to a final output video. Though AviSynth should be able to invoke VirtualDub plugins from its scripting language, I couldn’t figure out how to get it to work with Neat Video, so I did the next best thing: I created a pair of AviSynth scripts; one to feed  to Neat Video, and one to process the output  from Neat Video. The first script looks like this:</p><p> 与VirtualDub结合使用，AviSynth允许我编写微小的脚本以精确到帧的精度进行修剪和转换，然后将这些编辑呈现为最终的输出视频。尽管AviSynth应该能够从其脚本语言调用VirtualDub插件，但我无法弄清楚如何使其与Neat Video一起使用，所以我做了下一个最好的事情：我创建了一对AviSynth脚本；一台馈入Neat Video，另一台处理Neat Video的输出。第一个脚本如下所示：</p><p>  Absent of an explicit input argument, each AviSynth instruction receives the output of the previous instruction as its input. The Neat Video plugin for VirtualDub  expects its input to be encoded as 8-bit RGB. VirtualDub will automatically convert the source video to what Neat Video expects if not already in the proper format. Since I’m not sure exactly  how VirtualDub does its automatic conversion, I want to retain control over the process so I do the conversion myself from YUV to RGB using the Rec.601 matrix. I know that my source video is from an interlaced analog NTSC source; VirtualDub doesn’t know that unless I explicitly say so.</p><p>  由于没有明确的输入参数，每条AviSynth指令都会接收前一条指令的输出作为其输入。用于VirtualDub的Neat Video插件期望其输入被编码为8位RGB。 VirtualDub将自动将源视频转换为Neat Video期望的格式（如果格式不正确）。由于我不确定VirtualDub到底如何进行自动转换，因此我想保留对该过程的控制权，所以我自己使用Rec.601矩阵从YUV到RGB进行转换。我知道我的源视频来自隔行模拟NTSC源。除非我明确声明，否则VirtualDub不会知道。</p><p>  I render this intermediate video to an AVI container using the Huffyuv codec. Huffyuv is a lossless codec, meaning it can compress the video without any generational loss. Despite its name, Huffyuv is perfectly capable of keeping my video encoded as RGB. I can’t do further AviSynth processing on the result from Neat Video until I load it into my second AviSynth script, so I’m happy that its output can be unchanged from one script to the next.</p><p>  我使用Huffyuv编解码器将此中间视频渲染到AVI容器。 Huffyuv是一种无损编解码器，这意味着它可以压缩视频而不会造成任何代际损失。尽管名称如此，但Huffyuv完全能够将我的视频编码为RGB。在将Neat Video的结果加载到第二个AviSynth脚本之前，我无法对其进行进一步的AviSynth处理，因此，我很高兴其输出可以在一个脚本与下一个脚本之间保持不变。</p><p>  Colors reproduced by mixing photons can be broken down into three “primary colors.” We all learned about these in grade school:   red,   green, and   blue. Red and blue make   purple, blue and green make   turquoise, all three make   white, and so on.</p><p>  混合光子所产生的颜色可以分解为三种“原色”。我们都在小学学习过这些：红色，绿色和蓝色。红色和蓝色代表紫色，蓝色和绿色代表青绿色，所有三个代表白色，依此类推。</p><p> On TV screens, things are a bit more complicated. Way back when, probably before you were born, TV signals in the United States only came in black and white, and TVs only had one electron gun responsible for generating the entire picture. The picture signal mostly comprised of a varying voltage level per 525 lines indicating how bright or dark the picture should be at that point in that particular line. The history of the NTSC standard used to transmit analog television in the United States is well-documented elsewhere on the Internet, but the important fact here is that in 1953, color information was added to the TV signal broadcast to televisions conforming to the NTSC standard.</p><p>在电视屏幕上，情况要复杂一些。追溯到大概在您出生之前，美国的电视信号只有黑白信号，而电视只有一支电子枪负责生成整个图像。图像信号主要由每525行变化的电压电平组成，指示该图像在该特定行中该点的亮或暗程度。在美国，用于传输模拟电视的NTSC标准的历史在互联网上的其他地方都有充分的文献记载，但重要的是，在1953年，向广播到符合NTSC标准的电视的电视信号中添加了颜色信息。 。</p><p> One of the challenges in adding color to what was heretofore a strictly monochrome-only signal was that millions of black and white TVs were already in active use in the United States. A TV set was extremely expensive even by the early 1950s, so rendering all the active sets obsolete by introducing a new color standard would have proven quite unpopular. The solution—similar to how FM stereo radio was later standardized in 1961—was to add color as a completely optional, but still integral, signal of monochrome TV. The original black and white signal—now known as “luma”—would continue to be used to determine the brightness or “luminance” of the picture at any particular point on the screen, while the new color stream—known as “chroma”—would only transmit the color or “chrominance” information for that point. Existing black and white TVs would only know about the original “luma” signal, and so would continue to interpret it as a monochrome picture, whereas new color TVs would be aware of and overlay the new “chroma” stream on top of the original “luma” stream to produce a rich, vibrant, color picture. All of this information still had to fit into a relatively limited bandwidth signal, designed in the early 1940s to be transmitted through the air with graceful degradation in poor conditions.</p><p> 在迄今仅是单色信号的基础上增加色彩的挑战之一是，美国已经有数百万台黑白电视机投入使用。即使到1950年代初期，电视机也非常昂贵，因此通过引入新的色彩标准而使所有有源电视机过时的做法将被证明不受欢迎。该解决方案类似于FM立体声收音机后来在1961年进行标准化的方式，是将色彩添加为单色电视的完全可选但仍不可或缺的信号。原始的黑白信号（现在称为“亮度”）将继续用于确定屏幕上任何特定点上图片的亮度或“亮度”，而新的色彩流（称为“色度”）只会传送该点的颜色或“色度”信息。现有的黑白电视只会知道原始的“ luma”信号，因此会继续将其解释为单色图片，而新的彩色电视将意识到并覆盖新的“ chroma”流，并将其覆盖在原始“ luma”流产生丰富，充满活力的彩色图片。所有这些信息仍然必须适合一个相对有限的带宽信号，该信号在1940年代初设计为可以通过空中传输，在恶劣的条件下会逐渐衰减。</p><p>  The developers of early color computer monitors, by contrast, needed not worry about maintaining backward compatibility with black and white American television nor did they need to concern themselves with adopting a signal format that was almost 50 years old by that point. It should be of little surprise then, naturally, that computer monitors generate color closer to how we learned in grade school. Computer monitors in particular translate a signal describing separate intensities of red, green, and blue to a screen made up of triads of red, green, and blue dots of light. This signal describing what’s known as “  R  G  B” color (for   Red,   Green, and   Blue) comes both from that aforementioned color theory of mixing primaries, but also historically from those individual color signals more or less directly driving the respective voltages of three electron guns inside a color CRT. Despite both color TVs and computer monitors having three electron guns for mixing red, green, and blue primary colors, the way that color information is  encoded before entering the TV is a main differentiator.</p><p>  相比之下，早期彩色计算机显示器的开发人员无需担心与黑白美国电视保持向后兼容性，也不必担心采用那时已将近50年的信号格式。那么自然而然地，计算机显示器产生的色彩更接近我们在小学时所学的知识就不足为奇了。特别是计算机监视器将描述红色，绿色和蓝色的单独强度的信号转换为由红色，绿色和蓝色光点组成的三联体组成的屏幕。描述所谓的“ RGB”颜色（用于红色，绿色和蓝色）的信号不仅来自上述混合原色的颜色理论，而且历史上也来自那些或多或少直接驱动三支电子枪各自电压的颜色信号在彩色CRT中。尽管彩色电视和计算机监视器都具有用于混合红色，绿色和蓝色原色的三个电子枪，但是在进入电视之前对颜色信息进行编码的方法是主要区别。</p><p> Whereas RGB is the encoding scheme by which discrete Red, Green, and Blue values are represented, color TV uses something more akin to what’s known as “YUV.” YUV doesn’t really stand for anything—the “Y” component represents Luma, and the “UV” represents a coordinate into a 2D color plane, where  (1, 1) is   magenta,  (-1, -1) is   green, and  (0, 0) is   gray (the “default” value for when only the “Y” component is present, such as on black and white TVs). In NTSC, quadrature amplitude modulation is used to convey both of the UV components on top of the Y component’s frequency—I don’t know exactly what quadrature amplitude modulation is either, but suffice it to say it’s a fancy way of conveying two streams of information over one signal. 🙂</p><p> RGB是表示离散的红色，绿色和蓝色值的编码方案，而彩色电视则使用类似于“ YUV”的名称。 YUV并不代表任何东西，“ Y”分量代表亮度，“ UV”代表二维彩色平面中的坐标，其中（1，1）为洋红色，（-1，-1）为绿色， （0，0）为灰色（当仅存在“ Y”分量时（例如在黑白电视上）的“默认”值）。在NTSC中，正交幅度调制用于在Y分量的频率之上传输两个UV分量-我也不确切知道正交幅度调制是什么，但是可以说这是一种传输两种流的理想方法。一个信号的信息。 🙂</p><p> An interesting quirk of how the human visual system works is that we have evolved to be much more sensitive to changes in brightness than in color. Some  very  smart people have sciencey explanations as to why this is, but ultimately we can thank our early ancestors for this trait—being able to detect the subtlest of movements even in low light made us expert hunters. Indeed, when the lights are mostly off, most of us can still do a pretty good job of navigating our surroundings (read: hunting for the fridge) despite there being limited dynamic range in the brightness of what we  can see.</p><p> 关于人类视觉系统如何工作的一个有趣的怪癖是，我们已经进化为对亮度变化比对颜色变化更敏感。一些非常聪明的人对这是为什么有科学的解释，但最终我们可以感谢我们的早期祖先的这种特征-即使在低光下也能够检测到最细微的动作，这使我们成为专业的猎人。确实，当灯光大部分不亮时，尽管可见光的动态范围有限，我们大多数人仍然可以很好地导航周围的环境（阅读：寻找冰箱）。</p><p> Note that having a higher sensitivity to brightness vs. color does not mean humans are better at seeing in black and white. It merely means that we notice the difference between something   bright and something   dark better than we can tell if something is   one shade of red vs.   a different shade of red. In addition, humans are more sensitive to   orange/  blue than we are to   purple/  green. These facts actually came in very handy when trying to figure out how to fit a good-enough-looking color TV signal into the bandwidth already reserved (and used) for American television. Because we are not as sensitive to color, the designers of NTSC color TV could get away with transmitting  less color information than what’s in the luma signal. By reducing the amount of bandwidth for the purple/green range, color in NTSC can still be satisfactorily reproduced, though the designers of NTSC adopted a variant of YUV to accomplish this called “YIQ.” In YIQ, the Y component is still Luma, but the “IQ” represents a new coordinate into the same 2D color plane as YUV, just rotated slightly so that the purple/green spectrum falls on the axis with a smaller range. Nowadays with the higher bandwidth digital TV provides, we no longer need to encode using YIQ, but due again to the way our vision system responds to color and the technical benefits it provides, TV/video is still encoded using YUV, albeit will a fuller chroma representation.</p><p> 请注意，对亮度和颜色具有较高的敏感性并不意味着人类在黑白方面的视力会更好。这仅意味着我们注意到明亮的事物和黑暗的事物之间的区别要好于我们分辨事物是红色的阴影还是红色的阴影。此外，人类对橙色/蓝色比对紫色/绿色更敏感。当试图弄清楚如何将足够好看的彩色电视信号放入美国电视已经预留（和使用）的带宽中时，这些事实实际上非常有用。由于我们对颜色的敏感性不高，因此NTSC彩色电视的设计人员可以避免传输比亮度信号少的颜色信息。通过减少紫色/绿色范围的带宽量，尽管NTSC的设计人员采用YUV的变体来实现这一目标，但仍可以令人满意地重现NTSC中的颜色，称为“ YIQ”。在YIQ中，Y分量仍然是Luma，但是“ IQ”代表与YUV相同的2D彩色平面中的新坐标，只是稍微旋转即可使紫色/绿色光谱落在较小范围的轴上。如今，随着数字电视提供更高的带宽，我们不再需要使用YIQ进行编码，但是再次由于视觉系统对颜色的响应方式及其所提供的技术优势，尽管视频/视频将更加饱满，但仍然使用YUV对其进行编码色度表示。</p><p>  Each pixel on a modern computer screen is represented by at least three discrete values for   Red,   Green, and   Blue. Though NTSC defines 525 lines per frame (~480 visible), being an  analog standard means there really isn’t such a thing as “pixels” horizontally. However, most capture cards are configured to sample 720 points along each line of NTSC video, forming what we would call 720 “pixels” per line. But two important details must be noted:</p><p>  现代计算机屏幕上的每个像素至少由红色，绿色和蓝色的三个离散值表示。尽管NTSC每帧定义525行（可见480行），但作为模拟标准意味着实际上没有水平的“像素”之类的东西。但是，大多数捕获卡都配置为沿NTSC视频的每行采样720个点，形成每行720个“像素”。但是必须注意两个重要的细节：</p><p> Though 720 samples are enough to effectively capture the entire line, only 704 of them are typically visible and furthermore, NTSC TV is designed for a 4:3 aspect ratio. That is, if the picture is 480 square dots vertically, then it must be  (480 * 4) / 3 == 640 square dots horizontally, or the picture will appear squished and everything will look “fat.” A captured NTSC frame at 720×480 will need  horizontal scaling plus cropping to 640×480 to be displayed with the correct aspect ratio on a computer screen with square dots.</p><p>尽管720个样本足以有效地捕获整个线条，但通常只有704个样本可见，而且NTSC电视的宽高比为4：3。也就是说，如果图片垂直为480方形点，那么水平必须为（480 * 4）/ 3 == 640方形点，否则图片看起来会被压扁，并且所有内容看起来都是“胖”。在720×480处捕获的NTSC帧将需要水平缩放并裁剪为640×480，以在具有正方形点的计算机屏幕上以正确的纵横比显示。</p><p> 720 samples are enough to capture each line of the  luma component. The chroma component is a whole other story.</p><p> 720个样本足以捕获亮度分量的每一行。色度分量是另外一个故事。</p><p> Remember how the luma and chroma components are encoded separately, but that some of the chroma information can be discarded to save space and we’re not likely to notice? Turns out, computers can use that technique too to reduce bandwidth usage and save disk space. RGB is just how your computer talks to its display, but there’s no rule that says computer video  files need to be encoded as RGB. We can encode them as YUV, too, and this is where the term  chroma subsampling comes in.</p><p> 还记得亮度和色度分量是如何分别编码的，但是可以丢弃某些色度信息以节省空间，我们不太可能注意到吗？事实证明，计算机也可以使用该技术来减少带宽使用并节省磁盘空间。 RGB就是计算机与显示器进行对话的方式，但是没有规则说计算机视频文件需要编码为RGB。我们也可以将它们编码为YUV，这就是色度子采样这一术语出现的地方。</p><p> While we always want to sample all 704 visible “pixels” of luma information, we can often get away with capturing 50% or even as little as 25% of the chroma information for a given line of picture. The ratio of sampled chroma data to luma data is called the “chroma subsampling” ratio and is indicated by the notation   Y:a:b, where:</p><p> 尽管我们一直想对亮度信息的所有704个可见“像素”进行采样，但是对于给定的图像行，我们通常可以捕获50％甚至少至25％的色度信息。采样的色度数据与亮度数据的比率称为“色度二次采样”比率，并用符号Y：a：b表示，其中：</p><p> Y: the number of luma samples per line in the conceptual two-line block used by   a and   b to reference. This is almost always 4.</p><p> Y：概念性两行块中每行的亮度采样数，a和b用作参考。这几乎总是4。</p><p> a: the number of chroma samples mapped over t</p><p> a：t上映射的色度样本数</p><p>......</p><p>......</p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://blitter.net/blog/2020/11/24/digitizing-old-8mm-tapes/">https://blitter.net/blog/2020/11/24/digitizing-old-8mm-tapes/</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/mm/">#mm</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/分享/">#分享</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy; 2020 diglog.com </div></div></body></html>