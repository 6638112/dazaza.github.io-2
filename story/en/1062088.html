<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>与快餐和芹菜的异步任务 Asynchronous Tasks with FastAPI and Celery</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">Asynchronous Tasks with FastAPI and Celery<br/>与快餐和芹菜的异步任务 </h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2021-05-12 09:43:17</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2021/5/4ef40bb272914c5d2cae6f099c3a4365.png"><img src="http://img2.diglog.com/img/2021/5/4ef40bb272914c5d2cae6f099c3a4365.png" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>If a long-running process is part of your application&#39;s workflow, rather blocking the response, you should handle it in the background, outside the normal request/response flow.</p><p>如果长期运行过程是应用程序的一部分＆＃39; S工作流程，而是阻止响应，您应该在正常请求/响应流之外处理它。</p><p> Perhaps your web application requires users to submit a thumbnail (which will probably need to be re-sized) and confirm their email when they register. If your application processed the image and sent a confirmation email directly in the request handler, then the end user would have to wait unnecessarily for them both to finish processing before the page loads or updates. Instead, you&#39;ll want to pass these processes off to a task queue and let a separate worker process deal with it, so you can immediately send a response back to the client. The end user can then do other things on the client-side while the processing takes place. Your application is also free to respond to requests from other users and clients.</p><p> 也许您的Web应用程序要求用户提交缩略图（可能需要重新大小）并在注册时确认其电子邮件。如果您的应用程序处理了该图像并直接在请求处理程序中发送了确认电子邮件，那么最终用户将不必要地等待在页面加载或更新之前完成处理。相反，您＆＃39; ll希望将这些进程传递给任务队列，并让单独的工作进程处理它，因此您可以立即将响应发送回客户端。然后，在处理发生时，最终用户可以在客户端执行其他内容。您的应用程序也可以自由地响应其他用户和客户的请求。</p><p> To achieve this, we&#39;ll walk you through the process of setting up and configuring  Celery and Redis for handling long-running processes in a FastAPI app. We&#39;ll also use Docker and Docker Compose to tie everything together. Finally, we&#39;ll look at how to test the Celery tasks with unit and integration tests.</p><p> 为实现这一目标，我们＆＃39; LL通过设置和配置Celery和Redis来处理FastAPI应用程序的长期进程的过程。我们＆＃39; LL也使用Docker和Docker撰写，将所有东西系在一起。最后，我们＆＃39; ll看如何用单元和集成测试测试芹菜任务。</p><p>       Again, to improve user experience, long-running processes should be run outside the normal HTTP request/response flow, in a background process.</p><p>       同样，为了提高用户体验，在后台进程中应该在正常的HTTP请求/响应流之外运行长时间运行的进程。</p><p>   As you&#39;re building out an app, try to distinguish tasks that should run during the request/response lifecycle, like CRUD operations, from those that should run in the background.</p><p>   与您建立一个应用程序时，尝试区分应在请求/响应生命周期（如CRUD操作）中运行的任务从背景中运行。</p><p> It&#39;s worth noting that you can leverage FastAPI&#39;s  BackgroundTasks class, which comes directly from  Starlette, to run tasks in the background.</p><p> 值得注意的是，你可以利用Fastapi＆＃39; s backgroundtasks类，它直接来自Starlette，在背景中运行任务。</p><p>  from  fastapi  import  BackgroundTasks def  send_email ( email ,  message ):  pass @app . get ( &#34;/&#34; ) async  def  ping ( background_tasks :  BackgroundTasks ):  background_tasks . add_task ( send_email ,  &#34; [email protected]&#34; ,  &#34;Hi!&#34; )  return  { &#34;message&#34; :  &#34;pong!&#34; }</p><p>  来自Fastapi导入背景特设需要def send_email（电子邮件，消息）：pass @app。获得（＆＃34; /＆＃34;）async def ping（background_tasks：backgroundtasks）：background_tasks。 add_task（send_email，＆＃34; [电子邮件受保护]＆＃34;，＆＃34;嗨！＆＃34;）返回{＆＃34;消息＆＃34; ：＆＃34; Pong！＆＃34; } </p><p>  CPU intensive tasks: Celery should be used for tasks that perform heavy background computations since  BackgroundTasks runs in the same event loop that serves your app&#39;s requests.</p><p>CPU密集型任务：Celery应该用于执行繁重的背景计算的任务，因为背景特定在服务于您的应用程序的同一事件循环中运行。</p><p> Task queue: If you require a task queue to manage the tasks and workers, you should use Celery. Often you&#39;ll want to retrieve the status of a job and then perform some action based on the status -- i.e., send an error email, kick off a different background task, or retry the task. Celery manages all this for you.</p><p> 任务队列：如果您需要任务队列来管理任务和工人，则应使用Celery。通常，您＆＃39; ll想要检索作业的状态，然后根据状态 - 即，发送错误电子邮件，启动不同的后台任务，或重试任务来执行一些操作。芹菜为您管理所有这些。</p><p>  Our goal is to develop a FastAPI application that works in conjunction with Celery to handle long-running processes outside the normal request/response cycle.</p><p>  我们的目标是开发一个Fastapi应用程序，它与芹菜一起配合使用，以处理正常请求/响应周期之外的长期运行过程。</p><p> The end user kicks off a new task via a POST request to the server-side.</p><p> 最终用户通过向服务器端的POST请求启动新任务。</p><p> Within the route handler, a task is added to the queue and the task ID is sent back to the client-side.</p><p> 在路由处理程序中，将任务添加到队列中，并且任务ID被发送回客户端。</p><p> Using AJAX, the client continues to poll the server to check the status of the task while the task itself is running in the background.</p><p> 使用Ajax，客户端继续轮询服务器以检查任务本身在后台运行的任务状态。</p><p>   Clone down the base project from the  fastapi-celery repo, and then check out the  v1 tag to the master branch:</p><p>   从FastApi-Celery Repo克隆基本项目，然后从Master Branch中查看V1标记： </p><p>  Since we&#39;ll need to manage three processes in total (FastAPI, Redis, Celery worker), we&#39;ll use Docker to simplify our workflow by wiring them up so that they can all be run from one terminal window with a single command.</p><p>自从我们＆＃39; LL总共需要管理三个过程（Fastapi，Redis，Celery Worker），我们使用Docker通过将它们的工作流程来简化我们的工作流程，以便它们都可以从一个终端窗口运行单个命令。</p><p>      $ docker-compose  exec web python -m  pytest ==================================  test session  starts  ===================================platform linux -- Python  3.9.5, pytest-6.2.4, py-1.10.0, pluggy-0.13.1rootdir: /usr/src/appcollected  1 itemtests/test_tasks.py .  [ 100% ] ===================================  1 passed in  0.06s  ====================================</p><p>      $ Docker-Compose Exec网Python -M Pytest ==================================测试会话开始=== ================================平台linux  -  python 3.9.5，pytest-6.2.4，py-1.10 .0，Pluggy-0.13.1Rootdir：/ usr / src / appcollected 1 itemtests / test_tasks.py。 [100％] =================================== 1通过0.06s ====== ==============================.</p><p>  ├── .gitignore├── LICENSE├── README.md├── docker-compose.yml└── project ├── Dockerfile ├── main.py ├── requirements.txt ├── static │   ├── main.css │   └── main.js ├── templates │   ├── _base.html │   ├── footer.html │   └── home.html └── tests ├── __init__.py ├── conftest.py └── test_tasks.py</p><p>  ├──吉蒂尼 - ──授权¶──readme.md├──docker-compose.yml└──项目├────────────────────────────────静态─main.css│── -  main.js├──模板│├──_base.html│── .py└──test_tasks.py.</p><p>  An  onclick event handler in  project/templates/home.html is set up that listens for a button click:</p><p>  项目/ templates / home.html中的onclick事件处理程序设置为按钮点击：</p><p> &lt; div  class = &#34;btn-group&#34;  role = &#34;group&#34;  aria-label = &#34;Basic example&#34; &gt;  &lt; button  type = &#34;button&#34;  class = &#34;btn btn-primary&#34;  onclick = &#34;handleClick(1)&#34; &gt;Short &lt;/ a &gt;  &lt; button  type = &#34;button&#34;  class = &#34;btn btn-primary&#34;  onclick = &#34;handleClick(2)&#34; &gt;Medium &lt;/ a &gt;  &lt; button  type = &#34;button&#34;  class = &#34;btn btn-primary&#34;  onclick = &#34;handleClick(3)&#34; &gt;Long &lt;/ a &gt; &lt;/ div &gt;</p><p> ＆lt; div类=＆＃34; btn-group＆＃34;角色=＆＃34;组＆＃34; aria-label =＆＃34;基本示例＆＃34; ＆gt; ＆lt;按钮类型=＆＃34;按钮＆＃34; Class =＆＃34; BTN BTN-Primary＆＃34; onclick =＆＃34; handleclick（1）＆＃34; ＆gt;短＆lt; / a＆gt; ＆lt;按钮类型=＆＃34;按钮＆＃34; Class =＆＃34; BTN BTN-Primary＆＃34; onclick =＆＃34; handleclick（2）＆＃34; ＆gt;培养基＆lt; / a＆gt; ＆lt;按钮类型=＆＃34;按钮＆＃34; Class =＆＃34; BTN BTN-Primary＆＃34; onclick =＆＃34; handleclick（3）＆＃34; ＆gt;长＆lt; / a＆gt; ＆lt; / div＆gt;</p><p> onclick calls  handleClick found in  project/static/main.js, which sends an AJAX POST request to the server with the appropriate task type:  1,  2, or  3.</p><p> 在项目/静态/ main.js中找到的onclick调用handleclick，它将ajax post请求发送到服务器，具有适当的任务类型：1,2或3。</p><p> function  handleClick ( type )  {  fetch ( &#39;/tasks&#39; ,  {  method :  &#39;POST&#39; ,  headers :  {  &#39;Content-Type&#39; :  &#39;application/json&#39;  },  body :  JSON . stringify ({  type :  type  }),  })  . then ( response  =&gt;  response . json ())  . then ( res  =&gt;  getStatus ( res . data . task_id )); }</p><p> 函数handleclick（类型）{fetch（＆＃39; /任务＆＃39; {方法：＆＃39;帖子＆＃39;标题：{＆＃39; content-type＆＃39;：＆＃39;申请/ json＆＃39;}，body：json。stryify（{type：type}），}）。然后（响应=＆gt;响应。JSON（））。然后（res =＆gt; getstatus（res。数据。task_id））; } </p><p>        Celery uses a message  broker --  RabbitMQ,  Redis, or  AWS Simple Queue Service (SQS) -- to facilitate communication between the Celery worker and the web application. Messages are added to the broker, which are then processed by the worker(s). Once done, the results are added to the backend.</p><p>CELERY使用消息代理 -  RabbitMQ，REDIS或AWS简单的队列服务（SQS） - 以促进芹菜工人和Web应用程序之间的沟通。消息被添加到代理中，然后由工作人员处理。一旦完成，结果将添加到后端。</p><p> Redis will be used as both the broker and backend. Add both Redis and a Celery  worker to the  docker-compose.yml file like so:</p><p> Redis将被用作经纪人和后端。将redis和celery worker添加到docker-compose.yml文件中：</p><p> version :  &#39;3.8&#39; services :  web :  build :  ./project  ports :  -  8004:8000  command :  uvicorn main:app --host 0.0.0.0 --reload  volumes :  -  ./project:/usr/src/app  environment :  -  CELERY_BROKER_URL=redis://redis:6379/0  -  CELERY_RESULT_BACKEND=redis://redis:6379/0  depends_on :  -  redis  worker :  build :  ./project  command :  celery worker --app=worker.celery --loglevel=info  volumes :  -  ./project:/usr/src/app  environment :  -  CELERY_BROKER_URL=redis://redis:6379/0  -  CELERY_RESULT_BACKEND=redis://redis:6379/0  depends_on :  -  web  -  redis  redis :  image :  redis:6-alpine</p><p> 版本：＆＃39; 3.8＆＃39;服务：Web：构建：./project端口： -  8004：8000命令：Uvicorn Main：App --host 0.0.0.0  - 中加载卷： -  ./project:/usr/src/app环境： -  celery_broker_url = redis： // redis：6379/0  -  celery_result_backend = redis：// redis：6379/0 devens_on： -  redis工作者：build：./project命令：celery worker  -  app = worker.celery --loglevel = Info卷： - 。 /项目：/ usr / src / app环境： -  celery_broker_url = redis：// redis：6379/0  -  celery_result_backend = redis：// redis：6379/0 depends_on： -  web  -  redis redis：图片：Redis：6-Alpine</p><p>    import  os import  time from  celery  import  Celery celery  =  Celery ( __name__ ) celery . conf . broker_url  =  os . environ . get ( &#34;CELERY_BROKER_URL&#34; ,  &#34;redis://localhost:6379&#34; ) celery . conf . result_backend  =  os . environ . get ( &#34;CELERY_RESULT_BACKEND&#34; ,  &#34;redis://localhost:6379&#34; ) @celery . task ( name = &#34;create_task&#34; ) def  create_task ( task_type ):  time . sleep ( int ( task_type )  *  10 )  return  True</p><p>    从芹菜导入芹菜芹菜=芹菜（__name__）芹菜。 Conf。 broker_url =操作系统。环境。得到（＆＃34; celery_broker_url＆＃34;，＆＃34; redis：// localhost：6379＆＃34;）芹菜。 Conf。结果_Backend = OS。环境。得到（＆＃34; celery_result_backend＆＃34;，＆＃34; redis：// localhost：6379＆＃34;）@celery。任务（名称=＆＃34; create_task＆＃34;）def create_task（task_type）：时间。睡眠（int（task_type）* 10）返回true</p><p> Here, we created a new Celery instance, and using the  task decorator, we defined a new Celery task function called  create_task.</p><p> 在这里，我们创建了一个新的celery实例，并使用任务装饰器，我们定义了一个名为create_task的新芹菜任务函数。</p><p>   Update the route handler to kick off the task and respond with the task ID:</p><p>   更新路由处理程序以启动任务并响应任务ID：</p><p>            function  handleClick ( type )  {  fetch ( &#39;/tasks&#39; ,  {  method :  &#39;POST&#39; ,  headers :  {  &#39;Content-Type&#39; :  &#39;application/json&#39;  },  body :  JSON . stringify ({  type :  type  }),  })  . then ( response  =&gt;  response . json ())  . then ( res  =&gt;  getStatus ( res . data . task_id )); }</p><p>            函数handleclick（类型）{fetch（＆＃39; /任务＆＃39; {方法：＆＃39;帖子＆＃39;标题：{＆＃39; content-type＆＃39;：＆＃39;申请/ json＆＃39;}，body：json。stryify（{type：type}），}）。然后（响应=＆gt;响应。JSON（））。然后（res =＆gt; getstatus（res。数据。task_id））; } </p><p> When the response comes back from the original AJAX request, we then continue to call  getStatus() with the task ID every second:</p><p>从原始Ajax请求中返回响应时，我们将继续使用每秒任务ID调用getStatus（）：</p><p> function  getStatus ( taskID )  {  fetch ( `/tasks/ ${ taskID } ` ,  {  method :  &#39;GET&#39; ,  headers :  {  &#39;Content-Type&#39; :  &#39;application/json&#39;  },  })  . then ( response  =&gt;  response . json ())  . then ( res  =&gt;  {  const  html  =  `  &lt;tr&gt;  &lt;td&gt; ${ taskID } &lt;/td&gt;  &lt;td&gt; ${ res . data . task_status } &lt;/td&gt;  &lt;td&gt; ${ res . data . task_result } &lt;/td&gt;  &lt;/tr&gt;` ;  document . getElementById ( &#39;tasks&#39; ). prepend ( html );  const  newRow  =  document . getElementById ( &#39;table&#39; ). insertRow ();  newRow . innerHTML  =  html ;  const  taskStatus  =  res . data . task_status ;  if  ( taskStatus  ===  &#39;finished&#39;  ||  taskStatus  ===  &#39;failed&#39; )  return  false ;  setTimeout ( function ()  {  getStatus ( res . data . task_id );  },  1000 );  })  . catch ( err  =&gt;  console . log ( err )); }</p><p> 函数getStatus（taskID）{fetch（`/任务/ $ {taskId}`，{方法：＆＃39; get＆＃39;标题：{＆＃39; content-type＆＃39;：＆＃39;申请/ json＆＃39;}，}）。然后（响应=＆gt;响应。JSON（））。然后（res =＆gt; {const html =`＆lt; tr＆gt; $ {taskId}＆lt; / td＆gt; $ {res。数据。task_status}＆lt; / td＆gt;＆lt; td＆gt; $ {res。task_result}＆lt; / td＆gt;＆lt; / tr＆gt;`;文件。getElementbyid（＆＃39;任务＆＃39;）。prepend（html）; const newrow = document。getElementbyid（＆＃39;表＆ ＃39;）。insertrow（）; newrow。innerhtml = html; const taskstatus = res。数据。task_status;如果（taskstatus ===＆＃39;完成＆＃39; || taskstatus ===＆＃39;失败＆＃ 39;）返回false; setTimeout（function（）{getstatus（restatus。task_id）;}，1000）;}）。 catch（err =＆gt;控制台。日志（错误））; }</p><p> If the response is successful, a new row is added to the table on the DOM.</p><p> 如果响应成功，则将新行添加到DOM上的表中。</p><p>  @app . get ( &#34;/tasks/ {task_id} &#34; ) def  get_status ( task_id ):  task_result  =  AsyncResult ( task_id )  result  =  {  &#34;task_id&#34; :  task_id ,  &#34;task_status&#34; :  task_result . status ,  &#34;task_result&#34; :  task_result . result  }  return  JSONResponse ( result )</p><p>  @应用程序 。获得（＆＃34; /任务/ {task_id}＆＃34;）def get_status（task_id）：task_result = asyncresult（task_id）结果= {＆＃34; task_id＆＃34; ：task_id，＆＃34; task_status＆＃34; ：task_result。状态，＆＃34; task_result＆＃34; ：task_result。结果}返回jsonresponse（结果）</p><p>       Then, grab the  task_id from the response and call the updated endpoint to view the status:</p><p>       然后，从响应中获取Task_ID并调用更新的端点以查看状态：</p><p>     Update the  worker service, in  docker-compose.yml, so that Celery logs are dumped to a log file:</p><p>     在Docker-compose.yml中更新工作服务，以便芹菜日志转储到日志文件：</p><p> worker :  build :  ./project  command :  celery worker --app=worker.celery --loglevel=info --logfile=logs/celery.log  volumes :  -  ./project:/usr/src/app  environment :  -  CELERY_BROKER_URL=redis://redis:6379/0  -  CELERY_RESULT_BACKEND=redis://redis:6379/0  depends_on :  -  web  -  redis</p><p> 工人：build：./project命令：celery worker  -  app = worker.celery --loglevel = info --logfile = logs / celery.log卷： -  ./project:/usr/src/app环境： -  celery_broker_url = redis：// redis：6379/0  -  celery_result_backend = redis：// redis：6379/0 depends_on： -  web  -  redis </p><p> Add a new directory to &#34;project&#34; called &#34;logs. Then, add a new file called  celery.log to that newly created directory.</p><p>将新目录添加到＆＃34;项目＆＃34;叫做＆＃34;日志。然后，将名为celery.log的新文件添加到新创建的目录。</p><p>   You should see the log file fill up locally since we set up a volume:</p><p>   自从我们设置卷以来，您应该看到当地填写日志文件：</p><p> [ 2021-05-08  15:32:24,407: INFO/MainProcess ] Connected to redis://redis:6379/0 [ 2021-05-08  15:32:24,415: INFO/MainProcess ] mingle: searching  for neighbors [ 2021-05-08  15:32:25,434: INFO/MainProcess ] mingle: all alone [ 2021-05-08  15:32:25,448: INFO/MainProcess ]  [email protected] ready. [ 2021-05-08  15:32:29,834: INFO/MainProcess ] Received task: create_task [013df48c-4548-4a2b-9b22-7267da215361 ] [ 2021-05-08  15:32:39,825: INFO/ForkPoolWorker-7 ] Task create_task [013df48c-4548-4a2b-9b22-7267da215361 ] succeeded in  10.02114040000015s: True</p><p> [2021-05-08 15：32：24,407：INFO / MAINPROCESS]连接到REDIS：// REDIS：6379/0 [2021-05-08 15：32：24,415：INFO / MAINPROCESS] MINGLE：寻找邻居[2021 -05-08 15：32：25,434：信息/主题]混合：全部单独[2021-05-08 15：32：25,448：Info / mainProcess] [电子邮件受保护]准备好。 [2021-05-08 15：32：29,834：INFO / mainProcess]接收任务：CREATE_TASK [013DF48C-4548-4A2B-9B22-7267DA215361] [2021-05-08 15：32：39,825：INFO / FORKPOOLWORKER-7]任务create_task [013df48c-4548-4a2b-9b22-7267da215361]成功于10.02114040000015s：true</p><p>  Flower is a lightweight, real-time, web-based monitoring tool for Celery. You can monitor currently running tasks, increase or decrease the worker pool, view graphs and a number of statistics, to name a few.</p><p>  花是一种轻量级，实时，用于芹菜的基于网络的监控工具。您可以监控当前运行的任务，增加或减少工人池，查看图形和许多统计信息，以命名几个。</p><p>    dashboard :  build :  ./project  command :  flower --app=worker.celery --port=5555 --broker=redis://redis:6379/0  ports :  -  5556:5555  environment :  -  CELERY_BROKER_URL=redis://redis:6379/0  -  CELERY_RESULT_BACKEND=redis://redis:6379/0  depends_on :  -  web  -  redis  -  worker</p><p>    仪表板：build：./project命令：flower -app = worker.celery --port = 5555 --broker = redis：// redis：6379/0端口： -  5556：5555环境： -  celery_broker_url = redis：// redis：6379/0  -  celery_result_backend = redis：// redis：6379/0 depends_on： -  web  -  redis  - 工作人员</p><p>   Navigate to  http://localhost:5556 to view the dashboard. You should see one worker ready to go:</p><p>   导航到http：// localhost：5556要查看仪表板。你应该看到一名工人准备好了：</p><p>              ==================================  test session  starts  ===================================platform linux -- Python  3.9.5, pytest-6.2.4, py-1.10.0, pluggy-0.13.1rootdir: /usr/src/appplugins: celery-4.4.7collected  2 items /  1 deselected /  1 selectedtests/test_tasks.py .  [ 100% ] ======================  1 passed,  1 deselected in  60.05s  ( 0:01:00 )  ========================</p><p>              ==================================测试会话开始============= ======================平台linux  -  python 3.9.5，pytest-6.2.4，py-1.10.0，pluggy-0.13.1rootdir：/ usr / src / appplugins：celery-4.4.7 ofcolted 2 item / 1取消选择/ 1 selectedTests / test_tasks.py。 [100％] ====================== 1通过，1在60.05s中取消选择（0:01:00）========= ===============. </p><p> It&#39;s worth noting that in the above asserts, we used the  .run method (rather than  .delay) to run the task directly without a Celery worker.</p><p>值得注意的是，在上面的断言中，我们使用.Run方法（而不是.delay）直接在没有芹菜工人的情况下直接运行任务。</p><p>  @patch ( &#34;worker.create_task.run&#34; ) def  test_mock_task ( mock_run ):  assert  create_task . run ( 1 )  create_task . run . assert_called_once_with ( 1 )  assert  create_task . run ( 2 )  assert  create_task . run . call_count  ==  2  assert  create_task . run ( 3 )  assert  create_task . run . call_count  ==  3</p><p>  @patch（＆＃34; worker.create_task.run＆＃34;）def test_mock_task（mock_run）：ssuert create_task。运行（1）create_task。跑步 。 assert_called_once_once_on（1）assert create_task。运行（2）assert create_task。跑步 。 call_count == 2 assert create_task。运行（3）assert create_task。跑步 。 call_count == 3.</p><p>    $ docker-compose  exec web python -m pytest -k  &#34;test_mock_task&#34; ==================================  test session  starts  ===================================platform linux -- Python  3.9.5, pytest-6.2.4, py-1.10.0, pluggy-0.13.1rootdir: /usr/src/appplugins: celery-4.4.7collected  3 items /  2 deselected /  1 selectedtests/test_tasks.py .  [ 100% ] ============================  1 passed,  2 deselected in  0.13s  =============================</p><p>    $ docker-compose exec web python -m pytest -k＆＃34; test_mock_task＆＃34; ==================================测试会话开始============= ======================平台linux  -  python 3.9.5，pytest-6.2.4，py-1.10.0，pluggy-0.13.1rootdir：/ usr / src / appplugins：celery-4.4.7 ichected 3项目/ 2取消选择/ 1 selectedTests / test_tasks.py。 [100％] ============================ 1通过，2在0.13S中取消选择========== ===================.</p><p>   def  test_task_status ( test_app ):  response  =  test_app . post (  &#34;/tasks&#34; ,  data = json . dumps ({ &#34;type&#34; :  1 })  )  content  =  response . json ()  task_id  =  content [ &#34;task_id&#34; ]  assert  task_id  response  =  test_app . get ( f &#34;tasks/ {task_id} &#34; )  content  =  response . json ()  assert  content  ==  { &#34;task_id&#34; :  task_id ,  &#34;task_status&#34; :  &#34;PENDING&#34; ,  &#34;task_result&#34; :  None }  assert  response . status_code  ==  200  while  content [ &#34;task_status&#34; ]  ==  &#34;PENDING&#34; :  response  =  test_app . get ( f &#34;tasks/ {task_id} &#34; )  content  =  response . json ()  assert  content  ==  { &#34;task_id&#34; :  task_id ,  &#34;task_status&#34; :  &#34;SUCCESS&#34; ,  &#34;task_result&#34; :  True }</p><p>   def test_task_status（test_app）：response = test_app。帖子（＆＃34; /任务＆＃34;，data = json。转储（{＆＃34;类型＆＃34;：1}））content =响应。 json（）task_id = content [＆＃34; task_id＆＃34; assert task_id response = test_app。获取（f＆＃34;任务/ {task_id}＆＃34;）content =响应。 JSON（）assert content == {＆＃34; task_id＆＃34; ：task_id，＆＃34; task_status＆＃34; ：＆＃34;待处理＆＃34; ，＆＃34; task_result＆＃34; ：无}断言回复。 CONTER_CODE == 200而内容[＆＃34; task_status＆＃34; ] ==＆＃34;待决＆＃34; ：Response = test_app。获取（f＆＃34;任务/ {task_id}＆＃34;）content =响应。 JSON（）assert content == {＆＃34; task_id＆＃34; ：task_id，＆＃34; task_status＆＃34; ：＆＃34;成功＆＃34; ，＆＃34; task_result＆＃34; ：  真的 }</p><p> Keep in mind that this test uses the same broker and backend used in development. You may want to instantiate a new Celery app for testing.</p><p> 请记住，此测试使用开发中使用的相同代理和后端。您可能想要实例化一个新的Celery应用程序进行测试。</p><p>     This has been a basic guide on how to configure Celery to run long-running tasks in a FastAPI app. You should let the queue handle any processes that could block or slow down the user-facing code.</p><p>     这是如何配置Celery以在Fastapi应用程序中运行长期运行任务的基本指南。您应该让队列处理任何可能阻止或慢下用户代码的进程。</p><p> Celery can also be used to execute repeatable tasks and break up complex, resource-intensive tasks so that the computational workload can be distributed across a number of machines to reduce (1) the time to completion and (2) the load on the machine handling client requests.</p><p> Celery也可以用于执行可重复的任务并分解复杂的资源密集型任务，以便可以在许多机器上分发计算工作负载以减少（1）完成时间和（2）机器处理上的负载客户要求。 </p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://testdriven.io/blog/fastapi-and-celery/">https://testdriven.io/blog/fastapi-and-celery/</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/快餐/">#快餐</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/tasks/">#tasks</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/任务/">#任务</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/分享/">#分享</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy;2012-2021 diglog.com </div></div></body></html>