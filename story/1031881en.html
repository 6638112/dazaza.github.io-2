<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>保时捷分类器-以95%的准确率识别保时捷车型</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">保时捷分类器-以95%的准确率识别保时捷车型</h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2020-10-29 10:30:56</div><div class="page_narrow text-break page_content"><p>Trained using  fastai-v3,  pytorch and  Gradient.Uses  resnet50 and trained on a  Nvidia Quadro P5000.Built on  docker and is hosted on  Microsoft Azure Web Services.Trained on a dataset of publicly sourced images containing 30000 Porsche car models of varying degree of quality.Porsche cars, specially the latest generations of the Panamera/Taycan, Macan/Cayenne &amp; 911 / 718 can be pretty tricky to tell apart for a layman who isn’t paying very close attention, which is why I wanted to test out what kind of features this deep learning model would pick up.</p><p>使用Fastai-v3、pytorch和Gradient进行培训。使用resnet50，在NVIDIA Quadro P5000上进行培训。构建在坞站上，并托管在Microsoft Azure Web服务上。在包含30000款不同质量的保时捷车型的公开来源图像数据集上进行培训。保时捷汽车，特别是最新一代的Panamera/Taycan，Macan/Cayenne&Amp911/718对于一个不太关注的外行来说可能很难区分，这就是为什么我想测试这种深度学习模型会获得什么样的功能。</p><p>  In this tutorial we will see how to easily create an image dataset through Google Images. Note: You will have to repeat these steps for any new category you want to Google (e.g once for dogs and once for cats).</p><p>在本教程中，我们将了解如何通过Google Images轻松创建图像数据集。注意：对于任何你想用谷歌搜索的新类别，你都必须重复这些步骤(例如，一次针对狗，一次针对猫)。</p><p>    Go to Google Images and search for the images you are interested in. The more specific you are in your Google Search, the better the results and the less manual pruning you will have to do.</p><p>转到谷歌图片，搜索你感兴趣的图片。你在谷歌搜索中越具体，搜索结果就越好，你需要做的手动修剪就越少。</p><p> Scroll down until you’ve seen all the images you want to download, or until you see a button that says ‘Show more results’. All the images you scrolled past are now available to download. To get more, click on the button, and continue scrolling. The maximum number of images Google Images shows is 700.</p><p>向下滚动，直到您看到要下载的所有图像，或者直到您看到一个按钮，上面写着“显示更多结果”。您滚动过的所有图像现在都可以下载。要获取更多信息，请单击该按钮，然后继续滚动。Google Images最多显示700张图片。</p><p> It is a good idea to put things you want to exclude into the search query, for instance if you are searching for the Eurasian wolf, “canis lupus lupus”, it might be a good idea to exclude other variants:</p><p>将您想要排除的内容放入搜索查询中是一个好主意，例如，如果您正在搜索欧亚狼“canis lupus lupus”，那么排除其他变体可能是个好主意：</p><p>  You can also limit your results to show only photos by clicking on Tools and selecting Photos from the Type dropdown.</p><p>您还可以通过单击工具并从类型下拉列表中选择照片，将结果限制为仅显示照片。</p><p>  Now you must run some Javascript code in your browser which will save the URLs of all the images you want for you dataset.</p><p>现在，您必须在浏览器中运行一些Javascript代码，该代码将为您的数据集保存您想要的所有图像的URL。</p><p> In Google Chrome press CtrlShiftj on Windows/Linux and CmdOptj on macOS, and a small window the javascript ‘Console’ will appear. In Firefox press CtrlShiftk on Windows/Linux or CmdOptk on macOS. That is where you will paste the JavaScript commands.</p><p>在Google Chrome中，在Windows/Linux上按CtrlShiftj，在MacOS上按CmdOptj，会出现一个名为javascript“控制台”的小窗口。在Firefox中，按CtrlShiftk(Windows/Linux)或CmdOptk(MacOS)。这就是您将粘贴JavaScript命令的位置。</p><p> You will need to get the urls of each of the images. Before running the following commands, you may want to disable ad blocking extensions (uBlock, AdBlockPlus etc.) in Chrome. Otherwise the window.open() command doesn’t work. Then you can run the following commands:</p><p>您需要获取每个图像的URL。在运行以下命令之前，您可能需要禁用广告拦截扩展(uBlock、AdBlockPlus等)。在Chrome中。否则，window.open()命令不起作用。然后，您可以运行以下命令：</p><p>   Choose an appropriate name for your labeled images. You can run these steps multiple times to create different labels.</p><p>为带标签的图像选择适当的名称。您可以多次运行这些步骤来创建不同的标签。</p><p> In [ 0]: folder  =  &#39;718&#39;  file  =  &#39;718.csv&#39; In [ 0]: folder  =  &#39;911&#39;  file  =  &#39;911.csv&#39; In [ 0]: folder  =  &#39;cayenne&#39;  file  =  &#39;cayenne.csv&#39; In [ 0]: folder  =  &#39;macan&#39;  file  =  &#39;macan.csv&#39; In [ 0]: folder  =  &#39;taycan&#39;  file  =  &#39;taycan.csv&#39; In [ 0]: folder  =  &#39;panamera&#39;  file  =  &#39;panamera.csv&#39;</p><p>In[0]：Folder=&#39；718&#39；file=&#39；718.csv&#39；in[0]：Folder=&#39；911&#39；file=&#39；911.csv&#39；in[0]：Folder=&#39；cayenne&#39；file=&#39；cayenne.csv&#39；Folder=&#39；Macan&#39；file=&#39；macan.csv&#39；In[0]：Folder=&#39；taycan&#39；file=&#39；taycan.csv&#39；in[0]：Folder=&#39；Panamera&#39；file=&#39；panamera.csv&#39；</p><p>  In [ 0]: path  = Path( &#39;data/porsche&#39;) dest  = path /folder dest .mkdir(parents = True, exist_ok = True) In [ 0]: path .ls() Out[ 0]: [PosixPath( &#39;data/porsche/cayenne&#39;), PosixPath( &#39;data/porsche/panamera.csv&#39;), PosixPath( &#39;data/porsche/cayenne.csv&#39;), PosixPath( &#39;data/porsche/panamera&#39;), PosixPath( &#39;data/porsche/taycan&#39;), PosixPath( &#39;data/porsche/911.csv&#39;), PosixPath( &#39;data/porsche/taycan.csv&#39;), PosixPath( &#39;data/porsche/911&#39;), PosixPath( &#39;data/porsche/macan.csv&#39;), PosixPath( &#39;data/porsche/718&#39;), PosixPath( &#39;data/porsche/718.csv&#39;), PosixPath( &#39;data/porsche/macan&#39;)]</p><p>In[0]：path=path(&#39；data/Porsche&#39；)DEST=path/Folder dest.mkdir(Parents=True，Exist_ok=True)in[0]：path.ls()out[0]：[PosiPath(&#39；data/Porsche/Cayenne&#39；)，PosiPath(&#39；data/Porsche/panamera.csv&#39；)，PosiPath(&#39；data/Porsche/cayenne.csv&#39；)，PosixPath(&#39；data/Porsche/Panamera.csv&#39；)，PosixPath(&#39；data/Porsche/Panamenne.csv&#39；)，PosiPath(&#39；data/Porsche/Panamerne.csv&#39；)。)、PosiPath(&#39；data/Porsche/taycan&#39；)、PosiPath(&#39；data/Porsche/911.csv&#39；)、PosiPath(&#39；data/Porsche/taycan.csv&#39；)、PosiPath(&#39；data/Porsche/911&#39；)、PosiPath(&#39；data/Porsche/macan.csv&#39；)、PoSixPath(&#39；data/Porsche/718&#39；)、PoSixPath(&#39；data/Porsche/718&#39；)、PoSixPath(&#39；data/Porsche/718&#39；)、PoSixPath(&#39；data/Porsche/718&#39；)、PoSixPath(&#39；data/Porsche/718&#39；)。Data/Porsche/718.csv&#39；)，PosiPath(&#39；Data/Porsche/Macan&#39；)]。</p><p> Finally, upload your urls file. You just need to press ‘Upload’ in your working directory and select your file, then click ‘Upload’ for each of the displayed files.</p><p>最后，上传您的URL文件。您只需在工作目录中按“上载”并选择您的文件，然后为每个显示的文件单击“上载”即可。</p><p>    fast.ai has a function that allows you to do just that. You just have to specify the urls filename as well as the destination folder and this function will download and save all images that can be opened. If they have some problem in being opened, they will not be saved.</p><p>Ast.ai有一个函数可以让您这样做。您只需指定URL文件名和目标文件夹，此功能将下载并保存所有可以打开的图像。如果在打开它们时出现问题，将不会保存它们。</p><p> Let’s download our images! Notice you can choose a maximum number of images to be downloaded. In this case we will not download all the urls.</p><p>让我们下载我们的图片吧！请注意，您可以选择要下载的最大图像数量。在这种情况下，我们不会下载所有URL。</p><p>  In [ 0]:classes  = [ &#39;taycan&#39;, &#39;panamera&#39;, &#39;macan&#39;, &#39;cayenne&#39;, &#39;718&#39;, &#39;911&#39;]In [ 0]:download_images(path / file, dest, max_pics = 500) In [ 0]:  # If you have problems download, try with `max_workers=0` to see exceptions: download_images(path / file, dest, max_pics = 20, max_workers = 0)  ```Then we can remove  any images that can &#39;t be opened: `python In [0]: for c in classes: print(c) verify_images(path/c, delete=True, max_size=500) taycan panamera macan cayenne 718 911` ### View data  ```python  In [0]:  np.random.seed(42)  data = ImageDataBunch.from_folder(path, train=&#34;.&#34;, valid_pct=0.2,  ds_tfms=get_transforms(), size=224, num_workers=4).normalize(imagenet_stats)  In [0]:  #If you already cleaned your data, run this cell instead of the one before  np.random.seed(42)  data = ImageDataBunch.from_csv(path, folder=&#34;.&#34;, valid_pct=0.2, csv_labels=&#39;cleaned .csv &#39;,  ds_tfms=get_transforms(), size=224, num_workers=4).normalize(imagenet_stats)  ``` Good! Let&#39;s take a look at some of our pictures then . ```pythonIn [ 0]:data .classesOut[ 0]:[ &#39;718&#39;,  &#39;911&#39;,  &#39;cayenne&#39;,  &#39;macan&#39;,  &#39;panamera&#39;,  &#39;taycan&#39;]In [ 0]:data .show_batch(rows = 6, figsize =( 7, 8))In [ 0]:data .classes, data .c,  len(data .train_ds),  len(data .valid_ds)Out[ 0]:([ &#39;718&#39;,  &#39;911&#39;,  &#39;cayenne&#39;,  &#39;macan&#39;,  &#39;panamera&#39;,  &#39;taycan&#39;],  6,  1920,  480)</p><p>在[0]：CLASS=[&#39；taycan&#39；，&#39；Panamera&#39；，&#39；Macan&39；，&#39；Cayenne&39；，&#39；718&#39；，&#39；911&#39；]in[0]：download_images(path/file，est，max_picts=500)in[0]：#如果下载有问题，请尝试使用`max_worker=0`查看异常：download_images(path/file，est，max_picks=20，max_worker=0)``然后我们可以移除所有可以&#39的镜像；T被打开：`python in[0]：对于类中的c：print(C)VERIFY_IMAGES(path/c，delete=True，max_size=500)taycan Panamera Macan cayenne 718 911`#查看数据``python in[0]：np随机.Seed(42)data=ImageDataBunch.from_Folder(path，train=&#34；.&#34；；，valid_pct=0.2，ds_tfms=get_transforms()，size=224，num_worker=4).Normalize(ImageNet_Stats)in[0]：#如果您已经清理了数据，请运行此单元格，而不是np.随机.Seed(42)data=ImageDataBunch.from_csv(path，Folder=&#34；.&#34；，Valid_pct=0.2，CSV_Labels=&#39；Cleaned.csv&#39；，DS_tfms=get_transforms()，size=224，num_worker=4).ize(ImageNet_Stats)``好！那么让我们看看我们的一些照片吧。``pythonIn[0]：data.classesOut[0]：[&#39；718&#39；，&#39；911&#39；，&#39；cayenne&39；，&#39；Macan&#39；，&#39；Panamera&#39；，&#39；taycan&#39；]in[0]：data.show_Batch(row=6，figsize=(7，8))in[0]：data.class，data.c，len(data.ran_ds)，len(data.valid_ds)out[0]：([&#39；718&#39；，&#39；911&#39；，&#39；cayenne&#39；，&#39；Macan&#39；，&#39；Panamera&#39；，&#39；taycan&#39；]，6,1920,480)</p><p>    In [ 0]: learn .save( &#39;stage-1&#39;) In [ 0]: learn .unfreeze() In [ 0]: learn .lr_find()  25.00 % [ 1 / 4  00: 12 &lt; 00: 37] ```epoch  | train_loss  | valid_loss  | error_rate  | time -----  |  ----------  |  ----------  |  ----------  |  ---- 0  |  0.196860  |  #na# | 00:12 83.33 % [ 25 / 30  00: 10 &lt; 00: 02  0.6416]LR Finder  is complete,  type {learner_name} .recorder .plot() to see the graph . ```In [ 0]: # If the plot is not showing try to give a start and end learning rate # learn.lr_find(start_lr=1e-5, end_lr=1e-1)learn .recorder .plot()In [ 0]:learn .fit_one_cycle( 2, max_lr = slice( 3e-5, 3e-4))epoch train_loss valid_loss error_rate time 0  0.280386  1.524914  0.372917  00: 13 1  0.276844  1.312542  0.345833  00: 13In [ 0]:learn .save( &#39;stage-2&#39;) ``` ### InterpretationIn [ 0]:learn .load( &#39;stage-2&#39;);In [ 0]:interp  = ClassificationInterpretation .from_learner(learn)In [ 0]:interp .plot_confusion_matrix() ### Cleaning UpSome of our top losses aren &#39;t due to bad performance by our model. There are images in our data set that shouldn&#39;t be .Using the ImageCleaner widget  from fastai.widgets we can prune our top losses, removing photos that don &#39;t belong. ``` In [0]: from fastai.widgets import \* ``` First we need to get the file paths from our top_losses. We can do this with .from_toplosses. We then feed the top losses indexes and corresponding dataset to ImageCleaner. Notice that the widget will not delete images directly from disk but it will create a new csv file cleaned.csv from where you can create a new ImageDataBunch with the corrected labels to continue training your model. ``` In [0]: db = (ImageList.from_folder(path) .split_none() .label_from_folder() .transform(get_transforms(), size=224) .databunch() ) In [0]: # If you already cleaned your data using indexes from `from_toplosses`, # run this cell instead of the one before to proceed with removing duplicates. # Otherwise all the results of the previous step would be overwritten by # the new run of `ImageCleaner`. db = (ImageList.from_csv(path, &#39;cleaned .csv &#39;, folder=&#39; . &#39;) .split_none() .label_from_df() .transform(get_transforms(), size=224) .databunch() ) ``` Then we create a new learner to use our new databunch with all the images. ``` In [0]: learn_cln = cnn_learner(db, models.resnet50, metrics=error_rate) learn_cln.load(&#39;stage - 2 &#39;); In [0]: ds, idxs = DatasetFormatter().from_toplosses(learn_cln) In [0]: # Don&#39;t run this  in google colab  or  any other instances running jupyter lab . # If you do run this on Jupyter Lab, you need to restart your runtime and # runtime state including all local variables will be lost.ImageCleaner(ds, idxs, path) ```HBox(children =(VBox(children =(Image(value = b &#39; \xff\xd8\xff\xe0\x00\x10 JFIF \x00\x01\x01\x01\x00 d \x00 d \x00\x00\xff … Button(button_style=&#39;primary &#39;, description=&#39;Next Batch &#39;, layout=Layout(width=&#39;auto &#39;), style=ButtonStyle()) Flag photos for deletion by clicking &#39;Delete &#39;. Then click &#39;Next Batch &#39; to delete flagged photos and keep the rest in that row. ImageCleaner will show you a new row of images until there are no more to show. In this case, the widget will show you images until there are none left from top_losses.ImageCleaner(ds, idxs) You can also find duplicates in your dataset and delete them! To do this, you need to run .from_similars to get the potential duplicates&#39; ids  and then run ImageCleaner  with duplicates = True . The API works  in a similar way  as  with misclassified images: just choose the ones you want to delete  and click  &#39;Next Batch&#39; until there are no more images left .Make sure to recreate the databunch  and learn_cln  from the cleaned.csv file. Otherwise the file would be overwritten from scratch, losing  all the results  from cleaning the data from toplosses. ```In [ 0]:ds, idxs  = DatasetFormatter() .from_similars(learn_cln)Getting activations ... 100.00 % [ 36 / 36  00: 05 &lt; 00: 00]Computing similarities ...In [ 0]:ImageCleaner(ds, idxs, path, duplicates = True)HBox(children =(VBox(children =(Image(value = b &#39; \xff\xd8\xff\xe0\x00\x10 JFIF \x00\x01\x01\x01\x00 d \x00 d \x00\x00\xff … Button(button_style=&#39;primary &#39;, description=&#39;Next Batch &#39;, layout=Layout(width=&#39;auto &#39;), style=ButtonStyle()) ``` Remember to recreate your ImageDataBunch from your cleaned.csv to include the changes you made in your data! ### Putting your model in production First thing first, let&#39;s export the content of our Learner  object  for production: ```In [ 0]:learn .export() ```This will create a  file named  &#39;export.pkl&#39;  in the directory where we were working that contains everything we need to deploy our model (the model, the weights but also some metadata like the classes  or the transforms /normalization used) .You probably want to use CPU  for inference,  except at massive scale ( and you almost certainly don &#39;t need to train in real-time). If you don&#39;t have a GPU that happens automatically . You can test your model on CPU like so: ```In [ 0]:defaults .device  = torch .device( &#39;cpu&#39;)In [ 0]:img  = open_image(path / &#39;download.jpg&#39;)imgOut[ 0]: ```We create our Learner  in production enviromnent like this, just make sure that path contains the  file  &#39;export.pkl&#39;  from before. ```In [ 0]:In [ 0]:learn  = load_learner(path)In [ 0]:pred_class,pred_idx,outputs  = learn .predict(img)pred_classOut[ 0]:Category panamera ```So you might create a route something like this (thanks to Simon Willison  for the structure of this code): ``` @app.route( &#34;/classify-url&#34;, methods =[ &#34;GET&#34;])async  def  classify *url(request): bytes  = await get_bytes(request .query_params[ &#34;url&#34;])img  = open_image(BytesIO( bytes)) *,\_,losses  = learner .predict(img) return JSONResponse({ &#34;predictions&#34;:  sorted( zip(cat_learner .data .classes,  map( float, losses)),key = lambda p: p[ 1],reverse = True)})(This example  is  for the Starlette web app toolkit .) ``` ### Things that can go wrongMost of the time things will train fine  with the defaultsThere &#39;s not much you really need to tune (despite what you&#39;ve heard!)Most likely areLearning rateNumber of epochs ### Learning rate (LR) too high ```In [ 0]:learn  = cnn_learner(data, models .resnet34, metrics =error_rate)In [ 0]:learn .fit_one_cycle( 1, max_lr = 0.5) ```Total time:  00: 13epoch train_loss valid_loss error_rate 1  12.220007  1144188288.000000  0.765957 ( 00: 13) ### Learning rate (LR) too low ```In [ 0]:learn  = cnn_learner(data, models .resnet34, metrics =error_rate) ```Previously we had this result:Total time:  00: 57epoch  | train_loss  | valid_loss  | error_rate -----  |  ----------  |  ----------  |  ---------- 1  |  1.030236  |  0.179226  |  0.028369  | ( 00: 14) 2  |  0.561508  |  0.055464  |  0.014184  | ( 00: 13) 3  |  0.396103  |  0.053801  |  0.014184  | ( 00: 13) 4  |  0.316883  |  0.050197  |  0.021277  | ( 00: 15) ```In [ 0]:learn .fit_one_cycle( 5, max_lr = 1e-5) ```Total time:  01: 07epoch  | train_loss  | valid_loss  | error_rate -----  |  ----------  |  -----------  |  ----------- 1  |  1.349151  |  1.062807  |  0.609929  | ( 00: 13) 2  |  1.373262  |  1.045115  |  0.546099  | ( 00: 13) 3  |  1.346169  |  1.006288  |  0.468085  | ( 00: 13) 4  |  1.334486  |  0.978713  |  0.453901  | ( 00: 13) 5  |  1.320978  |  0.978108  |  0.446809  | ( 00: 13) ```In [ 0]:learn .recorder .plot_losses() ```As well  as taking a really  long time, it &#39;s getting too many looks at each image, so may overfit. ### Too few epochs ``` In [0]: learn = cnn_learner(data, models.resnet34, metrics=error_rate, pretrained=False) In [0]: learn.fit_one_cycle(1) ``` Total time: 00:14 epoch train_loss valid_loss error_rate 1 0.602823 0.119616 0.049645 (00:14) ### Too many epochs ``` In [0]: np.random.seed(42) data = ImageDataBunch.from_folder(path, train=&#34;.&#34;, valid_pct=0.9, bs=32, ds_tfms=get_transforms(do_flip=False, max_rotate=0, max_zoom=1, max_lighting=0, max_warp=0 ),size=224, num_workers=4).normalize(imagenet_stats) In [0]: learn = cnn_learner(data, models.resnet50, metrics=error_rate, ps=0, wd=0) learn.unfreeze() In [0]: learn.fit_one_cycle(40, slice(1e-6,1e-4)) Total time: 06:39 ``` epoch | train_loss | valid_loss | error_rate ----- | ---------- | ---------- | ---------- 1 | 1.513021 | 1.041628 | 0.507326 | (00:13) 2 | 1.290093 | 0.994758 | 0.443223 | (00:09) 3 | 1.185764 | 0.936145 | 0.410256 | (00:09) 4 | 1.117229 | 0.838402 | 0.322344 | (00:09) 5 | 1.022635 | 0.734872 | 0.252747 | (00:09) 6 | 0.951374 | 0.627288 | 0.192308 | (00:10) 7 | 0.916111 | 0.558621 | 0.184982 | (00:09) 8 | 0.839068 | 0.503755 | 0.177656 | (00:09) 9 | 0.749610 | 0.433475 | 0.144689 | (00:09) 10 | 0.678583 | 0.367560 | 0.124542 | (00:09) 11 | 0.615280 | 0.327029 | 0.100733 | (00:10) 12 | 0.558776 | 0.298989 | 0.095238 | (00:09) 13 | 0.518109 | 0.266998 | 0.084249 | (00:09) 14 | 0.476290 | 0.257858 | 0.084249 | (00:09) 15 | 0.436865 | 0.227299 | 0.067766 | (00:09) 16 | 0.457189 | 0.236593 | 0.078755 | (00:10) 17 | 0.420905 | 0.240185 | 0.080586 | (00:10) 18 | 0.395686 | 0.255465 | 0.082418 | (00:09) 19 | 0.373232 | 0.263469 | 0.080586 | (00:09) 20 | 0.348988 | 0.258300 | 0.080586 | (00:10) 21 | 0.324616 | 0.261346 | 0.080586 | (00:09) 22 | 0.311310 | 0.236431 | 0.071429 | (00:09) 23 | 0.328342 | 0.245841 | 0.069597 | (00:10) 24 | 0.306411 | 0.235111 | 0.064103 | (00:10) 25 | 0.289134 | 0.227465 | 0.069597 | (00:09) 26 | 0.284814 | 0.226022 | 0.064103 | (00:09) 27 | 0.268398 | 0.222791 | 0.067766 | (00:09) 28 | 0.255431 | 0.227751 | 0.073260 | (00:10) 29 | 0.240742 | 0.235949 | 0.071429 | (00:09) 30 | 0.227140 | 0.225221 | 0.075092 | (00:09) 31 | 0.213877 | 0.214789 | 0.069597 | (00:09) 32 | 0.201631 | 0.209382 | 0.062271 | (00:10) 33 | 0.189988 | 0.210684 | 0.065934 | (00:09) 34 | 0.181293 | 0.214666 | 0.073260 | (00:09) 35 | 0.184095 | 0.222575 | 0.073260 | (00:09) 36 | 0.194615 | 0.229198 | 0.076923 | (00:10) 37 | 0.186165 | 0.218206 | 0.075092 | (00:09) 38 | 0.176623 | 0.207198 | 0.062271 | (00:10) 39 | 0.166854 | 0.207256 | 0.065934 | (00:10) 40 | 0.162692 | 0.206044 | 0.062271 | (00:09) ```</p><p>在[0]中：在[0]中学习.save(&#39；Stage-1&39；)在[0]中：在[0]：学习.lr_find()25.00%[1/4 00：12&lt；00：37]```pech|TRAIN_LOSS|VALID_LOSS|ERROR_RATE|TIME-|-0|0.196860|#na#|00：1283.33%[25/30 00：10&lt；00：02 0.6416]LR查找器完成后，键入{LELENER_NAME}.recorder.lot()查看图形。`in[0]：#如果绘图没有显示，请尝试给出开始和结束学习速率#learn.lr_find(start_LR=1e-5，end_lr=1e-1)Learning.recorder.lot()in[0]：Learning.fit_one_Cycle(2，max_LR=Slice(3e-5，3e-4))EPOCH TRAIN_LOSS VALID_LOSS ERROR_RATE TIME 0 0.280386 1.524914 0.372917 00：13 1 0.276844 1.312542 0.345833 00：13IN[0]：Learning.save(&#39；Stage-2&#39；)`#解释在[0]中：Learning.load(&#39；Stage-2&#39；)；在[0]中：interp=ClassficationInterpretation.From_learner(LEARN)in[0]：interp.lot_conflomy_Matrix()#清理升级由于我们的模型表现不佳，我们的一些最大损失不在此列。我们的数据集中有一些不应该出现的图像。使用来自fast ai.widgets的ImageCleaner小部件，我们可以修剪掉最大的损失，删除不属于我们的照片。[0]中的``：从fast ai.widgets import\*`首先需要从top_loses获取文件路径。我们可以使用.from_toplosses执行此操作。然后，我们将顶级损失指数和相应的数据集提供给ImageCleaner。请注意，该小部件不会直接从磁盘删除图像，但它将创建一个新的CSV文件Cleaned.csv，您可以从该文件中创建具有更正标签的新ImageDataBunch，以继续训练您的模型。[0]中的``：db=(ImageList.from_older(Path).plit_one().label_from_older().Transform(get_transforms()，size=224).database unch())in[0]：#如果您已经使用`From_toplosses`中的索引清理了数据，#请运行此单元格而不是前面的单元格以继续删除重复项。#否则，上一步的所有结果将被#新运行的`ImageCleaner`覆盖。DB=(ImageList.from_csv(路径，已清理.csv；，文件夹=。&#39；).Split_None().label_from_df().transform(get_transforms()，size=224).databunch())``然后我们创建一个新的学习者，以便对所有图像使用新的数据库。[0]中的``：Learning_cln=cnn_learner(db，model s.resnet50，metrics=error_rate)Learning_cln.load(&#39；Stage-2&39；)；in[0]：ds，idxs=DatasetForMatter().From_toplosses(Learning_Cln)in[0]：#Don&#39；不要在Google CoLab或任何其他运行jupyter实验室的实例中运行此命令。#如果您确实在Jupyter Lab上运行此程序，则需要重新启动运行时，并且包括所有本地变量的#运行时状态将会丢失。ImageCleaner(ds，idxs，path)`Hbox(Child=(Vbox(Child=(Image(Value=b&#39；\xff\xd8\xff\xe0\x00\x10JFIF\x00\x01\x00 d\x00d\x00\x00\xff…。BUTTON(BUTTON_STYLE=&#39；PRIMARY&#39；，Description=&#39；Next Batch&#39；，Layout=Layout(width=&#39；auto&#39；)，Style=ButtonStyle())通过单击&#39；删除&#39；标记要删除的照片。然后单击下一批以删除已标记的照片，并将其余照片保留在该行中。ImageCleaner将向您显示新的一行图像，直到没有更多图像可显示。在这种情况下，小部件将显示图像，直到top_losses.ImageCleaner(ds，idxs)中没有图像为止。您还可以在数据集中找到重复项并将其删除！要做到这一点，您需要运行.From_Similars来获取潜在的重复ID，然后在Duplicate=True的情况下运行ImageCleaner。API的工作方式与错误分类的映像类似：只需选择要删除的映像，然后单击下一批，直到没有其他映像。请确保重新创建数据库并从Cleaned.csv文件学习_CLN。否则，该文件将被从头开始覆盖，从而丢失从toploses中清除数据的所有结果。`在[100.00]中：ds，idxs=DatasetForMatter().From_Similars(LEARN_CLN)正在获取激活...100.00%[36/36 00：05&lt；00：00]计算相似性...在[0]中：图像清洗器(DS，IDX，PATH，DUPLICATES=TRUE)Hbox(子项=(子项=(映像(值=b&#39；\xff\xd8\xff\xe0\x00\x10JFIF\x00\x01\x00 d\x00 d\x00\x00\xff…。BUTTON(BUTTON_STYLE=&#39；PRIMARY&#39；，description=&#39；Next Batch&#39；，Layout=Layout(width=&#39；auto&#39；)，style=ButtonStyle())`记住从清理的.csv重新创建ImageDataBunch，以包括您在数据中所做的更改！#首先要将模型投入生产，让&#39；的导出Learner对象的内容用于生产：``In[0]：Lear.export()`这将创建一个名为&#39；export.pkl&#39；的文件。在我们工作的目录中，包含部署模型所需的所有内容(模型、权重，但也包含一些元数据，如使用的类或转换/规范化)。您可能希望使用CPU进行推理，除非是大规模的(而且您几乎肯定不需要&#</p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://www.rkpblog.tech/2020/04/porsche-classifier/">https://www.rkpblog.tech/2020/04/porsche-classifier/</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/保时捷/">#保时捷</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/porsche/">#porsche</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/图像/">#图像</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/美国/">#美国</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/谷歌/">#谷歌</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/linux/">#linux</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/程序/">#程序</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy; 2020 diglog.com </div></div></body></html>