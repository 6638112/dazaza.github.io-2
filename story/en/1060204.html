<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Facebook如何编码视频 How Facebook encodes videos</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">How Facebook encodes videos<br/>Facebook如何编码视频 </h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2021-04-26 10:56:17</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2021/4/e57aeab536fa8fa3271a168013141896.jpg"><img src="http://img2.diglog.com/img/2021/4/e57aeab536fa8fa3271a168013141896.jpg" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>People upload hundreds of millions of videos to Facebook every day. Making sure every video is delivered at the best quality — with the highest resolution and as little buffering as possible — means optimizing not only when and how our video codecs compress and decompress videos for viewing, but also which codecs are used for which videos. But the sheer volume of video content on Facebook also means finding ways to do this that are efficient and don’t consume a ton of computing power and resources.</p><p>人们每天向Facebook上传数亿视频。确保每个视频都以最佳质量传送 - 具有最高分辨率，并且尽可能轻松缓冲 - 而不仅可以在我们的视频编解码器压缩和解压缩视频中的时间和解压缩视频时优化，而且还可以优化哪些编解码器用于哪些视频。但是Facebook上的视频内容的纯粹体积也意味着找到这一点的方法，这是有效的，不消耗一大吨的计算能力和资源。</p><p> To help with this, we employ a variety of codecs as well as adaptive bitrate streaming (  ABR ), which improves the viewing experience and reduces buffering by choosing the best quality based on a viewer’s network bandwidth. But while more advanced codecs like VP9 provide better compression performance over older codecs, like H264, they also consume more computing power. From a pure computing perspective, applying the most advanced codecs to every video uploaded to Facebook would be prohibitively inefficient. Which means there needs to be a way to prioritize which videos need to be encoded using more advanced codecs.</p><p> 为了帮助解决方案，我们使用各种编解码器以及适应性比特率流（ABR），这通过基于观众的网络带宽选择最佳质量来改善观看体验并减少缓冲。但是，虽然更高级的编解码器如VP9，但在旧的编解码器中提供更好的压缩性能，如H264，但它们也消耗更多的计算能力。从纯粹的计算角度来看，将最先进的编解码器应用于上传到Facebook的每个视频都会受到效率低效。这意味着需要一种优先考虑使用更高级编解码器进行编码的视频的方法。</p><p> Today, Facebook deals with its high demand for encoding high-quality video content by combining a benefit-cost model with a machine learning (ML) model that lets us prioritize advanced encoding for highly watched videos. By predicting which videos will be highly watched and encoding them first, we can reduce buffering, improve overall visual quality, and allow people on Facebook who may be limited by their data plans to watch more videos.</p><p> 如今，Facebook通过将福利成本模型与机器学习（ML）模型相结合来涉及其对编码高质量视频内容的高需求，让我们优先考虑高级观看视频的高级编码。通过预测哪个视频首先将高度观看和编码它们，我们可以减少缓冲，提高整体视觉质量，并允许在Facebook上的人们受到他们的数据计划来观看更多视频的影响。</p><p> But this task isn’t as straightforward as allowing content from the most popular uploaders or those with the most friends or followers to jump to the front of the line. There are several factors that have to be taken into consideration so that we can provide the best video experience for people on Facebook while also ensuring that content creators still have their content encoded fairly on the platform.</p><p> 但这任务并不像允许来自最流行上传者的内容或那些有最多朋友或追随者的内容跳到线前面的内容。有几个因素必须考虑，以便我们可以为Facebook上的人们提供最好的视频体验，同时也确保内容创建者仍然在平台上公平编码的内容。</p><p>  Traditionally, once a video is uploaded to Facebook, the process to enable ABR kicks in and the original video is quickly re-encoded into multiple resolutions (e.g., 360p, 480p, 720p, 1080p). Once the encodings are made, Facebook’s video encoding system tries to further improve the viewing experience by using more advanced codecs, such as VP9, or more expensive “recipes” (a video industry term for fine-tuning transcoding parameters), such as H264 very slow profile, to compress the video file as much as possible. Different transcoding technologies (using different codec types or codec parameters) have different trade-offs between compression efficiency, visual quality, and how much computing power is needed.</p><p>  传统上，一旦将视频上传到Facebook，就可以将ABR启动和原始视频的过程快速重新编码为多个分辨率（例如，360p，480p，720p，1080p）。一旦编码，Facebook的视频编码系统尝试通过使用更高级的编解码器，例如VP9或更昂贵的“食谱”（用于微调代码转换参数的视频行业术语），进一步提高观看体验，例如H264慢速配置文件，尽可能多地压缩视频文件。不同的代码转换技术（使用不同的编解码器类型或编解码器参数）在压缩效率，视觉质量和所需的计算能力之间具有不同的权衡。</p><p> The question of how to order jobs in a way that maximizes the overall experience for everyone has already been top of mind. Facebook has a specialized encoding compute pool and dispatcher. It accepts encoding job requests that have a priority value attached to them and puts them into a priority queue where higher-priority encoding tasks are processed first. The video encoding system’s job is then to assign the right priority to each task. It did so by following a list of simple, hard-coded rules. Encoding tasks could be assigned a priority based on a number of factors, including whether a video is a licensed music video, whether the video is for a product, and how many friends or followers the video’s owner has.</p><p> 如何以一种最大化每个人的整体体验的方式订购工作的问题已经是头脑。 Facebook拥有专门的编码计算池和调度员。它接受编码具有附加到它们的优先级值的作业请求，并将它们放入优先级队列，其中首先处理更高优先级编码任务。然后，视频编码系统的作业是为每个任务分配正确的优先级。它通过遵循简单的硬编码规则列表来完成。编码任务可以基于许多因素分配优先级，包括视频是否是许可的音乐视频，视频是否适用于产品，视频的所有者有多少朋友或追随者。</p><p> But there were disadvantages to this approach. As new video codecs became available, it meant expanding the number of rules that needed to be maintained and tweaked. Since different codecs and recipes have different computing requirements, visual quality, and compression performance trade-offs, it is impossible to fully optimize the end user experience by a coarse-grained set of rules.</p><p> 但是这种方法存在缺点。随着新视频编解码器可用，它意味着扩展所需维护和调整所需的规则数。由于不同的编解码器和配方具有不同的计算要求，视觉质量和压缩性能权衡，因此无法通过粗粒一组规则充分优化最终用户体验。 </p><p> And, perhaps most important, Facebook’s video consumption pattern is extremely skewed, meaning Facebook videos are uploaded by people and pages that have a wide spectrum in terms of their number of friends or followers. Compare the Facebook page of a big company like Disney with that of a vlogger that might have 200 followers. The vlogger can upload their video at the same time, but Disney’s video is likely to get more watch time. However, any video can go viral even if the uploader has a small following. The challenge is to support content creators of all sizes, not just those with the largest audiences, while also acknowledging the reality that having a large audience also likely means more views and longer watch times.</p><p>而且，也许是最重要的，Facebook的视频消费模式非常倾斜，否则Facebook视频由人员和页面上传，这些视频在其朋友或追随者的数量方面具有广泛的频谱。比较迪斯尼这样大型公司的Facebook页面，其中一个可能有200个粉丝的vlogger。 VLogger可以同时上传他们的视频，但迪士尼的视频可能会得到更多的观看时间。但是，即使上传者遵循以下任何视频，任何视频也可以去病毒。这一挑战是支持各种规模的内容创作者，而不仅仅是那些具有最大的受众的创造者，同时还承认拥有大量观众的现实也可能意味着更多的观点和更长的观看时间。</p><p>  The new model still uses a set of quick initial H264 ABR encodings to ensure that all uploaded videos are encoded at good quality as soon as possible. What’s changed, however, is how we calculate the priority of encoding jobs after a video is published.</p><p>  新模型仍然使用一组快速初始H264 ABR编码，以确保所有上传的视频都可以尽快以良好的质量编码。但是，在发布视频后，我们如何计算编码作业的优先级。</p><p>  A video consumes computing resources only the first time it is encoded. Once it has been encoded, the stored encoding can be delivered as many times as requested without requiring additional compute resources.</p><p>  视频仅在编码时使用计算资源。一旦被编码，就可以如所请求的不需要额外计算资源，存储的编码可以多次传送。</p><p> A relatively small percentage (roughly one-third) of all videos on Facebook generate the majority of overall watch time.</p><p> Facebook上所有视频的相对较小的百分比（大约三分之一）产生了大多数整体手表时间。</p><p>  We get the most bang for our buck, so to speak, in terms of maximizing everyone’s video experience within the available power constraints, by applying more compute-intensive “recipes” and advanced codecs to videos that are watched the most.</p><p>  我们最爆炸我们的巴克，以便在可用的电源限制内最大化每个人的视频体验，通过将更多的计算密集型的“食谱”和高级编解码器应用于最多的视频。</p><p>  Based on these observations, we came up with following definitions for benefit, cost, and priority:</p><p>  根据这些观察，我们提出了以下定义，以获得福利，成本和优先权：</p><p> Benefit = (relative compression efficiency of the encoding family at fixed quality) * (effective predicted watch time)</p><p> 福利=（在固定质量时编码家庭的相对压缩效率）*（有效预测的手表时间） </p><p> Relative compression efficiency of the encoding family at fixed quality:  We measure benefit in terms of the encoding family’s compression efficiency. “Encoding family” refers to the set of encoding files that can be delivered together. For example, H264 360p, 480p, 720p, and 1080p encoding lanes make up one family, and VP9 360p, 480p, 720p, and 1080p make up another family. One challenge here is comparing compression efficiency between different families at the same visual quality.</p><p>在固定质量下编码家庭的相对压缩效率：我们在编码家庭的压缩效率方面测量效益。 “编码族”是指可以一起传递的编码文件集。例如，H264 360P，480P，720P和1080P编码通道构成一个家庭，VP9 360P，480P，720P和1080P构成另一个家庭。这里的一个挑战是在相同的视觉质量下比较不同家庭之间的压缩效率。</p><p> To understand this, you first have to understand a metric we’ve developed called Minutes of Video at High Quality per GB datapack (MVHQ). MVHQ links compression efficiency directly to a question people wonder about their internet allowance: Given 1 GB of data, how many  minutes of high-quality video can we stream?</p><p> 要了解这一点，您首先必须了解我们在每个GB数据库（MVHQ）的高质量中开发了一次被称为视频的商品。 MVHQ将压缩效率直接链接到一个问题人们奇怪的互联网津贴：给出了1 GB的数据，我们可以汇集多少分钟的高质量视频？</p><p>   For example, let’s say we have a video where the MVHQ using H264 fast preset encoding is 153 minutes, 170 minutes using H264 slow preset encoding, and 200 minutes using VP9. This means delivering the video using VP9 could extend watch time using 1 GB data by 47 minutes (200-153) at a high visual quality threshold compared to H264 fast preset. When calculating the benefit value of this particular video, we use H264 fast as the baseline. We assign 1.0 to H264 fast, 1.1 (170/153) to H264 slow, and 1.3 (200/153) to VP9.</p><p>   例如，假设我们有一个视频，使用H264快速预设编码的MVHQ为153分钟，使用H264缓慢预设编码为170分钟，使用VP9 200分钟。这意味着使用VP9传递视频可以在高视觉质量阈值下通过47分钟（200-153）使用1 GB数据来扩展手表时间，而与H264快速预设相比。在计算该特定视频的益处时，我们使用H264作为基线。我们将1.0到H264快速，1.1（170/153）到H264慢，1.3（200/153）到VP9。</p><p> The actual MVHQ can be calculated only once an encoding is produced, but we need the value before encodings are available, so we use historical data to estimate the MVHQ for each of the encoding families of a given video.</p><p> 实际的MVHQ可以仅计算一次编码后，但我们需要在编码之前需要值，因此我们使用历史数据来估计给定视频的每个编码系列的MVHQ。</p><p> Effective predicted watch time:  As described further in the section below, we have a sophisticated ML model that predicts how long a video is going to be watched in the near future across all of its audience. Once we have the predicted watch time at the video level, we estimate how effectively an encoded family can be applied to a video. This is to account for the fact that not all people on Facebook have the latest devices, which can play newer codecs.</p><p> 有效的预测手表时间：如下面的部分中进一步描述的，我们有一个复杂的ML模型，预测视频将在近期观看多长时间的观众。一旦我们在视频级别获得了预测的手表时间，我们估计编码家庭可以应用于视频的有效性。这是为了解释这一事实，这不是Facebook上所有人都有最新的设备，可以发挥较新的编解码器。</p><p> For example, about 20 percent of video consumption happens on devices that cannot play videos encoded with VP9. So if the predicted watch time for a video is 100 hours the effective predicted watch time using the widely adopted H264 codec is 100 hours while effective predicted watch time of VP9 encodings is 80 hours.</p><p> 例如，大约20％的视频消耗发生在无法播放与VP9编码的视频的设备上。因此，如果视频的预测手表时间是100小时，则使用广泛采用的H264编解码器的有效预测的手表时间是100小时，而VP9编码的有效预测手表时间是80小时。</p><p> Normalized compute cost of the missing encodings in the family:  This is the amount of logical computing cycles we need to make the encoding family deliverable. An encoding family requires a minimum set of resolutions to be made available before we can deliver a video. For example, for a particular video, the VP9 family may require at least four resolutions. But some encodings take longer than others, meaning not all of the resolutions for a video can be made available at the same time.</p><p> 归一化的缺少编码的计算成本：这是我们需要使编码家庭可交付的逻辑计算周期的数量。在我们提供视频之前，编码家庭需要最少的分辨率进行可用。例如，对于特定视频，VP9家族可能需要至少四个分辨率。但是一些编码比其他编码需要更长，这意味着没有所有用于视频的分辨率都可以同时提供。 </p><p> As an example, let’s say Video A is missing all four lanes in the VP9 family. We can sum up the estimated CPU usage of all four lanes and assign the same normalized cost to all four jobs.</p><p>例如，让我们说视频A缺少VP9系列中的所有四个车道。我们可以总结所有四个车道的估计CPU使用量，并为所有四个作业分配相同的标准化成本。</p><p> If we are only missing two out of four lanes, as shown in Video B, the compute cost is the sum of producing the remaining two encodings. The same cost is applied to both jobs. Since the priority is benefit divided by cost, this has the effect of a task’s priority becoming more urgent as more lanes become available. Encoding lanes do not provide any value until they are deliverable, so it is important to get to a complete lane as quickly as possible. For example, having one video with all of its VP9 lanes adds more value than 10 videos with incomplete (and therefore, undeliverable) VP9 lanes.</p><p> 如果我们只丢失四个车道中的两个车道，如视频B所示，计算成本是产生剩余两个编码的总和。两项工作都适用了相同的成本。由于优先级的效益除以成本，这使得任务的优先级变得更加紧迫的效果随着更多车道可用。编码车道在可交付状态之前，不提供任何值，因此重要的是要尽快到达一个完整的车道。例如，拥有具有其所有VP9车道的一个视频，增加了超过10个视频，具有不完整的（并且因此，无法送达）VP9车道。</p><p>    With a new benefit-cost model in place to tell us how certain videos should be encoded, the next piece of the puzzle is determining which videos should be prioritized for encoding. That’s where we now utilize ML to predict which videos will be watched the most and thus should be prioritized for advanced encodings.</p><p>    通过新的福利成本模型，可以告诉我们某些视频应该进行编码，下一篇拼图正在确定应优先考虑哪些视频。这就是我们现在利用ML来预测哪些视频最多，因此应该优先考虑高级编码。</p><p> Our model looks at a number of factors to predict how much watch time a video will get within the next hour. It does this by looking at the video uploader’s friend or follower count and the average watch time of their previously uploaded videos, as well as metadata from the video itself including its duration, width, height, privacy status, post type (Live, Stories, Watch, etc.), how old it is, and its past popularity on the platform.</p><p> 我们的模型看起来有多种因素来预测视频在下一个小时内的观看时间。它通过查看视频上传者的朋友或追随者计数以及以前上传的视频的平均手表时间来实现这一目标，以及来自视频本身的元数据，包括其持续时间，宽度，高度，隐私状态，post类型（Live，Stories，手表等），它的年龄是多大的，它在平台上的过去的普及。</p><p>  Watch time has high variance and has a very long-tail skewed nature.  Even when we focus on predicting the next hour of watch time, a video’s watch time can range anywhere from zero to over 50,000 hours depending on its content, who uploaded it, and the video’s privacy settings. The model must be able to tell not only whether the video will be popular, but also how popular.</p><p>  手表时间具有高方差，具有非常长的扭曲性质。即使我们专注于预测下一小时的手表时间，视频的手表时间也可以根据上传IT的内容和视频的隐私设置，从零到50,000小时的任何地方。该模型必须能够识别视频是否将是流行的，而且还能讲述视频。</p><p> The best indicator of next-hour watch time is its previous watch time trajectory.  Video popularity is generally very volatile by nature. Different videos uploaded by the same content creator can sometimes have vastly different watch times depending on how the community reacts to the content. After experimenting with multiple features, we found that past watch time trajectory is the best predictor of future watch time. This poses two technical challenges in terms of designing the model architecture and balancing the training data:</p><p> 下一小时手表时间的最佳指标是它之前的手表时间轨迹。视频人气通常是非常不稳定的。由相同内容创建者上传的不同视频有时可能具有大量不同的钟表时间，具体取决于社区如何对内容作出反应。在尝试多个功能后，我们发现过去的手表时间轨迹是未来手表时间的最佳预测因子。在设计模型架构和平衡培训数据方面，这提出了两个技术挑战：</p><p> Newly uploaded videos don’t have a watch time trajectory. The longer a video stays on Facebook, the more we can learn from its past watch time. This means that the most predictive features won’t apply to new videos. We want our model to perform reasonably well with missing data because the earlier the system can identify videos that will become popular on the platform, the more opportunity there is to deliver higher-quality content.</p><p> 新上传的视频没有手表时间轨迹。视频在Facebook上的时间越长，我们就越可以从过去的手表时间中学到。这意味着最具预测功能不会适用于新视频。我们希望我们的模型与缺失数据进行合理良好的数据，因为系统较早的系统可以识别将在平台上流行的视频，机会越多，可以提供更高质量的内容。 </p><p> Popular videos have a tendency to dominate training data. The patterns of the most popular videos are not necessarily applicable to all videos.</p><p>流行视频具有主导培训数据的趋势。最受欢迎的视频的模式不一定适用于所有视频。</p><p> Watch time nature varies by video type.  Stories videos are shorter and get a shorter watch time on average than other videos.  Live streams get most of their watch time during the stream or a few hours afterward. Meanwhile, videos on demand (VOD) can have a varied lifespan and can rack up watch time long after they’re initially uploaded if people start sharing them later.</p><p> 观看时间性质因视频类型而异。 Stories视频较短，平均观看时间比其他视频更短。在溪流期间或之后几个小时，直播溪流获得大部分手表时间。同时，根据人们开始稍后分享它们，视频按需（VOD）的视频可以具有多种寿命，并且可以在最初上传后播放时间。</p><p> Improvements in ML metrics do not necessarily correlate directly to product improvements.  Traditional regression loss functions, such as RMSE, MAPE, and Huber Loss, are great for optimizing offline models. But the reduction in modeling error does not always translate directly to product improvement, such as improved user experience, more watch time coverage, or better compute utilization.</p><p> ML指标的改进不一定直接与产品改进相关联。传统的回归损失功能，如RMSE，MAPE和HUBER丢失，非常适合优化离线模型。但是，建模错误的减少并不总是直接转化为产品改进，例如改进的用户体验，观点时间覆盖或更好的计算利用率。</p><p>   To solve these challenges, we decided to train our model by using watch time event data. Each row of our training/evaluation represents a decision point that the system has to make a prediction for.</p><p>   为了解决这些挑战，我们决定通过使用手表时间事件数据训练我们的模型。我们的培训/评估的每一行代表了系统必须对其预测进行预测的决策点。</p><p> Since our watch time event data can be skewed or imbalanced in many ways as mentioned, we performed data cleaning, transformation, bucketing, and weighted sampling on the dimensions we care about.</p><p> 由于我们的手表时间事件数据可以在许多方面倾斜或不平衡，因此我们在我们关心的尺寸上执行了数据清洁，转换，铲斗和加权采样。</p><p> Also, since newly uploaded videos don’t have a watch time trajectory to draw from, we decided to build two models, one for handling upload-time requests and other for view-time requests. The view-time model uses the three sets of features mentioned above. The upload-time model looks at the performance of other videos a content creator has uploaded and substitutes this for past watch time trajectories. Once a video is on Facebook long enough to have some past trajectories available, we switch it to use the view-time model.</p><p> 此外，由于新上传的视频没有观看时间轨迹来绘制，我们决定构建两个模型，一个用于处理上传时间请求和其他用于查看时间请求。视图时间模型使用上面提到的三组特征。上传时间模型看其他视频的性能内容创建者已经上传并替换了过去的手表时间轨迹。一旦视频在Facebook上长时间才能拥有一些过去的轨迹，我们会切换它以使用视图时间模型。</p><p> During model development, we selected the best launch candidates by looking at both   Root Mean Square Error  (RMSE) and   Mean Absolute Percentage Error  (MAPE). We use both metrics because RMSE is sensitive to outliers while MAPE is sensitive to small values. Our watch time label has a high variance, so we use MAPE to evaluate the performance of videos that are popular or moderately popular and RMSE to evaluate less watched videos. We also care about the model’s ability to generalize well across different video types, ages, and popularity. Therefore, our evaluation will always include per-category metric as well.</p><p> 在模型开发期间，我们通过查看根均线误差（RMSE）和均值绝对百分比错误（MAPE）选择了最佳启动候选者。我们使用两个指标，因为RMSE对异常值敏感，而MAPE对小值敏感。我们的手表时间标签具有很高的方差，因此我们使用MAPE来评估流行或中度流行的视频的性能和RMSE评估较少观看的视频。我们还关心模型横跨不同视频类型，年龄和人气的能力。因此，我们的评估始终包括每个类别的度量。 </p><p> MAPE and RMSE are good summary metrics for model selection, but they don’t necessarily reflect direct product improvements. Sometimes when two models have a similar RMSE and MAPE, we also translate the evaluation to classification problem to understand the trade-off. For example, if a video receives 1,000 minutes of watch time but Model A predicts 10 minutes, Model A’s MAPE is 99 percent. If Model B predicts 1,990 minutes of watch time, Model B’s MAPE will be the same as Model A’s (i.e., 99 percent), but Model B’s prediction will result in the video more likely having high-quality encoding.</p><p>MAPE和RMSE是模型选择的良好摘要指标，但它们不一定反映直接产品改进。有时当两种型号有类似的RMSE和MAPE时，我们还会将评估转换为分类问题以了解权衡。例如，如果视频接收到1,000分钟的手表时间，但模型预测10分钟，则模型A的MAPE是99％。如果B模型预测手表时间1,990分钟，B模型的Mape将与模型A的MAPE相同，而模型B的预测将导致视频具有高质量编码的视频。</p><p> We also evaluate the classifications that videos are given because we want to capture the trade-off between applying advanced encoding too often and missing the opportunity to apply them when there would be a benefit. For example, at a threshold of 10 seconds, we count the number of videos where the actual video watch time is less than 10 seconds and the prediction is also less than 10 seconds, and vice versa, in order to calculate the model’s false positive and false negative rates. We repeat the same calculation for multiple thresholds. This method of evaluation gives us insights into how the model performs on videos of different popularity levels and whether it tends to suggest more encoding jobs than necessary or miss some opportunities.</p><p> 我们还评估给出了视频的分类，因为我们希望在应用高级编码之间捕获的权衡，并且在存在福利时缺少应用程序的机会之间的权衡。例如，在10秒的阈值下，我们计算实际视频手表时间小于10秒的视频数量，并且预测也小于10秒，反之亦然，以计算模型的误报和假负率。我们对多个阈值重复相同的计算。这种评估方法使我们能够深入了解模型如何对不同普及水平的视频进行视频，以及它是否倾向于建议更多的编码工作，而不是必要或错过一些机会。</p><p>  In addition to improving viewer experience with newly uploaded videos, the new model can identify older videos on Facebook that should have been encoded with more advanced encodings and route more computing resources to them. Doing this has shifted a large portion of watch time to advanced encodings, resulting in less buffering without requiring additional computing resources. The improved compression has also allowed people on Facebook with  limited data plans, such as those in  emerging markets, to watch more videos at better quality.</p><p>  除了使用新上传的视频提高观看者体验之外，新模型还可以在Facebook上识别应该使用更高级的编码和更多计算资源对它们进行编码的较旧的视频。这样做已经将大部分手表时间转移到高级编码，从而减少缓冲而不需要额外的计算资源。改进的压缩还允许在Facebook上允许人们使用有限的数据计划，例如新兴市场中的数据计划，以更好的质量观看更多视频。</p><p> What’s more, as we introduce new encoding recipes, we no longer have to spend a lot of time evaluating where in the priority range to assign them. Instead, depending on a recipe’s benefit and cost value, the model automatically assigns a priority that would maximize overall benefit throughput. For example, we could introduce a very compute-intensive recipe that only makes sense to be applied to extremely popular videos and the model can identify such videos. Overall, this makes it easier for us to continue to invest in newer and more advanced codecs to give people on Facebook the best-quality video experience.</p><p> 更重要的是，正如我们介绍新的编码配方，我们不再花费大量时间评估优先级范围以分配它们。相反，根据配方的好处和成本值，模型会自动分配最大化整体益处吞吐量的优先级。例如，我们可以介绍一个非常计算密集的食谱，只能应用于极其流行的视频，并且模型可以识别这些视频。总的来说，这使我们更容易继续投资于更新和更先进的编解码器，以便在Facebook上为人们提供最优质的视频体验。</p><p>  This work is the collective result of the entire Video Infra team at Facebook. The authors would like to personally thank Shankar Regunathan, Atasay Gokkaya, Volodymyr Kondratenko, Jamie Chen, Cosmin Stejerean, Denise Noyes, Zach Wang, Oytun Eskiyenenturk, Mathieu Henaire, Pankaj Sethi, and David Ronca for all their contributions.</p><p>  这项工作是Facebook的整个视频Infra团队的集体结果。作者谨此感谢Shankar Regunathan，Atasay Gokkaya，Volodymyr Kondratenko，杰米陈，Cosmin Stejerean，Denise Noyes，Zach Wang，Oytun Eskiyenenturk，Mathieu Henaire，Pankaj Sethi和David Ronca的所有贡献。 </p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://engineering.fb.com/2021/04/05/video-engineering/how-facebook-encodes-your-videos/">https://engineering.fb.com/2021/04/05/video-engineering/how-facebook-encodes-your-videos/</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/facebook/">#facebook</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/编码/">#编码</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/encodes/">#encodes</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/视频/">#视频</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/分享/">#分享</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy;2012-2021 diglog.com </div></div></body></html>