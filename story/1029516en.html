<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>AMD MI50 GPGPU用于科学和ML应用的初步评估</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">AMD MI50 GPGPU用于科学和ML应用的初步评估</h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2020-10-18 07:13:19</div><div class="page_narrow text-break page_content"><p>Skip to the content.      Competition in the High-Performance Computing GPGPU market has emerged with GPGPUs from Advanced Micro Devices (AMD) and Intel targeting future Exascale class systems.	The new AMD Radeon Instinct MI50 hints at the capabilities of AMD’s future GPUs.</p><p>跳到内容。随着Advanced Micro Devices(AMD)和Intel的GPGPU瞄准未来的亿级系统，高性能计算GPGPU市场出现了竞争。新的AMD RADEON本能MI50暗示了AMD未来图形处理器的能力。</p><p>  This study takes a first look at the MI50 performance on characteristic scientific and machine learning applications.</p><p>这项研究首先考察了军情五处在特色科学和机器学习应用方面的表现。</p><p>       All systems are use the single-root, dual-socket SuperMicro SYS-4029GP-TRT2 system.System details, diagrams, and benchmarking results can be found in the poster.</p><p>所有系统都使用单根、双插槽SuperMicro SYS-4029GP-TRT2系统。系统详细信息、图表和基准测试结果可在海报中找到。</p><p> We ran two case studies that represent common workloads we run in our lab:(a) a GPU-optimized rotating detonation engine simulation, and(b) a compute-heavy deep learning training task.Implementation and methodology details are described below.</p><p>我们运行了两个案例研究，它们代表了我们实验室中运行的常见工作负载：(A)GPU优化的旋转爆震发动机模拟，以及(B)计算量大的深度学习培训任务。实施和方法详细信息如下所述。</p><p>  Our machine learning benchmarks were run using TensorFlow 1.15 and  TensorFlow 1.x CNN benchmarks.While the tensorflow benchmarks are no longer updated for TensorFlow 2.x, they have been optimized for TensorFlow 1.15, making this a useful and replicable task for comparing GPGPU performance.</p><p>我们的机器学习基准是使用TensorFlow 1.15和TensorFlow 1.x CNN基准运行的。虽然TensorFlow基准不再针对TensorFlow 2.x进行更新，但它们已经针对TensorFlow 1.15进行了优化，这使其成为比较GPGPU性能的有用且可复制的任务。</p><p> Because our tests are run on a single node, we use the default  TensorFlow Distributed MirrorStrategy with the  NCCL/ RCCL all-reduce algorithm.</p><p>因为我们的测试在单个节点上运行，所以我们使用默认的TensorFlow Distributed MirrorStrategy和NCCL/RCCL All-Reduce算法。</p><p> The benchmark task is training ResNet50-v1 on a synthetic ImageNet dataset using a momentum optimizer.This compute-heavy task is characteristic of many other deep computer vision tasks with its dense image inputs and a deep, feed-forward, mostly convolutional architecture that translates well to GPGPUs.</p><p>基准任务是使用动量优化器在合成的ImageNet数据集上训练ResNet50-v1。这项计算繁重的任务是许多其他深度计算机视觉任务的特征，它具有密集的图像输入和深度、前馈、主要是卷积的体系结构，可以很好地转换为GPGPU。</p><p>  We used the HPC-oriented container platform  Singularity (v3.5.2) to manage our environment and dependencies for this study.Singularity ≥3.5 is required for ROCm support.</p><p>我们使用面向高性能计算的容器平台奇点(3.5.2版)来管理我们的环境和依赖关系，需要奇点ROCM3.5来支持≥。</p><p> All reported results were collected using official TensorFlow and ROCm images available on Docker Hub. Singularity images can be pulled with:</p><p>所有报告的结果都是使用Docker Hub上提供的官方TensorFlow和ROCM图像收集的。可以通过以下方式拉取奇点图像：</p><p>   # start a shell in the container environment w/ NVIDIA GPU access $ singularity shell  --nv  $PATH_TO_SIMG # run a python script in the container environment w/ ROCm GPU access $ singularity  exec  --rocm  $PATH_TO_SIMG python3 run.py</p><p>#在容器环境中使用NVIDIA GPU访问启动shell--NV$PATH_TO_SIMG#使用ROCM GPU访问$Singulicity exec--ROCM$PATH_TO_SIMG python3 run.py在容器环境中运行python脚本。</p><p>     An iteration includes both forward and backward passes through the network.We used the largest power-of-2 batch size that would fit in GPU memory: 64 images/device for the GTX and RTX systems (11gb) and 256 images/device for the V100 and MI50 systems (32gb).We ran enough warm-up iterations for the training speed to appear stable (5 steps for the NVIDIA hardware and 100 steps for AMD hardware).The final training throughput is the median of three runs with 500 steps each.</p><p>迭代包括通过网络的前向和向后遍历。我们使用GPU内存可以容纳的最大2次方批处理大小：对于GTX和RTX系统(11 GB)为64个图像/设备，对于V100和MI50系统(32 GB)为256个图像/设备。我们运行了足够的热身迭代以使训练速度保持稳定(NVIDIA硬件为5步，AMD硬件为100步)。最终的训练吞吐量是3次运行的中值，每次500步。</p><p> The following script will run ResNet50 training benchmarks on 1-8 GPUs.Fill out the variables at the top ( container_path,  gpu_flag, and  batch_size) based on your specific system.</p><p>以下脚本将在1-8个GPU上运行ResNet50培训基准。根据您的特定系统填写顶部的变量(CONTAINER_PATH、GPU_FLAG和BATCH_SIZE)。</p><p> container_path =... gpu_flag =...  # --nv or --rocm batch_size =...  # 64 for gtx or rtx (11gb), 256 for mi50 or v100 (32gb) # run benchmarks on 1-8 GPUs for n  in  {1..8 } ;  do singularity  exec  $gpu_flag  $container_path  \ python tf_cnn_benchmarks.py  --num_gpus  $n  --batch_size  $batch_size  \  --variable_update replicated  --all_reduce_spec nccl  \  --model resnet50  --data_name imagenet  --optimizer momentum  \  --nodistortions  --gradient_repacking 1  --ml_perf done</p><p>CONTAINER_PATH=...。GPU_FLAG=...#--NV或--ROCM BATCH_SIZE=...#64用于GTX或RTX(11 GB)，256用于mi50或V100(32 GB)#在1-8个GPU上针对{1..8}中的n运行基准测试；执行奇点执行$GPU_FLAG$CONTAINER_PATH\python TF_CNN_Benchmarks.py--num_GPU$n--BATCH_SIZE$BATCH_SIZE\--VARIAL_UPDATE REPLICATED--all_duce_spec NCCL\--model resnet50--data_name ImageNet--优化器动量\--无失真--梯度_重新打包1--ml_perf完成。</p><p>  NCCL_DEBUG=INFO will print out the GPU-GPU interconnects and NCCL ring topology used for the all-reduce operations, which is useful for verification purposes.</p><p>NCCL_DEBUG=INFO将打印出用于All-Reduce操作的GPU-GPU互连和NCCL环拓扑，这对于验证很有用。</p><p>  NCCL_P2P_LEVEL controls when to use direct GPU-to-GPU transport by setting the max allowable distance.A value of 0 (or LOC) disables all P2P communications.</p><p>NCCL_P2P_LEVEL通过设置最大允许距离来控制何时使用GPU到GPU的直接传输。值为0(或LOC)将禁用所有P2P通信。</p><p>  TF_XLA_FLAGS=--tf_xla_auto_jit=2 will force XLA compilation, optimizing the graph for your given hardware.This is particularly effective in mixed-precision mode when using GPUs with Tensor Cores.</p><p>TF_XLA_FLAGS=--TF_XLA_AUTO_JIT=2将强制XLA编译，优化给定硬件的图形。当使用带有张量内核的GPU时，这在混合精度模式下尤其有效。</p><p>  --trace_file=trace.json will save a tfprof trace of your training process, averaged over the first 10 steps.The results can be viewed at  chrome://tracing in the Chrome browser.This is useful for debugging distributed performance issues.</p><p>--trace_file=trace.json将保存培训过程的tfprof跟踪，它是前10步的平均值。可以在Chrome浏览器中的Chrome：//Tracking查看结果。这对于调试分布式性能问题很有用。</p><p>  --use_fp16 will run the training in mixed-precision mode.This will use NVIDIA Tensor Cores on supported hardware.</p><p>--USE_FP16将在混合精度模式下运行培训。这将在支持的硬件上使用NVIDIA张量内核。</p><p>  Performance per Watt is an extremely important metric when evaluating HPC systems.This is often reported in FLOPS/W (Floating Point Operations per Second per Watt) using a benchmark such as LINPACK.For this study, we use a practical machine learning analog:  training images per second per Watt.</p><p>在评估HPC系统时，每瓦性能是一个极其重要的指标。这通常以FLOPS/W(每秒每瓦浮点运算数)为单位，使用LINPACK这样的基准测试。在本研究中，我们使用一个实用的机器学习模拟：每秒每瓦训练图像。</p><p>  Non-GPU:  Running Average Power Limit, or  RAPL, is an Intel processor feature that provides information on energy and power consumption of different physical domains.Average power draw was collected using the powercap interface: we queried  energy_uj once per second over a 1-minute interval of a given workload, calculating average power over each timestep pair.Power data was collected over package-0 (core), package-1 (uncore), and the DRAM power plane.This excludes GPU power draw, which was recorded separately.</p><p>非GPU：运行平均功率限制(RAPL)是英特尔处理器的一项功能，可提供不同物理域的能量和功耗信息。平均功耗是使用PowerCap界面收集的：我们在给定工作负载的1分钟间隔内每秒查询一次energy_uj，计算每个时间步对的平均功耗。功耗数据是通过Package-0(核心)、Package-1(非核)和DRAM电源平面收集的。这不包括单独记录的GPU功耗。</p><p>  We collected our data using code modified from  the  powerstat tool.Other utilities for accessing RAPL metrics include  perf,  turbostat, or  powertop.</p><p>我们使用从powerstat工具修改的代码收集数据，其他用于访问RAPL指标的实用程序包括perf、turbostat或powertop。</p><p>  # For NVIDIAtimeout 60 nvidia-smi --query-gpu=timestamp,name,index,power.draw --format=csv --loop=1 -f $LOGFILE# For ROCmfor i in {1..60}; do rocm-smi -P --json &gt;&gt; $LOGFILE; sleep 1; done</p><p>#for NVIDIAtimeout 60 nvidia-smi--query-gpu=timeamp，name，index，power.raw--format=CSV--loop=1-f$logfile#for ROCmfor i in{1..60}；do ROCM-SMI-P--json&&gt;；&gt；$logfile；睡眠1；完成。</p><p> The utility scripts that we used can be found  here.To collect power information for different modes,we started a training run as described in  Training Throughput,waited until iteration 10 of training,then manually started the power consumption monitoring tools.</p><p>我们使用的实用程序脚本可以在这里找到。为了收集不同模式的电力信息，我们按照培训吞吐量中的描述启动了培训运行，等到培训的第10次迭代，然后手动启动功耗监控工具。</p><p>  This poster was presented at  ISC High Performance in June 2020.To cite our findings, please use:</p><p>这张海报于2020年6月在ISC High Performance大会上公布。要引用我们的发现，请使用：</p><p> @misc{ obenschain20, author = &#34;Keith Obenschain and Douglas Schwer and Alisha Sharma&#34;, title = &#34;Initial assessment of the AMD MI50 GPGPUs for scientific and machine learning applications&#34;, year = &#34;2020&#34;, howpublished = &#34;Research poster presented at ISC High Performance 2020&#34; }</p><p>@misc{obenschain20，Author=#34；Keith Obenschain和Douglas Schwer and Alisha Sharma&34；，title=#34；AMD MI50 GPGPU用于科学和机器学习应用程序的初步评估，年份=#34；2020&#34；，如何发布在ISC High Performance 2020&#34；上发布的研究海报</p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://emerging-architectures.github.io/amd_mi50_benchmarks/">https://emerging-architectures.github.io/amd_mi50_benchmarks/</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/ml/">#ml</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/美国/">#美国</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/谷歌/">#谷歌</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/linux/">#linux</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/程序/">#程序</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy; 2020 diglog.com </div></div></body></html>