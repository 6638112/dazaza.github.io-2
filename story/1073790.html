<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>神经元通过预测未来的活动来学习</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">神经元通过预测未来的活动来学习</h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2022-02-17 10:35:37</div><div class="page_narrow text-break page_content"><p>了解大脑如何学习可能会导致机器具有人类一样的智能能力。此前有人提出，大脑可以根据预测编码的原理运作。然而，预测系统是如何在大脑中实现的，目前尚不清楚。在这里，我们证明了单个神经元预测其未来活动的能力可能提供了一种有效的学习机制。有趣的是，这种预测性学习规则可以从代谢原理中推导出来，根据代谢原理，神经元需要最小化自身的突触活动（成本），同时通过招募其他神经元来最大化对局部血液供应的影响。我们展示了这种数学推导的学习规则如何在不同类型的大脑启发算法之间提供理论联系，从而为神经元学习的一般理论的发展提供了一个步骤。我们在神经网络模拟和清醒动物记录的数据中测试了这种预测性学习规则。我们的结果还表明，自发的大脑活动为神经元学习预测皮质动力学提供了“训练数据”。因此，单个神经元将惊喜最小化的能力，即实际活动和预期活动之间的差异，可能是理解大脑中计算的一个重要缺失元素。</p><p>神经科学正处于生物学在达尔文之前的阶段。它有无数详细的观察结果，但没有单一的理论解释所有这些观察结果之间的联系。我们甚至不知道这样的大脑理论应该是在分子水平上，还是在大脑区域的水平上，或者在两者之间的任何尺度上。然而，深入研究在癌症检测到自动驾驶汽车等任务中取得显著成果的深层神经网络可能会提供有用的见解。尽管这类网络可能有不同的输入和结构，但它们的大多数令人印象深刻的行为都可以通过底层的通用学习算法（称为反向传播1）来理解。</p><p>因此，更好地理解大脑使用的学习算法可能是发展统一的大脑功能理论的核心。有两种主要的方法来研究大脑中的学习机制：（1）实验性的，神经元活动的持续变化是由特定的干预引起的；（2）计算性的，算法的开发是为了实现特定的计算目标，同时仍然满足选定的生物约束3,4。在这篇文章中，我们探索了另一个选项—（3）理论推导，其中学习规则源自基本的细胞原理，即最大化细胞的代谢能量。使用这种方法，我们发现最大化神经元的能量平衡会产生一种预测性学习规则，在这种规则中，神经元会调整其突触权重，以最小化惊喜，即实际活动和预测活动之间的差异。有趣的是，这种衍生的学习规则与一些最有前途的生物启发学习算法有直接关系，比如预测编码和时间差分学习（见下文），基于Hebbian的规则可以被视为我们预测学习规则的特例（讨论）。因此，我们的方法可能在多个大脑启发算法之间提供理论联系，并可能为神经元学习的统一理论的发展提供一个步骤。</p><p>有多条证据表明，大脑作为一个预测系统运行5、6、7、8、9、10。然而，如何在大脑中实现精确的预测编码仍然存在争议。大多数提出的机制都涉及专门设计的带有“错误单元”的神经元电路，以便比较预期和实际活动11、12、13、14。这些模型假设了一个预测电路，但我们提出了一个替代方案，即在神经元内有一个内部预测模型。由于神经元的许多基本属性在整个进化过程中高度保守15、16、17，我们认为，使用预测性学习规则的单个神经元可以提供一个基本单元，从中可以构建各种预测性大脑。</p><p>有趣的是，我们的预测学习规则也可以通过修改时间差分学习算法来获得，使其在生物学上更合理。关于如何在大脑中实现类似反向传播的算法，时间差分学习是最有前途的想法之一。它基于神经元活动的差异来近似自上而下的错误信号4、18、19、20、21、22、23、24。这种算法的一个典型例子是对比Hebbian学习25、26、27，在某些假设28下，这被证明相当于反向传播。对比赫布式学习要求网络在隐藏层和输出层之间具有相互联系，这允许活动在两个方向上传播（图1a）。学习包括两个独立的阶段。首先，在“自由阶段”，一个样本刺激持续呈现给输入层，活动通过网络传播，直到动力学收敛到平衡（每个神经元的活动达到稳态水平）。在第二个“钳制阶段”，除了向输入呈现刺激外，输出神经元也被钳制在代表刺激类别的值上（例如，0或1），网络再次被允许收敛到平衡。对于每个神经元，钳制（\（{hat{x}}\）和自由（\（{check{x}}\）阶段的活动之间的差异用于根据方程式修改突触重量（w）</p><p>其中i和j分别是突触前和突触后神经元的指数，α是代表学习率的一个小数字。直观地说，这可以被视为调整权重，使自由期的每个神经元的活动更接近钳制期所代表的期望活动。这种算法明显的生物学合理性问题是，它要求神经元在两个不同阶段经历两次完全相同的刺激，并且神经元需要“记住”前一阶段的活动。我们的预测学习规则通过预测自由相稳态活动来解决这个问题，从而消除了对两个单独刺激呈现的要求。</p><p>a、 网络示意图。请注意，活动在隐藏层和输出层之间来回传播。b、 在自由期对不同刺激（以蓝色阴影标记）做出反应的神经元活动样本。自由相响应用于训练线性模型，以根据早期时间步的活动预测稳态活动（用阴影区域标记；详情见正文）。底部的轨迹显示输入的持续时间，点表示预测的活动。c、 神经元在网络输出被钳制的情况下对新刺激作出反应的活动。最初，网络只接收输入信号（自由相位），但经过几步之后，输出信号也会出现（钳制相位，底部黑色轨迹）。红点代表从初始活动（阴影区域）预测的稳态自由相活动。为了进行比较，虚线显示了在输出未被钳制的情况下，神经元在自由期的活动。突触重量（w）根据钳制期的稳态活动（\（{hat{x}}\）和预测的自由期活动（\（{tilde{x}}\）之间的差异成比例调整。</p><p>为了清楚起见，首先我们将描述如何通过修改对比Hebbian学习算法来获得预测学习规则。接下来，我们将在模拟和清醒动物记录的数据中验证预测性学习规则，并展示我们的结果如何为自发活动的功能提供新的启示。最后将详细介绍通过最大化神经元能量平衡来推导学习规则的过程。</p><p>如前所述，对比Hebbian学习算法要求网络在两个独立的学习阶段收敛到稳态平衡，因此必须两次呈现完全相同的刺激。然而，实际大脑中不太可能出现这种情况。在这里，我们建议通过将两个活动阶段合并为一个阶段来解决这个问题，这是受到皮层感觉处理的启发。例如，在视觉区域中，当呈现一张新图片时，最初会有自下而上的驱动活动，其中主要包含刺激的视觉属性（例如轮廓）。随后是包含更多抽象信息的自上而下调制，例如“该对象是类别x的成员”或“该对象是新颖的”（补充图1）。因此，我们的算法首先只运行自由阶段的初始部分，这代表了自下而上的刺激驱动活动，然后，经过几步之后，网络输出被钳制，对应于自上而下的调制。</p><p>这里的新见解是，初始自底向上的活动足以让神经元预测自由相活动的稳态部分，并且预测的自由相和钳制相之间的失配可以用作教学信号。为了在我们的模型中实现这个想法，对于每个神经元，在自由期的12个初始时间步（\（{check{x}{u{（1）}\）内的活动， ...,  \（{check{x}{（12）}}\）用于预测其在时间步120的稳态活动，\（{check{x}{（120）}\）（图1b）。具体地说，我们首先提出了自由阶段的样本刺激来训练线性模型，例如\（{check{x}{（120）}\approx{tilde{x}={\lambda{（1）}\check{x}{（1）}，+\ldots+\lambda{（12）}\check{x}{（12）{b}），其中\（{tilde{x}）表示预测的活动，λ和b对应于最小二乘模型的系数和偏移项，括号中的项对应于时间步长。接下来，使用一组新的刺激物，仅在前12个步骤中运行自由相，并从步骤13开始钳制网络输出（图1c）。然后应用上述最小二乘模型预测每个神经元的自由相稳态活动，并根据预测和钳制活动之间的差异更新权重（方法）。因此，为了修改突触重量，在方程式（1）中，我们用预测的活动（\（{tilde{x}}\）替换自由期的活动：</p><p>然而，问题是，这个等式意味着一个神经元还需要知道其所有突触前神经元的预测活动（\（{tilde{x}{i}\），这可能是不现实的。为了解决这个问题，我们用钳制阶段的实际突触前活动（\（{hat{x}{i}}）代替（\（{tilde{x}}{i}]），我们在网络模拟中验证了这一点（见下一节）。这种变化导致以下简化的突触可塑性规则（方程式（3））：</p><p>$${\Delta{w}{ij}={\alpha（{\hat{x}}{i}}{\hat{x}}{j}-{\hat{x}{i}{i}{\tilde{x}{j}}}={\alpha{hat{x}{i}{j}{$$</p><p>因此，为了修改突触权重，神经元只会将其实际活动（\（{hat{x}{j}）与其预测活动（\（{tilde{x}{uj}）进行比较，并将此差异按比例应用于每个输入贡献（\（{hat{x}{uj}]）。</p><p>为了测试预测学习规则是否可以用于解决标准的机器学习任务，我们创建了以下模拟。该神经网络有784个输入单元、1000个隐藏单元和10个输出单元，并在手写数字识别任务上进行训练（MNIST 29；补充图2和方法）。该网络实现了1.9%的错误率，这与使用反向传播算法29训练的具有类似结构的神经网络相似。这表明，具有预测学习规则的网络可以解决具有挑战性的非线性分类任务。</p><p>为了验证神经元能够正确预测未来的自由相活动，我们仔细观察了样本神经元。图2a显示了在第一次训练后，所有十个输出神经元对样本数字图像的反应。在时间步长1–12期间，仅显示输入信号，网络在空闲阶段运行。在时间步13，输出神经元被钳制，九个神经元的活动设置为0，代表正确图像类别的一个神经元的活动设置为1。为了进行比较，该图还显示了没有钳制输出（自由相）的相同神经元的活动。它表明，在自由阶段大约50步后，网络达到稳定状态，预测的活动密切匹配。当网络完全训练时，自由阶段的网络动力学仍需要大约50步才能收敛到稳定状态（图2b）。请注意，尽管所有单位最初在自由阶段开始时都会增加其活动，但它们后来会收敛到接近0，但代表正确类别的一个单位除外。同样，自由阶段前12步的预测与实际的稳态活动非常吻合。隐藏单元在大约50步后也收敛到稳定状态。图2c显示了一个具有代表性的隐藏神经元对五种样本刺激的反应。因为隐藏单元只能通过输出神经元的突触间接感受钳制信号，所以它们的稳态活动不一定像输出神经元那样只收敛到0或1。隐藏神经元的实际和预测稳态活动如图2d所示。预测自由相活度与实际自由相活度之间的平均相关系数为R = 1. ± 0.0001 s、 d.（对随机选择的200张测试图像进行1000个隐藏神经元的平均反应）。请注意，我们总是使用交叉验证方法，在这种方法中，我们根据数据子集为每个神经元训练一个预测模型，并将该模型应用于新的示例，然后用于更新权重（方法）。因此，神经元能够成功地将他们的预测推广到新的看不见的刺激。训练和测试数据集的网络错误率如图2e所示。这表明预测性学习规则运行良好，每个神经元都能准确预测其未来的活动。</p><p>a、 在网络训练开始时，十个输出神经元对样本刺激的反应。灰色阴影区域表示自由阶段的范围（时间步长1–12）。红色实线显示在第13步被钳制的神经元的活动。为了进行比较，虚线表示输出神经元未被钳制时的自由相活动。圆点表示根据初始活性（步骤1-12）预测的自由相稳态活性。b、 网络训练后相同神经元的活动。请注意，自由相和预测的活动收敛到所需的钳制活动。c、 网络训练后，隐层中代表性神经元对五种不同刺激的反应。实线和虚线分别表示固定相和自由相，点表示预测的活性。d、 预测自由相活动与实际自由相活动。为了清晰起见，在1000个隐藏神经元中，只有每10个被显示，以回应20个样本图像。不同的颜色代表不同的神经元，但由于颜色的数量有限，一些神经元可能共享相同的颜色。点沿对角线的分布表明预测是准确的。e、 在不同的训练时期，错误率降低。黄线和绿线分别表示训练和测试数据集的学习曲线。请注意，在每个时代，我们只使用了60000个培训示例中的2%。</p><p>我们还在多个其他网络架构中测试了预测学习规则，这些架构旨在反映生物神经元网络的其他方面。首先，我们引入了一个约束，即80%的隐藏神经元是兴奋性的，剩下的20%只有抑制性输出。这是因为观察到生物神经元释放兴奋性或抑制性神经递质，而不是两者都释放（Dale定律30），约80%的皮层神经元是兴奋性的。采用这种结构的网络实现了2.66%的错误率（补充图3a）。我们还在一个没有对称权重的网络中测试了我们的算法，其性能与原始网络类似（1.96%，补充图3b）。此外，我们在一个带有尖峰神经元的网络中实现了预测学习规则，再次获得了2.46%的类似错误率（补充图4）。我们的预测学习规则在深度卷积网络中得到了进一步测试（图3a），其结构已被证明类似于视觉系统31、32中的神经元处理。利用这个卷积网络，我们在一个更具挑战性的数据集上测试了我们的算法，该数据集是受生物启发的算法：CIFAR-10 33。该数据集由代表十个不同类别（例如飞机、汽车、鸟类和猫）的彩色图像组成。我们实现了20.03%的错误率，与使用时间反向传播（BPTT）算法训练同一网络的错误率相当（图3b；方法和代码中提供了详细信息，重现结果可在https://github.com/ykubo82/bioCHL/tree/master/conv)总之，这表明我们的预测学习规则在各种生物动机的网络架构中表现良好。</p><p>a、 描述我们的卷积（Conv.）网络架构（方法）。b、 使用预测（Pred.）训练的卷积网络的学习曲线学习规则（绿色）和使用BPTT训练的同一网络的学习曲线，用于比较。红线显示了BPTT的学习曲线，使用与我们的预测模型相同的学习率（红线；LR:0.4,0.028,0.025），BPTT所有层的学习率为0.1（黄线），BPTT所有层的学习率为0.2（紫线）。这表明，在CIFAR-10上，使用我们的预测学习规则的深度网络的性能与BPTT相当。</p><p>为了测试真实神经元是否也能预测其未来的活动，我们分析了清醒大鼠听觉皮层的神经元记录（方法）。作为刺激，我们呈现了六个音调，每个音调1 它很长，中间有1个 持续20多次的沉默 min.（补充信息）。对于六个音调中的每一个，我们分别计算了平均起始和偏移反应，为每个神经元提供了12种不同的活动模式（图4a）。对于每个刺激，15-25分钟的活动 ms时间窗用于预测30-40年内的平均未来活动 window女士。我们使用12倍交叉验证，其中来自11个刺激的反应用于训练最小二乘模型，然后应用最小二乘模型预测剩余刺激的神经元活动。这个过程对每个神经元重复12次。实际活性和预测活性之间的平均相关系数为R = 0.36 ± 0.05 s.e.m.（四只动物55个细胞的平均值；图4b）。单个神经元的相关系数分布与0显著不同（t检验P &书信电报； 0.0001; 所有测试都是双向的；插图，图4b）。这表明神经元具有可预测的动力学，并且，从最初的神经元反应，可以估计它们未来的活动。</p><p>a、 代表性神经元对不同刺激的反应。为了可视化，12个响应中只有5个显示出来。灰色阴影区域表示用于预测未来活动的时间窗口。圆点显示了30-40年的预测平均活动 ms时间窗口。颜色对应不同的刺激。B</p><p>......</p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/预测/">#预测</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/learn/">#learn</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/神经元/">#神经元</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/谷歌/">#谷歌</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy;2012-2021 diglog.com </div></div></body></html>