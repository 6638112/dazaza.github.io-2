<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>ML超越曲线拟合：因果推理和DO-COMPULE的介绍（2018） </title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">ML超越曲线拟合：因果推理和DO-COMPULE的介绍（2018） </h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2021-06-23 00:18:21</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2021/6/2916bd6015af3e9e1e962504cf897b6a.png"><img src="http://img2.diglog.com/img/2021/6/2916bd6015af3e9e1e962504cf897b6a.png" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>您可能已经遇到了犹太珍珠＆＃39;新书籍，以及在我的社交泡沫中广泛分享的相关面试。在采访中，珍珠驳回了我们在ml中的大部分曲线适合。虽然我相信＆＃39;＆＃39;虽然夸大了（方便地忽略了rl），它是一个很好的提醒，最富有成效的辩论常常被争议或彻底的傲慢评论触发。呼叫机学习炼金术是最近的一个伟大的例子。阅读文章后，我决定调查他着名的Do-Calmulus，并再次进行主题。</p><p> 再次，因为这发生在我周期性上。我首先在（非常不受欢迎但高级）本科课程贝叶斯网络中学习了DO-COMPULA。从那时起，我在各种情况下每2  -  3年重新遇到它，但不知怎的，它从未真正击中了和弦。我总是想到和＃34;这种东西是困难和/或不切实际的＆＃34;最终忘了它并继续前进。直到现在，我从未意识到这种东西有多基础。</p><p> 这一次，我想我完全掌握了因果推理的重要性，并且我变成了一个全面的信徒。我知道我迟到了比赛，但我几乎认为它＆＃39;对于使用数据和条件概率来了解这个工具包的基础知识的人，我觉得在整个职业生涯中完全无视这个令人尴尬的卫生。</p><p> 在这篇文章中，我试图解释基础知识，并说服你为什么也应该考虑这一点。如果你在深入学习，那个＆＃39;这是一个更好的理解理解这一点。如果用因果推断被解释为对比深度学习，珍珠＆＃39的评论可能会无益。相反，您应该将其解释为突出显示因果推断作为深度学习的巨大，相对望远镜的应用。不鼓励被呼吁地看待很多贝叶斯网络（看不到珍珠的巧合）来劝阻，他们不竞争，他们补充了深入学习。</p><p>  首先，因果演数在两种类型的条件分布之间区分了可能想要估计的。 TLDR：在ml中，我们通常只估计其中一个，但在某些应用中，我们实际上应该尝试或必须估计另一个。</p><p> 让事情设置，让＆＃39; s说我们有i.i.d.从某种关联$ p（x，y，z，\ ldots）上采样的数据。假设我们假设我们有大量的数据和最佳工具（例如，深度网络），以完全估计这种联合分布，或其任何财产，条件或边际分布。换句话说，假设$ P $＆＃39假设是已知的和易行的。假设我们最终对$ y $的变量达到$ x $。在高水平，人们可以用两种方式提出这个问题：</p><p> 观察到$ p（y \ vert x）$：$ y $的分布是什么，我观察到变量$ x $ trave $ x $。这就是我们通常在监督机器学习中估算的。它是一种条件分布，可以从$ p（x，y，z，\ ldots）计算，作为其边缘两个的比率。 $ p（y \ vert x）= \ frac {p（x，y）} {p（x）} $。我们非常熟悉这个对象，也知道如何从数据估算这一点。 </p><p>介入$ p（y \ vert do（x））$：$ y $的分布是什么，如果我将值设置为$ x $。这描述了$ y $ i将观察到我会观察到在数据生成过程中，人工迫使变量$ x $占据价值$ x $，但根据生成的原始过程模拟了变量的其余部分数据。 （请注意，数据生成过程与联合分配$ p（x，y，z，\ ldots）$，这是一个重要细节）。</p><p>  没有。$ p（y \ vert do（x））$和$ p（y \ vert x）$通常是相同的，并且您可以用几个简单的思想实验验证。说，$ y $是我浓缩咖啡机的压力和＃39; s锅炉，大约在0美元和1.1美元的$ 1.1 $酒吧，具体取决于它＆＃39被打开了多长时间。让$ x $是读取内置晴雨表。让＆＃39;说我们在随机时间联合观察x和y。假设晴雨表功能正常$ P（y | x）$应该是一个左右的单向分布，x $左右，由于测量噪音，随机性。但是，$ p（y | do（x））$ won＆＃39; t实际上取决于$ x $的值，通常与$ p（y）$通常相同，锅炉压力的边缘分布。这是因为人工地将晴雨表设定为值（例如，通过移动针）Won＆＃39; T实际上导致坦克中的压力上升或下降。</p><p> 总之，$ y $和$ x $是关联或统计上依赖的，因此看到$ x $允许我预测$ y $的值，但$ y $不是由$ x $造成的$ x $ sto设置$ x $ won＆＃39; t影响$ y $的分配。因此，$ p（y \ vert x）$和$ p（y \ vert do（x））$表现得非常不同。这个简单的例子只是冰山一角。介入和观察条件之间的差异可能更为细微，并且难以表征，当存在复杂的相互作用的许多变量时。</p><p>  根据您想要解决的应用程序，您应该寻求估计其中一个条件。如果您的最终目标是诊断或预测（即观察自然发生的$ x $并推断出$ y $的可能值），则需要观察条件$ p（y \ vert x）$。这就是我们在监督学习中所做的事情，这就是犹太珍珠叫曲线的珍珠。这对于一系列重要的应用程序都很好，如分类，图像分割，超分辨率，语音转录，机器翻译等等。</p><p> 在您最终想要控制或根据估计的条件选择$ x $的应用中，您应该寻求估计$ p（y \ vert do（x））$。例如，如果$ x $是一个医疗和$ y $是结果，你不仅对观察自然发生的治疗$ x $和预测结果，我们不仅感兴趣，我们希望主动选择治疗$ x $ ket了解它如何影响结果$ y $。在系统识别，控制和在线推荐系统中发生类似情况。</p><p>  这也许是我在之前的主要概念＆＃39; t之前。 $ p（y \ vert do（x））$实际上是vanilla条件分布，但它没有基于$ p（x，z，y，\ ldots）$，但不同的联合$ p_ {do（x = x）}（x，z，y，\ ldots）$。这是$ p_ {do（x = x）} $是我们将在实际执行有关干预的情况下观察的数据的联合分布。 $ p（y \ vert do（x））$是条件分布，我们将从随机控制试验中收集的数据或A / B测试中学习，其中实验者控制$ x $。请注意，在许多情况下，实际执行干预或随机试验可能是不可能的或至少是不切实际的或不道德的。你可以＆＃39; t做一个/ b试验强迫你的一半受试者吸烟，另一半到抽烟，以了解大麻的影响。即使您可以直接估计$ p（y \ vert do（x））$从随机实验，仍然存在。因果推断和DO-COMPULUS的主要点是：</p><p> 如果我无法直接测量$ p（y \ vert do（x））$直接在随机对照试验中，我可以根据我在受控实验之外观察到的数据来估计它吗？ </p><p>让＆＃39开始使用一个图表，如果我们只关心$ p（y \ vert x）$，即简单的监督学习案例：</p><p>  让＆＃39; s表示我们观察到3个变量，$ x，z，y $，按此顺序。数据被采样I.i.d.从3个变量的一些可观察的关节分布，由标记为＆＃39的蓝色因子图表示;可观察的关节＆＃39;如果你不知道是什么因子图，它＆＃39;不重要，圆圈代表随机变量，小方块代表了变量的接头分布＆＃39; s连接的变量。我们有兴趣预测$ y $ x $，并说$ z $是我们不想推断的第三种变量，但我们也可以衡量（我包括完整性，我包含这个）。观察条件$ P（Y \ VERT X）$通过简单的调节计算。从训练数据来看，我们可以构建$ q（y \ vert x; \ theta）$以近似该条件，例如使用深净最小化跨熵或其他任何条件。</p><p> 现在，如果我们＆＃39;重新对$ p（y \ vert do（x））$而不是$ p（y \ vert x）$？这是它的样子：</p><p>  因此，我们仍然具有蓝色观察的关节，数据仍然从该联合中取样。但是，我们希望估计的对象位于右下方，红色干预条件$ p（y \ vert do（x））$。这与干预接头有关，其由其上方的红色因子图表示。它＆＃39;在同一个域名的联合分布，但它与不同的分布不同。如果我们可以从这个红色分布中进行采样（例如，实际上运行随机对照试验我们得到$ x $），那么问题将通过简单的监督学习来解决。我们可以从红色关节生成数据，并直接从那里估算模型。但是，我们假设这是不可能的，我们所拥有的只是从蓝色关节采样的数据。我们必须看看我们是否可以以某种方式估计红色条件$ p（y \ vert do（x））$从蓝色关节。</p><p>  如果我们想在蓝色和红色关节之间建立连接，我们必须引入关于数据生成机制的因果结构的额外假设。我们唯一可以做出关于我们如何由于交互而改变的预测的方法是，如果我们知道变量是有因果关系的。单独的联合分配没有捕获有关因果关系的信息。我们必须介绍比这更具表现力的东西。这是它看起来的样子如何：</p><p>  除了可观察的关节之外，我们现在还有世界的因果模型（左上角）这种因果模型含有比联合分布更多的细节：它不仅知道压力和晴雨表读数都是依赖性的，而且还要依赖于压力，而且压力导致晴雨表也是如此。上去，而不是其他方式。该模型中的箭头对应于假设的原因方向，并且不存在箭头表示变量之间的缺乏因果关系。从因果图到联合分布的映射是多对一：几个因果图与相同的联合分布兼容。因此，通常不可能通过仅查看观察到的数据来结论不同的因果解释之间。</p><p> 提出了因果模型是一个建模步骤，我们必须考虑对世界如何工作的假设，导致的原因。一旦我们有一个因果关系图，我们就可以通过难以使因果网络进行干预的效果：删除以$ Operator以$ Operator删除导致节点的所有边缘。这在中顶面板上显示。然后肢体的因果模型产生了由绿色因子图表示的关节分布。该关节具有相应的条件分配$ \ tilde {p}（y \ vert do（x））$，我们可以用作我们的$ p的近似值（y \ vert do（x））$。如果我们有定性正确的原因结构（即没有缺少的节点，我们得到箭头的方向，如果所有正确的箭头的方向），则这个近似是精确的，$ \ tilde {p}（y \ vert do（x））= p（y \ vert do（x））$。如果我们的因果假设是错误的，则近似可能是虚假的。 </p><p>批判性地，要达到这种绿色的东西，从而建立观察数据和介入分布之间的桥梁，我们必须将数据与其他假设相结合，如果您愿意，先验知识。单独的数据不会让我们这样做。</p><p>  现在问题是，当我们只有来自蓝色分布的数据时，我们如何在绿色条件下说任何事情。我们处于更好的情况，而不是我们拥有与之相关的因果模型。为了缩短一个长话，这就是所谓的Do-Scalulus是为了。 DO-COMPULUS允许我们按摩绿色条件分布，直到我们在蓝色分布下的各种边缘，条件和期望方面表达它。 Do-Calculus扩展了我们使用四个附加规则的条件概率分布的工具包，我们可以应用于它们中的$ DO $运算符的条件分发。这些规则考虑了因果关系图的属性。细节可以＆＃39; t被压缩成一个博客文章，但这是它们的介绍文件..</p><p> 理想情况下，由于DO-COMPULAS导出，您最终有一个等效的$ \ tilde {p}（y \ vert do（x））$，它们不再有任何操作员，所以您估计它单独观察数据。如果是这种情况，我们会说因果查询$ \ tilde {p}（y \ vert do（x））是可识别的。相反，如果这是不可能的，无论我们尝试申请Do-Calculus多么努力，我们都会致电因果解法不可识别，这意味着我们能够从我们拥有的数据中估计它。下图总结了这一因果推理机械的全部荣耀。</p><p>  新面板名为＆＃34;可评估公式＆＃34;显示作为$ \ tilde {p}（y \ vert do（x））$的等效表达式，因为包括多个DO-COMBULUS规则的导出。请注意，如果您只关心$ p（y \ vert x）$执行因果推断，则如何如何无关，这是如何完全无关紧要的。如果我们可以＆＃39; t观察$ z $我们仍然可以监督学习，但我们赢得了＆＃39; t能够回答因果推断查询$ p（y \ vert do（x））$。</p><p>  您可以基于观察到的数据，完全验证原因图的有效性和完整性。然而，存在经验验证的因果模型的某些方面。特别地，因果关系图暗示了一组变量之间的条件独立性或依赖关系。这些依赖项或独立性可以经验测试，如果它们不存在于数据中，则表示您的因果模型是错误的指示。采取这个想法前进您可以尝试从经验数据中尝试推断出原因模型或至少方面的完整因果区发现。</p><p> 但是，底线是：一个完整​​的因果模型是一种先验知识的形式，您必须添加到分析中，以便在没有实际进行干预的情况下获得因果问题的答案。单独推理数据赢得＆＃39;能够给你这个。与贝叶斯分析中的前瞻不同 - 这是一个很好的，并且可以提高数据效率 - 因果推理中的因果图是必备的。有几个例外情况，您可以在没有它们的情况下运行随机控制实验。</p><p>  因果推断确实是基本的。它允许我们回答＆＃34;什么 -  we-did-x＆＃34;通常需要受控实验和明确干预措施的键入问题。而且我甚至触及了更强大的反事实甚至触及了。 </p><p>在某些情况下，您可以没有这种情况。通常，你真的只想做正常推断。在诸如无模型RL的其他应用程序中，明确控制某些变量的能力可能允许您明确地回答因果问题。但是存在几种情况和非常重要的应用程序，其中因果推断提供了以原则方式解决问题的唯一方法。</p><p> 我想再次强调，这不是您是否在深入学习或因果推断上工作的问题。您可以，在许多情况下，您应该，兼顾。因果推断和DO-COMPULA允许您了解问题并确定需要根据在因果图中捕获的假设来从数据估计的内容。但是一旦你完成了，你仍然需要强大的工具来实际估计来自数据的东西。在这里，您仍然可以使用深度学习，SGD，变分界等。它是应用于因因果推理的这种深度学习的横截面，最近的珍珠文章索赔是探讨的。</p><p> 更新：在下面的评论中，人们实际指出了一些相关论文（谢谢！）。如果您了解任何工作，请在那里添加它们。 </p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://www.inference.vc/untitled/">https://www.inference.vc/untitled/</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/超越/">#超越</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/curve/">#curve</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/数据/">#数据</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/谷歌/">#谷歌</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy;2012-2021 diglog.com </div></div></body></html>