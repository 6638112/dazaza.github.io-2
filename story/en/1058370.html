<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>DeepOnet：基于深度的基于NN的模型，用于近似线性和非线性运算符 DeepONet: A deep NN-based model to approximate linear and nonlinear operators</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">DeepONet: A deep NN-based model to approximate linear and nonlinear operators<br/>DeepOnet：基于深度的基于NN的模型，用于近似线性和非线性运算符 </h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2021-04-15 22:24:39</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2021/4/0c982b49af3e8221b8715b286fe2e54d.jpg"><img src="http://img2.diglog.com/img/2021/4/0c982b49af3e8221b8715b286fe2e54d.jpg" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>Artificial neural networks are known to be highly efficient approximators of continuous functions, which are functions with no sudden changes in values (i.e., discontinuities, holes or jumps in graph representations). While many studies have explored the use of neural networks for approximating continuous functions, their ability to approximate nonlinear operators has rarely been investigated so far.    Researchers at Brown University recently developed DeepONet, a new neural network-based model that can learn both linear and nonlinear operators. This  , presented in a paper published in  Nature Machine Intelligence, was inspired by a series of past studies carried out by a research group at Fudan University.</p><p>已知人工神经网络是连续功能的高效近似器，其是没有突然变化的值（即，不连续，孔或图形表示中的跳跃）的函数。虽然许多研究已经探索了使用神经网络来近似连续功能，但到目前为止，它们的近似非线性运营商的能力很少。棕色大学的研究人员最近开发了一个新的基于神经网络的模型，可以学习线性和非线性运营商。这是一篇在自然机器智能发表的论文中，由复旦大学研究小组进行的一系列过去研究启发。</p><p>  George Em Karniadakis, one of the researchers who carried out the study, told TechXplore, &#34;About five years ago, as I was in class teaching variational calculus, I asked myself if a neural network can approximate a functional (we know it approximates a function). I searched around and found nothing, until one day I stumbled on  a paper by Chen &amp; Chen published in 1993, where the researchers achieved functional approximation using a single layer of neurons. Eventually, I also read  another paper by the same team on operator regression, which we used as a starting point for our study. Since then, Prof T Chen has contacted me by email and thanked me for discovering his forgotten papers.&#34;</p><p>  乔治·埃卡尼亚达基斯，其中一项研究的研究人员，告诉Techxplore，＆＃34;大约五年前，当我在课堂教学变分微积分时，我问自己，如果神经网络可以近似功能（我们知道它近似函数）。我在四处寻找并找不到，直到有一天我偶然发现了陈＆amp的纸张;陈于1993年出版，研究人员使用一层神经元实现了功能逼近。最终，我还通过同一团队阅读了另一个纸张，我们用作我们研究的起点。从那以后，T Chen教授通过电子邮件联系了我，并感谢我发现了他被遗忘的论文。＆＃34;</p><p>  Inspired by the papers by Chen and Chen at Fudan University, Karniadakis decided to explore the possibility of developing a   that could approximate both linear and nonlinear operators. He discussed this idea with one of his Ph.D. students, Lu Lu, who started developing DeepONet.</p><p>  Karniadakis的陈和陈的论文的灵感来自于陈和陈，决定探讨开发可能近似线性和非线性运营商的可能性。他用他的博士学位讨论了这个想法。学生，陆路，谁开始开发深度。</p><p>  In contrast with conventional neural networks, which approximate functions, DeepONet approximates both linear and nonlinear operators. The model comprises two deep neural networks: one   that encodes the discrete input function space (i.e., branch net) and one that encodes the domain of the output functions (i.e., trunk net). Essentially, DeepONet takes functions as inputs, which are infinite dimensional objects, and maps them to other functions in the output space.</p><p>  相反，与近似函数的传统神经网络相比，Deeponet近似于线性和非线性运算符。该模型包括两个深神经网络：一个编码离散输入功能空间（即，分支网）的一个深度神经网络（即，分支网）和编码输出函数的域（即，Trunk Net）的一个。基本上，DeepOnet用作输入的功能，它是无限的维度对象，并将它们映射到输出空间中的其他功能。</p><p>   &#34;With standard neural networks, we approximate functions, which take data points as input and outputs data points,&#34; Karniadakis said. &#34;So DeepOnet is a totally new way of looking at neural networks, as its networks can represent all known mathematical operators, but also differential equations in a continuous output space.&#34;</p><p>   ＆＃34;对于标准神经网络，我们近似函数，将数据点作为输入和输出数据点，＆＃34;卡尼亚迪克斯说。 ＆＃34;所以Deeponet是一种全新的方式来看神经网络，因为它的网络可以代表所有已知的数学运算符，而且还可以在连续输出空间中的微分方程。＆＃34;</p><p>     Once it learns a given operator, DeepONet can complete operations and make predictions faster than other neural networks. In a series of initial evaluations, Karniadakis and his colleagues found that it could make predictions in fractions of a second, even those related to very complex systems.</p><p>     一旦它学习给定的运营商，DeepOnet就可以完成操作并使预测比其他神经网络更快。在一系列初始评估中，卡尼亚迪克斯和他的同事发现它可以在一秒钟的级分，甚至与非常复杂的系统相关的部分。</p><p>  &#34;DeepONet can be extremely useful for autonomous vehicles, as it can make predictions in real time,&#34; Karniadakis said. &#34;It could also be used as a building block to simulate digital twins, systems of systems, and even complex social dynamical systems. In other words, the networks we developed can represent black-box   after intense offline training.&#34;</p><p>  ＆＃34; Deeponet对自动车辆非常有用，因为它可以实时制作预测，而＃34;卡尼亚迪克斯说。 ＆＃34;它也可以用作模拟数字双胞胎，系统系统和甚至复杂的社会动态系统的构建块。换句话说，我们开发的网络可以在激烈的离线培训后代表黑盒。＆＃34; </p><p>  As part of their study, the researchers investigated different formulations of DeepONet&#39;s input function space and assessed the impact of these formulations on the generalization error for 16 distinct applications. Their findings are highly promising, as their model could implicitly acquire a variety of linear and nonlinear operators.</p><p>作为他们研究的一部分，研究人员研究了DeepOnet＆＃39; S输入功能空间的不同配方，并评估了这些配方对16个不同应用的泛化误差的影响。他们的发现非常有希望，因为他们的模型可以隐含地获得各种线性和非线性运营商。</p><p>  In the future, DeepONet could have a wide range of possible applications. For instance, it could enable the development of robots that can solve calculus problems or solve differential equations, as well as more responsive and sophisticated autonomous vehicles.</p><p>  未来，DeepOnet可以具有广泛的可能应用。例如，它可以使能够解决可以解决微积分问题或解决微分方程的机器人以及更敏感和复杂的自治车辆的开发。</p><p>  &#34;I am now collaborating with labs from the Department of Energy and also with many industries to apply DeepONet to complex applications, e.g., in hypersonics, in climate modeling such as applications to model ice-melting in Antarctica, and in many design applications.&#34;        More information:												Learning nonlinear operators via DeepONet based on the universal approximation theorem of operators.  Nature Machine Intelligence(2021).  DOI: 10.1038/s42256-021-00302-5.</p><p>  ＆＃34;我现在正在与能源部的实验室合作，也与许多行业合作，将Deeponet应用于复杂的应用，例如在静脉内建模中，例如应用于南极洲的冰融化的应用，以及许多设计应用。＆＃34;更多信息：基于运营商的通用近似定理，通过DeepOnet学习非线性运算符。自然机器智能（2021）。 DOI：10.1038 / S42256-021-00302-5。 </p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://techxplore.com/news/2021-04-deeponet-deep-neural-network-based-approximate.html">https://techxplore.com/news/2021-04-deeponet-deep-neural-network-based-approximate.html</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/模型/">#模型</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/deep/">#deep</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/deeponet/">#deeponet</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/分享/">#分享</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy;2012-2021 diglog.com </div></div></body></html>