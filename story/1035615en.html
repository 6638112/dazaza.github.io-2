<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>新的Apache Kafka到AWS S3连接器New Apache Kafka to AWS S3 Connector</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">New Apache Kafka to AWS S3 Connector<br/>新的Apache Kafka到AWS S3连接器</h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2020-11-21 19:40:49</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2020/11/92f228ab0a7fc02c8885af3008e82f77.jpg"><img src="http://img2.diglog.com/img/2020/11/92f228ab0a7fc02c8885af3008e82f77.jpg" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>Many in the community have been asking us to develop a new Kafka to S3 connector for some time. So we’re pleased to announce it&#39;s now available.</p><p>一段时间以来，社区中的许多人一直在要求我们开发新的Kafka至S3连接器。因此，我们很高兴地宣布它现已可用。</p><p> It’s been designed to deliver a number of benefits over existing S3 connectors:</p><p>与现有的S3连接器相比，它具有许多优势：</p><p>  Like our other  Stream Reactors , the connector extends the standard connect config adding a parameter for a SQL command (Lenses Kafka Connect Query Language or “KCQL”). This defines how to map data from the source (in this case Kafka) to the target (S3).</p><p>与我们的其他Stream Reactors一样，该连接器扩展了标准的connect配置，并为SQL命令（Lenses Kafka Connect查询语言或“ KCQL”）添加了一个参数。这定义了如何将数据从源（在本例中为Kafka）映射到目标（S3）。</p><p> Importantly, it also includes how data should be partitioned into S3, the bucket names and the serialization format (support includes JSON, Avro, Parquet, Text, CSV and binary).</p><p>重要的是，它还包括如何将数据划分为S3，存储桶名称和序列化格式（支持包括JSON，Avro，Parquet，Text，CSV和二进制）。</p><p>    The connector supports a number of different authentication mechanisms to the S3 bucket including standard AWS Credentials (using an access and secret key) and via an  IAM role for EC2.</p><p>连接器支持对S3存储桶的多种不同身份验证机制，包括标准AWS凭证（使用访问和密钥）以及通过EC2的IAM角色。</p><p> Where credentials are needed, the Lenses  secret manager plugins allow you to integrate with common key management solutions such as Hashicorp Vault and AWS Secret Manager.</p><p>在需要凭证的地方，可以使用Lenses秘密管理器插件与常见的密钥管理解决方案（例如Hashicorp Vault和AWS Secret Manager）集成。</p><p>  Having control over how the data is structured whilst being sinked allows you to optimize for specific use cases, workloads and read patterns by downstream applications (such as Snowflake or AWS Athena, Glue etc.) and cost. And you avoid having to build and deploy complex stream processing workloads prior to sending to S3.</p><p>控制数据在接收时的结构方式，可以让您针对特定的用例，工作负载和下游应用程序（例如Snowflake或AWS Athena，Glue等）的读取模式进行优化，并降低成本。而且，您避免在发送到S3之前必须构建和部署复杂的流处理工作负载。</p><p> Like all Stream Reactor and Kafka Connect connectors, the connector can be managed via your traditional deployment tools and frameworks or can be managed through Lenses. This adds a layer of RBAC, governance, auditing, error handling and monitoring to how to manage Kafka connectors.</p><p>像所有Stream Reactor和Kafka Connect连接器一样，该连接器可以通过传统的部署工具和框架进行管理，也可以通过Lenses进行管理。这为如何管理Kafka连接器增加了一层RBAC，治理，审计，错误处理和监视。</p><p>  The whole workload defined as Connect configuration &amp; SQL helps you manage data pipelines as configuration and over  GitOps.</p><p>定义为Connect configuration＆SQL的整个工作负载可帮助您通过配置和通过GitOps管理数据管道。</p><p>  Let’s assume a scenario where we have records in a Kafka topic  backblaze_smart related to manufacturing process failures for certain products and events need to be stored in an S3 bucket.</p><p>假设存在一个场景，其中我们在Kafka主题backblaze_smart中具有与某些产品的制造过程失败相关的记录，并且事件需要存储在S3存储桶中。</p><p>  Downstream analytics solutions (such as AWS Athena) run by different Data teams for each model need access to this data.</p><p>由不同数据团队针对每种模型运行的下游分析解决方案（例如AWS Athena）需要访问此数据。</p><p> For a read-performance and cost reason, the Data team asks that messages related to each model be partitioned into different objects within the S3 bucket and with a particular naming convention and placed in a  manufacturing_failures folder.</p><p>出于读取性能和成本的原因，数据团队要求将与每个模型相关的消息按特定的命名约定在S3存储桶中划分为不同的对象，并放置在manufacturing_failures文件夹中。</p><p>  connect.s3.kcql=INSERT INTO Manufacturing:manufacturing_failures SELECT serial_number, model, capacity_bytes, failure FROM backblaze_smart PARTITIONBY model STOREAS `Json` WITH_FLUSH_COUNT = 300</p><p>connect.s3.kcql =插入INTO制造：manufacturing_failures SELECT序列号，型号，容量字节，失败FROM backblaze_smartPARTITIONBY模型STOREAS`Json`WITH_FLUSH_COUNT = 300</p><p>    The Lenses.io Box is a free all-in-one Kafka + Lenses development docker. It’s a  perfect environment for developing real-time applications and testing connectors and it comes with sample data.</p><p>Lenses.io Box是一个免费的多合一Kafka + Lenses开发泊坞窗。这是用于开发实时应用程序和测试连接器的理想环境，并且附带示例数据。</p><p>  If you prefer to use your own Lenses or Kafka Connect environment, you can download the connector from  here and request a free trial of Lenses from lenses.io/start.</p><p>如果您喜欢使用自己的Lenses或Kafka Connect环境，则可以从此处下载连接器，并从lens.io/start请求免费试用Lenses。</p><p> We will create an IAM role in order to configure EC2 authentication to access the S3 bucket. If you’re not running Lenses Box on an EC2 instance, this won’t be necessary but you’ll need to provide an  Access and Secret key to write to S3 instead.</p><p>我们将创建一个IAM角色，以配置EC2身份验证以访问S3存储桶。如果您不在EC2实例上运行Lenses Box，则不需要这样做，但是您需要提供一个Access and Secret键来写入S3。</p><p>       3. 	In  Bucket name, enter a name for your bucket &lt;BUCKETNAME&gt;. Do not use hyphens or other special characters. This is a requirement of the connector later.</p><p>3.在存储桶名称中，输入存储桶的名称。请勿使用连字符或其他特殊字符。这是以后连接器的要求。</p><p>   Take note of your AWS region of your bucket as you’ll need this later.</p><p>记下您的存储桶的AWS区域，稍后将需要它。</p><p>  For the EC2 authentication to work, you must create an IAM role before you can launch the instance that will run Kafka Connect (the Lenses Box docker is packaged with Kafka Connect).</p><p>为了使EC2身份验证起作用，必须先创建IAM角色，然后才能启动将运行Kafka Connect的实例（Lenses Box泊坞窗与Kafka Connect打包在一起）。</p><p> With the IAM role created,  it will be attached to an instance running Kafka Connect/Box.</p><p>创建IAM角色后，它将被附加到运行Kafka Connect / Box的实例上。</p><p> Alternatively, if you will authenticate to the S3 bucket with AWS Secret and Access keys instead, follow the processes described  here.</p><p>或者，如果您将改为使用AWS Secret and Access密钥对S3存储桶进行身份验证，请按照此处描述的过程进行操作。</p><p>    3. 	On the  Select role type page, choose  EC2 and the  EC2 use case. Choose  Next: Permissions.</p><p>3.在“选择角色类型”页面上，选择EC2和EC2用例。选择“下一步：权限”。</p><p>   5. 	Open the JSON editor and paste the following policy, replacing the bucket name with the name of your bucket.</p><p>5.打开JSON编辑器并粘贴以下策略，将存储桶名称替换为您的存储桶名称。</p><p> This policy allows access to the S3 bucket and also to the Kafka functions we will need later.</p><p>此策略允许访问S3存储桶以及以后需要的Kafka功能。</p><p>  6. 	On the  Review page, enter a name  S3DataAccessPolicy for the policy and choose  Create policy.</p><p>6.在Review页面上，为策略输入名称S3DataAccessPolicy，然后选择Create policy。</p><p>  7. Return to the previous browser tab for  Create Role and refresh the policy list and find and check the newly created policy.</p><p>7.返回到用于创建角色的上一个浏览器选项卡，并刷新策略列表，然后查找并检查新创建的策略。</p><p>       If you’re deploying on an EC2 instance running docker we recommend you run on a  t2.large instance.</p><p>如果您要在运行docker的EC2实例上进行部署，建议您在t2.large实例上运行。</p><p> For the EC2 authentication to work, you’ll need to ensure the IAM Role associated with the instance running is assigned to the  S3DataAccessRole  just created.</p><p>为了使EC2身份验证有效，您需要确保将与正在运行的实例相关联的IAM角色分配给刚刚创建的S3DataAccessRole。</p><p>  Port 3030 will need to be configured in the Security Group in order to access Lenses. Depending on which other services you want to access, you may want to open up certain ports (but not essential for this walkthrough).</p><p>需要在安全组中配置端口3030才能访问镜头。根据您要访问的其他服务，您可能需要打开某些端口（但对于本演练不是必需的）。</p><p> 1. Request a Box license key for free from:  https://lenses.io/box/. You’ll receive an email with a docker run command</p><p>1.从以下网址免费索取Box许可证密钥：https：//lenses.io/box/。您会收到一封包含docker run命令的电子邮件</p><p>     Note: if you want to configure your own external producers/consumers to this instance, set the  ADV_HOST address accordingly.  But you’ll need to ensure you open up port 9092 in the security group too.</p><p>注意：如果要为此实例配置自己的外部生产者/消费者，请相应地设置ADV_HOST地址。但是，您还需要确保在安全组中打开端口9092。</p><p>   2.	The “Explore” page acts as a real-time data catalog. Search for the  backblaze_smart topic. This topic includes real-time flow from a sample producer within the Box environment.</p><p>2.“浏览”页面充当实时数据目录。搜索backblaze_smart主题。本主题包括Box环境中来自样品生产者的实时流量。</p><p>  3.	To be more precise about which fields to sink to S3, from within the SQL Studio run the statement</p><p>3.为了更准确地确定要插入S3的字段，请在SQL Studio中运行以下语句</p><p>    1.	It’s often a good idea to ensure you have access to the S3 bucket from within your environment using the AWS CLI.</p><p>1.确保使用AWS CLI从环境中访问S3存储桶通常是一个好主意。</p><p>      2.	If successfully accessing the bucket, from within Lenses, select “Connectors” from the top level menu. A number of sample connectors should already be configured in Box.</p><p>2.如果成功访问存储桶，请从Lenses中，从顶层菜单中选择“连接器”。 Box中应该已经配置了许多示例连接器。</p><p>  3.	Click  New Connector. Lenses will list all the available Connectors that are packaged by default in Box.</p><p>3.单击新建连接器。镜头将列出默认情况下包装在包装盒中的所有可用连接器。</p><p>  5.	Enter the details of the Connector. Take care to update the region of your S3 bucket in the parameters  aws.custom.endpoint &amp;  aws.region.  Ensure to update the bucket name  MyBucketName with the bucket created earlier in the  connect.s3.kcql parameter.</p><p>5.输入连接器的详细信息。注意在参数aws.custom.endpoint＆aws.region中更新S3存储桶的区域。确保使用先前在connect.s3.kcql参数中创建的存储桶来更新存储桶名称MyBucketName。</p><p> connect.s3.kcql=INSERT INTO MyBucketName:manufacturing_failures SELECT serial_number, model, capacity_bytes, failure FROM backblaze_smart PARTITIONBY model STOREAS `Json` WITH_FLUSH_COUNT = 3</p><p>connect.s3.kcql = INSERT INTO MyBucketName：manufacturing_failures SELECT序列号，模型，容量字节，失败FROM backblaze_smartPARTITIONBY模型STOREAS`Json`WITH_FLUSH_COUNT = 3</p><p>  If you&#39;re using credentials to authenticate instead of EC2, enter a secret and access key.</p><p>如果您使用凭据而不是EC2进行身份验证，请输入密钥和访问密钥。</p><p>      If you were successful, get ready to deploy the connector against your own Kafka Connect &amp; Kafka environment with a free trial of Lenses available from  lenses.io/start.</p><p>如果成功，请准备免费使用Lens.io/start上提供的Lenses试用版，将连接器部署到自己的Kafka Connect＆Kafka环境中。</p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://lenses.io/blog/2020/11/new-kafka-to-S3-connector/">https://lenses.io/blog/2020/11/new-kafka-to-S3-connector/</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/kafka/">#kafka</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/连接器/">#连接器</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/分享/">#分享</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy; 2020 diglog.com </div></div></body></html>