<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>为家庭服务器运行Nomad Running Nomad for a Home Server</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">Running Nomad for a Home Server<br/>为家庭服务器运行Nomad </h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2021-02-17 18:08:19</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2021/2/d3d75c523776204096d32caf9610a038.png"><img src="http://img2.diglog.com/img/2021/2/d3d75c523776204096d32caf9610a038.png" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>It&#39;s been a long time since I&#39;ve written a post on Hydra (my home server). I use Hydra as a testbed to learn new tools, workflows and it just gives me joy to self-host applications while learning something in return.</p><p>自从我在Hydra（我的家庭服务器）上写了一篇文章以来已经很长时间了。我将Hydra用作测试平台来学习新工具，工作流程，这给我自托管应用程序带来欢乐的同时又获得了一些回报。</p><p>    A pretty minimal K3s setup deployed on 2 RPi4 nodes. I couldn&#39;t continue with this setup because: Some of the apps didn&#39;t have ARM-based image (this was 2019, pre M1 hype era).</p><p>    在2个RPi4节点上部署了相当少的K3s设置。我无法继续此设置，因为：有些应用程序没有基于ARM的映像（这是在2019年，M1炒作时代之前）。</p><p>   It was so boring to write YAML (that I also did at work). Didn&#39;t give me joy.</p><p>   编写YAML太无聊了（我也在工作）。没给我欢乐。</p><p>  RPi 2x Nodes + K3s + DO Droplet. Tailscale for networking. This was a considerable step up from the previous setup. I deployed a DO node and added  Node Labels to deploy persistent workloads on DO Node only.</p><p>  RPi 2x节点+ K3s + DO Droplet。用于网络的尾标。与以前的设置相比，这是一个很大的进步。我部署了一个DO节点，并添加了Node Labels以仅在DO Node上部署持久性工作负载。</p><p> I used my own tooling  Kubekutr + Kustomize which helped with version control of my configs.</p><p> 我使用了自己的工具Kubekutr + Kustomize，它有助于配置的版本控制。</p><p> Took quite a bit of time to onboard new services. Got lazy, didn&#39;t host much apart from initial 3-4 applications.</p><p> 花了很多时间来启用新服务。懒了，除了最初的3-4个应用程序外没有太多其他内容。</p><p>  Single node on DO. Terraform for deploying Docker containers. I believe the third iteration nailed it for me. I kept the setup super simple, used Terraform for deploying workloads as Docker containers.</p><p>  DO上的单个节点。用于部署Docker容器的Terraform。我相信第三次迭代对我很有帮助。我保持设置超级简单，使用Terraform将工作负载部署为Docker容器。 </p><p>  Time to onboard new services reduced from a couple of hours to a few minutes. This was a huge win for me. I deployed around 10-15 new services to try it out on the server directly.</p><p>启用新服务的时间从几个小时减少到几分钟。对我来说，这是一个巨大的胜利。我部署了大约10-15项新服务，以直接在服务器上进行尝试。</p><p>   Around a month back,  Kailash had asked about feedback on  Nomad. We at  Zerodha (India&#39;s largest stock broker) are evaluating it to migrate our services to Nomad from Kubernetes (more on this later). It was almost 2 years since I last saw Nomad so it was definitely worth re-evaluating (esp since it hit 1.0 recently). I wanted to try out Nomad to answer a personal curiosity:  What does it do differently than Kubernetes? No better way than actually getting hands dirty, right?!</p><p>   大约一个月前，凯拉什（Kallash）询问了有关游牧民族的反馈。我们在Zerodha（印度最大的股票经纪商）进行了评估，以将我们的服务从Kubernetes迁移到Nomad（稍后会详细介绍）。自从我上次看到Nomad以来已经过去了将近2年，因此绝对值得重新评估（尤其是自从最近达到1.0以来）。我想尝试游牧回答个人的好奇心：这是什么做的不同于Kubernetes？没有比实际弄脏手更好的方法了，对吗？</p><p> After following the brief tutorials from the  official website I felt confident to try it for actual workloads. In my previous setup, I was hosting quite a few applications (Pihole, Gitea, Grafana etc) and thought it&#39;ll be a nice way to learn how Nomad works by deploying the same services in the Nomad cluster. And I came in with zero expectations, I already had a nice setup which was reliable and running for me. My experience with a local Nomad cluster was joyful, I was able to quickly go from 0-&gt;1 in less than 30 minutes. This BTW is a strong sign of how easy Nomad is to get started with as compared to K8s. The sheer amount of different concepts you&#39;ve to register in your mind before you can even deploy a single container in a K8s cluster is bizarre. Nomad takes the easy way out here and simplified the concepts for developers into just three things:</p><p> 在遵循了官方网站的简短教程之后，我有信心针对实际的工作量进行尝试。在我之前的设置中，我托管了许多应用程序（Pihole，Gita，Grafana等），并认为这将是通过在Nomad群集中部署相同服务来学习Nomad工作方式的好方法。我的期望值是零，我已经有了一个不错的设置，该设置可靠并且可以运行。我在本地Nomad群集中的体验很愉快，我能够在不到30分钟的时间内从0到1迅速达到。与K8相比，此BTW强烈表明Nomad入门容易。您甚至必须在K8s集群中部署单个容器之前就已经想过要登记的大量不同概念，这很奇怪。 Nomad在这里采取了简单的方法，将开发人员的概念简化为三件事：</p><p>  Job: Job is a collection of different groups. Job is where the constraints for type of scheduler, update strategies and ACL is placed.</p><p>  职位：职位是不同群体的集合。作业是放置调度程序类型，更新策略和ACL的约束的地方。</p><p> Group: Group is a collection of different tasks. A group is always executed on the same Nomad client node. You&#39;ll want to use Groups for use-cases like a logging sidecar, reverse proxies etc.</p><p> 组：组是不同任务的集合。组始终在同一Nomad客户端节点上执行。您将希望将Groups用于用例，例如日志记录Sidecar，反向代理等。</p><p> Task: Atomic unit of work. A task in Nomad can be running a container/binary/Java VM etc, defining the mount points, env variables, ports to be exposed etc.</p><p> 任务：原子工作单元。 Nomad中的任务可以运行容器/二进制/ Java VM等，定义安装点，env变量，要公开的端口等。</p><p> If you&#39;re coming from K8s you can think of Task as a Pod and Group as a Replicaset. There&#39;s no equivalent to Job in K8s. BUT! The coolest part? You don&#39;t have to familiarise yourself with all different types of Replicasets (Deployments, Daemonsets, Statefulsets) and different ways of configuring them.</p><p> 如果您来自K8，则可以将Task视为Pod，将Group视为Replicaset。在K8中，没有什么比Job更好的了。但！最酷的部分？您不必熟悉所有不同类型的复制副本（部署，后台驻留程序，状态集）以及配置它们的不同方法。 </p><p> Want to make a normal job as a periodic job in Nomad? Simply add the following block to your existing Job:</p><p>是否想在Nomad中做正常工作作为定期工作？只需将以下块添加到您现有的Job中：</p><p>  You want to make a service run as a batch job (on all Nomad nodes -- the equivalent of Daemonset in K8s)? Simply make the following change to your existing job:</p><p>  您要使服务作为批处理作业运行（在所有Nomad节点上-相当于K8s中的Daemonset）？只需对您现有的工作进行以下更改：</p><p>  You see  this is what I mean by the focus on UX. There are many many such examples which will leave a nice smile on your face if you&#39;re coming from K8s background.</p><p>  您会看到这就是我对UX的关注。如果您来自K8的背景，那么有很多这样的示例会在您的脸上留下漂亮的笑容。</p><p>    Tailscale VPN: Serves as a mesh layer between my laptop/mobile and DO server. Useful for exposing internal services.</p><p>    Tailscale VPN：在笔记本电脑/移动设备和DO服务器之间充当网状层。对于公开内部服务很有用。</p><p> Caddy for reverse proxying and automatic SSL setup for all services. I run 2 instances of Caddy:</p><p> Caddy用于所有服务的反向代理和自动SSL设置。我运行了2个Caddy实例：</p><p> Terraform: Primary component to have IaC (Infra as Code). Modules to manage: Nomad Jobs. Used for running workloads after templating env variables, config files in Nomad job files.</p><p> Terraform：具有IaC（红外线代码）的主要组件。管理模块：Nomad Jobs。在将环境变量，Nomad作业文件中的配置文件模板化后，用于运行工作负载。</p><p>   Nomad shines because it follows the UNIX philosophy of &#34;Make each program do one thing well&#34;. To put simply, Nomad is  just a workload orchestrator. It only is concerned about things like Bin Packing, scheduling decisions.</p><p>   Nomad之所以大放异彩，是因为它遵循UNIX的哲学，即“使每个程序做好一件事情”。简而言之，Nomad只是工作负载的协调者。它只关心诸如装箱，计划决策之类的事情。 </p><p> If you&#39;re running heterogeneous workloads, running a server (or a set of servers) quickly becomes expensive. Hence orchestrators tend to make sense in this context. They tend to save costs by making it efficient to run a vast variety of workloads. This is all an orchestrator has to do really.</p><p>如果您正在运行异构工作负载，则运行一台服务器（或一组服务器）会很快变得昂贵。因此，在这种情况下，协调者倾向于有意义。他们倾向于通过高效运行各种工作负载来节省成本。这是协调员真正要做的所有事情。</p><p> Nomad doesn&#39;t interfere in your DNS setup, Service Discovery, secrets management mechanisms and pretty much anything else. If you read some of the posts at  Kubernetes Failure Stories, the most common reason for outages is Networking (DNS, ndots etc). A lot of marketing around K8s never talks about these things.</p><p> Nomad不会干扰您的DNS设置，服务发现，机密管理机制以及几乎所有其他内容。如果您阅读Kubernetes失败案例中的一些文章，则最常见的中断原因是网络（DNS，ndots等）。围绕K8的许多营销从未谈论过这些事情。</p><p> I always maintain &#34;Day 0 is easy, Day N is the real test of your skills&#34;. Anyone can deploy a workload to a K8s cluster, it&#39;s always the Day N operations which involve debugging networking drops, mysterious container restarts, proper resource allocations and other such complex issues that require real skills  and effort. It&#39;s not as easy as  kubectl apply -f and my primary gripe is with people who miss out on this in their &#34;marketing&#34; pitches (obvious!).</p><p> 我始终认为“第0天很容易，第N天是对你的技能的真正考验”。任何人都可以将工作负载部署到K8s集群，这始终是Day N的操作，涉及调试网络中断，神秘的容器重启，正确的资源分配以及其他需要实际技能和精力的复杂问题。它不像kubectl应用-f那样容易，而我最主要的抱怨是那些在营销中错过了这一点的人间距（显而易见！）。</p><p>  Nomad hits the sweet spot of being operationally easy and functional. Nomad is a great choice if you want to:</p><p>  Nomad达到了易于操作且功能强大的最佳效果。如果您想：Nomad是一个不错的选择：</p><p> (Not joking) You are tired of running Helm charts or writing large YAML manifests. The config syntax for Nomad jobs is human friendly and easy to grasp.</p><p> （不是在开玩笑）您已经厌倦了运行Helm图表或编写大型YAML清单。 Nomad作业的配置语法对人类友好并且易于掌握。</p><p> Nomad is available as a single binary. If you want to try it locally, all you need is  sudo nomad agent -dev and you&#39;ll have a Nomad Server, Client running in dev mode along with a UI. This makes it easy for the developers to test out the deployments locally because there&#39;s very little configuration difference between this and production deployment. Not to forget it&#39;s super easy to self-host Nomad clusters. I&#39;m yet to meet anyone who self hosts K8s clusters in production without a dedicated team babysitting it always.</p><p> Nomad可作为单个二进制文件获得。如果要在本地尝试，则只需要sudo nomad agent -dev，您将拥有一个以开发人员模式运行的Nomad Server客户端以及一个UI。这使开发人员可以轻松地在本地测试部署，因为此部署与生产部署之间的配置差异很小。不要忘记，它非常容易自托管Nomad集群。我尚未见到任何在生产过程中自行托管K8集群的人，而始终没有专职团队照顾它的人。</p><p>   If you&#39;re relying on custom controllers and operators.  Operator Pattern is a new way of managing large complex distributed systems (like databases, job queues etc). There are a lot of community built operators which help in reducing the effort to run these services. However, all of these are tied deeply into the &#34;Kubernetes&#34; ecosystem. If you find yourself running any of such operators, it&#39;ll be tough (not impossible) to translate the same in Nomad ecosystem.</p><p>   如果您依赖自定义控制器和运算符。操作员模式是一种管理大型复杂分布式系统（如数据库，作业队列等）的新方法。有很多社区构建的运营商，可帮助减少运行这些服务的工作量。但是，所有这些都与＆＃34; Kubernetes＆＃34;生态系统。如果您发现自己正在运行任何这样的运算符，那么在Nomad生态系统中翻译相同的运算符将很困难（并非不可能）。 </p><p>   Since I migrated a couple of workloads from my DO docker containers setup to Nomad, I&#39;d demonstrate a few use cases which might be helpful if you want to start migrating your services to Nomad</p><p>由于我将一些工作负载从DO docker容器设置迁移到Nomad，因此我演示了一些用例，如果您想开始将服务迁移到Nomad，这可能会有所帮助</p><p>  Context: I&#39;m running Caddy as a reverse proxy for all the services. Since we discussed earlier, Nomad  only is concerned about scheduling, so how exactly do you do Service Discovery? You need Consul (or something like Consul, Nomad has no hard restrictions) to register a service name with it&#39;s IP Address. Here&#39;s how you can do that:</p><p>  上下文：我正在将Caddy作为所有服务的反向代理运行。如前所述，Nomad只关心调度，因此您如何精确地进行服务发现？您需要Consul（或Consul，Nomad之类的东西没有硬限制）才能使用其IP地址注册服务名称。这是您的操作方法：</p><p> In the  .task section of your Nomad job spec, you need to register the service name with the port you&#39;re registering and additional tags as metadata (optional):</p><p> 在Nomad工作规格的.task部分中​​，您需要使用您正在注册的端口注册服务名称，并将其他标签注册为元数据（可选）：</p><p>  Nomad&#39;s  template uses  consul-template behind the scenes. This is a small utility which continuously watches for Consul/Vault keys and provides the ability to reload/restart your workloads if any of those keys change. It can also be used to  discover the address of the service registered in Consul. So here&#39;s an example of  Caddyfile using Consul Template functions to pull the IP address of the upstream  gitea-web service:</p><p>  Nomad的模板在幕后使用领事模板。这是一个小型实用程序，可以持续监视Consul / Vault密钥，并且如果其中任何一个密钥发生更改，则可以重新加载/重新启动工作负载。它也可以用来发现在Consul中注册的服务的地址。因此，这是一个使用领事模板功能提取上游gitea-web服务的IP地址的Caddyfile的示例：</p><p> git.mrkaran.dev { {{ range service &#34;gitea-web&#34; }} reverse_proxy {{ .Address }}:{{ .Port }} {{ end }}}</p><p> git.mrkaran.dev {{{范围服务＆＃34; gitea-web＆＃34; }} reverse_proxy {{.Address}}：{{.Port}} {{end}}}</p><p> When a job is submitted to Nomad, a rendered template is mounted inside the container. You can define actions on what to do when the values change. For eg on a redeployment of Gitea container, the address will most likely change. We&#39;d like Caddy to automatically restart with the new address configured in the Caddyfile in that case:</p><p> 当作业提交给Nomad时，已渲染的模板将安装在容器内。您可以定义值更改时的操作。例如，在重新部署Gitea容器时，地址很可能会更改。在这种情况下，我们希望Caddy使用在Caddyfile中配置的新地址自动重启：</p><p>    I run a public instance of Gitea but I wanted to restrict the SSH access only to my Tailscale network. Nomad has an interesting feature   host_network which lets you bind different ports of a task on different network interfaces.</p><p>    我运行了Gitea的公共实例，但我想仅将SSH访问限制为我的Tailscale网络。 Nomad具有一个有趣的功能host_network，使您可以在不同的网络接口上绑定任务的不同端口。 </p><p> network { port &#34;http&#34; { to = 3000 } port &#34;ssh&#34; { to = 22 # Need a static assignment for SSH ops. static = 4222 # SSH port on the host only exposed to Tailscale IP. host_network = &#34;tailscale&#34; }}</p><p>网络{端口＆＃34; http＆＃34; {to = 3000}端口＆＃34; ssh＆＃34; {to = 22＃需要为SSH操作静态分配。 static = 4222＃主机上仅暴露于Tailscale IP的SSH端口。 host_network =＆＃34; tailscale＆＃34; }}</p><p>   Nomad doesn&#39;t have any templating functionalities, so all the config must be sourced from Consul and secrets should be sourced from Vault. However in the time constraint I had, I wanted to understand Nomad and Consul better and use Vault at a  later stage. I needed a way to interpolate the env variables. This is where Terraform comes into picture:</p><p>   Nomad没有任何模板功能，因此所有配置都必须来自Consul，机密应来自Vault。但是，由于时间限制，我想更好地了解Nomad和Consul，并在以后使用Vault。我需要一种插值环境变量的方法。这是Terraform出现的地方：</p><p> resource &#34;nomad_job&#34; &#34;app&#34; { jobspec = templatefile(&#34;${path.module}/conf/shynet.nomad&#34;, { shynet_django_secret_key = var.shynet_django_secret_key, shynet_postgresql_password = var.shynet_postgresql_password }) hcl2 { enabled = true }}</p><p> 资源＆＃34; nomad_job＆＃34; ＆＃34; app＆＃34; {jobspec = templatefile（＆＃34; $ {path.module} /conf/shynet.nomad&#34 ;, {shynet_django_secret_key = var.shynet_django_secret_key，shynet_postgresql_password = var.shynet_postgresql_password}} hcl2 {已启用= true}</p><p> We can pass the variables from Terraform (which can be sourced by  TF_VAR_ in your local env) to the Nomad job spec. Inside the job spec we can use  env to make it available to our task:</p><p> 我们可以将Terraform中的变量（可以通过本地环境中的TF_VAR_获取）传递给Nomad工作规范。在工作说明中，我们可以使用env使它可用于我们的任务：</p><p>   I use  restic to take periodic backups of my server and upload to Backblaze B2. Since Nomad supports running tasks as a different isolated environment ( chroot) using  exec driver and even without isolation using  raw_exec driver, I wanted to give that a try. I&#39;ve to resort using  raw_exec driver here because  /data file path on my host was not available to the chroot&#39;ed environment.</p><p>   我使用Restic定期备份服务器并上传到Backblaze B2。由于Nomad使用exec驱动程序支持将任务作为不同的隔离环境（chroot）运行，甚至没有使用raw_exec驱动程序进行隔离，因此我想尝试一下。我不得不在这里使用raw_exec驱动程序，因为主机上的/ data文件路径不适用于chroot环境。</p><p> job &#34;restic&#34; { datacenters = [&#34;hydra&#34;] type = &#34;batch&#34; periodic { cron = &#34;0 3 * * *&#34; time_zone = &#34;Asia/Kolkata&#34; prohibit_overlap = true } ... task &#34;backup&#34; {	 driver = &#34;raw_exec&#34;	 config {		# Since `/data` is owned by `root`, restic needs to be spawned as `root`. 		# `raw_exec` spawns the process with which `nomad` client is running (`root` i.e.).		command = &#34;$${NOMAD_TASK_DIR}/restic_backup.sh&#34;	 } } ...}</p><p> 工作＆＃34; restic＆＃34; {数据中心= [＆hydra＆＃34;]类型=＆＃34; batch＆＃34;定期{cron =＆＃34; 0 3 * * *＆＃34; time_zone =＆＃34;亚洲/加尔各答＆＃34; disable_overlap = true} ...任务＆＃34; backup＆＃34; {驱动程序=＆＃34; raw_exec＆＃34; config {＃由于`/ data`由`root`拥有，因此restic需要作为`root`产生。 ＃`raw_exec`生成运行Nomad`客户端的进程（即root）。命令=＆＃34; $$ {NOMAD_TASK_DIR} /restic_backup.sh&#34; }} ...}</p><p>   Nomad has been an absolute joy to work with. However, I&#39;ve spotted a few rough edge cases which I believe one should be aware of:</p><p>   与Nomad合作非常开心。但是，我发现了一些粗糙的情况，我相信人们应该意识到： </p><p> host_network property sometimes gets ignored when doing a modification to  service. I&#39;ve opened an  issue upstream but looks like other people are facing similar behaviours  here and  here.</p><p>修改服务时，有时会忽略host_network属性。我在上游打开了一个问题，但看起来其他人在这里和这里都面临着类似的行为。</p><p> host_network as of present  cannot bind to a floating IP address (DigitalOcean/GCP etc). I&#39;ve to resort to using my droplet&#39;s public IPv4 address for now.</p><p> 目前的host_network无法绑定到浮动IP地址（DigitalOcean / GCP等）。我现在不得不使用我的Droplet的公共IPv4地址。</p><p> I tried using Consul Connect (service mesh with mTLS) but looks like again because of  host_network, I&#39;m  unable to use it.</p><p> 我尝试使用Consul Connect（带有mTLS的服务网格），但是由于host_network再次出现，我无法使用它。</p><p> Nomad CLI can definitely be  improved for a much more consistent experience. I particularly missed using  kubectl when using  nomad.</p><p> 绝对可以改进Nomad CLI，以获得更一致的体验。使用游牧时，我特别想念使用kubectl。</p><p> That apart, I ended up sending a  PR to upstream addressing a CLI arg ordering issue.</p><p> 除此之外，我最终向上游发送了PR，解决了CLI arg排序问题。</p><p>  On a Nomad server  already bootstrapped, if you try changing  server.bind_addr, it won&#39;t have any effect. I almost pulled my hair debugging this, ultimately deleting the  data_dir of the server resolved the issue for me.</p><p>  在已经自举的Nomad服务器上，如果尝试更改server.bind_addr，它将没有任何效果。我几乎花了很多时间调试它，最终删除了服务器的data_dir为我解决了这个问题。</p><p> I&#39;m running DB  and the App together as a single &#34;group&#34; in my setup configs. Don&#39;t do this in production. Whenever you restart the job, the group will restart both the containers. The side effect of this is pretty interesting: Since we use Consul to fetch the DB Host, the app may start before the DB boots up  and registers its new address with Consul. I will fix the dependency in a future version but since I&#39;m running fewer workloads and there are automatic retries, it&#39;s okay enough for me to keep it like this.</p><p> 我将数据库和应用程序作为一个单独的＆＃34; group＆＃34;组一起运行在我的设置配置中。不要在生产中这样做。每当您重新启动作业时，组都会重新启动两个容器。这样做的副作用非常有趣：由于我们使用Consul来获取数据库主机，因此该应用程序可能在数据库启动并向Consul注册其新地址之前启动。我将在以后的版本中修复该依赖关系，但是由于我运行的工作负载更少，并且具有自动重试功能，因此我可以保持这种状态就可以了。 </p><p>  Nomad&#39;s community is pretty small compared to Kubernetes. However, the folks are super responsive on  Gitter,  Discourse and Github Issues. A few noteworthy mentions:</p><p>与Kubernetes相比，Nomad的社区很小。但是，人们对Gitter，Discourse和Github问题的反应超级好。值得一提的是：</p><p> @tgross who is super responsive on Github issues and does an excellent job at housekeeping the issues.</p><p> @tgross对Github问题具有超级响应能力，并且在整理问题方面做得很好。</p><p> Nomad&#39;s ecosystem is still in its nascent stage and I believe there are a lot of contribution opportunities for folks interested in Golang, Ops, Distributed Systems to contribute to Nomad. The codebase of Nomad is approachable and there are quite a few key areas which can be contributed to:</p><p> 游牧民族的生态系统仍处于起步阶段，我相信对Golang，Ops，分布式系统感兴趣的人们有很多为游牧民族做出贡献的机会。 Nomad的代码库是易于接近的，并且可以在以下几个关键领域做出贡献：</p><p> Nomad Job files: There are many helm charts available to follow best practices. Something similar in Nomad will definitely be interesting.</p><p> Nomad Job文件：有许多舵机图表可用于遵循最佳实践。游牧民族中类似的事物肯定会很有趣。</p><p> Nomad Gotchas: Since K8s is widely used and has a much larger adoption, it&#39;s only natural that the failure stories of K8s are highlighted a lot. Nomad being a pretty smaller community, we need more debugging and &#34;things that went wrong&#34; reference materials. You learn more from failures than 101 setup guides :)</p><p> Nomad Gotchas：由于K8的广泛使用和广泛采用，因此很自然地要特别强调K8的失败故事。游牧民族是一个相对较小的社区，我们需要更多的调试和出现问题的信息。参考资料。您从失败中学到的知识不止101条安装指南：)</p><p>  I think I&#39;m  sold on Nomad. I&#39;ve used Kubernetes in prod for 2 years but if you were to ask me to write a Deployment spec from scratch (without Googling/kubectl help) I won&#39;t be able to. After writing Nomad configs, I just can&#39;t think of the sheer amount of boilerplate that K8s requires to get an application running.</p><p>  我想我是在Nomad上出售的。我已经在产品中使用Kubernetes两年了，但是如果您要我从头开始编写Deployment规范（没有Googling / kubectl帮助），我将无法使用。编写Nomad配置后，我想不出K8要运行应用程序所需的大量样板。</p><p> Nomad is also a simpler piece to keep in your tech stack. Sometimes it&#39;s best to keep things simple when you don&#39;t really achieve any benefits from the complexity.</p><p> Nomad还是保留在您的技术堆栈中的一个更简单的部分。有时候，最好不要使事情简单，而实际上却不能从复杂性中获得任何好处。 </p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://mrkaran.dev/posts/home-server-nomad/">https://mrkaran.dev/posts/home-server-nomad/</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/服务器/">#服务器</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/nomad/">#nomad</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/分享/">#分享</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy; 2020 diglog.com </div></div></body></html>