[{"category": "", "categoryclass": "", "imagename": "4650ba5a8196232a490242c0eeade145.jpg", "infoid": 1072497, "ip": "", "isanchordig": 1, "ischecked": 1, "isdelete": 0, "isneo": 1, "mark": "", "name": "", "note": "\u6211\u5f88\u9ad8\u5174\u5ba3\u5e03\uff0c\u5b89\u5fb7\u70c8\u68ee\u00b7\u970d\u6d1b\u7ef4\u8328\u521a\u521a\u63d0\u9ad8\u4e869B\u7f8e\u5143\uff0c\u901a\u8fc7\u6211\u4eec\u7684\u98ce\u9669\uff0c\u589e\u957f\u548c\u751f\u7269\u8d44\u91d1\u6295\u8d44\u3002\u6211\u4eec\u611f\u8c22\u6211\u4eec\u5728\u8fc7\u53bb12\u5e74\u4e2d\u76f8\u4fe1\u6211\u4eec\u5e76\u56f0\u4f4f\u4e86\u6211\u4eec\u7684\u6709\u9650\u5408\u4f5c\u4f19\u4f34\uff0c\u5e76\u5e0c\u671b\u518d\u6b21\u8d62\u5f97\u4ed6\u4eec\u7684\u4fe1\u4efb\u3002\u6211\u4eec\u611f\u8c22\u6211\u4eec\u8bb8\u591a\u7f8e\u5999\u7684\u4f01\u4e1a\u5bb6\uff0c\u4f7f\u8fd9\u7ec4\u8d44\u91d1\u6210\u4e3a\u53ef\u80fd\u3002\n\u5728\u5185\u90e8\u63d0\u4f9b\u7684\u56fe\u8868\u548c\u56fe\u8868\u4ec5\u4f9b\u53c2\u8003\uff0c\u5e76\u5728\u5236\u5b9a\u4efb\u4f55\u6295\u8d44\u51b3\u7b56\u65f6\u4e0d\u5e94\u4f9d\u8d56\u3002\u8fc7\u53bb\u7684\u8868\u73b0\u5e76\u4e0d\u9884\u793a\u672a\u6765\u7684\u7ed3\u679c\u3002\u5185\u5bb9\u4ec5\u622a\u81f3\u6240\u793a\u65e5\u671f\u3002\u5728\u8fd9\u4e9b\u6750\u6599\u4e2d\u8868\u8fbe\u7684\u4efb\u4f55\u9884\u6d4b\uff0c\u4f30\u8ba1\uff0c\u9884\u6d4b\uff0c\u76ee\u6807\uff0c\u524d\u666f\u548c/\u6216\u610f\u89c1\u53ef\u80fd\u4f1a\u6709\u6240\u53d8\u5316\uff0c\u6055\u4e0d\u53e6\u884c\u901a\u77e5\uff0c\u53ef\u80fd\u4e0e\u4ed6\u4eba\u6240\u8868\u8fbe\u7684\u610f\u89c1\u4e0d\u540c\u6216\u76f8\u53cd\u3002\u6709\u5173\u5176\u4ed6\u91cd\u8981\u4fe1\u606f\uff0c\u8bf7\u53c2\u9605https://a16z.com/disclosures\u3002", "note_en": "I am excited to announce that Andreessen Horowitz just raised a fresh $9B to invest via our Venture, Growth, and Bio Funds. We are grateful to our Limited Partners who have believed in us and stuck with us over the past 12 years and hope to earn their trust once again. We thank our many wonderful entrepreneurs who made this set of funds possible.\n One might ask: \u201cWhy invest $9B in a brand new set of technology companies?\u201d Our answer begins with one of the firm\u2019s core   cultural values :   We believe in the future and we bet the firm that way.\n At Andreessen Horowitz, we specifically believe in the technology-enabled future. There are no more worthwhile endeavors than our most brilliant minds taking great risks to improve the world by doing something larger than themselves. As my partner Marc describes in   Technology Saves the World , without great advances in technology, life on Earth certainly will not get better and may well get worse.\n Beyond that, we see entrepreneurs every day with potential solutions ranging from a fairer creative economy to better education for low income students to cures for cancer. We never know which of these will work and that\u2019s why we value the people who bet their careers and their lives on solving these problems.\n It is our role and mission to help these entrepreneurs build the best companies they can and achieve their important goals. With these new funds, including a $1.5B Bio fund, $5B Growth fund, and $2.5B Venture fund, coupled with the $2.2B Crypto Fund and $400M Seed Fund we raised in 2021, we will continue to invest across the entire spectrum of stages, writing checks as small as $25,000 and up to hundreds of millions of dollars.\n    The views expressed here are those of the individual AH Capital Management, L.L.C. (\u201ca16z\u201d) personnel quoted and are not the views of a16z or its affiliates. Certain information contained in here has been obtained from third-party sources, including from portfolio companies of funds managed by a16z. While taken from sources believed to be reliable, a16z has not independently verified such information and makes no representations about the enduring accuracy of the information or its appropriateness for a given situation. In addition, this content may include third-party advertisements; a16z has not reviewed such advertisements and does not endorse any advertising content contained therein.\n This content is provided for informational purposes only, and should not be relied upon as legal, business, investment, or tax advice. You should consult your own advisers as to those matters. References to any securities or digital assets are for illustrative purposes only, and do not constitute an investment recommendation or offer to provide investment advisory services. Furthermore, this content is not directed at nor intended for use by any investors or prospective investors, and may not under any circumstances be relied upon when making a decision to invest in any fund managed by a16z. (An offering to invest in an a16z fund will be made only by the private placement memorandum, subscription agreement, and other relevant documentation of any such fund and should be read in their entirety.) Any investments or portfolio companies mentioned, referred to, or described are not representative of all investments in vehicles managed by a16z, and there can be no assurance that the investments will be profitable or that other investments made in the future will have similar characteristics or results. A list of investments made by funds managed by Andreessen Horowitz (excluding investments for which the issuer has not provided permission for a16z to disclose publicly as well as unannounced investments in publicly traded digital assets) is available at https://a16z.com/investments/.\n Charts and graphs provided within are for informational purposes solely and should not be relied upon when making any investment decision. Past performance is not indicative of future results. The content speaks only as of the date indicated. Any projections, estimates, forecasts, targets, prospects, and/or opinions expressed in these materials are subject to change without notice and may differ or be contrary to opinions expressed by others. Please see https://a16z.com/disclosures for additional important information.", "posttime": "2022-01-09 22:26:53", "source_domain": "slashdot.org", "source_name": "slashdot", "tags": "\u57fa\u91d1,fund,\u53ef\u80fd", "title": "Andreessen Horowitz\u5728\u4e09\u4e2a\u57fa\u91d1\u4e0a\u63d0\u9ad89B\u7f8e\u5143\uff1a1.5\u4ebf\u7f8e\u5143\u7684\u751f\u7269\u57fa\u91d1\uff0c\u589e\u957f\u57fa\u91d1\u4e3a5B\u7f8e\u5143\uff0c\u800c\u4e14\u4e3a2.5\u4ebf\u7f8e\u5143\u7684\u98ce\u9669\u57fa\u91d1", "title_en": "Andreessen Horowitz raises $9B across three funds: a $1.5B Bio Fund, a $5B Growth Fund, and a $2.5B Venture Fund", "transed": 1, "url": "https://a16z.com/2022/01/07/9b-to-build-the-future/", "via": "", "real_tags": ["\u57fa\u91d1", "fund", "\u53ef\u80fd"]}, {"category": "", "categoryclass": "", "imagename": "7ab5c145fcf4ea7b310f2710024d0f04.jpeg", "infoid": 1072496, "ip": "", "isanchordig": 1, "ischecked": 1, "isdelete": 0, "isneo": 1, "mark": "", "name": "", "note": "\u8fdb\u5165\u540c\u610f\u5408\u89c4 - \u52a0\u62ff\u5927\u516c\u53f8\u4e13\u6ce8\u4e8e\u4f9b\u5e94\u94fe\u53ef\u6301\u7eed\u6027\u7ba1\u7406\u3002\u66f4\u7b80\u5355\u5730\uff0c\u57fa\u4e8e\u6e25\u592a\u534e\u7684\u540c\u610f\u65e8\u5728\u5e2e\u52a9\u5236\u9020\u5546\u5bf9\u201c\u4ed6\u4eec\u4e0e\u4ed6\u4eec\u7684\u4ea7\u54c1\u8fdb\u884c\u4e1a\u52a1\u4ee5\u53ca\u4ed6\u4eec\u7684\u4ea7\u54c1\u662f\u5982\u4f55\u8fdb\u884c\u7684\uff0c\u201d\u7684\u51b3\u5b9a\u3002\n\u8be5\u516c\u53f8\u8ba1\u5212\u5229\u7528\u5176\u65b0\u8d44\u672c\u4e3b\u8981\u5728\u6b27\u6d32\u7ee7\u7eed\u6269\u5927\uff0c\u6700\u7ec8\u8fdb\u5165\u4e9a\u6d32\u5e02\u573a\uff0c\u5e76\u5728\u5176\u9500\u552e\uff0c\u670d\u52a1\uff0c\u5de5\u7a0b\uff0c\u5ba2\u6237\u7684\u6210\u529f\u548c\u8425\u9500\u56e2\u961f\u4e2d\u589e\u957f40\uff05\u3002", "note_en": "Enter   Assent Compliance  \u2014 a Canadian company focused on supply chain sustainability management. Put more simply, Ottawa-based Assent aims to help manufacturers make smarter decisions regarding \u201cwho they do business with and how their products are sourced,\u201d notes CEO Andrew Waitman.\n And today, the company is announcing it has raised $350 million at a valuation of more than $1 billion in a funding round led by Vista Equity Partners. The financing follows a $131 million Series C raise led by Warburg Pincus, which remains the company\u2019s largest shareholder.\n  Interestingly, Assent was bootstrapped for the first five years of its life \u2014 from 2010 to 2015. In the subsequent years, after Waitman came on as CEO, the company has raised over $500 million and grew its headcount from about 20 to 820 today (45% of which identify as female). While half a billion dollars raised in the U.S. is not uncommon, it\u2019s a bit more rare in the Canadian tech scene.\n Assent\u2019s trajectory continues to grow and Waitman projects the SaaS company will cross $100 million in annual recurring revenue (ARR) this year after growing ARR by over 50% in the past 12 months. Its customers include the likes of  GE Appliances, Polaris, Stryker and Escatec.\n The company delivers enterprise-wide supply chain sustainability solutions across product compliance, trade compliance and ESG \u2014 better known as  Environmental, Social and (Corporate) Governance . Assent has made a name for itself by being exclusively focused on complex manufacturing. Doubling down on that niche has allowed it to build what it claims is \u201cthe industry\u2019s largest network of supplier intelligence.\u201d Specifically, it works to help complex manufacturers proactively identify and manage risk, accelerate market access and growth and promote brand reputation.\n Assent\u2019s compliance platform provides centralized access to supply chain data for use by teams across a given company. It automates data collection and validation and provides \u201cconfigurable\u201d reporting so that its customers \u201ccan stay ahead\u201d of their data requirements.\n  \u201cThe increasing complexity and scale of regulations and varying requirements globally, combined with a heightened focus on ESG, presents challenges for companies across industries, particularly for manufacturers,\u201d Waitman said. \u201cAssent enables deep insight and rapid transparency to help ensure products are made with environmental and human rights standards necessary to compete \u2014 and win \u2014 in markets of the future.\u201d\n  The company plans to use its new capital mostly to continue expanding in Europe, eventually enter the Asian market and grow its headcount by 40% across its sales, services, engineering, customer success and marketing teams.\n \u201cManufacturing represents 20% of GDP,\u201d Waitman told TechCrunch. \u201cIt\u2019s an enormous market.\u201d\n Vista\u2019s Foundation Fund, which invests in middle-market companies seeking to scale and accelerate their growth trajectory, led the investment. Vista\u2019s Patrick Severson, co-head of the Vista Foundation Fund, and Jake Hodgman, managing director of the Foundation Fund, will join the Assent board of directors.\n Companies globally are facing increased demand to ensure they source their components and raw materials in an ethical and responsible manner, either from government regulators who oversee them or from customers and partners whose expectations hold them to higher standards, noted Severson. Assent is \u201cahead of the curve\u201d when it comes to solving enterprise supply chain challenges through technology.\n \u201c Assent\u2019s solution empowers companies to mitigate their brand and reputation risk and become better corporate citizens,\u201d  Severson added. \u201cThe scrutiny being placed on complex manufacturers in how they manage their supply chains is only increasing. Assent is uniquely positioned to be a clear leader in a future focused on manufacturers adopting supply chain sustainability best practices.\u201d", "posttime": "2022-01-09 22:25:04", "source_domain": "slashdot.org", "source_name": "slashdot", "tags": "compliance", "title": "\u57fa\u4e8e\u6e25\u592a\u534e\u7684\u7b26\u5408\u8981\u6c42\uff0c\u4e00\u4e2a\u53ef\u5e2e\u52a9\u516c\u53f8\u5408\u89c4\u6027\uff0c\u8d38\u6613\u5408\u89c4\u548cESG\u7684\u516c\u53f8\u7684SaaS\u63d0\u4f9b\u5546\uff0c\u4ee51\u4ebf\u7f8e\u5143+\u4f30\u4ef7\u63d0\u9ad8350\u4ebf\u7f8e\u5143", "title_en": "Ottawa-based Assent Compliance, a SaaS provider that helps companies with product compliance, trade compliance, and ESG, raises $350M at a $1B+ valuation", "transed": 1, "url": "https://techcrunch.com/2022/01/06/canadas-assent-compliance-lands-350m-from-vista-equity-for-supply-chain-data-management/", "via": "", "real_tags": []}, {"category": "", "categoryclass": "", "imagename": "", "infoid": 1072494, "ip": "", "isanchordig": 1, "ischecked": 1, "isdelete": 0, "isneo": 1, "mark": "", "name": "", "note": "\u5728\u5bfb\u627e\u62db\u8058\u65b0\u5b66\u751f\u7684\u65b0\u5b66\u751f\uff0c\u6211\u60f3\u84b8\u53d1\u4e00\u4e9b\u89c2\u5bdf\u5230\u7684\u6587\u672c\u5f62\u5f0f\u3002\u8fd9\u7bc7\u5e16\u5b50\u6d89\u53ca\u6211\u7684\u5370\u8c61\uff0c\u5373\u5b66\u672f\u754c\u662f\u5bf9'T\u5f62\u4eba\u7684\u4eba\uff0c\u5373\u4e00\u4e2a\u6216\u591a\u4e2a\u9886\u57df\u4e2d\u7684\u6df1\u5ea6\u666e\u904d\u5b58\u5728\u7684\u4eba\uff0c\u5728\u4e00\u4e2a\u6216\u591a\u4e2a\u9886\u57df\u4e2d\u7ed3\u5408\u4e86\u4e00\u4e2a\u6216\u591a\u4e2a\u9886\u57df\u3002 T\u5f62\u4eba\u7269\u5f80\u5f80\u4e0eI\u5f62\u4eba\uff0c\u901a\u5e38\u79f0\u4e3a\u4e13\u5bb6\u3002 1\uff0c\u5728\u8f6f\u4ef6\u884c\u4e1a\u7684\u6700\u65b0\u72b6\u6001\uff0c2\u4e2aT\u5f62PeoLteare\u5bfb\u6c42\u5546\u54c1\uff1a\u5f53\u524d\u7684\u201c\u6846\u67b6\u675c\u7a74\u201d\u53ef\u80fd\u5728\u51e0\u5e74\u5185\u4ee4\u4eba\u53d1\u5e03\uff0c\u4f46\u662f\u4ed6\u4eec\u4e5f\u53ef\u4ee5\u7684T\u5f62\u4eba\u585e\u7684\u6c34\u5e73\u9152\u5427\u6709\u52a9\u4e8e\u9879\u76ee\u7684\u5176\u4ed6\u65b9\u9762\uff0c\u5b89\u59ae\u7279\u53ef\u80fd\u4f1a\u5f00\u53d1\u65b0\u7684\u5782\u76f4\u6761\uff0c\u5373\u65b0\u4e13\u4e1a\u77e5\u8bc6\u52a0\u73ed\u3002 3.\n\u73b0\u5728\u8981\u505a\u4ec0\u4e48\uff1f\u6211\u6b63\u5728\u5199\u8fd9\u7bc7\u6587\u7ae0\uff0c\u56e0\u4e3a\u6211\u5728\u4e2a\u4eba\u89c2\u5bdf\u548c\u884c\u52a8\u4e2d\u53d1\u73b0\u4e86\u4e00\u4e2a\u95ee\u9898\uff1a\u51e0\u4e4e\u6240\u6709\u5305\u542b\u4e00\u4e2a\u826f\u597d\u7684I\u5f62\u548cT\u5f62\u7684\u4eba\u7684\u9879\u76ee\u90fd\u975e\u5e38\u597d\u3002\u7136\u800c\uff0c\u5728\u62db\u8058\u81ea\u5df1\u7684\u56e2\u961f\u65f6\uff0c\u6211\u5f00\u59cb\u66f4\u559c\u6b22\u4ee5T\u5f62\u7684\u5f62\u72b6\u66f2\u7ebf\uff0c\u800c\u4e0d\u662f\u7ef4\u6301\u575a\u5b9e\u7684\u5e73\u8861\u3002\u6211\u53ca\u65f6\u6293\u4f4f\u4e86\u81ea\u5df1\uff0c\u5e76\u5c06\u66f4\u52a0\u5173\u6ce8\u8fd9\u4e00\u504f\u96f7\u7684\u504f\u89c1 - \u6211\u5e0c\u671b\u5176\u4ed6\u4eba\u4f1a\u8fd9\u6837\u505a\uff01\n\u6211\u751a\u81f3\u770b\u5230\u672a\u805a\u7126\u7684\u672f\u8bed\u88ab\u629b\u51fa\u7684\u5019\u9009\u4eba\u3002\u8bf7\u6ce8\u610f\uff0c\u8fd9\u53d1\u751f\u5728AnInterview\u4e4b\u524d\uff0c\u56e0\u6b64\u771f\u7684\u6ca1\u6709\u5224\u65ad\u4ed6\u4eec\u7684\u91cd\u70b9\uff01 \u21a9\ufe0e", "note_en": "Being on the lookout for recruiting new students for  my new researchgroup, I wanted to distil some of my observationsinto textual form. This post deals with my impression that academia isdoing a disservice to \u2018T-shaped persons,\u2019 i.e.  persons combining deepexpertise in one or more fields with an ability to collaborate acrossareas. T-shaped personsare often contrasted with I-shaped persons, commonly known as experts.  1Given the state of the art in the software industry,  2 T-shaped peopleare a sought-for commodity: the current \u2018framework du jour\u2019 might beobsolete in a few years, but the horizontal bar of a T-shaped personensures that they can also contribute to other aspects of a project, andquite likely will develop new vertical bars, i.e. new expertise overtime.  3\n Output above all else.As I am looking at the many resumes and motivational letters fromexcellent students all over the globe, it occurred to me that academiais not necessarily kind to the Ts: the primary metric in academic hiringis still the \u2018scientific output,\u2019 which is measured in publications suchas journal articles, conference articles, etc. In machine learningresearch, the fast pace of the field now has created a situation inwhich even aspiring Ph.D. candidates are often expected to have a fewpublications under the belt already. Coming from mathematics, whereone paper  every few years\u00a0(!) is considered the mark ofa productive mathematician, these expectations are bonkers to me, andI wonder how many capable candidates end up pursuing other goals becauseof these invisible barriers.  4\n Hiring people: I before T.In any case, many graduate schools and resume reviewers tend to  ignorethe breadth of a person\u2019s skills, focusing instead only on the depth. Bytaking the scientific output, in conjunction with maybe some relevantcoursework, as the be-all and end-all, any other skills tend tobe missed. At best, it might raise an eyebrow or two in magnanimoussurprise: falling prey to precisely the issue I describe in this post,I noticed myself doing this for candidates that already convinced mebecause of their academic track record! At worst, additional skillsmight be considered detrimental upon review, because a T-shaped personmay have a smaller number of papers than others.  5\n This is a  problem for machine learning research. Given theaforementioned fast pace in the field, excellent research necessitatesmoving away from silos! There will of course always be a demand forpeople that have deep domain expertise, but many facets of contemporaryresearch can be addressed just as well by a T-shaped person, in myexperience.\n Ts as multipliers.Throughout my career, the most impactful projects always had a T-shapedperson onboard. This person would usually not be an expert in thesubject matter, but would be able to provide the direly-needed scaffolding and foundation of a project that is all too often ignoredin the initial phase, until it comes back later on with full swing towreak havoc. This includes, for instance:\n  In my experience, these skills\u2014and others\u2014are not commonly considered when hiringsomeone. And to some extent, having fallen into the same trap, I fullyunderstand this! Paraphrasing  Leonard McCoy in Star Trek,we want to state \u2018I\u2019m a researcher, not a(n) $X$,\u2019 with $X \\in$ $\\{$softwaredeveloper, designer, marketing person, artist, $\\dots\\}$\n Progress in our interdisciplinary times, however, also requires peoplethat are sufficiently skilled to tackle these  other tasks. Even thoughsuch tasks might seemingly be unrelated to the overall scientific goalof creating new knowledge, they are still a fundamental part of themodern process of scientific inquiry.\n What to do now? I am writing this post because I detected aninconsistency in my personal observations and my actions: virtually allthe projects that contained a good mix of I-shaped and T-shaped personssucceeded extraordinarily well. Yet, upon recruiting my own team,I started to prefer I-shaped profiles over T-shaped ones, instead ofstriving for a solid balance. I caught myself in time and willsubsequently pay more attention to this bias of mine\u2014I hope thatothers will do the same!\n Machine learning and academia in general are enriched by teamscomprising diverse backgrounds and personalities. We should strive toachieve this.\n (In case more incentives are needed: the largest groups and researchdivisions are already doing this\u2014they are hiring not only for academicoutput, but also based on general software skills, for instance. If it\u2019sgood enough for them, it should certainly be good enough for the rest ofus.)\n  There is a veritable zoo of characters of the alphabet, trying tocapture the elusive properties of people out there in the realworld. It should be understood that I do not even for a second thinkthat one pithy letter is sufficient to describe a real person;all of these characterisations are merely hinting towards certainproperties. As always in real life, there are many different shadeson a spectrum to consider here.\u00a0 \u21a9\ufe0e\n My views pertain only to jobs that have a distinct softwaredevelopment component. I lack personal experience about other typesof jobs and would love to learn more about them.\u00a0 \u21a9\ufe0e\n Over time, one might think that a T-shaped person thus turns intoa comb-like pattern. As far as I understand, this has not beenstudied yet by ethnographers. Maybe the term \u2018serial experts\u2019 wouldalso been appropriate, except for its unfortunate similarity to thecriminal world.\u00a0 \u21a9\ufe0e\n I realise that this question is slightly off-topic, so I willdefer it to a future blog post.\u00a0 \u21a9\ufe0e\n I have even seen the term  unfocused being thrown around inreviews of candidates. Notice that this happened  prior to aninterview, so there is really no basis to judge their focus!\u00a0 \u21a9\ufe0e", "posttime": "2022-01-09 22:20:18", "source_domain": "news.ycombinator.com", "source_name": "Hacker News", "tags": "\u5f62\u4eba,people", "title": "T\u5f62\u4eba\u548c\u5b66\u672f\u754c", "title_en": "T-Shaped People and Academia", "transed": 1, "url": "https://bastian.rieck.me/blog/posts/2022/t/", "via": "", "real_tags": ["\u5f62\u4eba", "people"]}, {"category": "", "categoryclass": "", "imagename": "97b3d2ac5d71c176f3a40244abe5d0b4.png", "infoid": 1072493, "ip": "", "isanchordig": 1, "ischecked": 1, "isdelete": 0, "isneo": 1, "mark": "", "name": "", "note": "\u7f8e\u56fd\u5b87\u822a\u5c40\u7684\u8a79\u59c6\u65af\u97e6\u4f2f\u592a\u7a7a\u671b\u8fdc\u955c\u56e2\u961f\u5b8c\u5168\u90e8\u7f72\u4e8621\u82f1\u5c3a\uff0c\u9540\u91d1\u7684\u4e3b\u8981\u955c\u5b50\uff0c\u6210\u529f\u5b8c\u6210\u4e86\u6240\u6709\u4e3b\u8981\u822a\u5929\u5668\u90e8\u7f72\u7684\u6700\u540e\u9636\u6bb5\uff0c\u4e3a\u79d1\u5b66\u8fd0\u8425\u505a\u51c6\u5907\u3002", "note_en": "NASA\u2019s James Webb Space Telescope team fully deployed its 21-foot, gold-coated primary mirror, successfully completing the final stage of all major spacecraft deployments to prepare for science operations.", "posttime": "2022-01-09 22:19:52", "source_domain": "news.ycombinator.com", "source_name": "Hacker News", "tags": "james,webb,\u79d1\u5b66", "title": "James WebB\u5b8c\u5168\u90e8\u7f72", "title_en": "James Webb is fully deployed", "transed": 1, "url": "https://www.nasa.gov/press-release/nasa-s-webb-telescope-reaches-major-milestone-as-mirror-unfolds", "via": "", "real_tags": ["james", "webb", "\u79d1\u5b66"]}, {"category": "", "categoryclass": "", "imagename": "eb03cfaab497f79211105a06473d2e1c.jpg", "infoid": 1072492, "ip": "", "isanchordig": 1, "ischecked": 1, "isdelete": 0, "isneo": 1, "mark": "", "name": "", "note": "\u5728\u519c\u6c11\u53d7\u5230\u8f83\u5c11\u53ef\u7528\u7684\u571f\u5730\u548c\u719f\u7ec3\u52b3\u52a8\u529b\u7684\u6311\u6218\u7684\u65f6\u5019\uff0c\u7ea6\u7ff0\u00b7\u8fea\u5c14\u6b63\u5728\u54cd\u5e94\u5176\u5b8c\u5168\u81ea\u4e3b\u76848R\u62d6\u62c9\u673a\u3002\u57282022\u4e2a\u6d88\u8d39\u7535\u5b50\u8868\u6f14\u4e2d\u4eae\u76f8\uff0c\u673a\u5668\u7ed3\u5408\u4e868R\u62d6\u62c9\u673a\uff0c\u542f\u7528\u4e86\u4e00\u79cd\u7279\u6b8a\u7684\u51ff\u5b50\u7281\uff0cGPS\u5f15\u5bfc\u7cfb\u7edf\u548c\u5148\u8fdb\u6280\u672f\u3002 \u201c\u9884\u8ba1\u5168\u7403\u4eba\u53e3\u5c06\u4ece2050\u5e74\u589e\u52a0\u523080\u4ebf\u5230\u8fd110\u4ebf\u4eba\u53e3\uff0c\u589e\u52a0\u4e86\u5168\u7403\u7cae\u98df\u9700\u6c4250\uff05\uff0c\u201dJohn Deere\u7684\u9996\u5e2d\u6280\u672f\u5b98Jahmy Hindman\u8bf4\u3002 \u201c\u519c\u6c11\u8fd8\u5fc5\u987b\u901a\u8fc7\u53d8\u5316\u7684\u53d8\u91cf\uff0c\u5982\u53d8\u5316\u7684\u5929\u6c14\u72b6\u51b5\uff0c\u571f\u58e4\u8d28\u91cf\u7684\u53d8\u5316\uff0c\u4ee5\u53ca\u7ba1\u7406\u6742\u8349\u548c\u5bb3\u866b\u7684\u53d8\u5316 - \u6240\u6709\u8fd9\u4e9b\u90fd\u4f1a\u5f71\u54cd\u5230\u4e00\u5e74\u4e2d\u6279\u8bc4\u65f6\u671f\u7684\u519c\u573a\u80fd\u529b\u3002\u201d\u914d\u5907\u516d\u5bf9\u7acb\u4f53\u58f0\u76f8\u673a\uff0c\u53ef\u5b9e\u73b0360\u00b0\u969c\u788d\u7269\u68c0\u6d4b\u548c\u8ddd\u79bb\u8ba1\u7b97\uff0c\u901a\u8fc7\u7f51\u7edc\u901a\u8fc7\u7f51\u7edc\uff0c\u8be5\u7f51\u7edc\u901a\u8fc7\u5927\u7ea6100\u6beb\u79d2\u7684\u6bcf\u4e2a\u50cf\u7d20\u8fdb\u884c\u5206\u7c7b\u3002\u8fd9\u51b3\u5b9a\u4e86\u673a\u5668\u662f\u5426\u7ee7\u7eed\u6216\u505c\u6b62\u3002\u6b64\u5916\uff0c\u8be5\u673a\u5668\u8fde\u7eed\u68c0\u67e5\u5176\u76f8\u5bf9\u4e8e\u5730\u7406\u6e90\u7684\u4f4d\u7f6e\uff0c\u4ee5\u786e\u4fdd\u5176\u5728\u5047\u8bbe\u7684\u4f4d\u7f6e\uff0c\u5728\u5c0f\u4e8e\u4e00\u82f1\u5bf8\u7684\u7cbe\u5ea6\u8303\u56f4\u5185\u3002 \u201c\u81ea\u52a88R\u62d6\u62c9\u673a\u5728\u8fc7\u53bb\u4e09\u5e74\u5185\u5728\u73b0\u573a\u6d4b\u8bd5\u671f\u95f4\u6536\u96c6\u4e865000\u591a\u4e07\u5f20\u56fe\u7247\uff0c\u201dJohn Deere\u7684vply Pell\uff0cVP\u81ea\u6cbb\u548c\u65b0\u7684\u4f01\u4e1a\u8bf4\u3002", "note_en": "In a time when farmers are challenged to produce more with less available land and skilled labor, John Deere is responding with its fully autonomous 8R tractor. Unveiled at the 2022 Consumer Electronics Show, the machine combines the 8R tractor, a TruSet-enabled chisel plow, a GPS guidance system, and advanced technologies. \u00a0 \u201cThe global population is expected to grow from about 8 billion to nearly 10 billion people by 2050, increasing global food demand by 50%,\u201d says Jahmy Hindman, chief technology officer at John Deere. \u201cFarmers must also work through the variables like changing weather conditions, variations in soil quality, and managing weeds and pests \u2013 all of which impact the ability to farm during critical times of the year.\u201d  Equipped with six pairs of stereo cameras that enable 360\u00b0 obstacle detection and distance calculation, the images are passed through a network that classifies each pixel in about 100 milliseconds. This determines whether the machine continues or stops. In addition, the machine continuously checks its position relative to a geofence to ensure it is operating where it is supposed to, within less than an inch of accuracy. \t\u00a0 \t\u201cThe autonomous 8R tractor collected more than 50 million images during in-field testing for the last three years,\u201d says Willy Pell, VP autonomy and new ventures at John Deere.\n   Once transported to the field, a farmer configures the machine for autonomous operation. Using the John Deere Operations Center mobile app, a simple swipe starts the autonomous tractor. While it works, a farmer can leave the field to focus on other tasks, yet still monitor the machine remotely from a mobile device. Access to live video, images, data, and metrics allows a farmer to adjust speed, depth, and more.\n  Should an anomaly or an issue appear in the field, a farmer will be alerted and be able to adjust, so the machine\u2019s performance is optimized. The autonomous 8R tractor can prep 325 acres in 24 hours.\n \u201cThe autonomous 8R tractor is doing something that was once thought impossible,\u201d says Julian Sanchez, director, emerging technology for John Deere.\u00a0\u201cThis machine is creating a digital footprint of the farm.\u201d \t\u00a0 \tDeere says the autonomous 8R tractor will be available later this year.\n      For related content and insights from industry experts, sign up for Successful Farming newsletters.  Sign up", "posttime": "2022-01-09 22:19:30", "source_domain": "news.ycombinator.com", "source_name": "Hacker News", "tags": "deere,\u673a\u5668", "title": "John Deere\u63ed\u5f00\u4e86\u5b8c\u5168\u81ea\u4e3b\u76848R\u62d6\u62c9\u673a", "title_en": "John Deere unveils fully autonomous 8R tractor", "transed": 1, "url": "https://www.agriculture.com/news/technology/john-deere-unveils-fully-autonomous-8r-tractor", "via": "", "real_tags": ["deere", "\u673a\u5668"]}, {"category": "", "categoryclass": "", "imagename": "6c99fa7194849af5f1031aec7f3feb17.jpg", "infoid": 1072491, "ip": "", "isanchordig": 1, "ischecked": 1, "isdelete": 0, "isneo": 1, "mark": "", "name": "", "note": "\u5728\u8fd9\u7bc7\u6587\u7ae0\u4e2d\uff0c\u6211\u63cf\u8ff0\u4e86\u6211\u7684\u65b0\u6d88\u606f\u8bbe\u7f6e\uff0c\u4ee5\u53ca\u5b83\u5982\u4f55\u76f4\u63a5\u4ece\u6f2b\u6e38\u7814\u7a76\u53d1\u9001\u6d88\u606f\uff0c\u800c\u4e14\u6211\u5728\u5e8a\u8fb9\u7761\u89c9\u65f6\u6211\u7559\u5728\u5e8a\u8fb9\uff0c\u6211\u9a7e\u9a76\u548c\u9732\u8425\u3002\n\u8981\u5728GO\u8bb0\u5f55\u4e2d\u53d1\u9001\u90ae\u4ef6\uff0c\u60a8\u53ea\u662f\u201c@\u201d\u60a8\u6b63\u5728\u5199\u7684\u4eba\u3002\u8981\u5411adriana\u53d1\u9001\u6d88\u606f\uff0c\u6211\u4f1a\u5199\u201c@adriana\u6d88\u606f\u5373\u5c06\u5230\u6765\u201d\u3002\u8981\u5411David Dohan\u53d1\u9001\u6d88\u606f\uff08\u4f7f\u7528\u540d\u5b57\u548c\u59d3\u6c0f\uff09\uff0c\u6211\u53ef\u4ee5\u5199\u201c@david dohan\uff1a\u6d88\u606f\u5373\u5c06\u5230\u6765\u201d\u3002\u60a8\u53ef\u4ee5@\u67d0\u4eba\u5728\u6d88\u606f\u4e2d\u7684\u4efb\u4f55\u4e00\u70b9\u3002\u60a8\u4e5f\u53ef\u4ee5@\u591a\u4eba\uff0cMessager\u5c06\u5b83\u4eec\u53d1\u9001\u7ec4\u6d88\u606f\u3002\n\u4eca\u5929\uff0c\u6240\u6709\u90ae\u4ef6\u90fd\u4f1a\u81ea\u52a8\u6dfb\u52a0\u5230\u6211\u7684\u201cMessager\u961f\u5217\u201d\uff0c\u4ed6\u4eec\u7b49\u5f85\u6279\u51c6\u524d\u8fdb\u884c\u6279\u51c6\u3002\u6211\u559c\u6b22\u8fd9\u79cd\u6279\u51c6\u7684\u65b9\u6cd5\u4f5c\u4e3a\u9ed8\u8ba4\u7684\u9ed8\u8ba4\u65b9\u6cd5\uff0c\u56e0\u4e3a\u5b83\u5fc3\u7406\u4e0a\u91ca\u653e\u6211\u6765\u5199\u6211\u53ef\u80fd\u65e0\u6cd5\u5199\u7684\u4e1c\u897f\u5982\u679c\u6211\u662f\u4f7f\u7528\u7acb\u5373\u53d1\u9001\u7684\u53d1\u9001\u6309\u94ae\u3002\u65e0\u8bba\u4f55\u65f6\uff0c\u6709\u65f6\u80fd\u591f\u7acb\u5373\u53d1\u9001\u67d0\u4e9b\u4e1c\u897f\uff0c\u8fd9\u5728\u5f53\u524d\u8bbe\u7f6e\u4e2d\u4e0d\u662f\u4e00\u4e2a\u5e72\u51c0\u7684\u9009\u9879\u3002\n\u6211\u5c06\u6b64\u7535\u5b50\u8868\u683c\u5305\u542b\u5728FERDI\u4e2d\u7684\u81ea\u5b9a\u4e49\u670d\u52a1\uff0c\u56e0\u6b64\u5b83\u4e0e\u6211\u4f7f\u7528\u7684\u6240\u6709\u6d88\u606f\u5e94\u7528\u7a0b\u5e8f\u4e00\u8d77\u751f\u6d3b\u3002 \uff08\u8fd9\u672c\u8eab\u53ef\u80fd\u662f\u672a\u6765\u7247\u6bb5\u7684\u4e3b\u9898\u3002\uff09\n\u6211\u4f7f\u7528Messager\u4e0d\u4ec5\u4ec5\u662f\u4eceMessager\u961f\u5217\u7535\u5b50\u8868\u683c\u4e2d\u53d1\u9001\u6d88\u606f\u5728\u6211\u4f7f\u7528\u7684\u6240\u6709\u6d88\u606f\u7cfb\u7edf\u4e2d\u4ee5\u7edf\u4e00\u7684\u65b9\u5f0f\u3002", "note_en": "In this post I describe my new Messager setup,and how it allows me to send messages directly from Roam Research  orfrom a standalone keyboard (no monitor) that I keep at my bedside as I drift off to sleep, and which I take driving and camping.\n Currently my setup supports sending messages toFacebook Messenger, Twitter,Slack, Discord, and iMessage.I intend to add gChat and email support next, since there are still a handful of people I want to message that don\u2019t use any of these.\n Above all else, the beauty of this project to me is its usability,which is hard to communicate in a write-up like this.Some of the usability comes from the way the components integrate with my existing workflows.Some of the usability comes from design choices(like using a keyboard with no monitor for note-taking and message drafting).I\u2019ll try to point out these usability elements along the way.Bear in mind I designed this primarily for myself(though I have a handful of friends along for the ride as well, trying it out and making their own contributions).\n   For some background, I developed Go Note Go, a headless keyboard designed for note-taking on the go.Go Note Go is a note-taking system for when you\u2019re on the go, with a focus on driving and camping.You can  read all about Go Note Go here and learn more on  its GitHub page.\n Go Note Go\u2019s main purpose is note-taking.Anything you type into Go Note Go or voice-record into it gets transcribed and uploaded to your notes as soon as it gets an internet connection.For me, Go Note Go uploads to Roam Research. It also supports RemNote, IdeaFlow, Mem, and Notion, and adding additional systems isn\u2019t too difficult.\n One of the usability perks of Go Note Go is that there is no monitor. This means you can\u2019t get distracted browsing the internet while writing on Go Note Go. You also can\u2019t get distracted wordsmithing your own writing. It makes writing pleasurable, even if it comes at the cost of having typos and stray thoughts in your writing; you can always clean those up later.\n Go Note Go does a lot more, so I do encourage you to  learn more about it, but it isn\u2019t the focus of this post, which is about sending messages.For the purposes of this post, Go Note Go is a data entry system for Roam. And since I\u2019ve also built a system that allows sending messages directly from Roam, this means I can now send messages directly from Go Note Go. So, I can send messages when driving, camping, and as I drift off to sleep at night.\n To send a message in Go Note Go, you simply \u201c@\u201d the person you are writing to. To send a message to Adriana, I would write \u201c@Adriana Message goes here\u201d. To send a message to David Dohan (using first and last name), I could write \u201c@David Dohan: Message goes here\u201d. You can @ someone at any point in the message. You can also @ multiple people, and Messager will send them a group message.\n Go Note Go acts as an outliner now too; this is both a big usability improvement for Go Note Go on it\u2019s own, and doubly so for using Go Note Go as a messager. An \u201coutliner\u201d is a system for taking notes as a series of nested bullets. You can push tab to indent notes underneath other notes; I\u2019ve developed a user experience that makes this moderately natural, even in the absence of a monitor or any other visual feedback. For sending messages, the outliner feature is a boon. Any notes you nest under an @\u2019d note will also register as additional messages for the @\u2019d recipients. This makes writing longer multiline messages a pleasure, even without a monitor.\n The default behavior of my messaging system is to hold the messages for approval before sending them. So, the messages that I write as I drift off to sleep don\u2019t send as I drift off to sleep. Instead, I see them in the morning and approve them, and only upon being approved are they sent automatically.\n This delayed-approve-then-send approach is particularly well suited for Go Note Go, where I likely make typos and want to clean up the messages before they are sent, since I am writing them without a monitor. Later in the post I\u2019ll dive into what the approval process looks like (tl;dr there\u2019s a spreadsheet where I can mark a message as \u201cOK\u201d to send), but first I want to share additional benefits of being able to send messages directly from my note-taking app, which is currently Roam Research.\n  Anything I write on my Go Note Go appears in Roam Research, but I can also take notes directly in Roam.Just like on Go Note Go, the way to draft a message in Roam is to \u201c@\u201d the person you are writing to.Messager has some heuristics it uses to translate your @\u2019s into proper recipients.So, the syntax for @\u2018ing someone isn\u2019t too strict.\n Using Roam offers some possibilities beyond what I can do on Go Note Go, such as including images in messages.Like on Go Note Go, you can use nested bullets to create longer messages,and you can @ as many people as you want for a message.In Roam, however, you can also include images in your messages.Messager will intelligently send those in the native format used by the underlying messaging service,rather than blindly sending the markdown stored in Roam.I find this feature, being able to use images naturally in Roam, and then have them send naturally as messages,quite pleasant.\n One future direction I\u2019d like for this project is to add a \u201csend\u201d button in Roam next to any messages I\u2019ve drafted there,as well as to display the status of the messages inline in my notes. That\u2019s not implemented now, but would be a nice-to-have for the future.\n Today, all messages are automatically added to my \u201cmessager queue\u201d where they wait for approval before being sent.I like having this approve-before-sending approach as the default, since it psychologically frees me up to write things I might not otherwise write if I was instead using a send button that sent immediately.However, sometimes being able to send something immediately is desirable, and that\u2019s not a clean option in the current setup.\n  Any messages in Roam (whether entered directly into Roam, or entered via Go Note Go), are automatically added to a spreadsheet, the \u201cMessager Queue\u201d. These are the spreadsheet\u2019s columns:\n  The Messager Queue sheet is filtered by default to show all pending messages. For each message it shows the  Service on which it will be sent and well as the  Recipient of the message. The service can be one of FB Messenger, Twitter, iMessage, a Slack server, or Discord. The recipient can either be an individual, a list of individuals, a group, a Slack channel, or a Discord server and channel.\n There\u2019s also a sheet that lists aliases, so it\u2019s easy to use a short name or informal name to refer to a longer service or recipient; e.g. I use \u201c@Audio Tools\u201d as a shorthand for sending to a group of 5 people on Messenger all interested in audio tools for networked thought.\n The Messager Queue sheet also displays the  Text of the message to send, so you can easily clean up the message here for any typos or clarifications before it is sent.\n The  Date and  Time columns allow for scheduling messages to be sent at any point in the future. Leave them blank and the message will be sent as soon as it is approved. Use keyboard shortcuts cmd-; (for date) and cmd-shift-; (for time) to quickly fill out these columns if desired.\n Finally, the  Approval column is the most important. Mark a messages as OK if you want it to be sent, or as Ignored if you deside to skip it. The  Status column is updated automatically by Messager when the message is sent (or if it fails to send, then the error appears here). You can also mark the Status manually with whatever value you want (e.g. if you send the message manually), and the Messager system will ignore that message going forward. If you want the system to retry sending a message, simply clear out the Status column and it will try again.\n I include this spreadsheet as a custom service in  Ferdi, so it lives alongside all the messaging apps I use. (This in itself might be the subject of a future  snippet.)\n  Beyond allowing me to catch a bunch of typos, it\u2019s also a psychologically useful thing for me.I am more willing to write and I feel able to say more things that I might not otherwise,knowing I have the opportunity to cancel or change the message later.In that way, it\u2019s like gmail\u2019s undo feature. In gmail, undo not a true undo, but having those 30 seconds after clicking send to retract the message make a big difference.\n Another benefit of sending the messages only after approving them is the ability to sleep at night. If I write a message at night, I know you haven\u2019t responded yet because my messages haven\u2019t even sent yet; they\u2019ll go out in the morning, after I\u2019ve had a chance to clean them up. So, I don\u2019t spend any mental effort wondering if there\u2019s a response from you. It also allows me to set the appropriate tone for the messages, by having them go out at a reasonable time, rather than appearing urgent by being sent in the middle of the night. And it does this without me needing to keep the message draft in my head as I sleep. So, I sleep better.\n This is why, while the ability to send messages immediately would also be a good feature to add, I am inclined to leave approve-in-the-morning messages as the system\u2019s default behavior.\n  One additional small usability feature is that Bieber Bot will message me in the morning or evening whenever there are messages in the Messager Queue awaiting my approval.\n This sounds like a small convenience, and in fact has proven even more useful than it might at first sound.When I wake up in the morning, I sometimes don\u2019t remember that I\u2019ve written messages the preceding night.So, having Bieber Bot send me the link to the Messager Queue and gently remind me to approve the messages has beenconsistently charming and welcome. Thanks, Bieber Bot.\n  Messager is the underlying system that sends the messages in the Messager Queue system.As noted previously, it supportsFacebook Messenger, Twitter,Slack, Discord, and iMessage.It also supports Hacker News, which hasn\u2019t been so useful for this project.And I am thinking I may add gChat and email support next.\n I use Messager for more than just sending messages from the Messager Queue spreadsheet;it also backs other projects like my  Kangaroo Auto-responder and  several parts of Bieber Bot.Its purpose, in the most broad sense, is to support programmatically sending and receiving messages in a uniform manner across all the messaging systems I use.\n For Facebook Messager, it uses  fbchat to enable programmatically sending and receiving messages as myself. It also uses Facebook\u2019s API to allow sending messages as Bieber Bot.\n For Twitter, it uses the API to support public tweets, private tweets (using a separate account;  see here for how I use this to reclaim my attention), and DMs.\n  Slack and Discord are the most recent additions, and they currently live outside the core Messager system;they are implemented using Browserflow flows.This means that I am effectively sending Slack and Discord messages as myself, rather than using an API to do so.The messages are sent in a browser using clicks and keyboard presses,all in the same human-centric UI that I would use if I were to send the messages manually.I\u2019m so grateful to Browserflow for making this possible, as Slack and Discord have been really key additions to this project.\n  I\u2019ve been using the setup for only a few days so far, and am continuing to actively develop it.So far, I absolutely love it.\n The headless typing experience provided by Go Note Go makes for a great environment for drafting messages.So too does using Roam Research while scrolling through social media. (I\u2019m the sort of person who doesn\u2019t usually like replying publicly to social media posts, but does enjoy engaging with them in 1:1 or small group chat messages.)Drifting off to sleep has proven to be another excellent time to share thoughts with friends.I don\u2019t want to start  a conversation with friends as I drift off to sleep, but loads of thoughts come to mind that I do want to share with people, and so adding them to my Messager Queue to send the next day has been quite satisfying.\n If this interests you, feel free to get in touch.If you do, I\u2019ll do my best to get back to you, likely as I\u2019m drifting off to sleep.", "posttime": "2022-01-09 22:19:00", "source_domain": "news.ycombinator.com", "source_name": "Hacker News", "tags": "\u7761\u7720,messages,\u6d88\u606f", "title": "\u5f53\u6211\u6f02\u79fb\u5230\u7761\u7720\u65f6\u53d1\u9001\u6d88\u606f", "title_en": "Sending messages as I drift off to sleep", "transed": 1, "url": "https://davidbieber.com/post/2022-01-08-new-messager-setup/", "via": "", "real_tags": ["\u7761\u7720", "messages", "\u6d88\u606f"]}, {"category": "", "categoryclass": "", "imagename": "16802186bedb3867a439e7a8d77cc89d.png", "infoid": 1072490, "ip": "", "isanchordig": 1, "ischecked": 1, "isdelete": 0, "isneo": 1, "mark": "", "name": "", "note": "\u5c0a\u656c\u7684\u5bc6\u7801\u5e08Moxie Marlinspike\u5728\u56fd\u5185\u64b0\u5199\u4e86\u4e00\u4e9b\u5173\u4e8eEthereum\u548c\u73b0\u4ee3'Crypto'\u751f\u6001\u7cfb\u7edf\u7684\u601d\u8003\u3002\u867d\u7136\u6211\u5728\u4e00\u5f00\u59cb\u5c31\u53c2\u4e0e\u6bd4\u7279\u5e01\uff0c\u4f46\u6211\u4ece\u672a\u53c2\u4e0e\u8fc7Ethereum\u6216Web3\uff0c\u76ee\u524d\u76ee\u524d\u6ca1\u6709\u4efb\u4f55\u52a0\u5bc6\u8d27\u5e01\uff0c\u6211\u975e\u5e38\u540c\u610f\u4ed6\u6240\u8bf4\u7684\u5f88\u591a\u3002\u5c3d\u7ba1\u5982\u6b64\uff0c\u6211\u4e0d\u540c\u610f\u4e00\u4e9b\u5173\u952e\u70b9\u3002\u5728\u8fd9\u7bc7\u6587\u7ae0\u4e2d\uff0c\u6211\u5c06\u603b\u7ed3\u4e00\u4e0bMoxie\u7684\u8bba\u70b9\u7684\u90e8\u5206\uff0c\u5e03\u5c40\u4e86\u51e0\u4e2a\u5206\u6b67\uff0c\u7136\u540e\u4e3a\u524d\u8fdb\u7684\u9053\u8def\u63d0\u4f9b\u4e00\u4e9b\u5efa\u8bae\u3002\n\u5173\u4e8eWEB3\u7684\u4e00\u4e2a\u4ee4\u4eba\u60ca\u8bb6\u7684\u4e8b\u60c5\uff0c\u5c3d\u7ba1\u5efa\u7acb\u5728\u201c\u52a0\u5bc6\uff0c\u201d\u662f\u5982\u4f55\u6d89\u53ca\u7684\u5bc6\u7801\u5b66\uff01\n\u6211\u4eec\u5e94\u8be5\u63a5\u53d7\u4eba\u4eec\u4e0d\u4f1a\u901a\u8fc7\u8bbe\u8ba1\u53ef\u4ee5\u5206\u53d1\u4fe1\u4efb\u7684\u7cfb\u7edf\u6765\u8fd0\u884c\u81ea\u5df1\u7684\u670d\u52a1\u5668\u800c\u65e0\u9700\u5206\u53d1\u57fa\u7840\u67b6\u6784\u7684\u524d\u63d0\u3002\u8fd9\u610f\u5473\u7740\u9884\u6d4b\u548c\u63a5\u53d7\u76f8\u5bf9\u96c6\u4e2d\u7684\u5ba2\u6237/\u670d\u52a1\u5668\u5173\u7cfb\u7684\u5fc5\u7136\u7ed3\u679c\u7684\u67b6\u6784\uff0c\u4f46\u4f7f\u7528\u52a0\u5bc6\uff08\u800c\u4e0d\u662f\u57fa\u7840\u7ed3\u6784\uff09\u6765\u5206\u53d1\u4fe1\u4efb\u3002\n\u8fd9\u4e9b\u90fd\u662f\u5f88\u5927\u7684\u95ee\u9898\u3002\u6211\u4eec\u4e0d\u5e0c\u671b\u4eba\u4eec\u5bf9\u52a0\u5bc6\uff0c\u9690\u79c1\u6216\u6743\u529b\u4e0b\u653e\u7b49\u6982\u5ff5\u5931\u53bb\u4fe1\u4efb\uff1a\n\u4e0d\u613f\u610f\u8fd0\u884c\u670d\u52a1\u5668\u7684\u6839\u672c\uff0c\u6216\u8005\u53ea\u662f\u73b0\u5728\u7684\u65b9\u5f0f\u5417\uff1f\u4e3a\u4ec0\u4e48\u975e\u6280\u672f\u7528\u6237\u4e0d\u60f3\u8fd0\u884c\u670d\u52a1\u5668\uff1f\u6bd5\u7adf\uff0c\u4ed6\u4eec\u901a\u8fc7\u50cfBitTorrent\u548cGnutella\u8fd9\u6837\u7684\u7a0b\u5e8f\u5df2\u7ecf\u8fc7\u53bb\u4e86\u3002\u591a\u4eba\u6e38\u620f\u901a\u5e38\u4e5f\u662f\u670d\u52a1\u5668\u7684\u5ef6\u8fdf\u539f\u56e0\uff0c\u4f9d\u9760\u4ec5\u7528\u4e8e\u5339\u914d\u7684\u4e2d\u5fc3\u4f1a\u8bae\u70b9\u3002 AirDrop\u8fd0\u884c\u670d\u52a1\u5668\u4ee5\u4fbf\u5de5\u4f5c\u3002\u7b49\u7b49\u3002\n\u6211\u4e00\u76f4\u5728\u8003\u8651\u8fd9\u4e9b\u95ee\u9898\u5f88\u957f\u4e00\u6bb5\u65f6\u95f4\u3002\u8fd9\u51e0\u5929\u6211\u4e13\u6ce8\u4e8e\u5bfb\u627e\u589e\u91cf\uff0c\u975e\u6fc0\u8fdb\u7684\u8def\u5f84\u524d\u8fdb\u3002\u5bf9\u6211\u6ca1\u6709\u66f4\u591a\u7684\u70b9\u5bf9\u70b9\u7f51\u7edc\uff0c\u81f3\u5c11\u6ca1\u6709\u4e00\u6bb5\u65f6\u95f4\u3002\n\u7528\u6237\u53ef\u4ee5\u6388\u6743\u3002\u53ea\u8981\u60a8\u5141\u8bb8\u5b83\uff0c\u7528\u6237\u53ef\u4ee5\u67e5\u770b\u548c\u62d2\u7edd\u5347\u7ea7\u3002\u56e0\u4e3a\u4ed6\u4eec\u5373\u5c06\u7ed9\u51fa\u4e00\u4e2a\u6f14\u793a\u800c\u4e0d\u662f\u60f3\u8981\u4ed6\u4eec\u7684\u8bbe\u7f6e\u6539\u53d8\uff0c\u6216\u8005\u4ed6\u4eec\u4e0d\u559c\u6b22\u65b0\u7684UI\u7b49\uff0c\u6216\u8005\u4f60\u53ef\u4ee5\u786e\u4fdd\u5e94\u7528\u7a0b\u5e8f\u59cb\u7ec8\u9ed8\u9ed8\u66f4\u65b0\u7c97\u94ec\u98ce\u683c\uff1a\u5728\u4f01\u4e1a\u90e8\u7f72\u4e2d\u6709\u7528\u6216\u5728\u54ea\u91cc\u6709\u5feb\u901f\u53d8\u5316\u7684\u5730\u65b9\u5ba2\u6237\u7aef/\u670d\u52a1\u5668\u534f\u8bae\u3002\u9009\u62e9\u6700\u6709\u610f\u4e49\u7684\u76ee\u6807\u5e02\u573a\u3002", "note_en": "Respected cryptographer Moxie Marlinspike has written up  some thoughts on Ethereum and the modern \u2018crypto\u2019 ecosystem. Although I was involved in Bitcoin right at the beginning, I\u2019ve never been involved in Ethereum or Web3, don\u2019t currently own any cryptocurrencies and I broadly agree with a lot of what he says. Nonetheless I disagree on a few critical points. In this essay I\u2019ll summarize parts of Moxie\u2019s argument, lay out a couple of disagreements and then provide some suggestions for a path forward.\n  I\u2019ll start with a small technical disagreement before moving onto thoughts about servers and cryptography.\n At the core of Moxie\u2019s argument is the observation that Ethereum claims to be a decentralized ecosystem but isn\u2019t. This is broadly true. He also observes that there are many excuses for this situation in circulation like \u201cit\u2019s early days\u201d which, as someone who used Bitcoin in 2009, seems quite wrong. 12 years is sufficient to have solved these problems.\n  When people talk about blockchains, they talk about distributed trust, leaderless consensus, and all the mechanics of how that works, but often gloss over the reality that clients ultimately can\u2019t participate in those mechanics. All the network diagrams are of servers, the trust model is between servers, everything is about servers.  Blockchains are designed to be a network of peers, but not designed such that it\u2019s really possible for your mobile device or your browser to be one of those peers.\n With the shift to mobile, we now live firmly in a world of clients and servers \u2014 with the former completely unable to act as the latter \u2014 and those questions seem more important to me than ever. Meanwhile, ethereum actually refers to servers as \u201cclients,\u201d so  there\u2019s  not even a word for an actual untrusted client/server interface that will have to exist somewhere, and no acknowledgement that if successful there will ultimately be billions (!) more clients than servers\n I feel a need to respond to this because it\u2019s only actually true for Ethereum. I should know because my first project when I joined the Bitcoin world was to work with Andreas Schildbach on a genuinely peer-to-peer mobile wallet app, which became  Bitcoin Wallet for Android. It had/has a competitive UX and was able to grow a large userbase, despite being built in the most decentralized way possible.\n  We could do this because Satoshi thought  very carefully about the untrusted client/server interface. From day one the Bitcoin protocol had a notion of a sort of lightweight client mode. Satoshi didn\u2019t give this mode a clear name but the section of the paper that discussed it was titled \u201cSimplified payment verification\u201d, so I started calling apps that used it SPV wallets and the name stuck. Exactly how SPV mode works is fully explained elsewhere, but briefly, the client app bootstraps connections to the P2P network as normal but sends a special message saying \u201cplease don\u2019t send me the contents of every block or transaction, I only want to see transactions matching a filter\u201d. It then downloads the  headers of every block from the peers, but not their contents, and does the necessary computations to select the block header chain with the highest total work. Transactions that match the filter come supplied with a Merkle branch linking them to the Merkle tree roots embedded into the headers. In this way a client can traverse a chain of blocks with fairly minimal bandwidth, storage and CPU requirements, whilst keeping the P2P network as an untrusted adversary. The filter in our implementation was a Bloom filter, so you could probabilistically hide what you were interested in (although in practice, real users cared much more about performance than this type of privacy).\n  One of the surprising things to me about web3, despite being built on \u201ccrypto,\u201d is how little cryptography seems to be involved!\n I think the protocol just outlined does use cryptography in some interesting ways, or rather, ways that were interestingly new in 2011 when we built out the infrastructure.\n This system was very complicated to implement but worked surprisingly well. We implemented lots of performance tricks like background wakeups to keep roughly synced, bandwidth adaptation, measuring peer latencies, syncing at night when plugged in to charge and so on. Whilst SPV wallets were never  quite as fast as competitors that simply polled a centralized database, they were  fast enough for many users.\n  That was then. This is now. Why doesn\u2019t Ethereum have SPV clients like Bitcoin did? Well, simply put it wasn\u2019t designed with resource consumption in mind (nor, frankly, ordinary commerce). A Bitcoin implementation not only controls how much work it does via SPV mode but can also parallelize and shard a lot of full-mode work to get great scalability. This is possible due to the way the contents of the blocks are designed. Ethereum kept the chain-of-blocks idea from Bitcoin but radically changed what those blocks had inside them, and in the process not only lost the ability to have mobile clients but also destroyed its own ability to scale through parallelism.\n Unfortunately a frequent problem in the crypto/blockchain space is what Moxie is doing here: conflating Ethereum, Bitcoin and the block chain algorithm together, leading to incorrect conclusions like \u201cblockchains don\u2019t scale well\u201d or \u201cblockchains can\u2019t have mobile clients\u201d when the truth was closer to \u201cEthereum can\u2019t do those things\u201d. (It can of course do many other things Bitcoin couldn\u2019t). If the question you\u2019re interested in is \u201cwhat\u2019s up with NFTs?\u201d then this distinction hardly matters, because after  the Bitcoin community drank the kool-aid it collapsed as a medium of exchange \u2014 nowadays I see no more opportunities to buy and sell things with Bitcoin than I did a decade ago. The momentum and interest moved to Ethereum. But if the question you\u2019re interested in is \u201chow do I build decentralized, privacy preserving systems\u201d, then the distinction does still matter.\n  The above argument is a bit nit-picky, so now I want to make a much bolder disagreement.\n Through his work on Signal and WhatsApp, Moxie is the primary advocate for what I\u2019d call centralized cryptography. He sums up his position well so I\u2019ll just quote it here:\n We should accept the premise that people will not run their own servers by designing systems that can distribute trust without having to distribute infrastructure. This means architecture that anticipates and accepts the inevitable outcome of relatively centralized client/server relationships, but uses cryptography (rather than infrastructure) to distribute trust.\n After 30+ years, email is still unencrypted; meanwhile  WhatsApp went from unencrypted to full e2ee in a year\n I agree with points 1 and 2, but there\u2019s a conceptual problem with the argument: cryptography cannot impose any limits on an adversary that also controls the client doing the encryption. Centralized infrastructure that uses cryptography to defeat the centralized infrastructure is a contradiction in terms that can never work.\n Let\u2019s put it less abstractly. Moxie claims that Signal and WhatsApp use end to end encryption to ensure they can\u2019t read our messages. How do we know this claim is true? I have nothing against Moxie and have never seen any evidence he\u2019s untrustworthy, but I also assign zero weight to this belief because WhatsApp could be silently changed tomorrow to disable that technology for one or more users, without anyone even noticing, including Moxie himself. As for Signal it\u2019s at least open source, but there\u2019s no way to check that the client I\u2019m using, or my friend is using, actually matches that source code. Even if there was it\u2019s irrelevant. Centralized infrastructure can claim to provide privacy but can never provide control: they can openly alter the deal at any time and I\u2019d be forced to continue using it, if I couldn\u2019t get my friends to switch to something else.\n This is not a theoretical argument. Disabling E2E encryption has  already happened, although hardly anyone knows about it. In 2019 WhatsApp  imposed forwarding limits on messages in order to \u201c slow down the spread of rumors, viral messages, and fake news\u201d. This represents a total defeat of the Signal protocol\u2019s cryptographic objectives: a basic goal of any modern cryptographic scheme is to ensure the same message encrypted twice doesn\u2019t encrypt to the same bytes. The point of this is to stop the adversary knowing when you\u2019re repeatedly sending the same message and encryption modes that get this wrong (like AES/ECB)  are discredited. Yet once Facebook \u2014 the adversary \u2014 became dominated by authoritarians who see unlimited communication as chaotic, they simply changed the client to include a forwarding counter outside the encrypted part of the message. There was nothing anyone could do about this. It just showed up one day, and all the fancy mathematics designed to stop this \u201cattack\u201d were irrelevant.\n  If an encryption scheme can\u2019t stop infrastructure providers having opinions on the moral value of messages, what\u2019s the point of it?\n Thus despite my respect for what Moxie has designed and accomplished, I have problems with pushing the Signal/WhatsApp approach as something that can provide privacy, decentralized control or even as something that has any effect at all. It is  at best a building block for later work that could meet these goals and it probably does act as a brake on Facebook\u2019s worst tendencies, so it\u2019s not nothing, but it\u2019s also not a robust foundation. Really, a simple blog post that says \u201cwe promise we don\u2019t log messages to disk\u201d should carry equal weight.\n These are big problems. We don\u2019t want people to lose trust in concepts like encryption, privacy or decentralization yet:\n    Firstly let\u2019s look at mobile messengers. There should be a quick incremental improvement here that would let them keep some central control whilst providing meaningful guarantees to their users: threshold signatures. Mobile operating systems check the signatures on app packages before applying updates. These are normal ECDSA or RSA signatures. It\u2019s possible to craft such signatures not from a single private key but from a group effort by the holders of several key \u2018shards\u2019. By splitting up their signing key and distributing the shards to a variety of auditing firms with access to the source code, updates can be approved by the group. If the firms are spread around the world and their contracts are public, this can be used to translate arbitrary natural language rules into a binary signed/not signed decision legible by Android/iOS app update engines.\n This isn\u2019t a total fix, because ultimately the audit firms would need to be paid (they have to check the source matches the social contract being advertised), and thus the central authority \u2014 our adversary \u2014 will be the ones picking the auditors. But it\u2019s still a big step up and would mean that if Facebook suddenly decided merely blocking forwarding isn\u2019t enough to fight \u201crumors\u201d or \u201cfake news\u201d, they\u2019d be stopped by the auditors who\u2019d (hopefully) refuse to sign the update that takes out the encryption.\n The downside to the app developer is relatively small \u2014 higher latency on pushing out updates, dollar cost \u2014 but it\u2019d be transparent to end users and wouldn\u2019t affect the UX which is what they prize most. They could continue to iterate on the app quickly and without needing to move an ecosystem.\n  Threshold signing with distributed audit would be a nice upgrade, but what about more conventional approaches? It seems like privacy is impossible without control, control is difficult without decentralization, but our attempts to build decentralized systems aren\u2019t working. What can be done?\n Let\u2019s take a step back and re-examine some of our foundational assumptions. Moxie argues:\n  The first clause is certainly true. The second is a prediction about the future, which is a notoriously difficult thing to predict.\n Is the reluctance to run servers  fundamental or is it merely  the way things are now? Why don\u2019t non technical users want to run servers? After all, they have done in the past via programs like BitTorrent and Gnutella. Multiplayer games are often also servers for latency reasons, relying on a central meeting point only for matchmaking. AirDrop runs a server in order to work. Etc.\n  The dominant server OS is some mix of Linux, AWS, Kubernetes, Apache/Nginx etc. This stack has horrific usability even for experts. Consider how awkward it is to configure working backups for a new Linux server \u2014 this is a  basic task which should be easy, yet it\u2019s not.\n But these things are all attributes of our current infrastructure, not things that must universally be true. The \u2018golden age\u2019 of home servers like BitTorrent nodes, web servers running in people\u2019s bedrooms etc was a few years after the millennium, when:\n  Clearly then, the factors that constrain self-run decentralized infrastructure today don\u2019t  have to be true, they are true because we don\u2019t make them false. An entirely different world is imaginable.\n It\u2019s worth noting here that despite widespread industry groupthink of the form \u201ceverything should be a web app\u201d (hence the gratuitously named Web3), Apple \u2014 the company most strongly associated with tech usability \u2014 is not really on board with the whole web/cloud trend. They implement everything as an app that runs locally on powerful and expensive hardware, where your data is fully under your control. Especially on macOS, you share as much or as little of it with Apple as you want. You can reject software updates, or accept them. You back up data to a \u201c time capsule\u201d, easily and locally. You can monitor what apps can do or send on the network. In many ways it\u2019s a traditional mindset reflecting the values of the 90s, yet it has  not held Apple back in any way in its competition with the drastically more centralized ChromeOS. I\u2019m not saying Apple is some paragon of decentralization, as obviously they aren\u2019t and the fact it\u2019s worked out this way is mostly due to their history rather than any strong pro-liberty philosophical stance. But still. They\u2019re an existence proof of what\u2019s technically possible.\n Thus I conclude it\u2019s not actually a given that users won\u2019t run their own infrastructure, or adopt more decentralized approaches. They don\u2019t do that  today because the software industry outside of Cupertino isn\u2019t interested in easily letting them do that. Linux distros in particular have failed to make a highly usable system, even for their own kind of people. And regardless of how much companies like Google or Facebook talk about privacy, their culture is and always will be to immediately leap for \u201cdo it all on the server\u201d, which of course Apple knows and fully exploits in their marketing.\n I\u2019m painting with a very broad brush here and there are exceptions \u2014 the trend towards running ML models on-device is a good and praiseworthy example of this. But I hope you\u2019ll agree that the generalities are right.\n  I\u2019ve been thinking about these problems for a long time. These days I\u2019m focused on finding incremental, non-radical paths forward. No more peer-to-peer networks for me, at least not for a while.\n  We should try to reduce the burden of building software. At this point, software projects require an enormous amount of human effort. Even relatively simple apps require a group of people to sit in front of a computer for eight hours a day, every day, forever. This wasn\u2019t always the case, and there was a time when 50 people working on a software project wasn\u2019t considered a \u201csmall team.\u201d\n I completely agree. Top of my list: it should be  way easier to build and distribute both desktop apps and small, one-machine servers. Far better than encryption is just not sending data to another place to begin with, and it\u2019s possible far more frequently than we actually exploit. Apple can make ultra-competitive yet private and decentralized \u2018experiences\u2019 like Pages, Numbers, GarageBand etc because of their deep history of building electronics, client-side software and distribution/supply chains. Yet the iLife apps stay up to date because Apple built their own app store infrastructure and OS to ensure they do. Other parts of the software industry struggle with even these basics.\n Step 1 for building a decentralized system: get code onto the powerful, high bandwidth devices users actually plug into AC power today, keep it up to date and for political reasons do it  outside of app stores. Ethereum has totally failed at this and Moxie is right to point that out. But the reason they failed is obvious once you actually try to do it: it\u2019s a universe of pain. Awkward, hacked together and  frequently abandoned tools, poor software update systems, numerous package and installer formats, and even needing to render icons at lots of different sizes all slows you down.\n I spent most of 2021 working on software that addresses all these problems. It lets you make self-updating desktop and server apps with only a small config file and a single command. It\u2019s not quite ready for beta yet and I didn\u2019t actually set out to write an advert for what I\u2019m doing when I started this essay, thus currently there\u2019s no website or mailing list for this project. You\u2019ll just have to keep an eye on my blog. I\u2019ll announce it here when it\u2019s launched, so subscribe for updates if you\u2019re interested.\n  It\u2019s a tool, not a service. You run it locally on whatever type of computer you have, and it can make fully signed and notarized downloads for Windows, Mac and Linux without needing you to own those operating systems.\n The apps stay fresh. Online updates are easy, just change the version in the config file, rebuild and re-upload the generated static files to a web server. You don\u2019t have to sacrifice iteration speed and the update tech is the most \u2018native\u2019 on each platform (MSIX on Windows, Sparkle on macOS, package managers on Linux).\n The user can be empowered. As long as you allow it, users can review and reject upgrades e.g. because they\u2019re about to give a presentation and don\u2019t want their setup changing, or they don\u2019t like the new UI etc. Or you can ensure apps always update silently Chrome style: useful in enterprise deployments or where there\u2019s a rapidly changing client/server protocol. Pick what makes most sense for your target market.\n Generates Linux server packages. Again, from any OS. They use systemd, can be sandboxed, can depend on other packages like databases, start automatically on install/boot, handle upgrades at the right times etc.\n Apps distributed this way don\u2019t have to be peer to peer apps. Simple GUI frontends to centralized services like WhatsApp Web also get easier to make. But once you\u2019re on the desktop (or a Linux server) you have way more options and available tradeoffs on the decentralization/control/privacy/usability spectrum. The first versions of this tool won\u2019t support threshold signed updates for example, but it\u2019s a feature we\u2019d really like to find time for.\n I\u2019m excited to launch this product and the company behind it, because I think that really nailing the basics is a key step towards solving some of the problems Moxie identified. Make it easy for developers to do the right thing, and more of us will do it. It\u2019s as simple as that.", "posttime": "2022-01-09 22:18:25", "source_domain": "news.ycombinator.com", "source_name": "Hacker News", "tags": "web3,moxie,\u670d\u52a1\u5668", "title": "Re\uff1aWeb3\u4e0a\u7684Moxie", "title_en": "Re: Moxie on Web3", "transed": 1, "url": "https://blog.plan99.net/re-moxie-on-web3-b0cfccd68067?gi=c5c13129e817", "via": "", "real_tags": ["web3", "moxie", "\u670d\u52a1\u5668"]}, {"category": "", "categoryclass": "", "imagename": "", "infoid": 1072489, "ip": "", "isanchordig": 1, "ischecked": 1, "isdelete": 0, "isneo": 1, "mark": "", "name": "", "note": "\u6b22\u8fce\u6765\u5230jwst\u7528\u6237\u6587\u6863\u4e3b\u9875agopethis\u7f51\u7ad9\u5728JWST\u822a\u5929\u5668\u548cInstru\u4e0a\u6301\u6709\u5168\u9762\u7684\u6587\u6863\uff08\u79f0\u4e3aJDox\uff09", "note_en": "Welcome to theJWST User Documentation HomepageThis website holds a comprehensive collection of documentation (known as JDox) on the JWST spacecraft and instru", "posttime": "2022-01-09 22:18:13", "source_domain": "news.ycombinator.com", "source_name": "Hacker News", "tags": "jwst,user", "title": "JWST\u7528\u6237\u6587\u6863", "title_en": "JWST User Documentation", "transed": 1, "url": "https://jwst-docs.stsci.edu/", "via": "", "real_tags": ["jwst", "user"]}, {"category": "", "categoryclass": "", "imagename": "f5fec1cfb9087db7d646a5cb21028075.png", "infoid": 1072488, "ip": "", "isanchordig": 1, "ischecked": 1, "isdelete": 0, "isneo": 1, "mark": "", "name": "", "note": "\u9a86\u9a7c\u9879\u76ee\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u548c\u6570\u5343\u79cd\u6a21\u62df\u6765\u4ece\u5b87\u5b99\u4e2d\u63d0\u53d6\u79d8\u5bc6\n\u7814\u7a76\u4eba\u5458\u8bbe\u8ba1\u4e86\u7528\u4e8e\u9988\u9001\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u6a21\u62df\uff0c\u4ece\u800c\u80fd\u591f\u4ece\u771f\u5b9e\uff0c\u53ef\u89c2\u5bdf\u5b87\u5b99\u7684\u89c2\u5bdf\u4e2d\u63d0\u53d6\u4fe1\u606f\u3002\u9a86\u9a7c\u662f4,233\u5b87\u5b99\u6a21\u62df\uff0c\u662f\u65e8\u5728\u8bad\u7ec3\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u7684\u6700\u5927\u8be6\u7ec6\u5b87\u5b99\u5b66\u6a21\u62df\u5957\u4ef6\u3002\n\u201c\u770b\u770b\u8fd9\u5c06\u80fd\u591f\u542f\u7528\u7684\u5176\u4ed6\u65b0\u53d1\u73b0\u662f\u4ee4\u4eba\u5174\u594b\u7684\uff0c\u201d\u4ed6\u8bf4\u3002", "note_en": "The CAMELS project uses machine learning and thousands of simulations to extract secrets from the cosmos\n   Totaling 4,233 universe simulations, millions of galaxies and 350 terabytes of data, a new release from the CAMELS project is a treasure trove for cosmologists. CAMELS \u2014 which stands for Cosmology and Astrophysics with MachinE Learning Simulations \u2014 aims to use those simulations  to train artificial intelligence models to decipher the universe\u2019s properties.\n Scientists are already using the data,  which is free to download, to power new research, says project co-leader Francisco Villaescusa-Navarro, a research scientist with the Simons Foundation\u2019s CMB (Cosmic Microwave Background) Analysis and Simulation group.\n Villaescusa-Navarro leads the project with associate research scientists at the Flatiron Institute\u2019s Center for Computational Astrophysics (CCA) Shy Genel and  Daniel Angl\u00e9s-Alc\u00e1zar, who is also a UConn Associate Professor of Physics.\n \u201cMachine learning is revolutionizing many areas of science, but it requires a huge amount of data to exploit,\u201d says Angl\u00e9s-Alc\u00e1zar. \u201cThe CAMELS public data release, with thousands of simulated universes covering a broad range of plausible physics, will provide the galaxy formation and cosmology communities with a unique opportunity to explore the potential of new machine-learning algorithms to solve a variety of problems.\u201d\n  The CAMELS team generated the simulations using code taken from the  IllustrisTNG and  Simba projects. The CAMELS team includes members of both projects, with Genel a part of the core team of IllustrisTNG and Angl\u00e9s-Alc\u00e1zar on the team that developed Simba.\n About half of the simulations combine the physics of the cosmos with the smaller-scale physics essential for galaxy formation. Each simulation is run with slightly different assumptions about the universe \u2014 for instance, regarding how much of the universe is invisible dark matter versus the dark energy pulling the cosmos apart, or how much energy supermassive black holes inject into the space between galaxies.\n The researchers designed the simulations to feed machine-learning models, which will then be able to extract information from observations of the real, observable universe. With 4,233 universe simulations, CAMELS is the largest ever suite of detailed cosmological simulations designed to train machine-learning algorithms.\n \u201cThe data will enable new discoveries and connect cosmology with astrophysics through machine learning,\u201d says Villaescusa-Navarro. \u201cThere has never been anything similar to this, with this many universe simulations.\u201d\n The CAMELS dataset is already powering research projects, with a wide range of papers utilizing the data in the works.\n Pablo Villanueva-Domingo of the University of Valencia in Spain led  one such paper. He and his colleagues leveraged the CAMELS simulations to train an artificial intelligence model to measure the mass of our Milky Way galaxy plus its surrounding dark matter halo, and the nearby Andromeda galaxy and its halo. The measurements \u2014 the first ever done using AI \u2014 put our galaxy\u2019s heft at 1 trillion to 2.6 trillion times the sun\u2019s mass. Those estimates are roughly in line with those made by other methods, demonstrating the AI approach\u2019s accuracy.\n Meanwhile, Villaescusa-Navarro headed an effort to use the CAMELS data to estimate the value of two parameters that govern the fundamental properties of the universe: what fraction of the universe is matter, and how evenly mass is distributed throughout the cosmos. First, he and his colleagues used CAMELS to generate maps such as the distribution of dark matter, gas and different properties of stars. Then, using the maps, they trained a machine-learning tool called a neural network to predict the values of the two parameters.\n \u201cThis is the same kind of algorithm used to tell the difference between a cat and a dog from the pixels of an image,\u201d says Genel, who co-authored the paper. \u201cThe human eye can\u2019t determine how much dark matter there is in a simulation, but a neural network can do that.\u201d\n The results showed the promise of leveraging CAMELS to precisely estimate such parameters in the future based on new observations of the universe, says Villaescusa-Navarro.\n \u201cIt\u2019s exciting to see what other new discoveries this will enable,\u201d he says.", "posttime": "2022-01-09 22:17:47", "source_domain": "news.ycombinator.com", "source_name": "Hacker News", "tags": "\u4e0b\u8f7d,\u514d\u8d39,\u57f9\u8bad,suite,\u6a21\u62df", "title": "\u6700\u5927\u7684AI\u57f9\u8bad\u5b87\u5b99\u6a21\u62df\u5957\u4ef6\u73b0\u5728\u53ef\u4ee5\u514d\u8d39\u4e0b\u8f7d", "title_en": "The Largest Suite of Cosmic Simulations for AI Training Is Now Free to Download", "transed": 1, "url": "https://today.uconn.edu/2022/01/the-largest-suite-of-cosmic-simulations-for-ai-training-is-now-free-to-download-already-spurring-discoveries/", "via": "", "real_tags": ["\u4e0b\u8f7d", "\u514d\u8d39", "\u57f9\u8bad", "suite", "\u6a21\u62df"]}, {"category": "", "categoryclass": "", "imagename": "86f1dfccf357b2fa8e7140fa0c327611.jpg", "infoid": 1072487, "ip": "", "isanchordig": 1, "ischecked": 1, "isdelete": 0, "isneo": 1, "mark": "", "name": "", "note": "\u5728\u51e0\u5e74\u524d\u7684\u6c42\u804c\u9762\u8bd5\u4e2d\uff0c\u9762\u8bd5\u5b98\u8bf7\u6211\u89e3\u91ca\u52a0\u5bc6\uff0c\u7f16\u7801\u548c\u54c8\u5e0c\u4e4b\u95f4\u7684\u533a\u522b\u3002\u5f53\u6211\u4e3a\u4e00\u5bb6\u4e13\u95e8\u52a0\u5bc6\u7684\u516c\u53f8\u5de5\u4f5c\u65f6\uff0c\u6240\u4ee5\u6211\u77e5\u9053\u6388\u4e88\u7684\u5dee\u5f02\u3002\n\u4e0e\u7f16\u7801\u4e0d\u540c\uff0c\u52a0\u5bc6\u6d88\u606f\uff0c\u5982Base64-\u7f16\u7801\u7684\u6587\u672c\u201cLQNBJA38QFHNITLOKNZDVG ==\u201d\u5b8c\u5168\u6ca1\u7528\u3002\u5373\u4f7f\u60a8\u77e5\u9053\u4f7f\u7528\u7684\u7b97\u6cd5\uff0c\u4e5f\u65e0\u6cd5\u4ece\u52a0\u5bc6\u7684\u6d88\u606f\u4ece\u52a0\u5bc6\u7684\u6d88\u606f\u4ece\u52a0\u5bc6\u7684\u6d88\u606f\u4e2d\u83b7\u53d6\u3002\nHashing\u662f\u4e00\u79cd\u6c38\u4e45\u5730\u5c06\u4e00\u4e2a\u53ef\u8bc6\u522b\u7684\u4e1c\u897f\u6c38\u4e45\u8f6c\u6362\u4e3a\u7edf\u4e00\u548c\u7b80\u5355\u7684\u65b9\u5f0f\u3002\u559c\u6b22\u628a\u725b\u78e8\u6210\u6c49\u5821\u5305 - \u4f60\u53ef\u4ee5\u59cb\u7ec8\u5236\u4f5c\u6c49\u5821\uff0c\u4f46\u4f60\u6c38\u8fdc\u4e0d\u80fd\u628a\u725b\u518d\u6b21\u653e\u5728\u4e00\u8d77\u3002", "note_en": "In a job interview years ago, the interviewer asked me to explain the difference between encryption, encoding, and hashing. At the time I was working for a company that specialized in encryption, so I took knowing the difference for granted.\n It wasn\u2019t until much later that I understood how easily most folks can confuse the three topics for one another. Let\u2019s take a look at each in turn.\n  Encoding is the practice of taking data in one format and converting it to another. There are no secrets involved \u2013 the specifications for each format are public, well-documented, and easily implemented everywhere.\n The content of this article is rendered in your browser as either ASCII or UTF-8. What that means is the ones and zeros representing are interpreted in a specific way that converts them into English characters.\n The text \u201cHi, folks!\u201d is nothing more than ones and zeros, interpreted as ASCII and converted into readable text. You could just as easily encode this data as hex, which would instead be the string \u201c48 69 2C 20 66 6F 6C 6B 73 21.\u201d\n These are completely interchangeable. There\u2019s nothing special or magic about encoding, it\u2019s merely a way to interpret and present the underlying, raw data.\n  With encryption, everything changes. Encryption requires a secret (a key, password, or passphrase) that is used to convert usable data into something indistinguishable from random noise. Given an encrypted message, you can only  decrypt it if you have the original secret.\n Unlike with encoding, an encrypted message, like the base64- encoded text \u201clqNBja38qFHnITloKNzdVg==,\u201d is entirely useless. There is no way you can get from an encrypted message back to the plain text original, even if you know the algorithm used, without the password.\n If, however, you know this message used AES for encryption. And you know it used \u201cthisisasecret\u201d as the password. Then you can properly decrypt the message and read \u201cHi, folks!\u201d yet again.\n  Anyone who\u2019s spent any period of time working with encryption has likely used a hashing algorithm as well. Hashes look somewhat like encrypted messages. The underlying algorithms take a piece of plain text and convert it (with or without a key) into something indistinguishable from random noise.\n  These algorithms are one-way. Even if you know the algorithm and any secret keys involved, there is no way to un-hash a string. It\u2019s an entirely destructive operation.\n  The easiest way to remember how these topics differ is with a simple mental model.\n Encoding is a way of translating between different formats. Like converting a Spanish recipe for cake into English.\n Encryption is a way of protecting data behind a secret. Like sealing a box of chocolate in a locked safe so your kids don\u2019t find it.\n Hashing is a way of permanently converting from one recognizable thing to something uniform and simple. Like grinding a cow into a hamburger \u2013 you can always make a burger, but you can never put the cow back together again.\n These are rough analogies, but they should help the next time you\u2019re faced with the same interview question.", "posttime": "2022-01-09 22:17:06", "source_domain": "news.ycombinator.com", "source_name": "Hacker News", "tags": "\u52a0\u5bc6,hashing", "title": "\u54c8\u5e0c\u4e0d\u662f\u52a0\u5bc6", "title_en": "Hashing is not encryption", "transed": 1, "url": "https://eric.mann.blog/hashing-is-not-encryption/", "via": "", "real_tags": ["\u52a0\u5bc6", "hashing"]}, {"category": "", "categoryclass": "", "imagename": "2cf3717162541ad7b03f044d3869e7b3.png", "infoid": 1072486, "ip": "", "isanchordig": 1, "ischecked": 1, "isdelete": 0, "isneo": 1, "mark": "", "name": "", "note": "\u547d\u4ee4\u884c\u5de5\u5177\u548c\u7ec8\u7aefJSON Viewer\ud83d\udd25\u3002\u901a\u8fc7\u5728GitHub\u4e0a\u521b\u5efa\u5e10\u6237\uff0c\u4e3aAntonmedv / FX\u5f00\u53d1\u6709\u52a9\u4e8e\u5f00\u53d1\u3002", "note_en": "Command-line tool and terminal JSON viewer \ud83d\udd25. Contribute to antonmedv/fx development by creating an account on GitHub.", "posttime": "2022-01-09 22:16:44", "source_domain": "news.ycombinator.com", "source_name": "Hacker News", "tags": "jq,interactive,\u5de5\u5177", "title": "FX\uff1aJQ\u8fdb\u7a0bJSON\u7684\u4e92\u52a8\u66ff\u4ee3\u65b9\u6848", "title_en": "FX: An interactive alternative to jq to process JSON", "transed": 1, "url": "https://github.com/antonmedv/fx", "via": "", "real_tags": ["jq", "\u5de5\u5177"]}, {"category": "", "categoryclass": "", "imagename": "", "infoid": 1072485, "ip": "", "isanchordig": 1, "ischecked": 1, "isdelete": 0, "isneo": 1, "mark": "", "name": "", "note": "2015\u5e74\uff0c\u6211\u8c08\u5230\u4e86\u4e00\u4e2a\u8c08\u8bdd\uff0c\u6211\u53eb\u505a\u5510\u7eb3\u5fb7\u00b7\u514b\u6717\u7684\u987e\u5ba2\u5723\u6bbf\u7684\u7266\u725b\u522e\u80e1\u5b50\u3002\u539f\u56e0\u662f\u5510\u7eb3\u5fb7\u00b7\u514b\u5766\u65af\u8fbe\u5230\u4e86\u6700\u5b8c\u7f8e\uff0c\u6700\u6f2b\u957f\u7684\u7266\u725b\u5243\u987b\uff1aTex\u3002\n\u4f46\u662f\uff0cTEX\u505a\u4e86\u4ec0\u4e48\uff1f\u4e3b\u8981\u662f\uff0c\u5b83\u786e\u5b9e\u662f\u6587\u672c\u5e03\u5c40\u548c\u51e0\u4ef6\u4e8b\u3002\u4f17\u6240\u5468\u77e5\uff0cKnuth\u5728\u7b97\u6cd5\u4e0a\u65e0\u6cd5\u4e0e\u4ed6\u81ea\u5df1\u7684\u7b97\u6cd5\u4e00\u8d77\u51fa\u73b0\uff0c\u540e\u6765\u4e0eMichael Plass\u4e00\u8d77\u51fa\u7248\u3002\u7b97\u6cd5\u505a\u4e86\u4ec0\u4e48\uff1f\u5b83\u627e\u5230\u4e86\u4e00\u4e2a\u89c6\u89c9\u4e0a\u4ee4\u4eba\u6109\u60a6\u7684\u65b9\u5f0f\uff0c\u5728\u6ca1\u6709\u53d1\u51fa\u7ebf\u6761\u7684\u60c5\u51b5\u4e0b\u653e\u7f6e\u4e00\u4e2a\u9875\u9762\u4e0a\u7684\u6bb5\u843d\uff0c\u770b\u8d77\u6765jarring\uff08\u4f8b\u5982\u901a\u8fc7\u8c03\u6574\u201c\u80f6\u6c34\u201d\uff0c\u5355\u8bcd\u4e4b\u95f4\u7684\u7a7a\u683c\uff09\u3002\u8fd9\u662f\u4e00\u4e2a\u5f88\u597d\u7684\u89e3\u91ca\u3002\n\u4f5c\u4e3a\u4e00\u4e2a\u526f\u4f5c\u7528\uff0cMetafont\u7a0d\u540e\u4f1a\u8fdb\u5316\u5230\u901a\u7528\u77e2\u91cf\u56fe\u7eb8\u7684Metapost\uff0c\u5b83\u5177\u6709\u6211\u4ecd\u7136\u9519\u8fc7\u7684\u8bb8\u591a\u73b0\u4ee3\u56fe\u5f62\u63cf\u8ff0\u8bed\u8a00\uff1a\u63cf\u8ff0\uff08\u53ef\u5bfb\u5740\uff09\u70b9\u4f5c\u4e3a\u4e24\u4e2a\u5176\u4ed6\u57fa\u5143\u4e4b\u95f4\u7684\u4ea4\u53c9\u70b9\u3002\n\u4f46\u5927\u591a\u6570\u60c5\u51b5\u4e0b\uff0c\u4e24\u4e2a\u5927\u9879\u76ee\u6d8c\u51fa\u3002\u7b2c\u4e00\u4e2a\u662fLeslie Lamport\u7684\u4e73\u80f6\u3002 Lamport\u662f\u4e00\u540d\u975e\u5e38\u9ad8\u6548\u7684\u7814\u7a76\u5458\uff0c\u4ee5TLA +\u4ee5\u6b63\u5f0f\u65b9\u6cd5\u7814\u7a76\u7740\u540d\uff0c\u4e5f\u662f\u8bb8\u591a\u5206\u5e03\u5f0f\u7b97\u6cd5\u7684\u94fa\u8bbe\u57fa\u7840\u3002\u4e73\u80f6\u662f\u57fa\u4e8e\u5206\u79bb\u4ecb\u7ecd\u548c\u5185\u5bb9\u7684\u60f3\u6cd5\u3002\u5b83\u56f4\u7ed5\u6587\u6863\u7c7b\u7684\u60f3\u6cd5\uff0c\u7136\u540e\u63cf\u8ff0\u67d0\u4e2a\u6587\u6863\u7684\u5e03\u7f6e\u65b9\u5f0f\u3002\u60f3\u60f3\u5e02\u573a\uff0c\u66f4\u590d\u6742\u3002\u7b2c\u4e8c\u4e2a\u662f\u4e0a\u4e0b\u6587\uff0c\u8fdc\u8fdc\u4e13\u6ce8\u4e8e\u7ec6\u7c92\u5ea6\u7684\u5e03\u5c40\u63a7\u5236\u3002\n\u901a\u8fc7\u5bf9\u5176\u5386\u53f2\u7684\u7406\u89e3\u63a5\u8fd1Tex\uff0c\u53ef\u4ee5\u4ece\u4e2d\u5438\u53d6\u5f88\u591a\u4e1c\u897f\u3002\u662f\u7684\uff0c\u66f4\u6362\u4f1a\u5f88\u68d2\uff0c\u4f46\u5b83\u9700\u8981\u5e74\u9f84\u3002", "note_en": "In 2015, I gave a talk in which I called  Donald Knuth the Patron Saint of Yak Shaves. The reason is that Donald Knuth achieved the most perfect and long-running yak shave: TeX.\n      The ultimate yak shave is the combination of improbable circumstance, the privilege to be able to shave at your hearts will and the will to follow things through to the end. Here\u2019s the way it was achieved with TeX. The recount is purely mine, inaccurate and obviously there for fun. I\u2019ll avoid the most boring facts that everyone always tells, such as  why Knuth\u2019s checks have their own Wikipedia page.\n      TeX was invented to typeset a book. No plural. It was invented to typeset the second edition of \u201cThe Art of Computer Programming\u201d. The second edition had to be typeset again, as \u201chot type\u201d typesetting, which was used for the first edition, was not available anymore. Being unimpressed by the available options, Knuth decided to write his own system, which later ended up as TeX.\n  But \u201cThe Art of Computer Programming\u201d is an impressive book in its own right: it is still unfinished, currently spanning 3.5 volumes (yes, the fourth is unfinished, but the first chapters are released). It was called a book of the century by  American scientist writers.\n    Digging deeper into TAOCP, it already shows the works of a yak shaver destined for greater things. All programs in this book refer to a common assembly language: MIX. Which was invented for the book.\n      The first version of TeX was implemented using the  SAIL programming language. It was later replaced by WEB. What\u2019s WEB? It\u2019s a programming language, invented by\u2026 You\u2019ll have guessed it by now, Donald Knuth. It transpiles to PASCAL. Knuth transpiled the WEB before it was cool.\n    WEB is a special language: in WEB, any bare text is just text. It\u2019s interleaved with marked pieces of code, which are later used for the program code. The documentation can be run through a special program to produce\u2026 a TeX file. The concept is called \u201cliterate programming\u201d and was introduced by\u2026 Donald Knuth.\n    But, what does TeX do? Mainly, it does text layout and a couple of other things. Knuth being known for research on algorithms couldn\u2019t do without coming up with his own algorithm, later published together with Michael Plass. What does the algorithm do? It finds a visually pleasing way to lay out a paragraph on a page without making line breaks look jarring (for example by adjusting the \u201cglue\u201d, the whitespace between words). Here\u2019s a  nice explanation.\n  It\u2019s still considered good and has a huge factor in the recognisable look of TeX documents.\n    Which brings us to the next problem:  what does this thing lay out? Generically speaking: objects and clusters of objects of varying sizes. Interestingly, that\u2019s what TeX deals with, it has no concept of a character other then dimensions.\n  Nevertheless, these are usually characters and characters are provided by fonts. Fonts must usually be licensed at a fee and free fonts weren\u2019t so available in the 70s.\n  Another very recognisable feature of TeX documents that they are often set in a font called \u201cComputer Modern\u201d.\n  I\u2019m trying to make this whole thing a bit more thrilling, so I will let you guess who created that one.\n    Fonts need to be authored. Usually, they are described in some vector description, often B\u00e9zier curves. This is fairly standard and not an innovation of Knuth.  But, he wrote a description language for that, along with an interpreter to turn this descriptions into proper font files. This is  METAFONT. It\u2019s not strictly part of TeX, it\u2019s just that the Yak happened to stand close.\n    As a side-note, METAFONT was later evolved into METAPOST for generic vector drawings, which has the one feature I still miss from many modern graphics description languages: the ability to describe an (addressable) point as the intersection between two other primitives.\n  Another side-note: both TeX and METAFONT still see releases, at a slow pace. TeX is currently at version 3.14159265, METAFONT at 2.7182818. Yep, TeX is slowly converging towards pi, while METAFONT towards e. Take that, semantic versioning advocates!\n  Yak shave 6: Come up with your own versioning scheme \rYak shave 7: Avoid adoption of it for greater good\n  We\u2019re not done yet. We can layout text (and other things), but where do we convert it to? Now, everyone knows the horror printers invoke, so no one wants to deal with those directly. Classic TeX instead converts things to  DVI, the \u201cdevice independent\u201d format. I don\u2019t know many details about it, except what\u2019s on the wiki page, which feels the need to specifically point out that \u201cDVI is not a document encryption format\u201d. It is again a stack-based language (in contrast to PostScript not turing complete), which can then be interpreted through a driver, which would then send that to whatever target (a printer, PDF or such). It was designed by\u2026\n      Note that I haven\u2019t mentioned that TeX is an\u2026 interesting\u2026 language by itself, but I don\u2019t consider that a yak shave, this was just the implementation.\n  That makes most of the initial implementation complete. Which means, in orderly fashion, you should give matters in the hand of the community.\n    Since the release of TeX, the community has been busy working on using it as a platform. If you ever downloaded the full TeX distribution, please bear in mind that you are downloading the amassed work of over 40 years, to make sure that each and every TeX document ever written builds. We\u2019re talking about documents here.\n  But mostly, two big projects sprung out of that. The first is LaTeX by Leslie Lamport. Lamport is a very productive researcher, famous for research in formal methods through TLA+ and also known laying groundwork for many distributed algorithms. LaTeX is based on the idea of seperating presentation and content. It is based around the idea of document classes, which then describe the way a certain document is layed out. Think Markdown, just much more complex. The second is ConTeXt, which is far more focused on fine grained layout control.\n    Community yak shave 1: Create not one, but two programs that are very ungoogleable\u2026 Before Google is invented.\n  Being active in a language that has lingo built around \u201cRust\u201d, \u201cCargo\u201d and \u201cmanifests\u201d, I feel right at home.\n  Now, the community also wants to evolve TeX: a lot has changed over the years in technology, so, for example, you\u2019d like to use modern font formats, directly write to modern output formats or use this new UTF-8 thingy. For that, there are specialised TeX interpreters, such as  pdf(la)tex,  lua(la)tex and  xe(la)tex. There\u2019s a problem here: you are not allowed to change TeX and distribute  it under that name. The thinking here is that if you have a  tex binary, you can compile any valid TeX from the past and from the future.\n  The first issue on that road is that WEB isn\u2019t really a popular programming language, neither is PASCAL and running it on modern systems is a bit of a pain. Which means\u2026\n          Whenever you feel like \u201ccan\u2019t we just replace this whole thing, it can\u2019t be so hard\u201d when handling TeX, don\u2019t forget how many years of work and especially knowledge were poured into that system. Typesetting isn\u2019t the  most popular knowledge around programmers. Especially see it in the context of the space it is in: they can\u2019t remove legacy. Ever. That would break documents.\n  TeX is also not a programming language. It might resemble one, but mostly, it should be approached as a typesetting system first. A lot of its confusing lingo gets much better then. It\u2019s not programming lingo.\n  By approaching TeX with an understanding for its history, a lot of things can be learned from it. And yes, a replacement would be great, but it would take ages.\n  In any case, I hope I thoroughly convinced you why Donald Knuth is the Patron Saint of Yak Shaves.\n    This comes out of a enjoyable discussion with  Arne from Lambda Island, who listened and said \u201cyou should totally turn this into a talk\u201d.\n  top", "posttime": "2022-01-09 22:16:00", "source_domain": "news.ycombinator.com", "source_name": "Hacker News", "tags": "knuth,\u7b97\u6cd5", "title": "\u5510\u7eb3\u5fb7Knuth  -  Yak Shaves\u7684\u987e\u5ba2\u5723\u5f92\uff082017\u5e74\uff09", "title_en": "Donald Knuth \u2013 The Patron Saint of Yak Shaves (2017)", "transed": 1, "url": "https://yakshav.es/the-patron-saint-of-yakshaves/", "via": "", "real_tags": ["knuth", "\u7b97\u6cd5"]}, {"category": "", "categoryclass": "", "imagename": "", "infoid": 1072484, "ip": "", "isanchordig": 1, "ischecked": 1, "isdelete": 0, "isneo": 1, "mark": "", "name": "", "note": "\u5728\u5f00\u59cb\u9605\u8bfb\u4e4b\u524d\uff0c\u60a8\u5e94\u8be5\u610f\u8bc6\u5230\u8fd9\u7bc7\u6587\u7ae0\u6709\u5173\u5728\u5e73\u53f0\u5de5\u4f5c\u4e24\u5e74\u540e\u88ab\u8feb\u7684\u590d\u6742\u60c5\u51b5\u548c\u9000\u6b3e\u3002\n\u6211\u9047\u89c1\u4e86\u7f57\u5bbe\uff0c\u6211\u4eec\u5f00\u5c55\u4e86\u4e00\u4e2a\u5934\u8111\u98ce\u66b4\u4f1a\u8bae\u548c\u4e00\u4e9b\u4f1a\u8bae\u3002\u6b64\u9636\u6bb5\u552f\u4e00\u5408\u7406\u7684\u4e8b\u60c5\u662f\u6dfb\u52a0\u624b\u52a8\u65f6\u95f4\u3002\u5728\u7a7a\u767d\u5c4f\u5e55\u4e0a\u6253\u5f00\u8f6f\u4ef6\u5e76\u53ea\u9700\u70b9\u51fb\u67d0\u4e2a\u4f4d\u7f6e\u5373\u53ef\u4fdd\u6301\u8ba1\u7b97\u673a\u7684\u6d3b\u52a8\u5e76\u6ca1\u6709\u610f\u4e49\u3002\u56e0\u6b64\uff0c\u6211\u5f55\u5236\u4e86\u624b\u52a8\u65f6\u95f4\uff0c\u5f88\u591a\u3002\u6211\u901a\u5e38\u4f1a\u4e0e\u5176\u4ed6\u5ba2\u6237\u4e00\u8d77\u505a\u5230\u8fd9\u4e00\u70b9\uff0c\u8fd9\u7edd\u4e0d\u662f\u4e00\u4e2a\u95ee\u9898\u3002\n\u7f57\u5bbe\u771f\u7684\u8981\u6c42\u9000\u6b3e\u5417\uff1f\u8fd9\u4e0d\u53ef\u80fd\u3002\u6211\u5f00\u59cb\u901a\u8fc7\u8c03\u7528\u7f57\u5bbe\u6765\u8c03\u67e5\u3002\u4ed6\u9053\u6b49\u5e76\u8868\u793a\u4ed6\u4ece\u6765\u6ca1\u6709\u53ec\u5524\u4efb\u4f55\u94f6\u884c\uff0c\u53e6\u5916\uff0c\u4ed6\u8bf4\u8fd9\u6709\u70b9\u641e\u7838\u4e86\uff0c\u56e0\u4e3a\u4ed6\u5fd8\u4e86\u4ed6\u6709\u201c\u5728\u4ed6\u7684\u8d26\u6237\u4e2d\u6ca1\u6709\u5b9e\u9645\u4e0a\u662f\u4ed6\u7684\u4fe1\u7528\u5361\u3002\n\u662f\u7684\uff0c\u5982\u679c\u6211\u624b\u52a8\u5f55\u5236\u6570\u5c0f\u65f6\uff0c\u5ba2\u6237\u53ef\u4ee5\u8981\u6c42\u9000\u6b3e\uff0c\u5e76\u8bc1\u660e\u4ed6\u4eec\u7684\u6848\u4ef6\u3002\u4f46\u8fd9\u4e0d\u662f\u5ba2\u6237\u8981\u6c42\u8fd9\u7b14\u94b1\u3002\u8fd9\u662f\u4fe1\u7528\u5361\u6240\u6709\u8005\uff0c\u8c01\u662f\u53e6\u4e00\u4e2a\u4eba\u3002\u8fd9\u662f\u4e0d\u5ba1\u67e5\u5ba2\u6237\u7684\u52aa\u529b\u7684\u9519\u3002\n\u6bcf\u5f53\u6211\u548c\u67d0\u4eba\u8bf4\u8bdd\u65f6\uff0c\u4ed6\u4eec\u90fd\u5f88\u9707\u60ca\u5e76\u8ba4\u4e3a\u5b83\u4e0d\u516c\u5e73\u3002\u6211\u51b3\u5b9a\u5728\u8fd9\u91cc\u5199\u8fd9\u7bc7\u6587\u7ae0\uff0c\u56e0\u4e3a\u6211\u5f88\u4e50\u610f\u542c\u5230\u8fd9\u4ef6\u4e8b\u7684\u53cc\u65b9\u7684\u610f\u89c1\u3002\u5982\u679c\u60a8\u5bf9\u6b64\u4e8b\u6709\u4efb\u4f55\u610f\u89c1\uff0c\u8bf7\u4e0e\u6211\u5206\u4eab\u3002", "note_en": "Before starting to read this, you should be aware that this article is concerning an Upwork complex situation and refund that\u2019s been forced to my account after two years of working on the platform.\n I\u2019m a successful Upwork freelancer, and I love it. I\u2019ve made over $100k on that platform and was able to career shift through it. The reason why I\u2019m posting about this is to understand whether I\u2019m being in a fair or a non-fair position from an external perspective.\n It\u2019s important to note that I\u2019ve informed Upwork\u2019s support that I\u2019ll post this problem externally online on Medium and my website. They didn\u2019t inform me not to.\n  I started off on Upwork a few years back. I built my status slowly and learned a huge deal along the way. In 2018, I signed a client as usual. Let\u2019s call him \u201cRobin\u201d for the sake of the non-disclosure agreements.\n Robin was far by the best and the worst thing that ever happened to me on Upwork. I\u2019ve worked with him till Sept of 2020. Robin worked with me fairly and I never had any dispute with Upwork on him. He needed presentations for investments, plans, designs, financial sheets; all within my area of expertise.\n It was perfect. I even met Robin in real life in Zurich, instead of virtually. We continued working via Upwork while locating in Zurich, as to not violate any Upwork terms.\n  There are two ways of recording how you work on Upwork, either  hourly through the software or  adding manual hours. They state it very obvious that  a freelancer falls under the Upwork protection if they record their hours through the software, not manually.\n I meet Robin, and we conduct a brainstorming session and a few meetings. The only reasonable thing to do at this stage is to add manual hours. It doesn\u2019t make sense to open the software on a blank screen, and just click somewhere to keep the computer alive. Hence, I recorded manual hours, lots of them. I usually do that with other clients as well, it\u2019s never a problem.\n Here\u2019s when it could be a problem: If  the client on Upwork asks for a chargeback (refund). Then he might be entitled to it if you\u2019re manually recording the hours.\n I\u2019m on very good terms with Robin. He would never request a refund from Upwork, I\u2019m sure of that.\n Anyway, that lasted for a couple of years and ended when he informed me that he has issues with Upwork and his credit card. I just told him to go sort it out and call me when he\u2019s ready to work again. I will not work with him for free till he fixes his credit card on Upwork. In all cases,I don\u2019t care really, I have several other clients, and Upwork pays me per week. So, worst-case scenario, I would lose one week of earnings, but that\u2019s tolerable.\n   We are writing today to let you know that a payment made to your account has been reversed by your client\u2019s bank.\n This reversal (chargeback) is a result of your client contacting their bank and asking them to reverse the payment for the following transaction(s):\n    I went nuts. A day after, a few other freelancers whom we were working with, started contacting me saying that Upwork is asking all of them for a refund as well.\n Is Robin really asking for a chargeback? That\u2019s impossible. I start investigating by calling Robin. He apologized and said he never called any bank, additionally, he said this is a bit of a mess-up as he forgot that there is  \u201ca credit card connected in his account that wasn\u2019t actually his\u201d.\n Let me translate this. Robin has been using someone else\u2019s credit card for two years, and this other person realized that money was being withdrawn in the previous two years on a platform called Upwork without his consent.\n  I\u2019ve worked with Robin for two years, and I worked hard for this.\n  They told me, here\u2019s what you can do:\u200a\u2014\u200a Provide us with proof of your work, and we will try to convince the bank to not ask for this chargeback on behalf of their client.\u200a\u2014\u200aThat option sounds illogical in all sorts of ways.  Why would  a bank take my side (a freelancer from another country) instead of his own actual client who never actually requested those services?\n Nevertheless, I sent Upwork two years\u2019 worth of projects. They respond 40 days later telling me that they tried and failed. Then they said something that seemed, in my point of view, a bit of a human-right violation.\n \u201cYou have to pay this money back, what we want you to do is work on our platform and we will take your earnings from there. Till then, you\u2019re not allowed to withdraw any earnings.\u201d  (Paraphrasing)\n Let me get this straight\u200a\u2014\u200aUpwork, a billion-dollar company, wants me, a freelancer, to work for free on their platform for approximately 230 hours (with my hourly rate) because a client on their platform was using someone else\u2019s credit card? How in god\u2019s name is that my fault?\n Yes, the clients can ask for a chargeback if I record the hours manually and their case was proven.  But that\u2019s not the client asking for the money. That\u2019s  the credit card owner, who is another person. That\u2019s Upwork\u2019s fault for not vetting their clients.\n Eventually, I keep trying to open a communication channel with Upwork and their support concerning this refund situation. They insist on this situation.\n    Whoever owns the credit card can ask their bank to chargeback a payment. We cannot get around this, unfortunately.\n We consider this matter closed as we believe we have gone over this with you at length.\u201d\n They consider this matter closed. I even tried to raise a complaint on this \u201cEscalation\u201d department\u200a\u2014\u200atheir response  \u201cWe\u2019re sorry, the executive escalations are the highest tier.\u201d\n At the moment of this writing, I\u2019m still on the platform. It\u2019s a little bit demotivational knowing that the next 230 hours that I\u2019ll work will go to Upwork instead of me because of this, so I\u2019m slowed down on a motivational level.\n I\u2019ve worked honorably and by the book on Upwork for a long time. When things were not making sense, I still followed the rules. I could\u2019ve easily gotten paid from Robin outside of Upwork. Heck, he was physically in front of me. Yet, I respect how Upwork opened my eyes to becoming the person I am today, and for that, I\u2019m forever grateful.\n Whenever I speak to someone about this, they are shocked and deem it unfair. I decided to write this here because I would love to hear opinions on both sides of the matter. If you have any opinion on this matter, please share it with me.\n In my opinion, a better way to think of this is as follows\u200a\u2014\u200aIf you\u2019re working as a cook at Mcdonalds and it turns out that Mcdonalds has been scamming the world without you being aware. Do you, as a cook, have the responsibility to pay what you honorably earned back to the world?", "posttime": "2022-01-09 22:15:28", "source_domain": "news.ycombinator.com", "source_name": "Hacker News", "tags": "client,\u7f57\u5bbe", "title": "\u6625\u5929\u8981\u6c42\u5ba2\u6237\u4f7f\u7528\u522b\u4eba\u7684\u5361\uff0c\u8981\u6c4212,500\u7f8e\u5143\u9000\u6b3e", "title_en": "Upwork asking for a $12,500 refund as the client was using someone else's card", "transed": 1, "url": "https://alanany.com/2021/12/23/upwork-12k-refund-client-using-another-credit-card/", "via": "", "real_tags": ["client", "\u7f57\u5bbe"]}, {"category": "", "categoryclass": "", "imagename": "", "infoid": 1072483, "ip": "", "isanchordig": 1, "ischecked": 1, "isdelete": 0, "isneo": 1, "mark": "", "name": "", "note": "\u7406\u89e3\u548c\u5efa\u6a21\u56f4\u7ed5\u673a\u5668\u5b66\u4e60\u9884\u6d4b\u7684\u4e0d\u786e\u5b9a\u6027\u5bf9\u4efb\u4f55\u751f\u4ea7\u6a21\u578b\u81f3\u5173\u91cd\u8981\u3002\u5b83\u63d0\u4f9b\u4e86\u5904\u7406\u6a21\u578b\u9891\u4e32\u79bb\u5176\u9002\u7528\u8303\u7574\u592a\u8fdc\u7684\u60c5\u51b5\u7684\u53e5\u67c4\uff0c\u8fdb\u5165\u4f7f\u7528\u9884\u6d4b\u7684\u5730\u533a\u662f\u5f7b\u5e95\u6216\u5f7b\u5934\u5f7b\u5c3e\u7684\u5371\u9669\u3002\u8ba4\u4e3a\u533b\u7597\u8bca\u65ad\u6216\u81ea\u52a8\u9a7e\u9a76\u6c7d\u8f66\u3002\n\u4e3a\u7b80\u5355\u8d77\u89c1\uff0c\u6211\u4eec\u5c06\u8003\u8651\u4ee5\u4e0b\u4f17\u6240\u5468\u77e5\u7684\u6b63\u6001\u5206\u5e03\uff0c\u4f46\u8be5\u65b9\u6cd5\u5bf9\u4e8e\u4efb\u4f55\u5176\u4ed6\u6982\u7387\u5206\u5e03\u4e5f\u662f\u7c7b\u4f3c\u7684\u3002\n\u8bbeM\uff08x\uff0c\u03b81\uff09\\ mu\uff08x\uff0c\u03b81\uff09\u03bc\uff08x\uff0c\u03b81\uff09\u548c\u03c3\uff08x\uff0c\u03b81\uff09\\ sigma\uff08x\uff0c\\ theta_1\uff09\u03c3\uff08x\uff0c\u03b81\uff09\u662f\u4e24\u4e2a\u5b50\u7f51\u7edc\u5177\u6709\u5404\u81ea\u7684\u57f9\u8bad\u53c2\u6570Th 1 \\ Theta_11 Th 1\u548cTh 2 \\Theta_2\u03b82\u3002\nl = 1 2\uff08y  - \u03bc\uff08x\uff0c\u03b81\uff09\u03c3\uff08x\uff0c\u03b82\uff09\uff092 + log {2\u03c0\u22c5\u03a3\uff08x\uff0c\u03b82\uff09}\uff08iii\uff09\\\u6807\u7b7e{iii} \\ mathcal {l} = \\ frac {1} {2}\u5de6\uff08\\ frac {y  -  \\ mu\uff08x\uff0c\\ theta_1\uff09} {\\ sigma\uff08x\uff0c\\ theta_2\uff09} \\\u53f3\uff09^ 2 + log \\\uff0c\\ left \\ {\\ \uff0c\\ sqrt {2 \\ pi} \\ cdot \\ sigma\uff08x\uff0c\\ theta_2\uff09\\\uff0c\\\u53f3\\} l = 2 1\uff08\u03c3\uff08x\uff0c\u03b82\uff09y  - \u03bc\uff08x\uff0c\u03b81\uff09\uff09 2 +\u65e5\u5fd7{2\u03c0\u22c5\u03a3\uff08x\uff0c\u03b82\uff09}\n\u6a21\u578b \u3002 eval\uff08\uff09ronal_dist = model\uff08x\uff09\uff03\u4f7f\u7528\u5f62\u72b6\uff08n\uff0cm\uff09\u7684x\u4e0a\u7684\u578b\u53f7\u5747\u503c= normal_dist\u3002\u5747\u503c\uff03\u68c0\u7d22\u4ee5\u5f62\u72b6\uff08n\uff0c\uff09std = normal_dist\u7684\u5e73\u5747\u503c\u3002 stddev\uff03\u68c0\u7d22\u6807\u51c6\u504f\u5dee\uff08n\uff0c\uff09\n\u8fd9\u79cd\u65b9\u6cd5\u5f88\u5bb9\u6613\u548c\u591a\u529f\u80fd - \u5f53\u6211\u9700\u8981\u4e00\u4e2a\u4e0d\u786e\u5b9a\u611f\u65f6\uff0c\u6211\u662f\u6211\u7684\u65b9\u6cd5\u3002", "note_en": "Understanding and modeling uncertainty surrounding a machine learning prediction is of critical importance to any production model. It provides a handle to deal with cases where the model strays too far away from its domain of applicability, into territories where using the prediction would be inacurate or downright dangerous. Think medical diagnosis or self-driving cars.\n Modeling uncertainty is a whole field of research in itself, with vast amount of theory and plethora of methods. Briefly, for simple models (such as the ubiquitous  linear regression), analytic approaches provide an exact solution. For more complex models where an exact solution is intractable, statistical sampling approaches can be used, the gold standard of which are  Markov Chain Monte Carlo methods (e.g. the state of the art  Hamiltonian Monte Carlo).\n However, when it comes to neural networks, both approaches fall short. Exact solutions are unavailable, and even the best sampling algorithms choke on the thousands \u2014 if not millions \u2014 of parameters a typical neural network is made of.\n Thankfully, even if full Bayesian uncertainty is out of reach, there exist a few other ways to estimate uncertainty in the challenging case of neural networks.\n Today, we\u2019ll explore one approach, which boils down to  parametrizing a probability distribution with a neural network.\n We\u2019ll use nothing but good ol\u2019 PyTorch, thanks to the little known   distributions package.\n     The first step is to choose an appropriate probability distribution. The choice is context dependent: in a regression setting, a Normal or LogNormal distribution may be appropriate while for classifications, one would pick a Categorical distribution. Thankfully, PyTorch   distributions package provides implementation for all the major probability distributions.\n  For simplicity\u2019s sake, we\u2019ll consider the well known Normal distribution in the following, but the approach would be similar for any other probability distribution.\n The normal distribution       N \\mathcal{N}     N with mean       \u03bc \\mu    \u03bc and standard deviation       \u03c3 \\sigma    \u03c3 is defined as follows:\n z \u223c N ( \u03bc , \u03c3 ) \u2005\u200a \u27fa \u2005\u200a P ( z \u2223 \u03bc , \u03c3 ) =  1  \u03c3   2 \u03c0 \u22c5 e x p  { \u2212  1 2   (   z \u2212 \u03bc \u03c3 ) 2 }   (i) \\tag{i} z \\sim \\mathcal{N}(\\mu, \\sigma) \\iff P(z \\mid \\mu, \\sigma) = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\cdot exp\\left\\{-\\frac{1}{2}\\left(\\frac{z - \\mu}{\\sigma}\\right)^2\\right\\}    z  \u223c     N ( \u03bc ,  \u03c3 )   \u27fa     P ( z  \u2223    \u03bc ,  \u03c3 )  =             \u03c3        2 \u03c0      \u200b          1 \u200b      \u22c5    e x p    { \u2212          2       1 \u200b         (          \u03c3       z  \u2212  \u03bc \u200b      )        2  }\n Here, \u201c      \u223c \\sim    \u223c\u201d merely means \u201csampled from\u201d, and       P ( z \u2223 \u03bc , \u03c3 ) P(z \\mid \\mu, \\sigma)    P ( z  \u2223    \u03bc ,  \u03c3 ) is the probability density function (PDF), a quantity that determines the likelihood of a value       z z    z given the distribution mean and standard deviation. Instances of Normal PDFs are shown below for various values of       \u03bc \\mu    \u03bc and       \u03c3 \\sigma    \u03c3.\n   Let\u2019s assume we are trying to model an outcome       y y    y from a set of features       x x    x. In the classical, non probabilistic setting, our neural network is represented by a function       f f    f, which depends both on the input       x x    x and the trainable parameters       \u0398 \\Theta    \u0398:\n   Looking back at the previous section, we can equate the prediction of our model with the distribution mean       \u03bc \\mu    \u03bc: not withstanding uncertainty,       \u03bc \\mu    \u03bc is the most probable outcome.\n  In turn, assuming a normal distribution is appropriate in this context, the standard deviation       \u03c3 \\sigma    \u03c3 is a good statistic to summarize the uncertainty surrounding our prediction.\n Let       \u03bc ( x ,  \u0398 1 ) \\mu(x, \\Theta_1)    \u03bc ( x ,   \u0398        1 \u200b    ) and       \u03c3 ( x ,  \u0398 1 ) \\sigma(x, \\Theta_1)    \u03c3 ( x ,   \u0398        1 \u200b    ) be two  sub networks with respective trainable parameters        \u0398 1 \\Theta_1     \u0398        1 \u200b    and        \u0398 2 \\Theta_2     \u0398        2 \u200b   .\n The mean network       \u03bc ( x ,  \u0398 1 ) \\mu(x, \\Theta_1)    \u03bc ( x ,   \u0398        1 \u200b    ) is nothing more than the original network       f f    f, i.e. the model prediction. The second network       \u03c3 ( x ,  \u0398 2 ) \\sigma(x, \\Theta_2)    \u03c3 ( x ,   \u0398        2 \u200b    ) is responsible for explicitly modeling uncertainty. From (i), we get:\n y \u223c N \u2009 [ \u2009 \u03bc ( x ,  \u0398 1 ) , \u03c3 ( x ,  \u0398 2 ) \u2009 ]   (ii) \\tag{ii} y \\sim \\mathcal{N}\\,[\\,\\mu(x, \\Theta_1), \\sigma(x, \\Theta_2)\\,]    y  \u223c     N  [  \u03bc ( x ,   \u0398        1 \u200b    ) ,  \u03c3 ( x ,   \u0398        2 \u200b    )  ]\n Note that in practice,        \u0398 1 \\Theta_1     \u0398        1 \u200b    and        \u0398 2 \\Theta_2     \u0398        2 \u200b    overlap, i.e. the two networks share their first few layers. (We\u2019ll look at an in-depth example later on.)\n We now have two sub-networks, with both shared and distinct parameters. We\u2019d really like to train them jointly, using a single loss function.\n The probability density function of equation (i) is an ideal candidate: the trick is to maximize the likelihood of observing       y y    y, which the PDF represents exactly.\n It is best to take the logarithm of the PDF rather than dealing with the pesky exponential. Plus, PyTorch expects a function to minimize, so we are negating the quantity: the loss function is the  negative log likelihood of observing       y y    y given       x x    x,        \u0398 1 \\Theta_1     \u0398        1 \u200b    and        \u0398 2 \\Theta_2     \u0398        2 \u200b   :\n L =  1 2   (   y \u2212 \u03bc ( x ,  \u0398 1 )  \u03c3 ( x ,  \u0398 2 ) ) 2 + l o g \u2009  { \u2009   2 \u03c0 \u22c5 \u03c3 ( x ,  \u0398 2 ) \u2009 }   (iii) \\tag{iii} \\mathcal{L} = \\frac{1}{2}\\left(\\frac{y - \\mu(x, \\Theta_1)}{\\sigma(x, \\Theta_2)}\\right)^2 + log\\,\\left\\{\\,\\sqrt{2\\pi}\\cdot\\sigma(x, \\Theta_2)\\,\\right\\}     L  =             2       1 \u200b         (          \u03c3 ( x ,   \u0398        2 \u200b    )       y  \u2212  \u03bc ( x ,   \u0398        1 \u200b    ) \u200b      )        2  +    l o g     {         2 \u03c0      \u200b     \u22c5  \u03c3 ( x ,   \u0398        2 \u200b    )   }\n Notice how we recovered the  square of difference term       ( y \u2212 \u03bc  ) 2 (y - \\mu)^2    ( y  \u2212    \u03bc  )        2 from the classic mean squared error, decorated with terms dependent on the standard deviation.\n This is it, we have parametrized the normal distribution with a neural network and devised an appropriate loss function. Every input gets its own unique set of mean (prediction) and standard deviation (uncertainty) neatly calibrated from optimization of the PDF.\n   We\u2019ll use data from the  OLS Regression Challenge, where the goal is to predict cancer mortality rates in US counties based on a number of socio-demographic variables such as median age, income, poverty rate, unemployment rate, etc.\n We won\u2019t be discussing the dataset or data prep steps any further, but the code to reproduce is available on  this jupyter notebook.\n  class  DeepNormal ( nn . Module ):  def  __init__ ( self ,  n_inputs ,  n_hidden ):  super (). __init__ ()  # Shared parameters  self . shared_layer  =  nn . Sequential (  nn . Linear ( n_inputs ,  n_hidden ),  nn . ReLU (),  nn . Dropout (),  )  # Mean parameters  self . mean_layer  =  nn . Sequential (  nn . Linear ( n_hidden ,  n_hidden ),  nn . ReLU (),  nn . Dropout (),  nn . Linear ( n_hidden ,  1 ),  )  # Standard deviation parameters  self . std_layer  =  nn . Sequential (  nn . Linear ( n_hidden ,  n_hidden ),  nn . ReLU (),  nn . Dropout (),  nn . Linear ( n_hidden ,  1 ),  nn . Softplus (),  # enforces positivity  )  def  forward ( self ,  x ):  # Shared embedding  shared  =  self . shared_layer ( x )  # Parametrization of the mean  \u03bc  =  self . mean_layer ( shared )  # Parametrization of the standard deviation  \u03c3  =  self . std_layer ( shared )  return  torch . distributions . Normal ( \u03bc ,  \u03c3 )\n The bulk of the implementation should look familiar: network layers (including trainable parameters) are defined in the  __init__ function, then the  forward function pieces everything together.\n         model . eval () normal_dist  =  model ( x )  # evaluate model on x with shape (N, M) mean  =  normal_dist . mean  # retrieve prediction mean with shape (N,) std  =  normal_dist . stddev  # retrieve standard deviation with shape (N,)\n       Different instances get different uncertainty profiles since       \u03bc \\mu    \u03bc and       \u03c3 \\sigma    \u03c3 both depend on       x x    x:\n   One way to find out is to  compare uncertainty to a measure of how  surprinsing or  unexpected an input is. Unexpected inputs should correlate with higher uncertainty (e.g. a self-driving car encountering a rare weather event).\n For our purpose here, unexpectedness is measured as the average deviation from the median of an instance\u2019s feature values. The most extreme the feature values, the more unexpected an instance.\n  There is an upward trend: uncertainty tends to grow with less expected inputs, just as it should.\n   In this post, we modeled uncertainty using the Normal distribution, but there are a plethora of other distributions available for different problems.\n   The benefit is an estimate of uncertainty around the model prediction, at the cost of a few extra layers.\n This approach is easy and versatile \u2014 it is my go to method when I need a sense of uncertainty.", "posttime": "2022-01-09 22:14:51", "source_domain": "news.ycombinator.com", "source_name": "Hacker News", "tags": "\u5efa\u6a21,uncertainty,\u6a21\u578b", "title": "\u7528Pytorch\u5efa\u6a21\u4e0d\u786e\u5b9a\u6027", "title_en": "Modeling Uncertainty with PyTorch", "transed": 1, "url": "https://romainstrock.com/blog/modeling-uncertainty-with-pytorch.html", "via": "", "real_tags": ["\u5efa\u6a21", "\u6a21\u578b"]}, {"category": "", "categoryclass": "", "imagename": "", "infoid": 1072482, "ip": "", "isanchordig": 1, "ischecked": 1, "isdelete": 0, "isneo": 1, "mark": "", "name": "", "note": "\u53d1\u5e03\u60a8\u5e0c\u671b\u6839\u636e\u5e94\u7528\u7a0b\u5e8f\u6570\u636e\uff08\u5982\u7528\u6237ID\u6216\u7528\u6237\u5fe0\u8bda\u5ea6\uff09\u6c47\u7387\u9650\u5236\u8bf7\u6c42\u3002\u4f46\u662f\uff0c\u60a8\u5e0c\u671b\u5728\u5e94\u7528\u7a0b\u5e8f\u5c42\u4e4b\u524d\u5e94\u7528\u901f\u7387\u9650\u5236\uff0c\u56e0\u6b64\u60a8\u65e0\u6cd5\u4fe1\u4efb\u5ba2\u6237\u63d0\u4f9b\u7684\u503c\u3002\n\u5982\u679c\u60a8\u8bd5\u56fe\u9632\u6b62DOS\u653b\u51fb\u786e\u4fdd\u9a8c\u8bc1\u8db3\u591f\u4fbf\u5b9c\u3002\n\u9a8c\u8bc1\u6210\u672c\u53ef\u80fd\u5f88\u4f4e\u3002\u8fd9\u662f\u56e0\u4e3a\u60a8\u4e00\u822c\u60f3\u8981\u9a8c\u8bc1\u8eab\u4efd\u9a8c\u8bc1\u7684\u8bf7\u6c42\u7684Auth-\u4ee4\u724c\uff0c\u5e76\u4e14\u9a8c\u8bc1Auth-token\u901a\u5e38\u4f1a\u7ed9\u60a8\u63d0\u4f9b\u8db3\u591f\u7684\u4fe1\u606f\u4ee5\u9a8c\u8bc1\u901f\u7387\u9650\u5236\u8bbe\u7f6e\uff08\u4f8b\u5982\u7528\u6237ID\uff09\u3002\u4f46\u662f\u5bf9\u4e8e\u516c\u5171\u4fe1\u606f\u7684\u8bf7\u6c42\uff0c\u53ef\u80fd\u4f1a\u5426\u5219\u53ef\u80fd\u4f1a\u4e0d\u5fc5\u8981\u5730\u63d0\u9ad8\u670d\u52a1\u8bf7\u6c42\u7684\u603b\u6210\u672c\u3002", "note_en": "Posted    You want to rate limit requests based on application data such as User ID or User Loyalty. However you want to apply rate-limiting before the application layer, so you have no way to trust the client provided values.\n This is a common problem, making the industry-standard approach rate limiting by IP (or CIDR block). In fact some  popular  CDNs only support rate-limits keyed by IP. Unfortunately IP-based limiting usually insufficient as it either allows too much malicious traffic or blocks a significant number of legitimate users (imagine a lot of users behind a carrier-grade or office NAT).\n  Pass the application info in a proxy-visible part of the request such as a cookie.\n  Configure the rate limiter to use the application info. (likely falling back to IP-based keys)\n  The application must validate the info and provide a \u201cuseless\u201d response if it isn\u2019t accurate.\n Step 1 and 2 are quite obvious but step 3 is the secret ingredient to allow a \u201cdumb\u201d proxy to apply rate-limiting based on application values. Step 3 ensues that spoofed values don\u2019t provide any value to the attacker, defeating the purpose of spoofing them in the first place.\n Note that \u201cvalue to the attacker\u201d can be very broad, so make sure that it reflects your rate limiting goals.\n If you are trying to prevent DoS attacks ensure that the validation is sufficiently cheap.\n  If you are trying to prevent scraping ensure that you don\u2019t return any valuable data.\n  If the information is being passed in a cookie unset (or correct) the cookie and redirect the user to the same URL.\n  NGINX can support this quite easily. Here is an example of rate limiting by User ID which is passed in the  uid cookie.\n  This snippet applies the same limit to users and IPs but two  limit_req_zones can be used to enforce different limits for each group.\n   Be sure that you don\u2019t lock out a user based on a mismatch. For example if you use an auth-token in the cookie to validate the user ID don\u2019t return a 401 if the auth token is expired or revoked. This will result in the user having all request blocked with no obvious way to fix the problem. (Your support team will probably need to ask them to clear their cookies).\n As mentioned above a better option would be to clear the untrusted data so that the user reverts to the regular IP-based filtering.\n  The cost of validation is likely low. This is because you will generally want to validate the auth-token for authenticated requests anyways and validating the auth-token will often give you enough information to validate the rate-limiting settings anyways (for example the user ID). However for requests for public information this validation may be otherwise unnecessary and raise the overall cost of serving the requests.\n Unfortunately I don\u2019t know of any great solutions, this is a cost of rate limiting based on authentication, you actually need to perform the authentication! One workaround is excluding requests for public data from rate limiting, then you don\u2019t need to validate the authentication information. However be sure that the requests that bypass the rate-limit in sync between the rate-limiter and the application as any endpoint that isn\u2019t validated is effectively unlimited (as an attacker can send a random rate-limit key for each request). One easy way to keep this in-sync is to strip the rate-limit key from the request before passing it to the application, then the application doesn\u2019t have anything to validate. This approach will reduce the cost but will leave the application exposed to scrapers, using a very high IP-based rate limit may be enough to prevent the worst attacks without affecting many legitimate requests.\n   Passing the rate-limiting info via cookie is an easy option because it is automatically added by the browser to all subsequent requests, however basically any method will work, including URL parameters or custom headers. Just be careful about locking a user out. If you are using a custom method to pass the rate-limiting information you need to ensure that all of your clients will gracefully handle a request that has been rejected due to mismatched rate-limiting information.\n  If you have a flexible enough rate-limiting system you can even set the rate limit based on the application data. For example logged-in users may get 10r/s but logged in users who have spent at least $20 can make 20r/s. This can be a good way to prevent the effectiveness of account-spamming while serving your most loyal customers reliably.", "posttime": "2022-01-09 22:14:23", "source_domain": "news.ycombinator.com", "source_name": "Hacker News", "tags": "\u901f\u7387,rate,\u9a8c\u8bc1", "title": "\u6bcf\u7528\u6237\u901f\u7387\u9650\u5236", "title_en": "Per-User Rate Limiting", "transed": 1, "url": "https://kevincox.ca/2021/04/14/per-user-rate-limiting/", "via": "", "real_tags": ["\u901f\u7387", "rate", "\u9a8c\u8bc1"]}]