<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>lmgrep：基于卢诺的Grep型实用程序 Lmgrep: Lucene-based grep-like utility</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">Lmgrep: Lucene-based grep-like utility<br/>lmgrep：基于卢诺的Grep型实用程序 </h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2021-04-26 10:26:52</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2021/4/19b17ae62623e1f3a52b0917d12f5316.png"><img src="http://img2.diglog.com/img/2021/4/19b17ae62623e1f3a52b0917d12f5316.png" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>What if  grep supported the functionality of a proper search engine like Elasticsearch without a need to install any servers or index the files before searching?  lmgrep aims to provide you just that.It is installed as just one executable file without any dependencies, provides a command-line interface, starts-up instantly, and works on macOS, Linux, and, yes, even Windows.</p><p>如果Grep支持像Elasticsearch这样的适当搜索引擎的功能，而无需在搜索之前安装任何服务器或索引文件？ LmgRep旨在为您提供。它只是只安装了一个没有任何依赖项的可执行文件，提供命令行界面，即时启动，并在麦斯卡斯，Linux上工作，甚至是Windows。</p><p>   Have you ever wished that  grep supported tokenization, stemming, etc, so that you don’t have to write wildcard regular expressions all the time? I’ve also shared that question and on a one nice day, I’ve tried to scratch that itch by exposing the Lucene query syntax as a CLI utility.  lmgep is the result of my effort. Give it a try and let me know how it goes.</p><p>   您是否曾希望获得Grep支持的令牌化，令人遗憾的等，因此您无需一直在写通配符？我还在一个愉快的日子里分享了这个问题，我试图通过将Lucene查询语法作为CLI实用程序揭示瘙痒。 LMGEP是我努力的结果。试一试，让我知道它是怎么回事。</p><p>  I’m perfectly aware that comparing Lucene and  grep is like comparing apples to oranges. However, I think that  lmgrep is best compared with the very tool that inspired it, namely  grep.</p><p>  我完全意识到比较Lucene和Grep就像将苹果与橘子的比较一样。但是，我认为与激励它的工具相比，Lmgrep最好，即Grep。</p><p> Anyway, what does  grep do?  grep reads a line from  stdin, examines the line to see if it should be forwarded to  stdout, and repeats until stdin is exhausted  1.  lmgrep tries to mimick exactly that functionality. Of course, there are many more options to  grep but it is the essence of the tool.</p><p> 无论如何，Grep做了什么？ Grep读取STDIN的一行，检查该行以查看它是否应该转发到STDOUT，并重复直到STDIN耗尽1. LMGREP尝试完全模仿该功能。当然，Grep还有更多选项，但这是工具的本质。</p><p>      Lucene is a Java library that provides indexing and search features. Lucene has been more than 20 years in development and it is the library that powers many search applications. Also, many developers are already familiar with the Lucene query syntax and know how to leverage it to solve complicated information retrieval problems.</p><p>      Lucene是一个提供索引和搜索功能的Java库。 Lucene在发展中已经超过了20年的发展，并且是赋予许多搜索应用程序的图书馆。此外，许多开发人员已经熟悉了Lucene查询语法，并且知道如何利用它来解决复杂的信息检索问题。</p><p> However powerful Lucene is, it is not well-suited for CLI application. The main problem is the startup time of JVM. To reduce the startup time I’ve compiled  lmgrep with the  native-image tool provided by GraalVM. In this way, the startup time is around 0.01s for Linux, macOS, and Windows.</p><p> 然而，强大的lucene是，它不适合CLI应用。主要问题是JVM的启动时间。要减少启动时间，我将使用Graalvm提供的本机映像工具编译Lmgrep。通过这种方式，启动时间为Linux，MacOS和Windows的0.01s。</p><p>  lmgrep by default expects two parameters: a search query and a GLOB pattern (similar to regexp) to find files to execute  lmgrep on. I assume that the dear reader doesn’t want to be tortured by reading the explanation on how the file names are being matched with GLOB, so I’ll skip it. Instead, I’ll focus on explaining how the search works within a file.</p><p>  lmgrep默认期望两个参数：搜索查询和Glob模式（类似于Regexp），以查找文件以执行Lmgrep On。我假设亲爱的读者通过阅读关于文件名如何与Glob匹配的解释，不希望被折磨，因此我会跳过它。相反，我将专注于解释搜索如何在文件中工作。 </p><p> lmgrep creates a Lucene Monitor (Monitor) object from the provided search query. Then text file is split into lines  2. Each line of text is passed to the Monitor for searching. The Monitor then creates an in-memory Lucene index with a single document created out of the line of text. Then the Monitor runs the search query on that in-memory index in the good ol&#39; Lucene way  3.  lmgrep takes the hits, formats them, and sends results to  STDOUT. That is how  lmgrep does the full-text search.</p><p>Lmgrep从提供的搜索查询创建一个Lucene Monitor（监视器）对象。然后将文本文件拆分为行2.每行文本都传递给监视器以进行搜索。然后，监视器创建内存内存LuceNe索引，其中包含从文本行中创建的单个文档。然后，监视器在良好的OL＆＃39中运行搜索查询。 Lucene Way 3. Lmgrep采用命中，格式化它们，并将结果发送到STDOUT。这就是LMGREP如何完成全文搜索。</p><p> The overall searching approach is similar to the one of Percolator in Elasticsearch.  lmgrep just limits the number of stored search queries to one and treats every text line as a document. A cool thing compared with the Percolator is that  lmgrep provides exact offsets of the matched terms while Elasticsearch does not expose offsets when highlighting.</p><p> 整体搜索方法类似于Elasticsearch中的渗滤器之一。 lmgrep仅限于将存储的搜索查询的数量限制为一个，并将每个文本行视为文档。与过滤器相比的冷却件是Lmgrep提供匹配项的精确偏移，而Elasticsearch在突出显示时不会暴露偏移量。</p><p> The described procedure seems to be somewhat inefficient. However, the  query parsing for  all the lines (and files) is done only once. Also, the searching itself is efficient thanks to Lucene in general and when queries are complicated thanks to the Presearcher of the Lucene Monitor in particular. Presearcher extracts terms from the search query and if none of these terms are in the index then a full query is not executed at all. Of course, many optimizations can be (and will be) implemented for  lmgrep such as batching of the documents. In general, the performance is limited by the Lucene Monitor.</p><p> 所描述的程序似乎有点低效。但是，所有行（和文件）的查询解析仅完成一次。此外，由于尤其感谢Lucene的研究人员，搜索本身是有效的，感谢Lucene，并且当尤其是Lucene显示器的PRESECHERS。 Presearcher从搜索查询中提取术语，如果这些术语中的任何一个都不在索引中，则根本不会执行完整查询。当然，许多优化可以是（并且将是）用于Lmgrep，例如批量文件。通常，性能受到Lucene监视器的限制。</p><p> What about the text analysis pipeline? By default,  lmgrep uses the  StandardTokenizer to tokenize text. Then the tokens are passed through several token filters in the following order:  LowerCaseFilter,  ASCIIFoldingFilter, and  SnowballFilter which is given the  EnglishStemmer. The same analysis pipeline is used for both the indexing and querying. All the components of the analysis pipeline are configurable via CLI flags, see the README. However, the order of the token filters, as of now, is not configurable. Moreover, various filters are not exposed at all (e.g.  StopwordsFilter, or WordDelimiterGraphFilter, etc.). Supporting a more flexible analysis pipeline configuration is left out for future releases. The more users the tool has the faster new features will be implemented ;)</p><p> 文本分析管道怎么样？默认情况下，Lmgrep使用StandardTokenizer授权文本。然后，令牌按以下顺序通过多个令牌过滤器：给出了英国系统的小孩子Filter，AsciifoldingFilter和Snowballfilter。相同的分析管道用于索引和查询。分析管道的所有组件可通过CLI标志配置，请参阅自述文件。但是，令牌过滤器的顺序，截至目前，不可配置。此外，各种滤波器根本不暴露（例如，秒表Filter，或WordDelimiterGraphFilter等）。支持更灵活的分析管道配置遗漏了未来的版本。该工具具有更快的新功能的用户将实现更快;）</p><p>  Almost every NLP project that I’ve worked on had the component called  dictionary annotator. Also, the vast majority of the projects used Elasticsearch in one way or another. The more familiar I’ve got with Elasticsearch I’ve got, the more of my NLP workload shifted towards implementing it inside Elasticsearch. One day I’ve discovered a tool called Luwak (a cool name isn’t it?) and read more about it. It kind of opened my eyes: the dictionary annotator can be implemented using Elasticsearch and the dictionary entries can be expressed as Elasticsearch queries. Thankfully, Elasticsearch has Percolator that hides all the complexity of managing temporary indices, batching search requests, etc.</p><p>  几乎每个我工作的NLP项目都有一个名为Dictionary Annotator的组件。此外，绝大多数项目以某种方式使用弹性研究。我越熟悉的是我所拥有的Elasticsearch，我的NLP工作量越多，就会在Elasticsearch内实现它。有一天，我发现了一个名为luwak的工具（一个很酷的名字不是它？）并阅读更多关于它的东西。它有点睁开眼睛：可以使用弹性研究可以实现字典注释器，并且字典条目可以表示为Elasticsearch查询。谢天谢地，Elasticsearch具有隐藏管理临时指标，批处理搜索请求等的所有复杂性的渗滤器。</p><p> Then I was given was an NLP project where one of the requirements was to implement data analysis using AWS serverless stuff: Lambda for text processing and Dynamo DB for storage. Of course, one of the required NLP components was a dictionary annotator. Since Elasticsearch was not available (because it is not serverless) I still wanted to continue working with dictionary entries as search queries, I’ve decided to leverage the Luwak library. From experiences of that project, the Beagle library was born.  lmgrep is loosely based on Beagle.</p><p> 然后我被给出了一个NLP项目，其中一个要求是使用AWS无法的东西来实现数据分析：Lambda用于文本处理和用于存储的Dynamo DB。当然，其中一个必需的NLP组件是字典注释器。由于Elasticsearch不可用（因为它不是无服务器），我仍然希望继续使用字典条目作为搜索查询，我决定利用Luwak图书馆。来自该项目的经验，比猎犬库出生。 Lmgrep松散地基于比猎犬。</p><p> When thinking about how to implement  lmgrep I wanted it to be based on Lucene because of the full-text search features. To provide a good experience the start-up time must be small. To achieve it,  lmgrep had to be compiled with the  native-image tool of the GraalVM. I’ve tried but the  native-image doesn’t support Method Handles that Lucene uses. Some more hacking was needed. I was lucky when I’ve discovered a toy project where the blog search was implemented on AWS Lambda that was backed by Lucene which was compiled by the  native-image tool. I’ve cloned the repo,  mvnw install, then included the artefacts to the dependencies list, and  lmgrep compiled with the  native-image tool successfully.</p><p> 在考虑如何实现LMGREP时，我希望它基于Lucene，因为全文搜索功能。为了提供良好的体验，启动时间必须很小。为了实现它，Lmgrep必须使用Graalvm的本机图像工具编译。我尝试过，但本地图像不支持方法处理Lucene使用。需要更多的黑客攻击。当我发现一个玩具项目时，我很幸运，其中博客搜索在AWS Lambda上由Lucene支持的leune，它由本机映像工具编译。我克隆了repo，mvnw安装，然后将文物包含在依赖关系列表中，并成功地使用本机映像工具编译了lmgrep。 </p><p> Then the most complicated part was to prepare executable binaries for different operating systems. Plenty of CPU, RAM, VirtualBox with Windows and macOS virtual machines, and here we go.</p><p>然后最复杂的部分是为不同的操作系统制作可执行的二进制文件。充足的CPU，RAM，VirtualBox与Windows和MacOS虚拟机，我们走了。</p><p> Did I say how much I enjoyed trying to get stuff done on Windows? None at all. How come that multiple different(!) command prompts are needed to get GraalVM to compile an executable? Now I know that it would a lot better to suffer the pain and to set up the Github Actions pipeline to compile the binaries and upload them to release pages.</p><p> 我说我有多喜欢试图在Windows上完成的东西吗？一个都没有。如何多个不同（！）命令提示来获取GRAALVM编译可执行文件？现在我知道遭受痛苦并设置GitHub操作管道将要编译二进制文件并将其上传到释放页面。</p><p>  The analysis pipeline is not as flexible as I’d like to (UPDATE 2021-04-24: implemented);</p><p>  分析管道不像我想的那样灵活（更新2021-04-24：实施）;</p><p>  Give an alias for  lmgrep with various options tailored for the code search (Java Example);</p><p>  为代码搜索量身定制的各种选项（Java示例）为Lmgrep提供Lmgrep的别名;</p><p>   Static website search, like AWS Lambda that has lmgrep and goes through all files on demand without upfront indexing.</p><p>   静态网站搜索，如AWS Lambda，它具有Lmgrep，并在没有提升索引的情况下通过所有文件进行所有文件。</p><p>  lmgrep scratched my itch. It was exciting to get it working. I hope that you’ll also find it interesting and maybe useful. Give it a try, let me know how it was for you, and most importantly any feedback welcome on how to improve  lmgrep.</p><p>  lmgrep抓了我的痒。让它工作很令人兴奋。我希望你也发现它有趣，也许有用。请尝试一下，让我知道如何为您，以及最重要的是有关如何改善Lmgrep的任何反馈欢迎。</p><p>    there is no necessity to split text files into lines, it is just to mimik how  grep operates.  ↩︎</p><p>    没有必要将文本文件拆分为行，它只是mimik如何运行。 ↩︎ </p><p> of course, the description is over-simplified, but it is accurate enough to get the overall idea.  ↩︎</p><p>当然，描述过于简化，但它足以获得整体想法。 ↩︎ </p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://www.jocas.lt/blog/post/intro-to-lucene-grep/">https://www.jocas.lt/blog/post/intro-to-lucene-grep/</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/程序/">#程序</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/卢诺/">#卢诺</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/lucene/">#lucene</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/搜索/">#搜索</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/分享/">#分享</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy;2012-2021 diglog.com </div></div></body></html>