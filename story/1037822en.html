<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Coinbase：从MongoDB到PostgreSQL的无缝迁移 Coinbase: Seamless MongoDB to PostgreSQL Migration</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">Coinbase: Seamless MongoDB to PostgreSQL Migration<br/>Coinbase：从MongoDB到PostgreSQL的无缝迁移 </h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2020-12-05 06:45:59</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2020/12/37e924a3f23b5ec9c95cdbd2c40b1094.png"><img src="http://img2.diglog.com/img/2020/12/37e924a3f23b5ec9c95cdbd2c40b1094.png" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>If you’re interested in distributed systems and building reliable shared services to power all of Coinbase, the Platform team is   hiring !</p><p>如果您对分布式系统以及构建可靠的共享服务以支持所有Coinbase感兴趣，那么Platform团队正在招聘！</p><p> In 2019, Coinbase set out to strengthen the infrastructure upon which its products are built and to create a solid foundation to support current and future product lines. As part of that effort, we decided to adopt AWS RDS PostgreSQL as our database of choice for relational workloads and AWS DynamoDB as our key-value store.</p><p> 在2019年，Coinbase着手加强其产品构建的基础设施，并为支持当前和未来的产品线奠定坚实的基础。作为这项工作的一部分，我们决定采用AWS RDS PostgreSQL作为关系工作负载的首选数据库，并采用AWS DynamoDB作为键值存储。</p><p> One of the first areas we decided to focus on was how to keep track of balances and move funds. Our products had each devised their own solutions and some legacy systems were also plagued by tech debt and performance issues. The ability to quickly and accurately process transactions is central to Coinbase’s mission to build an open financial system for the world.</p><p> 我们决定重点关注的第一个领域是如何跟踪余额和转移资金。我们的产品各自设计了自己的解决方案，并且某些遗留系统也受到技术债务和性能问题的困扰。快速准确地处理交易的能力是Coinbase建立面向全球的开放财务系统的使命的核心。</p><p> We designed and built a new ledger service to be fast, accurate and serve all current and future needs across products and have undertaken our biggest migration as of yet, moving over 1 billion rows of corporate and customer transaction and balance information from MongoDB to our new PostgreSQL-based solution, without scheduled maintenance and no perceptible impact to users.</p><p> 我们设计并构建了一种新的分类帐服务，以快速，准确地满足产品中所有当前和将来的需求，并进行了迄今为止最大的迁移，将超过10亿行公司和客户交易以及余额信息从MongoDB移动到了新的基于PostgreSQL的解决方案，无需定期维护，也不会对用户产生明显影响。</p><p>  Make it uneventful — By designing the process so that it runs without disrupting normal business operations.</p><p>  使过程变得平稳—通过设计流程使其运行而不会中断正常的业务运营。</p><p>   Accuracy and Correctness: Since we’re dealing with funds, we knew this would be a very sensitive migration and wanted to take every precaution, make sure that every last satoshi is accounted for.</p><p>   准确性和正确性：由于我们在处理资金问题，因此我们知道这将是非常敏感的迁移，因此，我们会采取一切预防措施，确保将每一个最后的麻烦都考虑在内。</p><p> Repeatable: Additionally, the shape of our data was completely different in the new system vs the legacy system. Further, we had to deal with technical debt and cruft accumulated over time in our monolithic application. We knew we needed to account for the possibility of not getting everything right in a single go, so we wanted to devise a repeatable process that we could iterate on until getting it right.</p><p> 可重复性：此外，新系统与旧系统的数据形状完全不同。此外，我们不得不处理整体应用程序中随着时间推移而积累的技术债务和杂项。我们知道我们需要考虑一次无法正确解决所有问题的可能性，因此我们想设计一个可重复的过程，我们可以反复进行此过程，直到正确为止。 </p><p> No Maintenance Downtime: We wanted every transaction on Coinbase to execute while working on this. We didn’t want to do any scheduled maintenance or take any downtime for the transition.</p><p>无需维护停机时间：我们希望Coinbase上的每笔交易都能在执行的同时执行。我们不想进行任何计划的维护，也不想花任何停机时间进行过渡。</p><p>  We can deconstruct the migration into 2 separate problems: Switching live writes and reads over the new service, and migrating all of the historical data into the new service.</p><p>  我们可以将迁移分解为两个独立的问题：切换实时写入和读取新服务，以及将所有历史数据迁移到新服务中。</p><p>  For the migration we decided to take a dual-write / dual-read phased approach. Phase 1 is before the migration, where we only have the legacy system in place. In Phase 2, we introduce the new system. We dual write to both the legacy and new system the read path we read from both, then log discrepancies and return the result from the legacy system. With Phase 3, we’ve built up the confidence in our new setup, so we favor it when returning results. We still have the old system around and can switch back to it if needed. Finally, we phase out unused code to finish the migration (Phase 4).</p><p>  对于迁移，我们决定采用双重写入/双重读取阶段方法。第1阶段是迁移之前的阶段，在该阶段中，我们只有旧系统。在阶段2中，我们介绍了新系统。我们将从两者读取的读取路径双重写入旧系统和新系统，然后记录差异并从旧系统返回结果。在第3阶段，我们增强了对新设置的信心，因此在返回结果时会偏爱它。我们仍然有旧系统，可以根据需要切换回旧系统。最后，我们逐步淘汰未使用的代码以完成迁移（第4阶段）。</p><p> We won’t go into details about our dual-write implementation, since the general idea has been previously covered by industry  blog  posts.</p><p> 我们不会详细介绍双重写入的实现方式，因为业界博客文章以前已经涵盖了总体思路。</p><p> What’s interesting is something that happens in between Phase 2 and Phase 3, namely the backfill of all customer data into our new system so that we can achieve parity.</p><p> 有趣的是，在第2阶段和第3阶段之间发生了一些事情，即将所有客户数据回填到我们的新系统中，以便我们可以实现奇偶校验。</p><p>  We considered multiple approaches to backfilling the billion-plus rows that represent all the transactions carried out on Coinbase from its inception, all with pros and cons.</p><p>  我们考虑了多种方法来回填十亿多行，这些行代表了从一开始就在Coinbase上进行的所有交易，各有利弊。</p><p> The most straightforward solution would have been to do it all at the application level, leveraging the ledger client implementation we had in place for the dual writes. It has the advantage of exercising the same code paths we have in place for live writes — there would be a single mapping from old to new to maintain. However, we would have had to modify the service interface to allow for the backfill and we would have had to set up long running processes together with a checkpointing mechanism in case of failure. We also benchmarked this solution, and found that it would be too slow to meet our requirements for fast iteration.</p><p> 最直接的解决方案是在应用程序级别上完成所有工作，利用我们为双重写入而设置的分类帐客户端实现。它的优点是可以执行与实时写入相同的代码路径-从旧到新只有一个映射才能维护。但是，我们将不得不修改服务接口以允许回填，并且在发生故障的情况下，我们必须建立长时间运行的进程以及检查点机制。我们还对该解决方案进行了基准测试，发现它太慢了，无法满足我们对快速迭代的要求。 </p><p> We eventually decided to pursue an ETL-based solution. At a high level, this entailed generating the backfill data from the ETL-ed source database, dumping it into S3 and loading it directly into the target Postgres database. One key advantage to this approach is that doing data transformation using SQL is fast and easy. We could run the entire data generation step in ~20 minutes, examine the output, verify internal consistency and do data quality checks directly on the output without having to run the entire backfill pipeline.</p><p>我们最终决定采用基于ETL的解决方案。从高层次上讲，这需要从ETL版本的源数据库中生成回填数据，并将其转储到S3中，然后直接将其加载到目标Postgres数据库中。这种方法的一个主要优点是使用SQL进行数据转换既快速又容易。我们可以在大约20分钟内运行整个数据生成步骤，检查输出，验证内部一致性，并直接在输出上进行数据质量检查，而不必运行整个回填管道。</p><p> Our data platform provider offers a variety of connectors and drivers for programmatic access. This means that we could use our standard software development tools and lifecycle — the code that we wrote for the data transformation was tested, reviewed and checked into a repository.</p><p> 我们的数据平台提供商提供了用于程序访问的各种连接器和驱动程序。这意味着我们可以使用我们的标准软件开发工具和生命周期-我们为数据转换编写的代码已经过测试，审查和检入存储库。</p><p> It also has first-class support for unloading data into S3, which made it easy for us to export the data after provisioning the appropriate resources.</p><p> 它还具有一流的支持，可以将数据卸载到S3中，这使我们在配置适当的资源后可以轻松导出数据。</p><p> One the other end, AWS provides the  aws_s3 postgres extension, which allows bulk importing data into a database from an S3 bucket. Directly importing into live, production tables however proved problematic, since inserting hundreds of millions of rows into indexed tables is slow, and it also affected the latency of live writes.</p><p> 另一端，AWS提供了aws_s3 postgres扩展，该扩展允许从S3存储桶将数据批量导入数据库。但是，直接将其导入实时生产表存在问题，因为将数亿行插入索引表很慢，并且还影响了实时写入的延迟。</p><p>    The import now becomes limited by the I/O, which becomes a bottleneck. We ended up slowing it down a bit by splitting the data into multiple files and adding short sleep intervals in between the sequential imports.</p><p>    现在，导入受到I / O的限制，这成为了瓶颈。通过将数据拆分为多个文件，并在顺序导入之间添加了较短的睡眠间隔，我们最终降低了速度。</p><p> Next up, recreating the indexes on the tables. Luckily, Postgres allows for index creation without write-locking the table, by using the  CONCURRENT keyword. This allows the table to continue taking writes while the index is being created.</p><p> 接下来，在表上重新创建索引。幸运的是，Postgres通过使用CONCURRENT关键字，可以在不写锁定表的情况下创建索引。这允许表在创建索引时继续进行写操作。</p><p> So far, so good. The real complexity however comes from our requirement to have a migration that doesn’t involve scheduled maintenance or halting transaction processing. We want the target database to be able to sustain live writes without missing a single one, and we want the backfilled data to seamlessly connect to the live data. This is further complicated by the fact that every transaction stores information about the cumulative balances of all accounts involved — this makes it easy for us to evaluate and maintain data integrity and to look up point in time balances for any account at any timestamp.</p><p> 到现在为止还挺好。但是，真正的复杂性来自我们对迁移的要求，该迁移不涉及计划的维护或停止事务处理。我们希望目标数据库能够维持实时写入而不会丢失单个写入，并且我们希望回填的数据无缝连接到实时数据。每个事务都存储有关所涉及的所有帐户的累计余额的信息，这使情况变得更加复杂-这使我们可以轻松地评估和维护数据完整性，并在任何时间戳下查找任何帐户的时间点余额。 </p><p> We solved for this by using triggers that replicate inserts, updates, deletes to the live tables into the backfill tables. Our concurrent index generation allows us to write to these tables while the indexes are being created.</p><p>为此，我们使用触发器将活动表的插入，更新，删除复制到回填表中，从而解决了这一问题。通过并发索引生成，我们可以在创建索引时写入这些表。</p><p> After indexing is complete, in a single transaction, we flipped the backfill and live tables, drop the triggers, and drop the now unneeded tables. Live writes continue as if nothing happened.</p><p> 索引完成后，在单个事务中，我们翻转了回填表和活动表，删除了触发器，并删除了现在不需要的表。实时写操作继续进行，好像什么也没发生。</p><p> At the end of this process, we run another script that goes through all of the data and restores data integrity by recreating the cumulative balances and the links between sequential transactions.</p><p> 在此过程的最后，我们运行另一个脚本，该脚本遍历所有数据并通过重新创建累积余额和顺序事务之间的链接来恢复数据完整性。</p><p> Last but not least, we run another round of integrity checks and comparisons against the legacy datastore to make sure that the data is correct and complete.</p><p> 最后但并非最不重要的一点是，我们针对旧数据存储库进行了另一轮完整性检查和比较，以确保数据正确且完整。</p><p>  Wait for dual written data to be loaded into ETL, so that we have overlap between live written data and backfill data.</p><p>  等待将双重写入数据加载到ETL中，以便实时写入数据和回填数据之间存在重叠。</p><p> The process would take 4 to 6 hours to run and was mostly automated. We did this over and over while working through data quality issues and fixing bugs.</p><p> 该过程需要4到6个小时才能运行，并且大部分是自动化的。我们在解决数据质量问题和修复错误时一遍又一遍地做。</p><p>  Our final migration and backfill was not a memorable one. We didn’t have a “war room”, no standby on-call engineers, just another run of our process after which we decided that it was time to flip the switch. Most people within the company were blissfully unaware. An uneventful day.</p><p>  我们最后的迁移和回填并不令人难忘。我们没有“作战室”，没有待命的值班工程师，只是我们流程的另一轮运行，之后我们决定是时候进行切换了。公司中的大多数人都不高兴。平稳的一天。 </p><p> We’ve been live with the ledger service for almost a year now. We have the capacity to sustain orders of magnitude more transactions per second than with our previous system, and with tight bounds on latency. Existing and new features, such as the  Coinbase Card, all rely on the ledger service for fast and accurate balances and transactions.</p><p>我们使用分类帐服务已经快一年了。 与以前的系统相比，我们有能力维持每秒更多数量级的事务，并且在延迟方面有严格的限制。 现有和新功能（例如Coinbase卡）都依靠分类帐服务来快速准确地进行余额和交易。 </p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://blog.coinbase.com/seamless-mongodb-to-postgresql-migration-127735cc989c">https://blog.coinbase.com/seamless-mongodb-to-postgresql-migration-127735cc989c</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/mongodb/">#mongodb</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/seamless/">#seamless</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/数据/">#数据</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/分享/">#分享</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy; 2020 diglog.com </div></div></body></html>