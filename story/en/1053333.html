<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>jamrtc  -  Livebrits for Live Musicians JamRTC – WebRTC for Live Musicians</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">JamRTC – WebRTC for Live Musicians<br/>jamrtc  -  Livebrits for Live Musicians </h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2021-03-19 03:48:52</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2021/3/8964c2863379f02233f590919904a20e.jpeg"><img src="http://img2.diglog.com/img/2021/3/8964c2863379f02233f590919904a20e.jpeg" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>This is an attempt to create a simple prototype for doing jam sessions using WebRTC as a technology, and in particular taking advantage of  Janus as an open source WebRTC server for the purpose. The main reason why this effort uses Janus and not P2P or another server is simply that I&#39;m the main author of Janus itself, and so that&#39;s what I&#39;m most familiar with: you&#39;re of course free to try and come up with different attempts that use different backends, or no backend at all (the more we use WebRTC to help music, the better!).</p><p>这是一种尝试使用WebRTC作为一种技术来创建一个简单的原型，以便使用WebRTC作为一种技术，特别是为了目的，利用Janus作为开源WebRTC服务器。这项努力使用Janus而不是P2P或另一台服务器的主要原因只是我的主要作者，即Janus本身的主作者，所以＆＃39;我最熟悉的是什么：你＆＃39;当然可以自由地尝试并提出使用不同后果的不同尝试，或者根本没有后端（我们越多使用WebRTC来帮助音乐，更好！）。</p><p> It&#39;s very early stages, and mostly meant as a playground for interested developers, musicians and more in general tinkerers, to experiment whether it&#39;s a viable road or not.</p><p> 它＆＃39;非常早期的阶段，并且主要是为了作为一个游乐场，享受有兴趣的开发人员，音乐家和更多的迂回者，来实验它是否是一个可行的道路和第39条。</p><p>  In 2021, I made a presentation at  FOSDEM called  Can WebRTC help musicians?, which tried to go through some common music-based scenarios, and how WebRTC could possibly help implement them on the Internet when real-time communication is required, especially in light of the impact the COVID pandemic had on the music world. The presentation was mostly an overview, and probably asked more questions than it answered, but it did contain a section on jam sessions as a key scenario WebRTC might help with, considering the real-time nature of the technology.</p><p>  在2021年，我在Fosdem提出了一个叫做的歌词WebRTC帮助音乐家？，试图通过一些常见的基于音乐的场景，以及WebRTC在需要实时通信时如何在互联网上实现它们，特别是在光线下影响Covid Pandemic在音乐界的影响。该演示文稿主要是概述，并且可能询问更多的问题，而不是回答的问题，但它确实包含一个关于Jam会话的一节，因为考虑到技术的实时性质，我们可以帮助。</p><p> It started from a few assumptions, they most important one being that browsers (usually the main target for WebRTC applications) are not a good device for participating in a jam session: in fact, the audio pipeline they implement presents some obstacles, like too much tinkering with the audio they capture (AGC, AEC), too much latency (integrated buffers and synchronization mechanisms), no way to easily capture generic devices (made for generic microphones, mostly), and no way to interact with lower-latency audio systems on the operating system (e.g., the  JACK Audio Connection Kit). As such, the idea was to try and come up with a native application instead, in order to attempt to overcome the obstacles above. This is what this repo is trying to provide a foundation for.</p><p> 它始于几个假设，它们最重要的是那个浏览器（通常是WebRTC应用程序的主要目标）不是参与JAM会话的好装置：事实上，他们实施的音频管道呈现出一些障碍物，就像太多障碍滋补他们捕获的音频（AGC，AEC），太多延迟（集成缓冲区和同步机制），无法轻松捕获通用设备（为通用麦克风，主要是通用麦克风），并且无法与下延迟音频系统交互在操作系统上（例如，插孔音频连接套件）。因此，这个想法是尝试和提出本机应用，以便尝试克服上面的障碍。这就是这个repro试图为之提供的基础。</p><p>  This effort is not trying to replace anything, let alone well known applications: for instance, while I never used it, I&#39;m well aware that Jamulus is very widespread among musicians, who use it successfully every day. Heck, I even thought of calling this project &#34;JAMus&#34; (as in Jam over Janus) and then changed my mind because it sounded too much like Jamulus itself!  😁 The only purpose of this project is to experiment with whether or not WebRTC (which the other tools are not built upon) can also help build something comparable in terms of requirements, especially considering there&#39;s advantages in having WebRTC as part of the stack in a scenario like this: if it grows into something more than that, then great, but that&#39;s not the point.</p><p>  这种努力不是试图替换任何东西，更不用说众所周知的应用程序：例如，我从未使用过它，我很清楚jamulus在音乐家中普遍存在，每天都会使用它。哎呀，我甚至想到这个项目＆＃34; Jamus＆＃34; （如在Janus的果酱中）然后改变了我的想法，因为它听起来像Jamulus本身一样！ 😁该项目的唯一目的是试验WebRTC（其他工具未建立）还可以帮助建立在要求方面可比的东西，特别是考虑到WebRTC作为其中的一部分堆栈在这样的场景中：如果它增长进入那样的东西，那么很棒，而且那不是这一点。</p><p> If you&#39;re looking for something you can use RIGHT AWAY and is known to work great, then Jamulus or a similar application is indeed what you should use! If you&#39;re curious about WebRTC and music, then this is a good place to experiment with that, knowing it&#39;s not much more than a toy right now.</p><p> 如果你＆＃39;重新寻找你可以立即使用的东西，并且已知工作很大，那么Jamulus或类似的应用程序确实是你应该使用的！如果你＆＃39;对WebRTC和音乐的好奇，那么这是一个实验的好地方，知道它并不多于现在的玩具。</p><p>  Why not?  😁 Jokes apart, the main reason is that, as technology, WebRTC should be suited for the job, since it&#39;s main purpose is exchanging live audio/video/data streams in real-time. While it&#39;s mostly used for traditional use cases like conferencing, streaming, and stuff like that, the tools are there to do something in the &#34;creative&#34; department as well.</p><p>  为什么不？ 😁笑话分开，主要原因是，作为技术，WebRTC应该适合这份工作，因为它主要目的是实时交换实时音频/视频/数据流。虽然它和＃39; s大多用于传统用例，如会议，流媒体和类似的东西，这些工具在那里在＆＃34中做某事;创意＆＃34;部门也是如此。 </p><p> Apart from that, there are some other advantages in using WebRTC for the job. If the music streams you&#39;re exchanging are WebRTC-based, e.g., via an SFU like the Janus VideoRoom or others, then it&#39;s very easy to distribute the same streams to &#34;traditional&#34; endpoints as well, like browsers, mobile endpoints, or others. This means you could build a simple web app to serve a small or larger audience, for instance, whose requirements for super-low latency would not be the same as those of the players involved. At the same time, WebRTC streams are easy to integrate in other frameworks for further processing, e.g., for mixing, processing, transcoding, or broadcasting purposes, which make them a useful tool for additional requirements and use cases: you can find some examples in a  Janus Workshop I did at ClueCon TGI2021 ( slides).</p><p>除此之外，使用WebRTC为工作有一些其他优势。如果音乐流＆＃39;重新交换是基于WebRTC的，例如，通过像Janus VideoOom或其他人这样的SFU，那么它很容易分发与＆＃34的相同的流。端点以及浏览器，移动端点或其他端点。这意味着您可以构建一个简单的Web应用程序，以服务于小型或更大的受众，例如，其对超低延迟的要求不会与所涉及的玩家的要求不同。同时，WebRTC流易于在其他框架中集成以进行进一步处理，例如，用于混合，处理，转码或广播目的，这使其成为其他要求和用例的有用工具：您可以找到一些示例我在ClueCon TGI2021（幻灯片）做了Janus Workshop。</p><p>  As anticipated, the main idea behind this effort was to try and write a native WebRTC application to optimize the process as much as possible, especially where latency is involved. I decided to base this on @GStreamer &#39;s  webrtcbin, for a few different reasons:</p><p>  由于预期，这项努力背后的主要思想是尝试编写本机WebRTC应用程序以尽可能优化该过程，尤其是涉及延迟的地方。我决定在@gstreamer和＃39; s webrtcbin上基于一些原因：</p><p> I already had a bit of experience with it, having used it briefly in a couple of other projects;</p><p> 我已经有了一点经验，在其他项目中简单地使用它;</p><p>   it&#39;s relatively easy to build a GUI on top of GStreamer&#39;s building blocks (I used GTK+ 3.0, here).</p><p>   它比较容易在GStreamer＆＃39; S构建块上构建一个GUI（我在这里使用GTK + 3.0）。</p><p> At the same time, I wanted to use Janus as a reference server for all endpoints engaged in a session. This led to the diagram you can see below:</p><p> 与此同时，我想使用Janus作为参与会话中的所有端点的参考服务器。这导致了你可以看到的图表：</p><p>  In a nutshell, the idea was to have this GStreamer-based native application join a Janus  VideoRoom, and then:</p><p>  简而言之，这个想法是将基于GStreamer的本机应用程序加入Janus VideoOom，然后：</p><p> subscribe to media from other participants (e.g., drum and bass player) via the same server.</p><p> 通过同一服务器订阅来自其他参与者（例如，鼓和低音播放器）的媒体。 </p><p> I conceived the application to not only allow you to share musical instruments, but also to have a parallel channel to interact with the other participants. As such, by default when launching JamRTC it will create two WebRTC PeerConnections: one to send your webcam + microphone, and another to send your instrument as an audio-only stream; of course you can choose whether you want to publish everything, just something, or nothing at all. When other participants join the session, the tool is conceived to automatically subscribe to whatever they&#39;re sharing: all the feeds are then rendered in a very simple (and super-ugly) UI, where audio streams are visualized via a wavescope.</p><p>我构思了应用程序，不仅允许您分享乐器，而且还有一个并行频道与其他参与者互动。因此，默认情况下，启动jamrtc时它将创建两个WebRTC PEERConnections：一个要发送您的网络摄像头+麦克风，另一个用于将乐器发送为仅音频流;当然，您可以选择是否要发布所有内容，只为某种东西或根本没有。当其他参与者加入会话时，构思该工具以自动订阅它们＆＃39;重新分享：然后在非常简单（和超级丑陋）UI中呈现所有馈送，其中音频流通过波臂可视化。</p><p> It&#39;s important to point out that, when using JACK as the audio backend, JamRTC is conceived not to automatically pick the devices to capture: this is up to you to do, by creating the connections you want manually. I&#39;ll get back to this later on, when explaining how to test what&#39;s currently there.</p><p> 重要的是要指出，当使用千斤顶作为音频后端时，jamrtc会设想，不要自动选择要捕获的设备：这取决于您手动创建所需的连接。我稍后再回到这一点，当解释如何测试目前的目前＆＃39;那里。</p><p>    Make sure the related development versions of the libraries are installed, before attempting to build JamRTC, as to keep things simple the  Makefile is actually very raw and naive: it makes use of  pkg-config to detect where the libraries are installed, but if some are not available it will still try to proceed (and will fail with possibly misleading error messages). All of the libraries should be available in most repos (they definitely are on Fedora, which is what I use everyday, and to my knowledge Ubuntu as well).</p><p>    确保安装了库的相关开发版本，然后在尝试构建jamrtc之前，保持事物简单的makefile实际上是非常原始的和天真的：它使用pkg-config来检测库的安装位置，但如果有些不可用它仍然会尝试继续（并且可能会失败，可能会误导错误消息）。所有图书馆都应该在大多数REPOS中提供（它们肯定是在Fedora上，这是我每天使用的，以及我的知识Ubuntu）。</p><p> Once the dependencies are installed, all you need to do to build JamRTC is to type:</p><p> 一旦安装了依赖项，您需要做的就是构建jamrtc即可键入：</p><p>  This will create a  JamRTC executable. Trying to launch that without arguments should display a help section:</p><p>  这将创建一个jamrtc可执行文件。尝试启动没有参数的启动应该显示一个帮助部分：</p><p> [lminiero@lminiero JamRTC]$ ./JamRTCUsage: JamRTC [OPTION?] -- Jam sessions with Janus!Help Options: -h, --help Show help optionsApplication Options: -w, --ws Address of the Janus WebSockets backend (e.g., ws://localhost:8188; required) -r, --room Room to join (e.g., 1234; required) -d, --display Display name to use in the room (e.g., Lorenzo; required) -M, --no-mic Don&#39;t add an audio source for the local microphone (default: enable audio chat) -W, --no-webcam Don&#39;t add a video source for the local webcam (default: enable video chat) -v, --video-device Video device to use for the video chat (default: /dev/video0) -i, --instrument Description of the instrument (e.g., Guitar; default: unknown) -s, --stereo Whether the instrument will be stereo or mono (default: mono) -I, --no-instrument Don&#39;t add a source for the local instrument (default: enable instrument) -b, --jitter-buffer Jitter buffer to use in RTP, in milliseconds (default: 0, no buffering) -c, --src-opts Custom properties to add to jackaudiosrc (local instrument only) -S, --stun-server STUN server to use, if any (hostname:port) -T, --turn-server TURN server to use, if any (username:password@host:port) -l, --log-level Logging level (0=disable logging, 7=maximum log level; default: 4) -J, --no-jack For testing purposes, use autoaudiosrc/autoaudiosink instead (default: use JACK)</p><p> [lminiero @ lminiero jamrtc] $ ./jamrtcusage：jamrtc [选项？]  - 与Janus的Jam会话！帮助选项：-h，--help show optionsApplication选项：-w，-ws -ws的Janus Websockets后端地址（例如，WS：// localhost：8188;需要）-R， - 高级空间加入（例如，1234;必填）-d， -  display显示名称用于房间（例如，lorenzo;需要）-m ，--no-mic don＆＃39; t添加了本地麦克风的音频源（默认值：启用音频聊天）-w，--no-webcam don＆＃39; t为本地网络摄像头添加一个视频源（默认值：启用视频聊天）-V， - 视频设备视频设备用于视频聊天（默认：/ dev / video0）-i， - 仪器的 - 仪器描述（例如，吉他;默认：未知）-s， - 立体仪器是否是立体声或单声道（默认：单声道）-I，--no-internirmon don＆＃39; t为本地仪器添加一个源（默认值：启用仪器）-b，--jitter-buffer抖动缓冲区用于RTP，以毫秒为单位（默认值：0，无缓冲）-c，--src-opts自定义预防rties添加到jackaudiosrc（仅限本地乐器）-s，--stun-server stun服务器使用，如果有的话（hostname：port）-t，--turn-server转动服务器使用，如果有的话（用户名：密码@主机：端口）-L，--log级日志记录级别（0 =禁用日志记录，7 =最大日志级别;默认值：4）-j，--no-jack用于测试目的，使用autoAudiosrc / autoAudiosink（默认：使用插孔）</p><p>  At the moment, you can only customize the behaviour of JamRTC at startup, via command-line arguments, as there are no visual settings in the GUI or parameters you can tweak dynamically. This means that there are some required arguments to start the tool, namely:</p><p>  目前，您只能通过命令行参数自定义jamrtc在启动时的行为，因为GUI或参数中没有可视设置，您可以动态调整。这意味着有一些必需的参数来启动工具，即： </p><p>  All the other arguments are optional, and allow you to customize how you want the tool to behave. As anticipated, for instance, by default the tool will try to capture webcam and microphone (for a visual interaction with the other participants) and a local instrument: you can use the available arguments to disable any of those, and only publish what you want to send. The other arguments should be pretty self-explainatory as well.</p><p>所有其他参数都是可选的，并允许您自定义要操作的操作方式。例如，预期，默认情况下，该工具将尝试捕获网络摄像头和麦克风（用于与其他参与者的视觉交互）和本地仪器：您可以使用可用参数禁用其中的任何一个，只能发布您想要的发送。其他论点也应该是非常自我解释的。</p><p> Note well! One important option is  -J(or  --no-jack). By default, JamRTC will assume JACK is running, and so will attempt to use it to both capture and render the audio streams: if you just want to test this without JACK, passing this flag will make JamRTC use  autoaudiosrc and  autoaudiosink instead where audio is involved, thus in theory choosing whatever you&#39;re using in your system. Take into account that this will limit the control you have on how devices are captured ( autoaudiosrc will pick what it wants and likely not your guitar  😁 ), and that latency will probably be much higher as well.</p><p> 注意！一个重要的选项是-j（或--no-jack）。默认情况下，jamrtc将假设插孔运行，因此将尝试将其用作捕获并呈现音频流：如果您只想在没有杰克的情况下测试此标志，那么通过此标志将使Jamrtc使用AutoAudioSRC和AutoAudioSink，而不是音频从而在理论上选择了无论你在系统中使用什么。考虑到这将限制您对捕获设备的控制（AutoAudiosrc如何选择它想要的并且可能不是您的吉他😁）的控制，并且延迟也可能更高。</p><p>  Connect to a local Janus instance in room 1234 as &#34;Lorenzo&#34; and publish everything via JACK, calling the instrument &#34;Guitar&#34;</p><p>  连接到1234室的当地Janus实例，如＆＃34; Lorenzo＆＃34;并通过杰克发布所有内容，呼叫仪器＆＃34;吉他＆＃34;</p><p>    Note that room  1234 is the default room on our online demos, and so you&#39;ll find random people in it that are just joining via their browser. As such, it&#39;s a bad idea to use that room for testing, unless you know there&#39;s no one else except you and who you want to test with. You may want to deploy your own Janus instance for testing.</p><p>    请注意，1234房间是我们在线演示的默认房间，所以您＆＃39; ll在它中找到随机的人，这只是通过他们的浏览器加入。因此，它＆＃39;除非你知道，除非你知道除了你和你想测试之外的其他人，否则它是一个糟糕的想法。您可能希望部署自己的Janus实例进行测试。</p><p> Connect to a local Janus instance in room 1234 as &#34;Lorenzo&#34; and publish everything, but use a different video device</p><p> 连接到1234室的当地Janus实例，如＆＃34; Lorenzo＆＃34;并发布所有内容，但使用不同的视频设备</p><p>  Connect to a local Janus instance in room 1234 as &#34;Lorenzo&#34; and only publish webcam and instrument (no microphone)</p><p>  连接到1234室的当地Janus实例，如＆＃34; Lorenzo＆＃34;并且只发布网络摄像头和仪器（无麦克风）</p><p>  Connect to a local Janus instance in room 1234 as &#34;Lorenzo&#34; and only publish your instrument (no microphone/webcam) as stereo</p><p>  连接到1234室的当地Janus实例，如＆＃34; Lorenzo＆＃34;并且只发布您的乐器（无麦克风/网络摄像头）作为立体声 </p><p>     Tinker with the default  videoroomtest.html demo page in the Janus repo, or write your own web application for the purpose.</p><p>与Janus Repo中的默认videoroomtest.html演示页面的修补程序，或为此目的写自己的Web应用程序。</p><p> Note: In case you plan to write your own web-based frontend, it&#39;s worth pointing out that JamRTC &#34;abuses&#34; the display field of the VideoRoom API to correlate the multiple feeds. In fact, as anticipated by default JamRTC publishes two separate PeerConnections, one for webcam+mic, and another for the instrument: in order to allow other participants they both come from you, JamRTC actually uses a JSON object serialized to string as the display used for each publisher stream. This should be taken into account when designing a web-based application, as otherwise different PeerConnections coming from the same participant would be rendered as separate participants (which is what the default VideoRoom demo will indeed do).</p><p> 注意：如果您计划编写自己的基于Web的前端，它的值得指出jamrtc＆＃34;滥用行为＆＃34;录像室API的显示字段以关联多个馈送。事实上，由于默认情况下，默认情况下，默认情况下发布了两个单独的PEERConnections，一个用于网络摄像头+ MIC，另一个用于仪器：为了允许其他参与者来自您，Jamrtc实际上使用序列化的JSON对象序列化为字符串作为所使用的显示器对于每个发布者流。在设计基于Web的应用程序时，应考虑到这一点，因为否则来自同一参与者的不同的PEERConnection将被呈现为单独的参与者（这是默认的视频演示确实做的）。</p><p>    Quite frankly and in all self-deprecating honesty, nothing to write back home about, but as a start (and for someone who knows very little about GUI development) it&#39;s not that awful...  🤭</p><p>    坦率地坦率地，在所有自我贬低的诚实中，没有什么可以写回家的，但作为一个人的开始（以及对GUI发展的非常少的人）它＆＃39;不是那个可怕的......</p><p> Assuming you&#39;re sharing everything, you&#39;ll see your video on top, then a visual representation of your microphone, and finally a visual representation of your instrument. In case any of those is not being shared, they just won&#39;t be there, and the related labels will be updated accordingly.</p><p> 假设你和＃39;重新分享一切，你＆＃39; ll在顶部看到你的视频，然后是麦克风的视觉表示，最后是您乐器的视觉表示。如果其中任何未分享，他们刚刚赢得＆＃39; t在那里，相关标签将相应更新。</p><p> When someone else joins the session, a new column will appear with the media they&#39;re sharing instead:</p><p> 当别人加入会话时，将出现一个新列，媒体将显示它们＆＃39;重新分享：</p><p>  I sketched the current layout with Glade, and at the moment it only accomodates four participants, whether they&#39;re active or just attendees: the moment more participants join, their media is rendered independently by GStreamer in separate floating windows. Hopefully later on this can be made more dynamic and adaptive, but that&#39;s not what I really care about right now.</p><p>  我勾勒出目前的窗帘，目前它只适应四个参与者，无论是活动还是只有与会者，他们是＆＃39;当时参与者加入的那一刻，他们的媒体是独立的，在单独的浮动窗口中独立呈现。希望后来可以做出更具活力和自适应的，但这不是我现在真正关心的。</p><p> As anticipated, the GUI currently is passive, meaning there&#39;s no interactive component: there&#39;s no menus, no buttons, nothing you can tweak or anything like that, what you see is what you get. Since I&#39;m very new to GUI development, and GTK in particular, this is the best I could come up with: besides, the code itself is probably not very &#34;separated&#34; in terms of logic vs. rendering, so refactoring the UI may not be that easy. Anyway, feedback from who&#39;s smarter in this department will definitely help make this more usable in the future, when maybe the media itself works better than it does today!</p><p> 如预期的那样，GUI目前是被动的，意思是那里的被动，没有互动组件：没有菜单，没有菜单，没有按钮，你可以在那样调整或任何东西，你所看到的是你所看到的。自从我＆＃39; m非常新的GUI开发，特别是GTK，这是​​我可以提出的最好的：此外，代码本身可能不是很好＆＃34;分离＆＃34;在逻辑与渲染方面，因此重构UI可能不是那么容易。无论如何，来自世界卫生组织的反馈＆＃39;在这个部门的智慧肯定会有助于使未来更加有用，当时媒体本身比今天更好！ </p><p> Note: sometimes, when people join some of their media are not rendered right away, and you have to minimize the application and unminimize it again: this is probably related to my poor UI coding skills, as it feels like a missing message somewhere to wake something up.</p><p>注意：有时，当人们加入一些媒体时，没有立即渲染，您必须尽量减少应用程序并再次引入它：这可能与我的差的UI编码技能有关，因为它感觉像在某处丢失的信息一样一些东西。</p><p>  As anticipated, when using JACK to handle audio, JamRTC will connect subscriptions to the speakers automatically, but will not automatically connect inputs as well: that&#39;s up to you to do, as you may want to actually share something specific to your setup (e.g., the raw input from the guitar vs. what Guitarix is processing).</p><p>  如预期的那样，当使用千斤顶来处理音频时，jamrtc会自动将订阅者连接到扬声器，但不会自动连接输入：那样，您可以做到，因为您可能希望实际分享您的特定于某些特定的东西设置（例如，吉他与吉他的原始输入与吉他是什么）。</p><p> Assuming you&#39;re asking JamRTC to share both microphone (for the audio/video chat) and an instrument, this is what you should see in JACK:</p><p> 假设你＆＃39;重新要求jamrtc分享麦克风（用于音频/视频聊天）和仪器，这就是您在杰克中所看到的：</p><p>  As you can see, there are two JACK input nodes, both of which currently not receiving input from any source. The first thing you may want to do is feed the instrument node (called &#34;JamRTC Guitar&#34; here) in this picture: let&#39;s connect Guitarix in this example, which is getting the raw guitar feed from my Focusrite soundcard; in order to hear what I&#39;m playing, I&#39;m connecting Guitarix to the speakers too. The important part is that the moment we start feeding the instrument node, it will be sent via WebRTC to the server, and so to the other participants:</p><p>  如您所见，有两个插孔输入节点，两者都没有从任何源接收输入。您可能想要做的第一件事是馈送仪器节点（称为＆＃34; jamrtc guitar＆＃34;这里）在此图片中：在这个例子中，在这个例子中连接吉他，这是从我的原始吉他饲料FOMETRITE SOCECARD;为了听到我的＆＃39; m播放，我也将吉他连接到扬声器。重要的是，我们开始喂养仪器节点的那一刻，它将通过WebRTC发送到服务器，依此类别的参与者：</p><p>  Since we want to share our microphone to chat with the other participants as well, we may need an app to help with that: in this instance, in fact, the capture device is my Focusrite soundcard, which is not where my microphone is. Specifically, I want to use the microphone of my laptop, so I can use tools like  zita-a2j to add an Alsa device as an additional capture device, e.g.:</p><p>  由于我们希望分享我们的麦克风来与其他参与者聊天，我们可能需要一个应用程序来帮助：在这种情况下，实际上，捕获设备是我的焦点声卡，这不是我的麦克风的位置。具体而言，我想使用我的笔记本电脑的麦克风，所以我可以使用像Zita-A2J这样的工具，将ALSA设备添加为额外的捕获设备，例如：</p><p>  At this point, I can connect the output of that to the JamRTC chat node (called &#34;JamRTC mic&#34;), which will as a result start sending our voice via WebRTC as well:</p><p>  此时，我可以将其连接到jamrtc聊天节点（调用＆＃34; jamrtc mic＆＃34;），这将开始通过WebRTC发送我们的声音：</p><p>  When other participants join, JamRTC automatically plays their contributions by connecting the related JACK notes to the speakers instead, as that&#39;s what we assume would be the main purpose:</p><p>  当其他参与者加入时，jamrtc通过将相关的jack笔记连接到扬声器，而不是它的主要目的是主要目的： </p><p>  Considering how JACK works, you&#39;re of course free to (also) connect the output to something else, e.g., a DAW.</p><p>考虑到杰克如何工作，你当然是免费的（也）将输出连接到别的东西，例如，DAW。</p><p>  This should be very much considered a pre-alpha, as while it &#34;works&#34;, I&#39;m still not satisfied with it. The main issue is, obviously, the latency, which is still too high even in a local environment despite my attempts to reduce it. I&#39;m still trying to figure out where the issue might be, as it may be either something in the GStreamer pipelines (WebRTC stack? buffers? queues? JACK integration?), in Janus (something adding latency there?) or WebRTC itself. I don&#39;t know enough about the GStreamer internals to know if anything can be improved there (I already disabled the webrtcbin jitter buffer, but not sure it helped much), so the hope is that by sharing this effort and letting more people play with it, especially those knowldedgeable with any of the different technologies involved, we can come up with something that can be really used out there.</p><p>  这应该非常多被认为是一个alpha，就像它＆＃34;作品＆＃34;，我仍然不满意。主要问题显然是，尽管我试图减少它，即使在当地环境中也仍然过高。我仍然试图弄清楚这个问题的地方，因为它可以是GStreamer管道中的东西（WebRTC堆栈？缓冲区？队列？队列？杰克集成？），在Janus（在那里添加延迟？）或WebRTC本身。我不知道GStreamer内部人士知道什么是可以改进的GStreamer内部，我已经禁用了WebRTCBIN抖动缓冲区，但不确定它有很多帮助），所以希望通过分享这项努力并让更多的人分享并让更多的人与之玩，特别是那些拥有任何不同技术的知识，我们可以提出可以真正用在那里的东西。</p><p> Notice that one other known limitation is that, out of the box, this currently only works on Linux: this is because we explicitly use some GStreamer elements that may only be available there (e.g.,  jackaudiosrc,  jackaudiosink,  xvimagesink). This is very simply because Linux is what I use everyday and what I&#39;m familiar with: besides, while I know JACK allows for low latency on Linux, I have no idea what is typically used on other operatng systems instead for the same purpose. Should you want to try and build this on other systems as well, you&#39;ll probably have to tweak the code a bit: of course, if you get it running on Windows and/or Mac OS, I&#39;d be glad to have the changes contributes back to the repo!</p><p> 请注意，一个其他已知的限制是，出于框中，此目前仅适用于Linux：这是因为我们显式使用可能只在那里提供的一些GStreamer元素（例如，jackaudiosrc，xvimagesink，xvimagesink，xvimagesink）。这是非常简单的，因为Linux是我每天使用的，我熟悉的东西：除了我知道杰克允许Linux上的低延迟，我不知道其他操作系统上通常使用什么目的。您是否希望在其他系统上尝试并在其他系统上建立它，您可能需要调整代码：当然，如果您在Windows和/或Mac OS上运行，i＆＃39; d很高兴有变化有助于回购！</p><p> Apart from these more fundamental aspects, there are other things I&#39;d like to add to the tool sooner or later, in particolar related to usability, e.g.:</p><p> 除了这些更基本的方面，还有其他东西我＆＃39; d想早晚添加到工具中，在与可用性相关的粒子中，例如：</p><p>    There&#39;s no group, chat or mailing list for the project, right now: I don&#39;t anticipate the need for one in the short term, but if enough people show interest, we can figure something out (maybe a room on Matrix, which worked great for FOSDEM). In the meanwhile, if you have ideas or feedback, feel free to open issues where they can be discussed, and please do submit pull requests if you fix some outstanding bug (of which there are plenty, I&#39;m sure). There&#39;s a  thread on LinuxMusicians that discusses playing music online as well which you may be interested in: LinuxMusicians itself may be another venue where to discuss the tool in general, maybe in a dedicated thread.</p><p>    目前＆＃39;没有组，聊天或邮寄列表，现在：我不会在短期内预测需要一个，但如果足够的人表现出兴趣，我们就可以解决问题（也许是矩阵上的房间，为FOSDEM工作了很好。与此同时，如果您有想法或反馈，请随时打开他们可以讨论的问题，如果您修复了一些出色的错误（其中有很多，i＆＃39; m确定），请执行提交拉请求。在Linuxmusicians上的一个线程讨论了在线播放音乐的线程：LinuxMusicians本身可能是一般讨论该工具的另一个地点，也许是在专用线程中。 </p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://github.com/lminiero/jamrtc">https://github.com/lminiero/jamrtc</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/webrtc/">#webrtc</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/livebrits/">#livebrits</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/分享/">#分享</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy;2012-2021 diglog.com </div></div></body></html>