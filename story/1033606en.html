<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>使用jemalloc在围棋中进行手动内存管理</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">使用jemalloc在围棋中进行手动内存管理</h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2020-11-07 11:11:26</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2020/11/9b245f67c3b3cbeea18876c89a1c8070.png"><img src="http://img2.diglog.com/img/2020/11/9b245f67c3b3cbeea18876c89a1c8070.png" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>Dgraph Labs has been a user of the Go language since our inception in 2015. Fiveyears and 200K lines of Go code later, we&#39;re happy to report that we are stillconvinced Go was and remains the right choice. Our excitement for Go has gonebeyond building systems, and has led us to even write scripts in Go that wouldtypically be written in Bash or Python. We find that using Go has helped usbuild a codebase that is clean, readable, maintainable and - most importantly -efficient and concurrent.</p><p>Dgraph Labs自2015年成立以来一直是围棋语言的用户。五年来，我们用了20万行围棋代码，我们很高兴地告诉大家，我们仍然坚信围棋是正确的选择，无论是现在还是现在，我们都坚信围棋是正确的选择。我们对围棋的兴奋已经超越了构建系统，甚至让我们用围棋编写了脚本，这些脚本通常是用Bash或Python编写的。我们发现，使用Go帮助我们构建了一个干净、可读、可维护的代码库--最重要的是--高效和并发。</p><p> However, there&#39;s one area of concern that we have had since the early days: memory management. We have nothing against the Go garbage collector, but whileit offers a convenience to developers, it has the same issue that other memorygarbage collectors do:  it simply cannot compete with the efficiency of manualmemory management.</p><p>然而，有一个领域是我们从早期就开始关注的：内存管理。我们并不反对Go垃圾收集器，但虽然它为开发人员提供了便利，但它也有与其他内存垃圾收集器相同的问题：它根本无法与手动内存管理的效率竞争。</p><p> When you manage memory manually, the memory usage is lower, predictable andallows bursts of memory allocation to not cause crazy spikes in memory usage.For Dgraph using Go memory, all of those have been a problem  1. In fact, Dgraphrunning out of memory is a very common complaint we hear from our users.</p><p>当您手动管理内存时，内存使用率更低、更可预测，并且允许内存分配突发不会导致内存使用量的疯狂峰值。对于使用Go Memory的Dgraph来说，所有这些都是一个问题1。事实上，Dgraph内存不足是我们从用户那里听到的一种非常常见的抱怨。</p><p> Languages like Rust have been gaining ground partly because it allows safemanual memory management. We can completely empathize with that.</p><p>像Rust这样的语言已经取得了一定的进展，部分原因是它允许安全的内存管理。我们完全可以理解这一点。</p><p> In our experience, doing manual memory allocation and chasing potential memoryleaks takes less effort than trying to optimize memory usage in a language withgarbage collection  2. Manual memory management is well worth the trouble whenbuilding database systems that are capable of virtually unlimited scalability.</p><p>根据我们的经验，手动分配内存并追踪潜在的内存泄漏比尝试在具有垃圾收集的语言中优化内存使用要少2。在构建能够几乎无限伸缩的数据库系统时，手动内存管理是非常值得的。</p><p> Our love of Go and our need to avoid Go GC led us to find  novel ways to domanual memory management in Go. Of course,  most Go users will never need to domanual memory management; and we would recommend against it unless you need it. And when you do need it, you&#39;ll know.</p><p>我们对围棋的热爱和避免围棋GC的需要让我们找到了在围棋中进行动态内存管理的新方法。当然，大多数围棋用户永远不需要域内存管理；除非您需要，否则我们建议您不要这样做。当你真的需要它的时候，你会知道的。</p><p> In this post, I&#39;ll share what we have learned at Dgraph Labs from ourexploration of manual memory management, and explain how we manually managememory in Go.</p><p>在这篇文章中，我将分享我们在Dgraph实验室从手动内存管理的实践中学到的东西，并解释我们是如何在围棋中手动管理内存的。</p><p>  The inspiration came from the Cgo wiki section about  Turning C arrays into Goslices. We could use  malloc to allocate memory in C and use unsafe to pass it over to Go, without any interference from Go GC.</p><p>灵感来自CGO wiki中关于将C数组转换为Goslices的部分。我们可以使用Malloc在C中分配内存，并使用unSafe将其传递给Go，而不会受到Go GC的任何干扰。</p><p> import &#34;C&#34;import &#34;unsafe&#34;... var theCArray *C.YourType = C.getTheArray() length := C.getTheArrayLength() slice := (*[1 &lt;&lt; 28]C.YourType)(unsafe.Pointer(theCArray))[:length:length]</p><p>导入&#34；C&34；导入&#34；不安全...。28]C.YourType)(unsafe.Pointer(theCArray))[：length:length]阵列*C.YourType=C.getTheArray()长度：=C.getTheArrayLength()切片：=(*[1；&lt；&lt；var。</p><p>  Note: the current implementation has a bug. While Go code is permitted to write nil or a C pointer (but not a Go pointer) to C memory, the current implementation may sometimes cause a runtime error if the contents of the C memory appear to be a Go pointer. Therefore, avoid passing uninitialized C memory to Go code if the Go code is going to store pointer values in it. Zero out the memory in C before passing it to Go.</p><p>注意：当前的实现有一个错误。虽然允许GO代码将NIL或C指针(但不是GO指针)写入C内存，但如果C内存的内容显示为GO指针，则当前实现有时可能会导致运行时错误。因此，如果GO代码要在其中存储指针值，请避免将未初始化的C内存传递给GO代码。将C中的内存清零，然后将其传递给Go。</p><p> So, instead of using  malloc, we use its slightly more expensive sibling, calloc.  calloc works the same way as  malloc, except it zeroes outthe memory before returning it to the caller.</p><p>因此，我们没有使用Malloc，而是使用其价格稍高的同类产品calloc。Calloc的工作方式与malloc相同，不同之处在于它在将内存返回给调用者之前将内存清零。</p><p> We started out by just implementing basic  Calloc and  Free functions, whichallocate and de-allocate byte slices for Go via Cgo. To test these functions, wedeveloped and ran a continuous  memory usage test. This testendlessly repeated an allocate/de-allocate cycle in which it first allocatedvarious randomly-sized memory chunks until it had allocated 16GB of memory, andthen freed these chunks until just 1GB of memory was left allocated.</p><p>我们一开始只实现了基本的Calloc和Free函数，它们通过CGO为Go分配和取消分配字节片。为了测试这些功能，我们开发并运行了一个持续的内存使用测试。这个测试无休止地重复了一个分配/释放周期，在这个周期中，它首先分配各种随机大小的内存块，直到分配了16 GB的内存，然后释放这些内存块，直到只剩下1 GB的内存分配。</p><p> The C equivalent of this program behaved as expected. We would see the RSSmemory in our  htop increasing to 16GB, then going down to 1GB, increasing backto 16GB, and so on. However, the Go program using  Calloc and  Free woulduse progressively more memory after each cycle (see chart below).</p><p>此程序的C等效项的行为符合预期。我们会看到HTOP中的RSS内存增加到16 GB，然后下降到1 GB，然后又增加到16 GB，以此类推。然而，使用Calloc和Free的围棋程序在每个周期之后会逐渐使用更多的内存(见下图)。</p><p> We attributed this behavior to memory fragmentation due to lack of threadawareness in the default  C.calloc calls. After some help from the Go #dark-arts Slack channel (particular thanks to Kale Blankenship), we decidedto give  jemalloc a try.</p><p>我们将此行为归因于默认的C.calloc调用中缺乏线程感知导致的内存碎片。在得到Go#黑暗艺术松弛频道的一些帮助后(特别感谢凯尔·布兰肯希普)，我们决定尝试一下Jemalloc。</p><p>  jemalloc is a general purpose malloc(3) implementation that emphasizesfragmentation avoidance and scalable concurrency support. jemalloc first cameinto use as the FreeBSD libc allocator in 2005, and since then it has found itsway into numerous applications that rely on its predictable behavior. — http://jemalloc.net</p><p>Jemalloc是一个通用的Malloc(3)实现，它强调避免碎片和可伸缩的并发支持。Jemalloc在2005年作为FreeBSD libc分配器首次投入使用，从那时起，它就被大量依赖于其可预测行为的应用程序所取代。--http://jemalloc.net。</p><p> We switched our APIs over to use jemalloc  3 for  calloc and  free calls.  And itperformed beautifully: jemalloc supports threads natively with little memoryfragmentation. The allocation-deallocation cycles from our memory usagemonitoring test were circulating between expected limits, ignoring a smalloverhead required to run the test.</p><p>我们将API转换为使用jemalloc 3进行calloc和free调用。它的执行非常出色：jemalloc本身就支持线程，几乎没有内存碎片。我们的内存使用监控测试中的分配-释放周期在预期限制之间循环，忽略了运行测试所需的混乱。</p><p> Just to ensure that we&#39;re using jemalloc and avoid a name clash, we added a je_ prefix during installation, so our APIs are now calling  je_calloc and je_free, instead of  calloc and  free.</p><p>为了确保我们使用的是jemalloc并避免名称冲突，我们在安装过程中添加了je_prefix，所以我们的API现在调用的是je_calloc和je_free，而不是calloc和free。</p><p>   In the above chart, allocating Go memory via C.calloc resulted in major memoryfragmentation, causing the program to hog on to 20GBs of memory by the 11thcycle. Equivalent code with jemalloc had no noticeable fragmentation,going down close to 1GB on every cycle.</p><p>在上面的图表中，通过C.calloc分配围棋内存会导致大量内存碎片，导致程序在第11个周期占用20GBs的内存。与jemalloc相同的代码没有明显的碎片，每个周期都会减少近1 GB。</p><p> At the end of the program (small dips on far right), after all theallocated memory was released, C.calloc program resulted in still hogging justunder 20GB of memory, while jemalloc showed 400MB of memory usage.</p><p>在程序末尾(最右边的小点)，在释放所有分配的内存后，C.calloc程序仍然占用不到20 GB的内存，而jemalloc显示400MB的内存使用量。</p><p>     ptr := C.je_calloc(C.size_t(n), 1)	if ptr == nil {		// NB: throw is like panic, except it guarantees the process will be		// terminated. The call below is exactly what the Go runtime invokes when		// it cannot allocate memory.		throw(&#34;out of memory&#34;)	}	uptr := unsafe.Pointer(ptr)	atomic.AddInt64(&amp;numBytes, int64(n))	// Interpret the C pointer as a pointer to a Go array, then slice.	return (*[MaxArrayLen]byte)(uptr)[:n:n]</p><p>Ptr：=C.je_calloc(C.size_t(N)，1)如果ptr==nil{//NB：抛出类似于死机，除非它保证进程将被//终止。下面的调用正是Go运行时在//无法分配内存时调用的。抛出(&#34；out out Memory&#34；)}uptr：=unSafe.Pointer(PTR)atom ic.AddInt64(&amp；numBytes，int64(N))//将C指针解释为指向GO数组的指针，然后切片。返回(*[MaxArrayLen]字节)(Uptr)[：n：n]。</p><p> We made this code part of  Ristretto‘s z package, so both Dgraph and Badgercan use it. To allow our code to switch to using jemalloc to allocate the byteslices, we added a build tag  jemalloc. To further simplify our deployments, wemade the  jemalloc library be statically linked in any resulting Go binary bysetting the right LDFLAGS.</p><p>我们将此代码作为Ristretto的z包的一部分，因此Dgraph和Badger都可以使用它。为了允许我们的代码切换到使用jemalloc来分配字节片，我们添加了一个构建标记jemalloc。为了进一步简化我们的部署，我们通过设置正确的LDFLAGS，将jemalloc库静态链接到任何生成的GO二进制文件中。</p><p>  Now that we have a way to allocate and free a byte slice, the next stepis to use it to layout a Go struct. We can start with a basic one ( full code).</p><p>既然我们已经有了分配和释放字节片的方法，下一步就是使用它来布局GO结构。我们可以从一个基本的(完整代码)开始。</p><p> type node struct { val int next *node}var nodeSz = int(unsafe.Sizeof(node{}))func newNode(val int) *node { b := z.Calloc(nodeSz) n := (*node)(unsafe.Pointer(&amp;b[0])) n.val = val return n}func freeNode(n *node) { buf := (*[z.MaxArrayLen]byte)(unsafe.Pointer(n))[:nodeSz:nodeSz] z.Free(buf)}</p><p>Type node struct{val int next*node}var nodeSz=int(unSafe.Sizeof(node{}))func newNode(Val Int)*node{b：=z.Calloc(NodeSz)n：=(*node)(unSafe.Pointer(&amp；b[0]))n.val=val return n}func FreeNode(n*node){buf：=(*[z.MaxArrayLen]byte)(unsafe.Pointer(n))[：nodeSz:nodeSz]z.Free(Buf)}。</p><p> In the code above, we laid out a Go struct on C allocated memory using  newNode.We created a corresponding  freeNode function, which can free up the memory oncewe were done with the struct. The Go struct has the basic data type  int and apointer to the next node struct, all of which were set and accessed in theprogram.We allocated 2M node objects and created a linked list out of them todemonstrate the proper functioning of jemalloc.</p><p>在上面的代码中，我们使用newNode在C分配的内存上布置了一个go结构，并创建了相应的freNode函数，一旦使用完该结构，就可以释放内存。GO结构的基本数据类型是int和指向下一个节点结构的指针，所有这些都是在程序中设置和访问的。我们分配了2M个节点对象，并创建了一个链表来演示jemalloc的正确功能。</p><p> With default Go memory, we see 31 MiB of heap allocated for the linked list with2M objects, but nothing allocated via jemalloc.</p><p>对于默认的go内存，我们看到有31MiB的堆被分配给具有2M个对象的链表，但没有通过jemalloc进行分配。</p><p> $ go run .Allocated memory: 0 Objects: 2000001node: 0...node: 2000000After freeing. Allocated memory: 0HeapAlloc: 31 MiB</p><p>$GO运行。分配的内存：0对象：2000001节点：0...释放后节点：200000。分配的内存：0Heapalc：31 MiB。</p><p> Using the jemalloc build tag, we see 30 MiB of memory allocated via jemalloc,which goes down to zero after freeing the linked list. The Go heap allocation isonly a tiny 399 KiB, which probably comes from the overhead of running theprogram.</p><p>使用jemalloc构建标记，我们看到通过jemalloc分配了30MiB的内存，在释放链表之后，这个内存降到了零。Go堆分配只有很小的399 KiB，这可能来自运行程序的开销。</p><p> $ go run -tags=jemalloc .Allocated memory: 30 MiB Objects: 2000001node: 0...node: 2000000After freeing. Allocated memory: 0HeapAlloc: 399 KiB</p><p>$go run-tag=jemalloc。已分配内存：30 MiB对象：2000001节点：0...节点：200000释放后。分配的内存：0Heapalc：399 KiB。</p><p>  The above code works great to avoid allocating memory via Go.  But, it comes at acost: lower performance. Running both the instances with  time, we see thatwithout jemalloc, the program ran in 1.15s. With jemalloc, it ran ~5x slower at5.29s.</p><p>上面的代码可以很好地避免通过GO分配内存。但是，这也是要付出代价的：较低的性能。用时间运行这两个实例，我们看到在没有jemalloc的情况下，程序运行时间为1.15s。使用jemalloc时，它的运行速度慢了约5倍，为5.29s。</p><p> $ time go run .go run . 1.15s user 0.25s system 162% cpu 0.861 total$ time go run -tags=jemalloc .go run -tags=jemalloc . 5.29s user 0.36s system 108% cpu 5.200 total</p><p>$时间去奔跑，去奔跑。1.15s用户0.25s系统162%cpu 0.861总计$time go run-tag=jemalloc.go run-tag=jemalloc。5.29s用户0.36s系统108%cpu总计5.200。</p><p> We attribute the slower performance to the fact that Cgo calls were made eachtime that memory was allocated, and each Cgo call comes with some overhead. Todeal with this, we wrote an  Allocator library in  ristretto/z package. This library allocates bigger chunks of memory in one call, which can then beused to allocate many small objects, avoiding expensive Cgo calls.</p><p>我们将性能降低归因于每次分配内存时都会进行CGO调用，而且每次CGO调用都会带来一些开销。为了解决这个问题，我们在ristretto/z包中编写了一个分配器库。这个库在一次调用中分配更大的内存块，然后这些内存块可以用来分配许多小对象，从而避免昂贵的CGO调用。</p><p> Allocator starts with a buffer and when exhausted, creates a new buffer oftwice the size. It maintains an internal list of all the allocated buffers.Finally, when the user is done with the data, they can call  Release to free upall these buffers in one go. Note that  Allocator does not do any memory movement.This helps ensure that any  struct pointers we have stay valid.</p><p>分配器从一个缓冲区开始，当耗尽时，它会创建一个两倍大小的新缓冲区。它维护所有已分配缓冲区的内部列表。最后，当用户处理完数据后，他们可以调用Release来一次性释放所有这些缓冲区。注意，Allocator不做任何内存移动，这有助于确保我们拥有的任何结构指针保持有效。</p><p> While this might look a bit like the slab-style memory management that tcmalloc/ jemalloc use, this is a lot simpler. Once allocated, you can notfree up just one struct. You can only free up all of the memory used by Allocator  4.</p><p>虽然这看起来有点像tcmalloc/jemalloc使用的板式内存管理，但它要简单得多。一旦分配，就不能只释放一个结构。您只能释放分配器4使用的所有内存。</p><p> What Allocator does well is to layout millions of structs for cheap and freethem when done, without involving the Go heap. The same program shownabove, when run with a new  allocator build tag, runs even faster thanthe Go memory version.</p><p>Allocator做得很好的是以较低的成本布局数百万个结构，并在完成后释放它们，而不涉及Go堆。上面显示的相同程序，当使用新的分配器构建标记运行时，运行速度甚至比Go Memory版本更快。</p><p> $ time go run -tags=&#34;jemalloc,allocator&#34; .go run -tags=&#34;jemalloc,allocator&#34; . 1.09s user 0.29s system 143% cpu 0.956 total</p><p>$time go run-tag=&#34；jemalloc，allocator&#34；.go run-tag=&#34；jemalloc，allocator&#34；。1.09s用户0.29s系统143%cpu总计0.956。</p><p> Starting in Go 1.14, the  -race flag turns on memory alignment checks forstructs.  Allocator has an  AllocateAligned method which returns memorystarting with the right pointer alignment to pass those checks. Depending uponthe size of the struct, this could result in some memory waste butmakes CPU instructions more efficient due to correct word boundaries.</p><p>从GO 1.14开始，-race标志打开对structs的内存对齐检查。Allocator有一个AllocateAligned方法，该方法返回内存，从右指针对齐开始，以通过这些检查。根据结构的大小，这可能会导致一些内存浪费，但会因为正确的字边界而使CPU指令更有效率。</p><p> We faced another memory management problem: Sometimes memory allocation happensat a very different place from deallocation. The only communication betweenthese two places might be the structs allocated with no way to pass down theactual  Allocator object. To deal with this, we assign a unique ID to each Allocator object, which the objects store in a  uint64 reference. Each new Allocator object is stored on a global map against its reference.  Allocatorobjects can then be recalled using this reference and released when the data isno longer required.</p><p>我们还面临着另一个内存管理问题：有时内存分配发生在与释放非常不同的地方。这两个位置之间唯一的通信可能是分配的结构，它们无法向下传递实际的Allocator对象。为了解决这个问题，我们为每个分配器对象分配了一个唯一的ID，这些对象将其存储在uint64引用中。每个新的分配器对象都存储在针对其引用的全局映射上。然后，可以使用该引用重新调用分配器对象，并在不再需要数据时将其释放。</p><p>   When allocating a struct manually, as shown above, it is important to ensurethat there&#39;s no reference within the struct to Go-allocated memory. Consider aslight modification to the struct above:</p><p>如上所述，当手动分配结构时，重要的是要确保结构中没有对Go分配的内存的引用。考虑对上面的结构进行轻微修改：</p><p>  Let&#39;s use the  root := newNode(val) func defined above to allocate a nodemanually. If, however, we then set  root.next = &amp;node{val: val}, whichallocates all the other nodes in the linked list via Go memory, we are bound toget the following segmentation fault:</p><p>让我们使用上面定义的根：=newNode(Val)函数来按需分配一个。但是，如果我们随后设置root.next=&amp；node{val：val}，它通过Go Memory来分配链表中的所有其他节点，我们必然会得到以下分段错误：</p><p> $ go run -race -tags=&#34;jemalloc&#34; .Allocated memory: 16 B Objects: 2000001unexpected fault address 0x1cccb0fatal error: fault[signal SIGSEGV: segmentation violation code=0x1 addr=0x1cccb0 pc=0x55a48b]</p><p>$GO RUN-RACE-TAG=&#34；jemalloc&#34；。已分配内存：16 B对象：2000001意外故障地址0x1cccb0致命错误：故障[信号SIGSEGV：分段冲突代码=0x1 Addr=0x1cccb0 PC=0x55a48b]</p><p> The memory allocated by Go gets garbage collected because no valid Go struct ispointing to it. Only C-allocated memory is referencing it, and the Go heap doesnot have any reference to it, resulting in the above fault. So, if youcreate a struct and manually allocate memory to it, it&#39;s important to ensurethat  all the recursively accessible fields are allocated manually as well.</p><p>GO分配的内存会被垃圾回收，因为没有有效的GO结构指向它。只有C分配的内存在引用它，而Go堆没有任何对它的引用，这导致了上面的错误。因此，如果您创建一个结构并手动为其分配内存，重要的是要确保所有递归可访问的字段也都是手动分配的。</p><p> For example, if the above struct was using a byte slice, we allocate that byteslice using  Allocator as well to avoid mixing Go memory with C memory.</p><p>例如，如果上面的结构使用一个字节片，我们也使用Allocator来分配该字节片，以避免将GO内存和C内存混为一谈。</p><p>   Allocator is great for manually allocating millions of structs. However, we haveuse cases where we need to create billions of small objects and sort them. Theway one would do that in Go, even with  Allocator, looks something like this:</p><p>分配器非常适合手动分配数百万个结构。然而，我们有需要创建数十亿个小对象并对它们进行排序的用例。在围棋中做到这一点的方法，即使是使用Allocator，看起来也是这样的：</p><p> var nodes []*nodefor i := 0; i &lt; 1e9; i++ { b := allocator.AllocateAligned(nodeSz) n := (*node)(unsafe.Pointer(&amp;b[0])) n.val = rand.Int63() nodes = append(nodes, n)}sort.Slice(nodes, func(i, j int) bool { return nodes[i].val &lt; nodes[j].val})// nodes are now sorted in increasing order of val.</p><p>Var Nodes[]*nodefor i：=0；i&lt；1e9；i++{b：=allocator.AllocateAligned(NodeSz)n：=(*node)(unSafe.Pointer(&amp；b[0]))n.val=rand.Int63()Nodes=append(Nodes，n)}排序。Slice(Nodes，func(i，j int)bool{Return Nodes[i].val&lt；Nodes。</p><p> All these 1B nodes are manually allocated on the  Allocator, which getsexpensive. We also need to pay the cost of the slice in Go, which at 8GB ofmemory (8 bytes per node pointer, 1B entries) is itself quite expensive.</p><p>所有这些1B节点都是在分配器上手动分配的，这会很昂贵。我们还需要支付Go中的切片成本，8 GB的内存(每个节点指针8字节，1B条目)本身就相当昂贵。</p><p> To deal with these kinds of use cases, we built  z.Buffer, which can be memorymapped on a file to allow Linux to page memory in and out as required by thesystem. It implements  io.Writer and replaces our reliance on  bytes.Buffer.</p><p>为了处理这类用例，我们构建了z.Buffer，它可以被内存映射到一个文件上，从而允许Linux根据系统的需要调入和调出内存。它实现了io.Writer，取代了我们对bytes.Buffer的依赖。</p><p> More importantly,  z.Buffer provides a new way to allocate smaller slices ofdata. With a call to  SliceAllocate(n),  z.Buffer would write the length ofthe slice being allocated (n) followed by allocating the slice. This allows z.Buffer to understand slice boundaries and iterate over them correctly with SliceIterate.</p><p>更重要的是，z.Buffer提供了一种分配较小数据片的新方法。通过调用SliceALLOCATE(N)，z.Buffer将写入要分配的片的长度(N)，然后分配片。这使得z.Buffer能够理解切片边界，并使用SliceIterate正确地迭代它们。</p><p>  For sorting, we initially tried to get slice offsets from  z.Buffer, access theslices to compare, but sort only the offsets. Given an offset,  z.Buffer canread the offset, find the length of the slice and return that slice. So thissystem allowed us to access the slices in sorted order, without incurring anymemory movements. While novel, that mechanism put a lot of pressure on memory,because we were still paying the 8GB memory penalty just to bring those offsetsinto Go memory.</p><p>对于排序，我们最初尝试从z.Buffer获取切片偏移量，访问要比较的切片，但只对偏移量进行排序。在给定偏移量的情况下，z.Buffer可以读取偏移量，找到切片的长度并返回该切片。因此，该系统允许我们按排序顺序访问切片，而不会引起任何内存移动。虽然很新奇，但这种机制给内存带来了很大的压力，因为我们仍然在支付8 GB的内存损失，只是为了把这些补偿放入Go内存中。</p><p> One crucial limitation we had was that slices were not of the samesize. Moreover, we could only access these slices in sequential order, not inreverse or random order, without calculating and storing the offsets in advance.Most in-place sort algorithms assume that values are of the same size   5, can berandomly accessed and can be readily swapped. Go&#39;s  sort.Slice works the sameway, and hence wasn&#39;t a good fit for  z.Buffer.</p><p>我们有一个关键的限制，那就是切片的大小不一样。此外，我们只能按顺序访问这些切片，而不能以逆序或随机顺序访问这些切片，而不能提前计算和存储偏移量。大多数就地排序算法都假设值的大小相同为5，可以随机访问，并且可以很容易地交换。去吧。Slice的工作方式是一样的，因此不太适合Z.Buffer。</p><p> With these limitations, we found the merge sort algorithm to be the most suitablefor this job.  With merge sort, we can operate on the buffer in sequentialorder, taking only an extra half the memory hit over the size of the buffer.This not only turned out to be cheaper than bringing offsets into memory, but itwas a lot more predictable in terms of memory usage overhead as well  (roughlyhalf the buffer size). Even better, the overhead required to run merge sort isitself memory-mapped.</p><p>有了这些限制，我们发现合并排序算法最适合这项工作。使用合并排序，我们可以按顺序对缓冲区进行操作，在缓冲区大小上只需要额外一半的内存命中率。事实证明，这不仅比将偏移量引入内存更便宜，而且在内存使用开销方面也更可预测(大约是缓冲区大小的一半)。更好的是，运行合并排序所需的开销本身就是内存映射的。</p><p> Merge sort also had one very positive effect. With offset based sorting, we hadto keep the offsets in memory while iterating over and processing the buffer,which put even more pressure on memory. With merge sort,  the extra memoryneeded is released by the time iteration starts, which means more memory isavailable for buffer processing.</p><p>合并排序还有一个非常积极的效果。使用基于偏移量的排序，我们不得不在迭代和处理缓冲区时将偏移量保留在内存中，这给内存带来了更大的压力。使用合并排序，所需的额外内存在迭代开始时被释放，这意味着有更多的内存可用于缓冲处理。</p><p> z.Buffer also supports allocating memory via  Calloc, and automaticallymemory mapping it once it exceeds a certain user-specified limit. This makes itwork really well across all sizes of data.</p><p>Z.Buffer还支持通过Calloc分配内存，一旦内存超过用户指定的限制，就会自动进行内存映射。这使得它在各种大小的数据上都能很好地工作。</p><p> buffer := z.NewBuffer(256&lt;&lt;20) // Start with 256MB via Calloc.buffer.AutoMmapAfter(1&lt;&lt;30) // Automatically mmap it after it becomes 1GB.for i := 0; i &lt; 1e9; i++ { b := buffer.SliceAllocate(nodeSz) n := (*node)(unsafe.Pointer(&amp;b[0])) n.val = rand.Int63()}buffer.SortSlice(func(left, right []byte) bool { nl := (*node)(unsafe.Pointer(&amp;left[0])) nr := (*node)(unsafe.Pointer(&amp;right[0])) return nl.val &lt; nr.val})// Iterate over nodes in increasing order of val.buffer.SliceIterate(func(b []byte) error { n := (*node)(unsafe.Pointer(&amp;b[0])) _ = n.val return nil})</p><p>Buffer：=z.NewBuffer(256；&lt；20)//通过Calloc.Buffer.AutoMmapAfter(1&lt；&lt；30)从256MB开始//它变成1GB后自动映射。对于i：=0；i&lt；1e9；i++{b：=Buffer.SliceAllocate(NodeSz)n：=(*node)(unSafe.Point(&amp；B[0])n.val=rand.Int63()}Buffer.SortSlice(func(Left，Right[]byte)bool{nl：=(*node)(unSafe.Pointer(&amp；Left[0]))nr：=(*node)(&amp；right[0])return nl.val&lt；nr.val})//按val.Buffer.Slicer.Slice.Node递增顺序遍历节点。B[0]))_=n.val返回值为空})。</p><p>  All of this discussion would not be complete without touching on memory leaks.Now that we are using manual memory allocation, there are bound to be memoryleaks where we forgot to deallocate memory.  How do we catch those?</p><p>如果不涉及内存泄漏，所有这些讨论都将是不完整的。现在我们使用的是手动内存分配，在我们忘记释放内存的情况下，必然会有内存泄漏。我们怎么才能抓住它们呢？</p><p> One simple thing we did early on was to have an atomic counter track the numberof bytes allocated via these calls, so we can quickly know how much memory wehave manually allocated in the program via  z.NumAllocBytes(). If by theend of our memory test we still had any memory left, this indicated a leak.</p><p>我们之前做的一件简单的事情是让原子计数器跟踪通过这些调用分配的字节数，这样我们就可以通过z.NumAllocBytes()快速知道我们在程序中手动分配了多少内存。如果在内存测试结束时仍有剩余内存，则表明存在泄漏。</p><p> When we did find a leak, we initially tried to use the  jemalloc memoryprofiler. But, we soon realized that it isn&#39;t helpful. It doesn&#39;t see the entirecall stack due to the Cgo boundary. All that the profiler sees are allocationsand de-allocations coming from the same  z.Calloc and  z.Free calls.</p><p>当我们确实发现了一个漏洞时，我们最初尝试使用jemalloc内存分析器。但是，我们很快意识到这并没有什么用处。由于CGO边界的原因，它看不到整个recall堆栈。分析器看到的所有内容都是来自相同z.Calloc和z.Free调用的分配和释放。</p><p> Thanks to the Go runtime, we were able to quickly build a simple system to capturethe callers into  z.Calloc and match them against  z.Free calls. Thissystem requires mutex locks, so we chose not to enable it by default. Instead,we use a  leak build flag to turn on leak debug messages for our dev builds.This automatically detects leaks, and prints out the places where any leaksoccur.</p><p>多亏了Go运行时，我们能够快速构建一个简单的系统来将调用者捕获到z.Calloc中，并将它们与z.Free调用进行匹配。这个系统需要互斥锁，所以我们选择默认不启用它。相反，我们使用泄漏构建标志来打开开发人员构建的泄漏调试消息。这会自动检测泄漏，并打印出发生泄漏的位置。</p><p> // If leak detection is enabled.pc, _, l, ok := runtime.Caller(1)if ok { dallocsMu.Lock() dallocs[uptr] = &amp;dalloc{ pc: pc, no: l, sz: n, } dallocsMu.Unlock()}// Induced leak to demonstrate leak capture. The first number shows// the size of allocation, followed by the function and the line// number where the allocation was made.$ go test -v -tags=&#34;jemalloc leak&#34; -run=TestCalloc...LEAK: 128 at func: github.com/dgraph-io/ristretto/z.TestCalloc 91</p><p>//如果启用了泄漏检测。pc，_，l，ok：=runtime.Caller(1)if ok{dallocsMu.Lock()dallocs[uptr]=&amp；dalloc{pc：pc，no：l，sz：n，}dallocsMu.Unlock()}//诱导泄漏以演示泄漏捕获。第一个数字显示//分配的大小，后跟函数和//进行分配的行号。$go test-v-tag=&#34；jemalloc leak&#34；-run=TestCalloc...leak：128 at func：github.com/dgraph-io/ristretto/z.TestCalloc 91。</p><p>  With these techniques, we get the best of both worlds: We can do  manual memoryallocation in critical, memory-bound code paths. At the same time,we can get the benefits of  automatic garbage collection in non-critical codepaths. Even if you are not comfortable using Cgo or jemalloc, you could apply thesetechniques on bigger chunks of Go memory, with similar impact.</p><p>使用这些技术，我们两全其美：我们可以在关键的、内存受限的代码路径中进行手动内存分配。同时，我们还可以在非关键代码路径中获得自动垃圾回收的好处。即使你不习惯使用CGO或jemalloc，你也可以将这些技术应用到更大的围棋内存上，产生类似的效果。</p><p> All of the libraries mentioned above are available under Apache 2.0 license inthe  Ristretto/z package. The memtest and demo code is located in contrib folder.</p><p>上面提到的所有库都在Ristretto/z包中的Apache2.0许可下可用。MemTest和演示代码位于Conrib文件夹中。</p><p> Both Badger and Dgraph (particularlyBadger) have already gained immensely from using these libraries. We can nowprocess terabytes of data with limited memory usage –  in line with what you&#39;dexpect from a C++ program. We are further identifying areas where we putpressure on Go memory, and relieving it by switching to manual memorymanagement where that makes sense.</p><p>獾和Dgraph(特别是獾)都已经从使用这些库中获益良多。我们现在可以使用有限的内存来处理TB级的数据--这符合您对C++程序的期望。我们正在进一步找出围棋记忆面临压力的领域，并在有意义的地方切换到手动记忆管理来缓解压力。</p><p> Dgraph v20.11 ( T&#39;Challa) release will be the first one to include all of thesememory management features. Our goal is to ensure that Dgraph never needs morethan 32 GB of physical RAM to run any kind of workload. And using  z.Calloc, z.Free,  z.Allocator and  z.Buffer helps us achieve this goal with Go.</p><p>Dgraph v20.11(T&#39；Challa)版本将是第一个包含所有内存管理功能的版本。我们的目标是确保Dgraph永远不需要超过32 GB的物理RAM来运行任何类型的工作负载。使用z.Calloc、z.Free、z.Allocator和z.Buffer可以帮助我们通过Go实现这一目标。</p><p> Over the years, we have tried all tricks of the trade within Go. Usingsync.Pool, maintaining our own freelists, avoiding allocations on heapwherever possible, using buffer arenas and so on.  ↩︎</p><p>多年来，我们在GO中尝试了所有的交易技巧。使用sync.Pool，维护我们自己的自由列表，尽可能避免堆上的分配，使用缓冲区区域等等。↩︎。</p><p> When you gain experience writing in a language with manual memorymanagement, you develop an eye towards the allocations and deallocations.Moreover, profiling tools further help you determine memory leaks toeradicate them from the code base. This is no different from gaining an eyetowards concurrency patterns when writing code in Go. Both concurrency andmanual memory management look particularly hard to outsiders, but are justpart of the game for the developers regularly working on those languages.  ↩︎</p><p>当您获得使用手动内存管理的语言编写代码的经验时，您就会注意到分配和释放。此外，性能分析工具还可以进一步帮助您确定内存泄漏，以便从代码库中消除内存泄漏。这与在Go中编写代码时获得眼向并发模式没有什么不同。在外人看来，并发和手动内存管理都特别困难，但对于经常致力于这两种语言的开发人员来说，它们只是游戏的一部分。↩︎</p><p>  In fact, some experimentation with managing freelists within allocatorproved to be slower than just using Calloc and Free, due to the need for mutexlocks.  ↩︎</p><p>事实上，由于需要互斥锁，在allocator中管理自由职业者的一些实验被证明比仅仅使用Calloc和Free要慢。↩︎。</p><p> A slice of variable-length strings  var buf []string is still fixed sizefrom the perception of the slice.  buf[i] and  buf[j] take exactly the sameamount of memory, because they&#39;re both pointers to string, and can be readilyswapped within  buf. That&#39;s not the case here with byte slices being laid outon a much bigger byte buffer.  ↩︎</p><p>可变长度字符串的片段var buf[]字符串的大小仍然是固定的，这取决于对片段的感知。Buf[i]和buf[j]占用的内存量完全相同，因为它们都是指向字符串的指针，并且可以在buf内随时交换。这里的情况并非如此，字节片被放置在一个大得多的字节缓冲区上。↩︎</p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://dgraph.io/blog/post/manual-memory-management-golang-jemalloc/">https://dgraph.io/blog/post/manual-memory-management-golang-jemalloc/</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/内存/">#内存</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/jemalloc/">#jemalloc</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/memory/">#memory</a></button></div></div><div class="shadow p-3 mb-5 bg-white rounded clearfix"><div class="container"><div class="row"><div class="col-sm"><div><a target="_blank" href="/story/1032431.html"><img src="http://img2.diglog.com/img/2020/10/thumb_f84a708f828fff14f092a76e6ba324d4.jpg" class="img-fluid" onerror="this.style.display='none'"></a></div><div class="item_title"><a target="_blank" href="/story/1032431.html">现代Kafka-API存储系统的每核线程缓存管理</a></div><span class="my_story_list_date">2020-10-31 9:55</span></div><div class="col-sm"><div><a target="_blank" href="/story/1032085.html"><img src="http://img2.diglog.com/img/2020/10/thumb_7b3f9021ea7798c4df33855ddbc4f79f.jpg" class="img-fluid" onerror="this.style.display='none'"></a></div><div class="item_title"><a target="_blank" href="/story/1032085.html">Gem5中的ARM事务性内存扩展支持</a></div><span class="my_story_list_date">2020-10-30 2:0</span></div><div class="col-sm"><div><a target="_blank" href="/story/1031631.html"><img src="http://img2.diglog.com/img/2020/10/thumb_444d759ef07609563082147df13a7e22.jpg" class="img-fluid" onerror="this.style.display='none'"></a></div><div class="item_title"><a target="_blank" href="/story/1031631.html">Linus Torvalds欢呼“历史性的”Linux5.10抛弃了废弃的地址artef</a></div><span class="my_story_list_date">2020-10-28 6:6</span></div><div class="col-sm"><div><a target="_blank" href="/story/1030601.html"><img src="http://img2.diglog.com/img/2020/10/thumb_af62daf8ef2bb0719075fe04e35ad4e0.jpeg" class="img-fluid" onerror="this.style.display='none'"></a></div><div class="item_title"><a target="_blank" href="/story/1030601.html">让我们用GPU构建一个高性能的模糊器</a></div><span class="my_story_list_date">2020-10-23 0:41</span></div></div></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/美国/">#美国</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/谷歌/">#谷歌</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/linux/">#linux</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/程序/">#程序</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy; 2020 diglog.com </div></div></body></html>