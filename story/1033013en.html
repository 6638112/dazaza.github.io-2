<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>AI教父Geoff Hinton：“深度学习将能够做任何事情。”</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">AI教父Geoff Hinton：“深度学习将能够做任何事情。”</h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2020-11-04 02:15:03</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2020/11/be8e1e5468352429159fb69334573f53.jpg"><img src="http://img2.diglog.com/img/2020/11/be8e1e5468352429159fb69334573f53.jpg" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>The modern AI revolution began during an obscure research contest. It was 2012, the third year of the annual ImageNet competition, which challenged teams to build computer vision systems that would recognize 1,000 objects, from animals to landscapes to people.</p><p>现代人工智能革命始于一场鲜为人知的研究竞赛。那是2012年，也就是一年一度的ImageNet比赛的第三个年头，比赛挑战团队建立能够识别1000个物体的计算机视觉系统，从动物到风景再到人。</p><p>  In the first two years, the best teams had failed to reach even 75% accuracy. But in the third, a band of three researchers—a professor and his students—suddenly blew past this ceiling. They won the competition by a staggering 10.8 percentage points. That professor was Geoffrey Hinton, and the technique they used was called deep learning.</p><p>在最初的两年里，最好的团队甚至没有达到75%的准确率。但在第三次实验中，一群三名研究人员--一名教授和他的学生--突然越过了这个天花板。他们以惊人的10.8个百分点赢得了比赛。这位教授就是杰弗里·辛顿，他们使用的技术叫做深度学习。</p><p>  Hinton had actually been working with deep learning since the 1980s, but its effectiveness had been limited by a lack of data and computational power. His steadfast belief in the technique ultimately paid massive dividends. The fourth year of the ImageNet competition, nearly every team was using deep learning and achieving miraculous accuracy gains. Soon enough deep learning was being applied to tasks beyond image recognition, and within a broad range of industries as well.</p><p>自20世纪80年代以来，辛顿实际上一直在研究深度学习，但由于缺乏数据和计算能力，其有效性一直受到限制。他对这项技术的坚定信念最终带来了巨大的回报。在ImageNet比赛的第四年，几乎每个团队都在使用深度学习，并实现了奇迹般的准确率增长。很快，足够深入的学习被应用到图像识别以外的任务中，也应用到了广泛的行业中。</p><p>  Last year, for his foundational contributions to the field, Hinton was awarded the Turing Award, alongside other AI pioneers Yann LeCun and Yoshua Bengio. On October 20, I spoke with him at MIT Technology Review’s annual EmTech MIT conference about the state of the field and where he thinks it should be headed next.</p><p>去年，由于他对该领域的基础性贡献，辛顿与其他人工智能先驱严乐村(Yann LeCun)和约书亚·本吉奥(Yoshua Bengio)一起被授予图灵奖。10月20日，在“麻省理工学院技术评论”(MIT Technology Review)的年度EMTech MIT会议上，我与他谈到了该领域的现状以及他认为该领域下一步的发展方向。</p><p>    You think deep learning will be enough to replicate all of human intelligence. What makes you so sure?</p><p>你认为深度学习就足以复制人类的所有智慧。你怎么这么肯定？</p><p>  I do believe deep learning is going to be able to do everything, but I do think there’s going to have to be quite a few conceptual breakthroughs. For example, in 2017  Ashish Vaswani et al. introduced  transformers, which derive really good vectors representing word meanings. It was a conceptual breakthrough. It’s now used in almost all the very best natural-language processing. We’re going to need a bunch more breakthroughs like that.</p><p>我确实相信深度学习将能够做任何事情，但我确实认为将会有相当多的概念突破。例如，2017年，Ashish Vaswani等人。介绍了转换器，它派生出非常好的表示词义的向量。这是一个观念上的突破。现在几乎所有最好的自然语言处理都使用它。我们需要更多这样的突破。</p><p>  And if we have those breakthroughs, will we be able to approximate all human intelligence through deep learning?</p><p>如果我们有了这些突破，我们是否能够通过深度学习接近所有人类的智能？</p><p>  Yes. Particularly breakthroughs to do with how you get big vectors of neural activity to implement things like reason. But we also need a massive increase in scale. The human brain has about 100 trillion parameters, or synapses. What we now call a really big model, like  GPT-3, has 175 billion. It’s a thousand times smaller than the brain. GPT-3 can now generate pretty plausible-looking text, and it’s still tiny compared to the brain.</p><p>是。特别是在如何获得大的神经活动矢量来实现像理性这样的东西方面的突破。但我们也需要大规模扩大规模。人脑大约有100万亿个参数，或称突触。我们现在所说的非常大的型号，像GPT-3，有1750亿。它比大脑小一千倍。GPT-3现在可以生成看起来相当合理的文本，而且与大脑相比仍然很小。</p><p>    Both. There’s a sort of discrepancy between what happens in computer science and what happens with people. People have a huge amount of parameters compared with the amount of data they’re getting. Neural nets are surprisingly good at dealing with a rather small amount of data, with a huge numbers of parameters, but people are even better.</p><p>两者都有。在计算机科学中发生的事情和人身上发生的事情之间存在着某种差异。与他们获得的数据量相比，人们有大量的参数。神经网络令人惊讶地擅长处理相当少量的数据，具有大量的参数，但人的能力更强。</p><p>  A lot of the people in the field believe that common sense is the next big capability to tackle. Do you agree?</p><p>该领域的许多人认为，常识是下一个需要攻克的重大能力。你同意吗？</p><p>  I agree that that’s one of the very important things. I also think motor control is very important, and deep neural nets are now getting good at that. In particular, some recent work at Google has shown that you can do fine motor control and combine that with language, so that you can open a drawer and take out a block, and the system can tell you in natural language what it’s doing.</p><p>我同意这是非常重要的事情之一。我也认为运动控制非常重要，而深层神经网络现在正变得越来越擅长这一点。特别值得一提的是，谷歌最近的一些工作表明，你可以进行精细的运动控制，并将其与语言相结合，这样你就可以打开抽屉，拿出一个积木，系统可以用自然语言告诉你它在做什么。</p><p>  For things like GPT-3, which generates this wonderful text, it’s clear it must understand a lot to generate that text, but it’s not quite clear how much it understands. But if something opens the drawer and takes out a block and says, “I just opened a drawer and took out a block,” it’s hard to say it doesn’t understand what it’s doing.</p><p>对于像GPT-3这样生成这个精彩文本的东西来说，很明显它必须理解很多东西才能生成这个文本，但是它理解多少还不是很清楚。但如果某个东西打开抽屉拿出一块积木说，“我刚打开抽屉拿出一块积木”，很难说它不明白它在做什么。</p><p>  The AI field has always looked to the human brain as its biggest source of inspiration, and different approaches to AI have stemmed from different theories in cognitive science. Do you believe the brain actually builds representations of the external world to understand it, or is that just a useful way of thinking about it?</p><p>人工智能领域一直将人脑作为其最大的灵感来源，不同的人工智能方法源于认知科学中的不同理论。你认为大脑实际上是通过构建外部世界的表征来理解它的，还是这只是一种有用的思考方式？</p><p>  A long time ago in cognitive science, there was a debate between two schools of thought. One was led by Stephen Kosslyn, and he believed that when you manipulate visual images in your mind, what you have is an array of pixels and you’re moving them around. The other school of thought was more in line with conventional AI. It said, “No, no, that’s nonsense. It’s hierarchical, structural descriptions. You have a symbolic structure in your mind, and  that’s what you’re manipulating.”</p><p>很久以前，在认知科学中，两个学派之间存在着一场争论。其中一个是由斯蒂芬·科斯林(Stephen Kosslyn)领导的，他相信当你在脑海中操纵视觉图像时，你得到的是一组像素，你在四处移动它们。另一种学派更符合传统的人工智能。它说，“不，不，那是胡说八道。它是分层的、结构化的描述。你的头脑里有一个象征性的结构，这就是你在操纵的。“。</p><p>  I think they were both making the same mistake. Kosslyn thought we manipulated pixels because external images are made of pixels, and that’s a representation we understand. The symbol people thought we manipulated symbols because we also represent things in symbols, and  that’s a representation we understand. I think that’s equally wrong. What’s inside the brain is these big vectors of neural activity.</p><p>我想他们都在犯同样的错误。科斯林认为我们操纵像素是因为外部图像是由像素组成的，这是我们理解的一种表现形式。符号人们认为我们操纵了符号，因为我们也用符号来表示事物，这是我们理解的一种表示。我认为这同样是错误的。大脑内部是这些神经活动的大载体。</p><p>  There are some people who still believe that symbolic representation is one of the approaches for AI.</p><p>有一些人仍然认为符号表示是人工智能的方法之一。</p><p>  Absolutely. I have good friends like Hector Levesque, who really believes in the symbolic approach and has done great work in that. I disagree with him, but the symbolic approach is a perfectly reasonable thing to try. But my guess is in the end, we’ll realize that symbols just exist out there in the external world, and we do internal operations on big vectors.</p><p>绝对一点儿没错。我有像赫克托·莱韦斯克这样的好朋友，他非常相信象征性的方法，并在这方面做了大量的工作。我不同意他的观点，但象征性的方法是完全合理的尝试。但我的猜测是，最终，我们会意识到符号只是存在于外部世界，我们对大向量进行内部运算。</p><p>  What do you believe to be your most contrarian view on the future of AI?</p><p>你认为你对人工智能未来最逆向的观点是什么？</p><p>  Well, my problem is I have these contrarian views and then five years later, they’re mainstream. Most of my contrarian views from the 1980s are now kind of broadly accepted. It’s quite hard now to find people who disagree with them. So yeah, I’ve been sort of undermined in my contrarian views.</p><p>嗯，我的问题是我有这些相反的观点，然后五年后，它们就成了主流。我上世纪80年代的大多数逆向观点现在都被广泛接受。现在很难找到不同意他们意见的人。所以，是的，我的逆向观点在某种程度上被削弱了。</p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://www.technologyreview.com/2020/11/03/1011616/ai-godfather-geoffrey-hinton-deep-learning-will-do-everything/">https://www.technologyreview.com/2020/11/03/1011616/ai-godfather-geoffrey-hinton-deep-learning-will-do-everything/</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/深度学习/">#深度学习</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/教父/">#教父</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/godfather/">#godfather</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/认为/">#认为</a></button></div></div><div class="shadow p-3 mb-5 bg-white rounded clearfix"><div class="container"><div class="row"><div class="col-sm"><div><a target="_blank" href="/story/1032226.html"><img src="http://img2.diglog.com/img/2020/10/thumb_b8027d74da693b3965919283f0a9934e.jpg" class="img-fluid" onerror="this.style.display='none'"></a></div><div class="item_title"><a target="_blank" href="/story/1032226.html">如何学习机器学习和深度学习：软件工程师指南</a></div><span class="my_story_list_date">2020-10-30 12:2</span></div><div class="col-sm"><div><a target="_blank" href="/story/1030180.html"><img src="http://img2.diglog.com/img/2020/10/thumb_be19ff4c03d49d80cc65e6e1636fc086.png" class="img-fluid" onerror="this.style.display='none'"></a></div><div class="item_title"><a target="_blank" href="/story/1030180.html">Thelio Mega：世界上最小的四GPU深度学习系统</a></div><span class="my_story_list_date">2020-10-21 5:22</span></div><div class="col-sm"><div><a target="_blank" href="/story/1030055.html"><img src="http://img2.diglog.com/img/2020/10/thumb_feddd3c63be51cbfdf0157dd7226aed9.jpg" class="img-fluid" onerror="this.style.display='none'"></a></div><div class="item_title"><a target="_blank" href="/story/1030055.html">为什么深度学习能奏效，尽管它不应该奏效</a></div><span class="my_story_list_date">2020-10-20 22:43</span></div><div class="col-sm"><div><a target="_blank" href="/story/1029627.html"><img src="http://img2.diglog.com/img/2020/10/thumb_707469b8b44026f59e4810b4eb6b5320.jpeg" class="img-fluid" onerror="this.style.display='none'"></a></div><div class="item_title"><a target="_blank" href="/story/1029627.html">生产资源列表中的深度学习</a></div><span class="my_story_list_date">2020-10-19 0:33</span></div></div></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/美国/">#美国</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/谷歌/">#谷歌</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/linux/">#linux</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/程序/">#程序</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy; 2020 diglog.com </div></div></body></html>