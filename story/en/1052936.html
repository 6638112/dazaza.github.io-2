<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>GRPC易于误解 gRPC Is Easy to Misconfigure</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">gRPC Is Easy to Misconfigure<br/>GRPC易于误解 </h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2021-03-17 13:49:15</div><div class="page_narrow text-break page_content"><p>Google&#39;s  gRPC is an RPC system that supports many languages, and is relatively widely used. I think its popularity is due to being used for parts of Docker and Kubernetes. I think gRPC is mostly fine, but it is surprisingly easy to screw up by misconfiguring it. Part of that is because RPC systems are challenging to get right. They need to be useful for a wide variety of services, ranging from high request rate services that handle thousands of tiny requests each second, to services that need to transfer a lot of data, or servics with thousands of concurrent, slow requests that take minutes to complete. As a result, an RPC system like gRPC needs to be very configurable. Unfortunately, it is also pretty easy to configure it in a way that causes hard to understand errors.</p><p>Google＆＃39; S GRPC是一个支持许多语言的RPC系统，并且相对广泛地使用。我认为它的受欢迎程度是由于用于Docker和Kubernetes的部分。我认为GRPC大多是很好的，但通过错误配置它令人惊讶地搞砸了。部分是因为RPC系统有挑战性。他们需要对各种各样的服务有用，从高索取率服务范围内，这些服务每秒处理数千个小型请求，需要传输大量数据的服务，或者具有数千个并发，慢速请求的服务需要几分钟的服务去完成。结果，GRPC等RPC系统需要非常可配置。不幸的是，以一种导致难以理解的错误的方式配置它也很容易。</p><p> The rest of this blog post is going to describe two examples of annoying edge cases I ran into recently. I wasted about a day to debug and understand each of these. Mostly I&#39;m hoping that if someone else runs into these errors, they will find this article and I can save them time. I&#39;m also hopeful that the gRPC team will eventually make this library easier to use, by improving the error messages and documenting best practices.</p><p> 此博客文章的其余部分将描述我最近遇到的令人讨厌的边缘案例的两个例子。我浪费了一天时间来调试并理解这些。主要是我希望如果别人遇到这些错误，他们会发现这篇文章，我可以节省时间。我也希望通过改进错误消息和记录最佳实践，GRPC团队最终将使此库更易于使用此库。</p><p>  gRPC is designed to reuse TCP connections for multiple requests. However, many networks terminate connections that are idle for too long. For example, the  AWS NLB TCP load balancer has a 350 second timeout. TCP has an optional keepalive mechanism. It is enabled by default on Linux, but with a 2 hour timeout before sending the first keepalive. This is useful for cleaning up long dead connections, but not to keep these connections alive through NATs or load balancers. Go configures  TCP keepalives to 15 seconds by default, which should be often enough to keep the network connection alive.</p><p>  GRPC旨在重用TCP连接以获取多个请求。但是，许多网络终止了空闲时间过长的连接。例如，AWS NLB TCP负载均衡器具有350秒的超时。 TCP具有可选的核心机制。在Linux上默认启用它，但在发送第一个Keepalive之前，使用2小时超时。这对于清理长死连接是有用的，但不能通过NAT或负载均衡器保持这些连接。默认情况下，Go将TCP Keepalives配置为15秒，这应该通常足以保持网络连接。</p><p> Unfortunately, TCP keepalives are invisible to applications, and may not be supported by some operating systems. As a result, gRPC has its own keepalives. However, the  gRPC client-side keepalive specification itself says: &#34;client authors must coordinate with service owners for whether a particular client-side setting is acceptable&#34;. If a client sends keepalive pings too often, servers close the connection. This is to prevent large numbers of idle clients from consuming too many resources. The default is to allow one ping every 5 minutes, if an RPC call is active.</p><p> 不幸的是，TCP KeekAlives对应用程序是看不见的，可能不受某些操作系统的支持。因此，GRPC有自己的keepalives。但是，GRPC客户端Keepalive规范本身表示：＆＃34;客户作者必须与服务主协调，以便是否可以接受特定客户端设置和＃34;如果客户端经常发送Keepalive Ping，则服务器关闭连接。这是为了防止大量空闲客户端消耗太多资源。如果RPC调用处于活动状态，则默认为允许每5分钟一次。</p><p> In my opinion, this means this setting is virtually unusable and should be avoided. The server defaults are insufficient for some load balancers (e.g.  Azure&#39;s TCP load balancer drops idle connections after 4 minutes by default). It is hard and error prone to deploy a configuration that is more aggressive. You will have to first deploy all servers to permit the more aggressive pinging, then you will need to deploy the clients. If you want to undo it, you will need to do the opposite: first deploy the clients to ping less, then deploy the servers. If you screw this order up, or make a configuration error, you get intermittent &#34;transport is closing&#34; errors. As an alternative, always set a deadline on your gRPC requests, and use a reasonable retry policy. If that is insufficent, then you can set keepalives on the server, which avoids most of the problems. I  wrote a long bug report asking for the gRPC documentation to be improved so hopefully others can avoid my mistake.</p><p> 在我看来，这意味着这个设置几乎无法使用，应该避免。某些负载均衡器的服务器默认值不足（例如Azure＆＃39; S TCP Load Balancer默认情况下4分钟后丢弃空闲连接）。很容易出错，部署更具侵略性的配置。您必须首先部署所有服务器以允许更激进的ping，那么您需要部署客户端。如果您想撤消它，您需要执行相反的操作：首先将客户端部署到Ping少，然后部署服务器。如果您拧紧此订单，或进行配置错误，则会收到间歇性＆＃34;运输正在关闭＆＃34;错误。作为替代方案，始终在GRPC请求上设置截止日期，并使用合理的重试策略。如果这是困难的，那么您可以在服务器上设置Keepalive，这避免了大多数问题。我写了一个长的错误报告，要求改进GRPC文档，所以希望其他人可以避免我的错误。</p><p> For others who might encounter this error, when client keepalive is too aggressive, client RPCs will fail with gRPC code UNAVAILABLE (14) and message &#34;transport is closing&#34;. The solution is to remove the client keepalive configuration. If you enable verbose gRPC logs, you will see:</p><p> 对于那些可能遇到此错误的其他人，当客户端KeepAlive过于激进时，客户RPC将失败，GRPC代码不可用（14）​​和消息＆＃34;运输正在关闭＆＃34;解决方案是删除客户端keepalive配置。如果启用详细的GRPC日志，您将看到：</p><p>   ERROR: 2021/03/14 11:02:26 [transport] transport: Got too many pings from the client, closing the connection.</p><p>   错误：2021/03/14 11:02:26运输：从客户端的乒乓球，关闭连接。 </p><p>  If you return an error from a gRPC request, it returns a  status code, a status message (unicode string), and an optional error details  (undocumented but supported by the library). So what happens when a server accidentally returns a really large error message? Unfortunately, the connection may get closed. In general, you can only return a maximum of about 7 kiB in your gRPC error message (3 kiB if you use the optional error details). That should be plenty. However, if you have an error message that prints a variable-length data structure, the right request can cause this limit to be exceeded. That is how I ran into this problem. The solution is to return shorter error messages. I also added a gRPC server interceptor to truncate errors, to make sure I don&#39;t accidentally do this again.</p><p>如果从GRPC请求返回错误，则返回状态代码，状态消息（Unicode字符串）和可选错误详细信息（未被记录但库支持）。那么当服务器意外返回一个非常大的错误消息时会发生什么？不幸的是，连接可能会关闭。通常，您只能在GRPC错误消息中返回最多约7个Kib（如果使用可选的错误详细信息，则为3 Kib）。这应该很多。但是，如果您的错误消息打印了可变长度数据结构，则正确的请求可能导致超出此限制。这就是我遇到这个问题的方式。解决方案是退回更短的错误消息。我还添加了GRPC服务器拦截器来截断错误，以确保我不小心再次这样做了。</p><p> By default, the Go gRPC implementation defaults to limits error messages to 16 MiB. If you exceed this limit, on the client, you will see one of two errors. On the server you will see nothing, because as far as it is aware, it returned the error correctly.</p><p> 默认情况下，GO GRPC实现默认为将错误消息限制为16个MIB。如果您超过此限制，请在客户端上，您将看到两个错误之一。在服务器上，您将看到任何内容，因为就知道，它正确地返回了错误。</p><p>  The C client limits error messages to 8 kiB. If you exceed this limit, on the client you will see one of two errors, depending on if the server is a Go or C server.</p><p>  C客户端将错误消息限制为8个Kib。如果超出此限制，则在客户端上，您将看到两个错误中的一个，具体取决于服务器是GO或C服务器。</p><p>   ERROR: 2021/03/05 10:13:18 [transport] header list size to send violates the maximum size (8192 bytes) set by client</p><p>   错误：2021/03/05 10:13:18 [传输]标题列表大小发送违反客户端设置的最大大小（8192字节） </p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://www.evanjones.ca/grpc-is-tricky.html">https://www.evanjones.ca/grpc-is-tricky.html</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/grpc/">#grpc</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/easy/">#easy</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/分享/">#分享</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy;2012 - 2021 diglog.com </div></div></body></html>