<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>一些人认为，合成数据可以让人工智能系统变得更好Some argue that synthetic data can make AI systems better</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">Some argue that synthetic data can make AI systems better<br/>一些人认为，合成数据可以让人工智能系统变得更好</h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2022-02-20 17:10:40</div><div class="page_narrow text-break page_content"><p>It may be counterintuitive. But some argue that the key to training AI systems that must work in messy real-world environments, such as self-driving cars and warehouse robots, is not, in fact, real-world data. Instead, some say,  synthetic data is what will unlock the true potential of AI. Synthetic data is generated instead of collected, and the consultancy Gartner has estimated that  60 percent of data used to train AI systems will be synthetic. But its use is controversial, as questions remain about whether synthetic data can accurately mirror real-world data and prepare AI systems for real-world situations.</p><p>这可能违反直觉。但一些人认为，训练必须在混乱的现实世界环境中工作的人工智能系统（如自动驾驶汽车和仓库机器人）的关键实际上不是真实世界的数据。相反，有人说，合成数据将释放人工智能的真正潜力。合成数据是生成的，而不是收集的，咨询公司Gartner估计，用于训练人工智能系统的数据中有60%将是合成的。但它的使用存在争议，因为合成数据是否能准确反映现实世界的数据，并为人工智能系统为现实世界的情况做好准备，仍然存在疑问。</p><p> Nvidia has embraced the synthetic data trend, and is striving to be a leader in the young industry. In November, Nvidia founder and CEO Jensen Huang  announced the launch of the  Omniverse Replicator, which Nvidia describes as “an engine for generating synthetic data with ground truth for training AI networks.” To find out what that means,  IEEE Spectrum spoke with  Rev Lebaredian, vice president of simulation technology and   Omniverse engineering at Nvidia.</p><p>英伟达已经接受了合成数据的趋势，并正在努力成为年轻行业的领导者。十一月，NVIDIA创始人兼首席执行官Jensen Huang宣布推出全能复制器，NVIDIA将其描述为“一个用于生成人工智能数据的引擎，用于训练人工智能网络。”为了弄清这意味着什么，IEEE Spectrum采访了Nvidia仿真技术和Omniverse工程副总裁雷夫·勒巴雷迪亚。</p><p>    The    Omniverse Replicator is described as “a powerful synthetic data generation engine that produces physically simulated synthetic data for training neural networks.” Can you explain what that means, and especially what you mean by “physically simulated”?</p><p>Omniverse Replicator被描述为“一个强大的合成数据生成引擎，可以生成用于训练神经网络的物理模拟合成数据。”你能解释一下这意味着什么，尤其是你所说的“物理模拟”是什么意思吗？</p><p>  Rev Lebaredian: Video games are essentially simulations of fantastic worlds. There are attempts to make the physics of games somewhat realistic: When you blow up a wall or a building, it crumbles. But for the most part, games aren’t trying to be truly physically accurate, because that’s computationally very expensive. So it’s always about: What approximations are you willing to do in order to make it tractable as a computing problem? A video game typically has to run on a small computer, like a console or even on a phone. So you have those severe constraints. The other thing with games is that they’re fantasy worlds and they’re meant to be fun, so real-world physics and accuracy is not necessarily a great thing.</p><p>勒巴雷迪亚牧师：电子游戏本质上是对梦幻世界的模拟。有人试图让游戏的物理部分变得现实一些：当你炸毁一堵墙或一栋建筑时，它就会倒塌。但在大多数情况下，游戏并不试图真正做到物理上的精确，因为这在计算上非常昂贵。所以它总是关于：为了使它成为一个可处理的计算问题，你愿意做什么近似？视频游戏通常必须在小型计算机上运行，比如控制台，甚至是手机上。所以你有这些严格的限制。游戏的另一个特点是，它们是梦幻世界，它们是为了好玩，所以现实世界的物理和准确性不一定是件好事。</p><p>  With Omniverse, our goal is to do something that really hasn’t been done before in real-time world simulators. We’re trying to make a physically accurate simulation of the world. And when we say physically accurate, we mean all aspects of physics that are relevant. How things look in the physical world is the physics of how light interacts with matter, so we simulate that. We simulate how atoms interact with each other with rigid-body physics, soft-body physics, fluid dynamics, and whatever else is relevant. Because we believe that if you can simulate the real world closely enough, then you gain superpowers.</p><p>有了Omniverse，我们的目标是做一些在实时世界模拟器中从未做过的事情。我们试图对世界进行物理上精确的模拟。当我们说物理精确时，我们指的是物理的所有相关方面。物理世界中事物的外观是光如何与物质相互作用的物理学，所以我们对此进行模拟。我们用刚体物理、软体物理、流体动力学以及其他相关的东西来模拟原子之间的相互作用。因为我们相信，如果你能足够紧密地模拟现实世界，那么你就会获得超能力。</p><p>  Lebaredian: First, you get teleportation. If I can take this room around me and represent it in a virtual world, now I can move my camera around in that world and teleport to any location. I can even put on a VR headset and feel like I’m inside it. And if I can synchronize the state of the real world with the virtual one, then there’s really no difference. I might have sensors on Mars that ingest the real world and send over a copy of that info to Earth in real time—or 8 minutes later or whatever it takes for the speed of light to travel from Mars. If I can reconstruct that world virtually and immerse myself in it, then effectively it’s like I’m teleporting to Mars 8 minutes ago.</p><p>勒巴雷迪亚：首先，你可以进行远程传送。如果我能把这个房间放在我周围，并在虚拟世界中表现出来，现在我可以在那个世界中移动我的相机，并传送到任何位置。我甚至可以戴上虚拟现实耳机，感觉自己就在里面。如果我能同步真实世界和虚拟世界的状态，那就真的没有区别了。我可能会在火星上安装传感器，接收真实世界，并在实时或8分钟后将该信息的副本发送到地球，或者以光速从火星传播到地球所需的任何方式。如果我能虚拟地重建那个世界并沉浸其中，那就好像我在8分钟前传送到火星一样。</p><p> And given some initial conditions about the state of the world, if you can simulate accurately enough, then you can potentially predict the future. Say I have the state of the world right now in this room and I’m holding this phone up. I can simulate what happens the moment I let go and it falls—and if my simulation is close enough, then I can predict how this phone is going to fall and hit the ground. What’s really cool about that is you can change the initial conditions and do some experiments. You can say, What can alternate futures look like? What if I reconfigure my factory or make different decisions about how I manipulate things in my environment? What would these different futures look like? And that allows you to do optimizations. You can find the best future.</p><p>给定一些关于世界状态的初始条件，如果你能足够准确地模拟，那么你就有可能预测未来。假设我现在在这个房间里，我拿着这个电话。我可以模拟当我放开手机，手机掉下来的那一刻发生了什么，如果我的模拟足够接近，那么我可以预测这部手机将如何掉下来并撞到地面。最酷的是你可以改变初始条件，做一些实验。你可以说，替代未来会是什么样子？如果我重新配置我的工厂，或者就如何在我的环境中操作东西做出不同的决定，会怎么样？这些不同的未来会是什么样子？这允许你进行优化。你可以找到最好的未来。</p><p>   Okay, so that’s what you’re trying to build with Omniverse. How does all this help with AI?</p><p>好吧，这就是你试图用Omniverse构建的。这些对人工智能有什么帮助？</p><p> Lebaredian: In this new era of AI, developing advanced software is no longer something that just a grad student with a laptop can do. It requires serious investment. All the most advanced algorithms that mankind will develop in the future are going to be trained by systems that require a lot of data. That’s why people say data is the new oil. And it seems like the big tech companies that collect data have a natural advantage. But the truth is that for most of the AI that we’re going to create in the future, none of the data we have collected is that useful.</p><p>勒巴雷迪亚：在这个人工智能的新时代，开发高级软件不再是一个拥有笔记本电脑的研究生所能做的事情。这需要认真的投资。人类未来将开发的所有最先进的算法都将由需要大量数据的系统进行训练。这就是为什么人们说数据就是新的石油。而且，收集数据的大型科技公司似乎有着天然的优势。但事实是，对于我们未来将要创建的大多数人工智能，我们收集的数据都没有那么有用。</p><p> I noticed it when we did a demo for [the conference]   SIGGRAPH 2017. We had a   robot that could play dominoes, and we had multiple AI models that we had to train. One of the basic ones was a computer-vision model that could detect the dominoes that were on the table, tell you their orientation, and then tell you how many pips were on each domino: one, five, six, or whatever.</p><p>当我们为2017年[the conference]SIGGRAPH做演示时，我注意到了这一点。我们有一个可以玩多米诺骨牌的机器人，我们有多个人工智能模型需要训练。其中一个基本的是一个计算机视觉模型，它可以检测桌子上的多米诺骨牌，告诉你它们的方向，然后告诉你每个多米诺骨牌上有多少个点子：一个、五个、六个，或者其他什么。</p><p> Surely Google would have all the image data you need to train such an AI.</p><p>谷歌肯定会拥有你训练这种人工智能所需的所有图像数据。</p><p> Lebaredian: You can search Google images and you’ll find lots of pictures of dominoes, but what you’ll find is, first of all, none of them are labeled. A human has to label what each domino is and the side of each domino, and that’s a whole bunch of manual labor. But even if you get past the labeling, you’ll find that the images don’t have much diversity. We needed our algorithm to be robust to different lighting conditions because we were going to train it in our lab, but then take it to the show floor at SIGGRAPH. The cameras and sensors we used might also change, so the conditions around those could be different. We wanted the algorithm to work with any type of dominoes, whether they’re plastic or wood or whatever material. So even for this really simple thing, the necessary data just didn’t exist. If we were to go collect that data, we’d have to buy dozens or maybe hundreds of different dominos sets, set up different lighting conditions and different sensors and all of that. So, back then, we quickly coded off in a game engine a random domino generator that randomized all of that stuff. And overnight we trained a model that could do this robustly, and it worked in the convention center with different cameras.</p><p>勒巴雷迪亚：你可以搜索谷歌图片，你会发现很多多米诺骨牌的图片，但你会发现，首先，它们都没有标签。人类必须标记每一张骨牌是什么以及每一张骨牌的侧面，这需要大量的体力劳动。但即使你通过了标签，你也会发现图像没有太多的多样性。我们需要我们的算法对不同的光照条件具有鲁棒性，因为我们将在实验室对其进行训练，然后将其带到SIGGRAPH的展厅。我们使用的摄像头和传感器也可能会发生变化，因此周围的条件可能会有所不同。我们希望该算法能适用于任何类型的多米诺骨牌，无论它们是塑料、木材还是任何材料。所以，即使对于这个非常简单的事情，必要的数据也不存在。如果我们要去收集这些数据，我们就必须购买几十个甚至数百个不同的多米诺骨牌，设置不同的照明条件和不同的传感器等等。所以，当时，我们很快在游戏引擎中编写了一个随机多米诺骨牌生成器，将所有这些东西随机化。一夜之间，我们训练了一个模型，这个模型可以很好地做到这一点，它在会议中心用不同的摄像机工作。</p><p> That’s one simple case. For something more complex like self-driving cars or autonomous machines, the amount of data that we need, and the accuracy and diversity of that data, is just impossible to get from the real world. There’s really no way around it. Without physically accurate simulation to generate the data we need for these AIs, there’s no way we’re going to progress.</p><p>这是一个简单的例子。对于一些更复杂的东西，比如自动驾驶汽车或自动机器，我们需要的数据量，以及这些数据的准确性和多样性，是不可能从现实世界中获得的。真的没办法。如果没有精确的物理模拟来生成这些人工智能所需的数据，我们就不可能取得进展。</p><p> With Omniverse Replicator, are customers getting a one-size-fits-all synthetic data generator? Or are you tailoring it for different industries?</p><p>有了Omniverse Replicator，客户是否能得到一个一刀切的合成数据生成器？还是为不同的行业量身定制？</p><p> Lebaredian: What we’re building with Omniverse is a very general development platform that anyone can take and customize for their particular needs. Out of the box you get multiple renderers, which are simulators of the physics of light and matter. You get a spectrum of them that let you trade off accuracy for speed.</p><p>勒巴雷迪亚：我们用Omniverse构建的是一个非常通用的开发平台，任何人都可以根据自己的特殊需求进行定制。开箱即用，你可以得到多个渲染器，它们是光和物质物理的模拟器。你可以得到一系列的数据，让你在速度和准确性之间进行权衡。</p><p> We have a bunch of ways to bring in 3D data as inputs to Omniverse Replicator to generate the data that you need. For pretty much everything that’s man-made these days, there’s a 3D virtual representation of it somewhere. If you’re designing a car, a phone, a building, a bridge, or whatever, you use a CAD tool. The problem is that all these tools speak different languages. The data is in different formats. It’s very hard to combine them and build a scene that has all those constituent parts.</p><p>我们有很多方法将3D数据作为输入引入Omniverse Replicator，以生成您需要的数据。如今，几乎所有人造的东西，都有一个3D虚拟表示。如果你在设计一辆汽车、一部手机、一栋建筑、一座桥梁，或者其他任何东西，你需要使用CAD工具。问题是，所有这些工具都使用不同的语言。数据的格式不同。很难将它们结合起来，构建一个包含所有这些组成部分的场景。</p><p> With Omniverse, we’ve gone through the trouble of trying to connect all of these existing tools and harmonizing them. We built Omniverse on top of a system called   universal scene description that was originally developed by   Pixar and later open-sourced. We think USD is to virtual worlds as HTML is to Web pages: It’s a common way to describe things. We built a lot of tools around USD to let users transform the data, modify it, randomize things. But the source data can come from virtually anywhere because we have connectors to all the different tools that are relevant.</p><p>有了Omniverse，我们经历了连接所有这些现有工具并协调它们的困难。我们在一个名为universal scene description的系统上构建了Omniverse，该系统最初由皮克斯开发，后来是开源的。我们认为USD对于虚拟世界的意义就像HTML对于网页的意义一样：它是描述事物的常用方式。我们围绕USD构建了很多工具，让用户转换数据、修改数据、随机化数据。但源数据几乎可以来自任何地方，因为我们有连接到所有相关不同工具的连接器。</p><p>  Can you give me an example of an industry that would use Replicator to make synthetic data for AI training?</p><p>你能给我举一个使用Replicator为人工智能培训制作合成数据的行业的例子吗？</p><p> Lebaredian: We’ve shown the example of autonomous vehicles. There’s a lot of money going into figuring out how to make vehicles drive themselves, and synthetic data is becoming a major part of training the AI systems. We’ve already done some specialization within Omniverse Replicator for this domain: We have big outdoor worlds with roads and lanes and cars and pedestrians and street signs and all that kind of stuff.</p><p>勒巴雷迪亚：我们展示了自动驾驶汽车的例子。有大量资金用于研究如何让车辆自动驾驶，合成数据正在成为人工智能系统培训的主要部分。我们已经在Omniverse Replicator中为这个领域做了一些专门的工作：我们有巨大的户外世界，有道路、车道、汽车、行人和街道标志等等。</p><p> We’ve also done some specialization for robotics. But if we don’t support your domain out of the box, since it’s a tool kit, you can take it and do what you like with it. People have many paths to bring in their own 3D data or get data to construct virtual worlds. There are libraries and third-party 3D asset providers out there.</p><p>我们还为机器人技术做了一些专门研究。但是，如果我们不支持你的领域开箱即用，因为它是一个工具包，你可以用它做你喜欢的事情。人们有很多途径来引入自己的3D数据或获取数据来构建虚拟世界。还有图书馆和第三方3D资产提供商。</p><p>  For an autonomous vehicle company, an advantage of generating synthetic data is that it could train its vehicles on dangerous conditions, right? It can put in snow and ice, hard turns, that kind of thing?</p><p>对于一家自动驾驶汽车公司来说，生成合成数据的优势在于，它可以在危险条件下对车辆进行训练，对吗？它能把雪和冰，硬转弯，诸如此类的东西？</p><p> Lebaredian: They can change day and night conditions and position pedestrians and animals in dangerous situations that you wouldn’t want to construct in the real world. We don’t want to put humans or animals in perilous situations in real life, but I sure do want my autonomous vehicle to know how to react to these types of fringe situations. So if we can train them in the virtual world where it’s safe first, we get the best of both worlds.</p><p>勒巴雷迪亚：他们可以改变白天和夜间的条件，在你不想在现实世界中建造的危险情况下安置行人和动物。我们不想让人类或动物在现实生活中处于危险的境地，但我确实希望我的自动驾驶汽车知道如何应对这些边缘情境。因此，如果我们能在安全第一的虚拟世界中训练他们，我们就能两全其美。</p><p> So this synthetic data can be used in AI training as “ground truth data” with built-in labels that are superaccurate. But is that the best training strategy? These AI systems often need to operate in the world with incomplete and imperfect information.</p><p>因此，这些合成数据可以在人工智能训练中用作“地面真相数据”，并带有超精确的内置标签。但这是最好的训练策略吗？这些人工智能系统通常需要在信息不完整和不完美的世界中运行。</p><p> Lebaredian: It’s good for the training part. The way most AI is created today is through a type of learning called supervised learning. In the example of a neural network that can tell the difference between a cat and a dog, you first train it on pictures of cats and dogs that are labeled: This is a cat and this is a dog. It learns from those examples. Then you go apply that network on new images that aren’t labeled, and it will tell you what each one is.</p><p>勒巴雷迪亚：这对训练有好处。当今大多数人工智能的创建方式都是通过一种称为监督学习的学习方式。在一个可以区分猫和狗的神经网络的例子中，你首先在猫和狗的图片上训练它，这些图片被标记为：这是一只猫，这是一只狗。它从这些例子中学习。然后你把这个网络应用到没有标签的新图像上，它会告诉你每个图像是什么。</p><p> For example, in autonomous vehicles you want your car to know, by looking through its sensors at the world, the relative 3D positions of all of the cars and pedestrians around it. But it’s just getting a 2D image that’s nothing but pixels; there’s no information about it. So if you’re going to train a network to infer that 3D information, you first have to draw a box around things in 2D and then you have to tell it, ‘Here’s how far away it is based on the particular lens that was used with that sensor.’ But if we synthesize the data in Omniverse, we have all of that 3D information at full physical accuracy. We can provide exact labeling without the errors that a human would introduce into the system. So the resulting neural network that we train is going to be smarter and more accurate.</p><p>例如，在自动驾驶汽车中，你想让你的汽车通过传感器观察世界，了解周围所有汽车和行人的相对3D位置。但它只是得到一个只有像素的2D图像；没有相关信息。因此，如果你要训练一个网络来推断3D信息，你首先必须在2D中画一个框，然后你必须告诉它，‘这是根据传感器使用的特定镜头的距离。’但如果我们在Omniverse中合成数据，我们就能以完全物理精度获得所有3D信息。我们可以提供准确的标签，而不会出现人为引入系统的错误。因此，我们训练的神经网络将更加智能和准确。</p><p>  Is overfitting a problem in this context? Is there a danger that a system trained with synthetic data would perform well on synthetic data, but fail in the real world?</p><p>在这种情况下，过度装修是一个问题吗？使用合成数据训练的系统在合成数据上表现良好，但在现实世界中失败，这是否存在危险？</p><p> Lebaredian: Synthetic data is actually a great way to solve for the overfitting problem, because it’s much easier for us to provide a diverse data set. If we’re training a network to recognize people’s facial expressions, but we only train it on Caucasian males, then we’ve overfit to Caucasian males and it will fail when you give it more diverse subjects. Synthetic data doesn’t make that worse. But with synthetic data it’s easier for us to create diversity of data. If I’m generating images of humans and I have a synthetic data generator, that allows me to change the configurations of people’s faces, their skin tone, eye color, hairstyle, and all of those things.</p><p>勒巴雷迪亚：合成数据实际上是解决过度拟合问题的一种很好的方法，因为我们更容易提供多样化的数据集。如果我们训练一个网络来识别人们的面部表情，但我们只训练高加索男性，那么我们已经过度适应高加索男性，当你给它更多不同的主题时，它就会失败。合成数据并不会让情况变得更糟。但有了合成数据，我们更容易创造多样性的数据。如果我正在生成人类的图像，并且我有一个合成数据生成器，它允许我改变人们的面部结构、肤色、眼睛颜色、发型，以及所有这些东西。</p><p> It seems like synthetic data could help with the big problem of algorithmic bias, since one of the sources of algorithmic bias is bias in data sets used to train AI systems. Can we use synthetic data to train AIs in the unbiased world that we would prefer to live in, as opposed to the world we actually live in?</p><p>合成数据似乎有助于解决算法偏差这一大问题，因为算法偏差的来源之一是用于训练人工智能系统的数据集中的偏差。我们能否使用合成数据，在我们更愿意生活的无偏见世界中，而不是在我们实际生活的世界中，对人工智能进行培训？</p><p> Lebaredian: We’re synthesizing the worlds that our AIs are born in. They are born inside a computer and they’re just trained on whatever data we give them. So we can construct ideal worlds with the diversity that we want, and our AIs can be better for it. By the time they’re done, they are more intelligent than anybody we have out here in the real world. And when we put them in the real world, they behave better than they would have if they were only trained on what they see out here.</p><p>勒巴雷迪亚：我们正在合成人工智能诞生的世界。他们出生在一台电脑里，他们只需要接受我们提供给他们的任何数据的训练。因此，我们可以用我们想要的多样性来构建理想世界，我们的人工智能也可以因此变得更好。当他们完成时，他们比我们在现实世界中的任何人都更聪明。当我们把他们放在现实世界中时，他们的表现会比只接受他们在这里看到的东西的训练要好。</p><p> So what are the pitfalls to using synthetic data? Is it susceptible to adversarial attacks?</p><p>那么，使用合成数据的陷阱是什么呢？它容易受到敌对攻击吗？</p><p> Lebaredian: Adversarial attacks, similar to overfitting problems, are not something that’s unique to synthetic data versus any other kind of data. The solution is to just have more data and better data.</p><p>勒巴雷迪亚：对抗性攻击，类似于过度拟合问题，并不是合成数据相对于任何其他类型的数据所独有的。解决方案就是拥有更多的数据和更好的数据。</p><p> The problem with synthetic data is that generating good synthetic data is hard. It requires you having a great simulator like Omniverse and one that is physically accurate so it can match the real world well enough. If we create a synthetic data generator that makes images that look like cartoons, that’s not going to be good enough. You wouldn’t want to put a robot that only knows how to interpret cartoon worlds in a hospital where it’s going to work with the elderly and children. That would be a scary thing to do. You need your simulator to be as physically accurate as possible to make use of this. But it is an extremely difficult problem.</p><p>合成数据的问题在于，生成好的合成数据很难。它需要你有一个像Omniverse这样的很棒的模拟器，一个物理上精确的模拟器，这样它才能很好地匹配现实世界。如果我们创建一个合成数据生成器，使图像看起来像卡通，那就不够好了。你不会想把一个只会解读卡通世界的机器人放在医院里，在那里它将与老人和儿童一起工作。那将是一件可怕的事情。你需要你的模拟器在物理上尽可能精确，以利用这一点。但这是一个极其困难的问题。</p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/人工智能/">#人工智能</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/认为/">#认为</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/synthetic/">#synthetic</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/数据/">#数据</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/谷歌/">#谷歌</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy;2012-2021 diglog.com </div></div></body></html>