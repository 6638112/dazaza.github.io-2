<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>苹果M1预示RISC-V的崛起 Apple M1 foreshadows Rise of RISC-V</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">Apple M1 foreshadows Rise of RISC-V<br/>苹果M1预示RISC-V的崛起 </h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2020-12-20 10:50:05</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2020/12/ef8070b86d04c03c301e73389babcf7e.jpeg"><img src="http://img2.diglog.com/img/2020/12/ef8070b86d04c03c301e73389babcf7e.jpeg" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>The M1 is the beginning of a paradigm shift, which will benefit RISC-V microprocessors, but not the way you think.</p><p>M1是模式转变的开始，这将使RISC-V微处理器受益，但不会像您想的那样。</p><p>   By now it is pretty clear that Apple’s M1 chip is a big deal. And the implications for the rest of the industry is gradually becoming clearer. In this story I want to talk about a connection to RISC-V microprocessors which may not be obvious to most readers.</p><p>   到目前为止，很明显，苹果公司的M1芯片很重要。而且，对其他行业的影响也越来越清晰。在这个故事中，我想谈谈与RISC-V微处理器的连接，这对大多数读者而言可能并不明显。</p><p> Let me me give you some background first:  Why Is Apple’s M1 Chip So Fast?</p><p> 首先让我为您提供一些背景知识：为什么Apple的M1芯片这么快？</p><p> In that story I talked about two factors driving M1 performance. One was the use of massive number of decoders and Out-of-Order Execution (OoOE). Don’t worry it that sounds like technological gobbledegook to you.</p><p> 在那个故事中，我谈到了驱动M1性能的两个因素。一种是使用大量的解码器和乱序执行（OoOE）。别担心，这听起来像是技术上的骗子。</p><p> Thi  s story will be all about the other part:  Heterogenous computing. Apple is aggressively pursued a strategy of adding specialized hardware units, I will refer to as  coprocessors throughout this article:</p><p> Thi的故事将涉及另一部分：异构计算。 Apple积极追求添加专用硬件单元的策略，在本文中，我将其称为协处理器：</p><p> GPU (Graphical Processing Unit) for graphics and many other tasks with a lot of data parallelism (do the same operation on many elements at the same time).</p><p> GPU（图形处理单元），用于图形和许多其他具有大量数据并行性的任务（同时对多个元素执行相同的操作）。</p><p> Instead of adding a lot more general purpose processors to their solution, Apple has started adding a lot more  coprocessors to their solution. You could also use the term  accelerator.</p><p> 苹果没有在解决方案中添加更多的通用处理器，而是开始在解决方案中添加更多的协处理器。您还可以使用术语加速器。 </p><p> This isn’t an entirely new trend, my good old Amiga 1000 from 1985 had coprocessors to speed up audio and graphics. Modern GPUs are essentially coprocessors. Google’s Tensor Processing Units are a form of coprocessors used for machine learning.</p><p>这不是一个全新的趋势，我从1985年开始使用的老式Amiga 1000具有协处理器来加快音频和图形处理的速度。现代GPU本质上是协处理器。 Google的Tensor处理单元是一种用于机器学习的协处理器。</p><p>   Unlike a CPU, a coprocessor cannot live alone. You cannot make a computer by just sticking a coprocessor into it. Coprocessor as special purpose processors which do a particular task really well.</p><p>   与CPU不同，协处理器不能单独存在。您不能仅通过将协处理器插入其中来制造计算机。协处理器作为专用处理器，可以很好地完成特定任务。</p><p> One of the earliest examples of a coprocessors was the Intel 8087 floating point unit (FPU). The humble Intel 8086 microprocessor could perform integer arithmetic but not floating point arithmetic. What is the difference?</p><p> 协处理器的最早示例之一是Intel 8087浮点单元（FPU）。不起眼的Intel 8086微处理器可以执行整数运算，但不能执行浮点运算。有什么不同？</p><p>   These are fairly easy to work with for computers. You could probably wire together a solution to add integer numbers with some simple chips yourself.</p><p>   这些对于计算机来说相当容易使用。您可能会自己组合一个解决方案，以使用一些简单的筹码相加整数。</p><p> The problem starts when you want decimals. Say you want to add or multiply numbers such as  4.25, 84.7 or 3.1415.</p><p> 当您需要小数时，问题就开始了。假设您要添加或乘以4.25、84.7或3.1415之类的数字。</p><p> These are examples of floating point numbers. If the number of digits after the point was fixed, we would call it fixed point numbers. Money is often treated this way. You usually have two decimals after the point.</p><p> 这些是浮点数的示例。如果该点之后的位数是固定的，我们将其称为固定点号。金钱常常被这样对待。您通常在该点后有两位小数。</p><p> You can however emulate floating point arithmetic with integers, it is just slower. That is akin to how early microprocessors could not multiply integers either. They could only add and subtract. However one could still perform multiplication. You just had to emulate it will multiple additions. For instance  3 × 4 is simply  4 + 4 + 4.</p><p> 但是，您可以使用整数来模拟浮点运算，但是速度较慢。这类似于早期的微处理器也不能够将整数相乘。他们只能加减。但是，仍然可以执行乘法。您只需要模拟它将添加多个内容。例如3×4就是4 + 4 + 4。 </p><p> It is not important to understand the code example below, but it may help you understand how multiplication can be performed by a CPU only by using addition, subtraction and branching (jumping in code).</p><p>理解下面的代码示例并不重要，但是它可以帮助您了解CPU如何仅通过使用加，减和分支（代码跳转）来执行乘法。</p><p> loadi r3, 0 ; Load 0 into register r3 multiply:   add r3, r1 ; r3 ← r3 + r1  dec r2 ; r2 ← r2 - 1  bgt r2, multiply ; goto multiply if r2 &gt; 0</p><p> loadi r3，0;将0加载到寄存器r3中：乘以r3，r1； r3←r3 + r1 dec r2; r2←r2-1 bgt r2，相乘；如果r2＆gt;转到0</p><p> If you  do want to understand microprocessors and assembly code, read my beginner friendly intro:  How Does a Modern Microprocessor Work?</p><p> 如果您确实想了解微处理器和汇编代码，请阅读我的初学者入门介绍：现代微处理器如何工作？</p><p>  What all coprocessor do is similar to this. There is always a way for the CPU to do the same task as the coprocessor. However this will usually require repetition of multiple simpler operations. The reasons we got GPUs early on, was that repeating the same calculations on millions of polygons or pixels was really time consuming for a CPU.</p><p>  所有协处理器的工作与此相似。 CPU总是有一种方法可以完成与协处理器相同的任务。但是，这通常需要重复多个更简单的操作。我们之所以提早使用GPU是因为，对数百万个多边形或像素重复相同的计算对于CPU来说确实很耗时。</p><p>  Let us look at the diagram below to get a better sense of how a coprocessor work together with the microprocessor (CPU), or general purpose processor, if you will.</p><p>  让我们看一下下面的图，以更好地了解协处理器如何与微处理器（CPU）或通用处理器一起工作。</p><p>  We can think of green and light blue busses as pipes. Numbers are pushed through these pipes to reach different functional units of the CPU (drawn as gray boxes). The inputs and outputs of these boxes are connected to these pipes. You can think of the inputs and outputs of each box as having valves. The red control lines are used to open and close these valves. Thus the  Decoder, in charge of the red lines, can open valves on two gray boxes to make numbers flow between them.</p><p>  我们可以将绿色和浅蓝色的公共汽车视为管道。通过这些管道将数字推送到CPU的不同功能单元（绘制为灰色框）。这些盒子的输入和输出连接到这些管道。您可以认为每个盒子的输入和输出都有阀门。红色控制线用于打开和关闭这些阀。因此，负责红线的解码器可以打开两个灰色框上的阀，以使数字在它们之间流动。</p><p>  This lets us explain how data is fetched from memory. To perform operations on numbers we need them in registers. The  Decoder uses the control lines to open the valves between the gray  Memory box and the  Registers box. This is how it specifically happens:</p><p>  这让我们解释了如何从内存中获取数据。要对数字执行运算，我们需要在寄存器中进行操作。解码器使用控制线打开灰色“存储”框和“寄​​存器”框之间的阀门。具体是这样的： </p><p> The Decoder opens a valve on  Load Store Unit (LSU) which causes a memory address to flow out on the green address bus.</p><p>解码器打开负载存储单元（LSU）上的阀，该阀使内存地址从绿色地址总线上流出。</p><p> Another valve is opened on the  Memory box, so it can receive the address. It gets delivered by the green pipe (address bus). All other valves are closed so e.g. Input/Output cannot receive the address.</p><p> 内存盒上的另一个阀门被打开，因此它可以接收地址。它由绿色管道（地址总线）传送。所有其他阀门都关闭，例如输入/输出无法接收地址。</p><p> The memory cell with the given address is selected. Its content flows out onto the blue data bus, because the Decoder has opened the valve to the data bus.</p><p> 选择具有给定地址的存储单元。它的内容流出到蓝色数据总线上，因为解码器已经打开了通往数据总线的阀门。</p><p> The data in the memory cell could flow anywhere, but the  Decoder has only opened the input valve to the  Registers.</p><p> 存储单元中的数据可以流到任何地方，但是解码器仅打开了寄存器的输入阀。</p><p> Things like mouse, keyboard, the screen, GPU, FPU, Neural Engine and other coprocessors are equal to the Input/Output box. We access them just like memory locations. Hard drives, mouse, keyboard, network cards, GPU, DMA (direct memory access) and coprocessors all have memory addresses mapped to them.</p><p> 诸如鼠标，键盘，屏幕，GPU，FPU，神经引擎和其他协处理器之类的东西都等于“输入/输出”框。我们像访问存储位置一样访问它们。硬盘驱动器，鼠标，键盘，网卡，GPU，DMA（直接内存访问）和协处理器都具有映射到它们的内存地址。</p><p>  What exactly do I mean by that? Well let me just make up some addresses. If you processor attempts to read from memory address 84 that may mean the x-coordinate of your computer mouse. While say 85 means the y-coordinate. So to get a mouse coordinates you would do something like this in assembly code:</p><p>  我到底是什么意思？好吧，让我补充一些地址。如果处理器尝试从内存地址84读取，则可能意味着计算机鼠标的x坐标。虽然说85表示y坐标。因此，要获取鼠标坐标，您可以在汇编代码中执行以下操作：</p><p>  For a  DMA controller there might might be address 110, 111 and 113 which as special meaning. Here is an unrealistic made up assembly code program using this to interact with the DMA controller:</p><p>  对于DMA控制器，可能会有地址110、111和113，这是特殊含义。这是一个不切实际的汇编代码程序，使用该程序与DMA控制器进行交互： </p><p> loadi r1, 1024 ; set register r to source address loadi r2, 50 ; bytes to copy loadi r3, 2048 ; destination address  store r1, 110 ; tell DMA controller start address store r2, 111 ; tell DMA to copy 50 bytes store r3, 113 ; tell DMA where to copy 50 bytes to</p><p>loadi r1，1024;将寄存器r设置为源地址loadi r2，50；要复制的字节数loadi r3，2048;目的地址存储器r1，110；告诉DMA控制器开始地址存储r2，111;告诉DMA复制50个字节的存储区r3，113;告诉DMA将50个字节复制到哪里</p><p> Everything works in this manner. You read and write to special memory addresses. Of course a regular software developers never sees this. This stuff is done by  device drivers. The programs you use only see virtual memory addresses where this is invisible. But the drivers will have these addresses mapped into its virtual memory addresses.</p><p> 一切都以这种方式工作。您读写特殊的内存地址。当然，常规的软件开发人员从来没有看到过这种情况。这些工作是由设备驱动程序完成的。您使用的程序只能看到不可见的虚拟内存地址。但是驱动程序会将这些地址映射到其虚拟内存地址。</p><p>  I am not going to say too much about virtual memory. Essentially we got real addresses. The addresses on the green bus will get translated from virtual addresses to real physical addresses. When I began programming in C/C++ in DOS, there was no such thing. I could just set a C pointer to point straight to a memory address of the video memory and start writing straight to it to change the picture.</p><p>  我不会过多地谈论虚拟内存。本质上，我们得到了真实的地址。绿色总线上的地址将从虚拟地址转换为实际物理地址。当我开始在DOS中使用C / C ++进行编程时，没有这种东西。我可以将C指针设置为直接指向视频内存的内存地址，然后开始直接向其写入以更改图片。</p><p> char *video_buffer = 0xB8000; // set pointer to CGA video buffer video_buffer[3] = 42; // change color of 4th pixel</p><p> 字符* video_buffer = 0xB8000; //将指针设置为CGA视频缓冲区video_buffer [3] = 42; //更改第4个像素的颜色</p><p>  Coprocessors work the same way as this. The Neural Engine, GPU, Secure Enclave and so on will have addresses you communicate with. What is important to know about these as well as something like the DMA controller is that they can work asynchronously.</p><p>  协处理器的工作方式与此相同。神经引擎，GPU，安全区域等将具有您与之通信的地址。了解这些以及诸如DMA控制器之类的重要信息是它们可以异步工作。</p><p> That means the CPU can can arrange a whole bunch of instructions for the  Neural Engine or GPU which it understands and write these into a buffer in memory. Afterwards it informs the Neural Engine or GPU coprocessor about location of these instructions, by talking to their IO addresses.</p><p> 这意味着CPU可以为它理解的神经引擎或GPU安排一整套指令，并将它们写入内存中的缓冲区。然后，通过与它们的IO地址进行对话，将这些指令的位置通知神经引擎或GPU协处理器。</p><p> You don’t want the CPU to sit there and idle waiting for the coprocessor to chew through all the instructions and data. You don’t want to do that with the DMA either. That is why usually you can provide some kind of interrupt.</p><p> 您不希望CPU坐在那里闲着等待协处理器仔细检查所有指令和数据。您也不想使用DMA进行操作。这就是为什么通常您可以提供某种中断的原因。 </p><p>  Various cards you stick into your PC, whether they are graphics cards or network cards will have assigned some interrupt line. It is kind of like a line that goes straight to your CPU. When this line get activated, the CPU drops everything it is holding to deal with your interrupt.</p><p>您插入PC的各种卡（无论是图形卡还是网卡）都将分配一些中断线。就像一条直线直接进入您的CPU。激活此行后，CPU会将其持有的所有内容都丢弃以处理中断。</p><p> Or more specifically. It stores in memory its current location and the values of its registers, so it can return to whatever it was doing later.</p><p> 或更具体地说。它在内存中存储其当前位置及其寄存器的值，因此可以返回到以后执行的操作。</p><p> Next it looks up in a so called interrupt table what to do. The table has an address of a program you want to run when that interrupt is triggered.</p><p> 接下来，它在所谓的中断表中查找要做什么。该表具有触发该中断时要运行的程序的地址。</p><p> As a programmer you don’t see this stuff. To you it will appear more like callback functions which you register for certain events. Drivers typically handle this at the lower level.</p><p> 作为程序员，您不会看到这些东西。对您来说，它看起来更像是为某些事件注册的回调函数。驱动程序通常在较低级别上进行处理。</p><p> Why am I telling you all these nerdy details? Because it helps develop an intuition about what is going on when you use coprocessors. Otherwise it is unclear what communicating with a coprocessor actually entails.</p><p> 我为什么要告诉你所有这些书呆子的细节？因为它有助于您了解使用协处理器时发生的情况。否则，不清楚与协处理​​器进行通信实际上需要做什么。</p><p> Using interrupts allow lots of things to happen in parallel. An application may fetch an image from the network card, while the CPU is interrupted by the computer mouse. The mouse has been moved and we need the new coordinates. The CPU can read these and send them to the GPU, so it can redraw the mouse cursor in the new location. When the GPU is drawing the mouse cursor the CPU could begin processing the image retrieved from the network.</p><p> 使用中断可以使许多事情并行发生。当CPU被计算机鼠标中断时，应用程序可能会从网卡获取图像。鼠标已移动，我们需要新的坐标。 CPU可以读取这些并将其发送到GPU，因此可以在新位置重新绘制鼠标光标。当GPU绘制鼠标光标时，CPU可以开始处理从网络检索到的图像。</p><p>  Likewise with these interrupts we can send complex machine learning tasks to the M1 Neural Engine to say identify a face on the WebCam. Simultaneously the rest of the computer is responsive because the Neural Engine is chewing through the image data in parallel to everything else the CPU is doing.</p><p>  同样，通过这些中断，我们可以将复杂的机器学习任务发送给M1神经引擎，以说出WebCam上的面孔。同时，计算机的其余部分都响应，因为神经引擎正在与CPU所做的其他事情并行地浏览图像数据。 </p><p>   Back in 2010 at UC Berkley the Parallel Computing Laboratory saw the development towards heavier use of coprocessors. They saw how the end of Moore’s Law meant that you could no longer easily squeeze more performance out of general purpose CPU cores. You needed specialized hardware: Coprocessors.</p><p>早在2010年，在加州大学伯克利分校，并行计算实验室就看到了向大量使用协处理器的发展。他们看到摩尔定律的终结意味着您不再能够轻易地从通用CPU内核中挤出更多性能。您需要专用的硬件：协处理器。</p><p> Let us reflect momentarily on why that is. We know that the clock frequency cannot easily be increased. We are stuck on close to 3–5 GHz. Go higher and Watt consumption and heat generation goes through the roof.</p><p> 让我们暂时反思为什么。我们知道时钟频率不能轻易增加。我们被困在3–5 GHz附近。升高，瓦特消耗和热量就会通过屋顶。</p><p> However we are able to add a lot more transistors. We simply cannot make the transistors work faster. Thus we need to do more work in parallel. One way to do that is by adding lots of general purpose cores. We could add lots of decoders and do Out-of-Order Execution (OoOE) as I have discussed before:  Why Is Apple’s M1 Chip So Fast?</p><p> 但是，我们可以添加更多的晶体管。我们根本无法使晶体管工作得更快。因此，我们需要并行进行更多工作。一种方法是添加大量通用内核。正如我之前所讨论的，我们可以添加很多解码器并执行乱序执行（OoOE）：为什么苹果的M1芯片这么快？</p><p> You can keep playing that game and eventually you have 128 general cores like the  Ampere Altra Max ARM processor. But is that really the best use of our silicon? For servers and cloud services lots of cores work well. But for desktop computing this has limited utility.</p><p> 您可以继续玩这个游戏，最终拥有128个通用内核，例如Ampere Altra Max ARM处理器。但这真的是我们硅的最佳用途吗？对于服务器和云服务，许多核心都可以正常工作。但是对于台式机计算，它的实用性有限。</p><p> Instead of spending all that silicon on more CPU cores, perhaps we can add more coprocessors instead?</p><p> 与其将所有的芯片都花在更多的CPU内核上，不如我们可以添加更多的协处理器？</p><p> Think about it this way: You got a transistor budget. In the early days, maybe you had a budget of 20 000 transistors and you figured you could make a CPU with 15 000 transistors. That is close to reality in the early 80s. Now this CPU could do maybe 100 different tasks. Say making a specialized coprocessor to one fo these tasks cost you 1000 transistors. If you made a coprocessor for every task you would get to 100 000 transistors. That would blow your budget.</p><p> 这样考虑：您有一个晶体管预算。在早期，也许您有2万个晶体管的预算，并且您认为可以使CPU具有15 000个晶体管。这在80年代初已经接近现实。现在，该CPU可以执行100个不同的任务。假设为这些任务制作一个专用的协处理器，将花费1000个晶体管。如果您为每个任务创建一个协处理器，那么您将获得10万个晶体管。那会浪费你的预算。</p><p> Thus in early designs you need to focus on general purpose computing. But today, we can stuff chips with so many transistors, we hardly know what to do with them.</p><p> 因此，在早期设计中，您需要专注于通用计算。但是今天，我们可以用很多晶体管填充芯片，我们几乎不知道该怎么办。 </p><p> Thus designing coprocessors has become a big thing. A lot of research goes into making all sorts of new coprocessors. However these tend to contain pretty dumb accelerators which needed to be babied. Unlike a CPU they cannot read instructions which tells them all the steps to do. They don’t generally know how to access memory and organize anything.</p><p>因此，设计协处理器已成为一件大事。进行各种新型协处理器的研究很多。但是，这些往往包含漂亮的笨拙的加速器，需要加油。与CPU不同，它们无法读取告诉他们所有步骤的指令。他们通常不知道如何访问内存和组织任何事情。</p><p> Thus the common solution to this is to have a simple CPU as a sort of controller. So the whole coprocessor is some specialized accelerator circuit controlled by a simple CPU, which configures the accelerator to do its job. Usually this is highly specialized. For instance, something like a Neural Engine or Tensor Processing Unit deal with very large registers that can hold matrices (rows and columns of numbers).</p><p> 因此，对此的常见解决方案是使用简单的CPU作为一种控制器。因此，整个协处理器是由一个简单的CPU控制的专用加速器电路，该电路配置加速器以完成其工作。通常这是高度专业化的。例如，诸如神经引擎或张量处理单元之类的东西处理的是非常大的寄存器，可以容纳矩阵（行和数字列）。</p><p> This is exactly what RISC-V got designed for. It has a bare minimum instruction-set of about 40–50 instructions which lets it do all the typical CPU stuff. It may sound like a lot, but keep in mind that an x86 CPU has over 1500 instructions.</p><p> 这正是RISC-V设计的目的。它仅有约40至50条指令的最小指令集，这使其可以执行所有典型的CPU工作。听起来可能很多，但是请记住，x86 CPU具有超过1500条指令。</p><p> Instead of having a large fixed instruction-set, RISC-V is designed around the idea of extensions. Every coprocessor will be different. It will thus contain a RISC-V processor to manage things which implements the core instruction-set as well as an extension instruction-set tailor made for what that co-processor needs to do.</p><p> RISC-V不需要扩展的大型指令集，而是围绕扩展的概念设计的。每个协处理器都是不同的。因此，它将包含一个RISC-V处理器来管理实现核心指令集的事物以及针对该协处理器需要做什么而定制的扩展指令集。</p><p> Okay, now maybe you start to see the contours of what I am getting at. Apple’s M1 is really going to push the industry as whole towards this coprocessor dominated future. And to make these coprocessors, RISC-V will be an important part of the puzzle.</p><p> 好吧，现在也许您开始看到我正在了解的轮廓。苹果的M1确实将推动整个行业朝着这个协处理器主导的未来发展。为了制造这些协处理器，RISC-V将成为难题的重要组成部分。</p><p> But why? Can’t everybody making a coprocessor just invent their own instruction-set? After all that is what I think Apple has done. Or possibly they use ARM. I have no idea. If somebody knows, please drop me a line.</p><p> 但为什么？制作协处理器的每个人都不能只是发明自己的指令集吗？毕竟，我认为苹果已经做到了。或者可能他们使用ARM。我不知道。如果有人知道，请给我打个电话。</p><p>  Making chips have become a complicated and costly affair. Building up tools to verify your chip. Run tests programs, diagnosis and a host of other things requires a lot of effort.</p><p>  制造芯片已成为一件复杂而昂贵的事情。建立工具以验证您的芯片。运行测试程序，诊断和许多其他事情需要很多努力。 </p><p> This is part of the value of going with ARM today. They have a large ecosystem of tools to help verify your design and test it.</p><p>这是当今使用ARM的价值的一部分。他们拥有庞大的工具生态系统，可帮助您验证设计并对其进行测试。</p><p> Going for custom proprietary instruction-sets is thus not a good idea. However with RISC-V there is a standard which multiple companies can make tools for. Suddenly there is an eco-system and multiple companies can share the burden.</p><p> 因此，寻求定制的专有指令集不是一个好主意。但是，使用RISC-V可以为多家公司提供标准工具。突然有一个生态系统，多家公司可以分担负担。</p><p> But why not just use ARM which is already there? You see ARM is made as a general purpose CPU. It has a large fixed instruction-set. After pressure from customers and RISC-V competition ARM has relented and in  2019 opened its instruction-set for extensions.</p><p> 但是，为什么不使用现有的ARM呢？您会看到ARM被制成通用CPU。它具有较大的固定指令集。在客户和RISC-V竞争的压力下，ARM放松了态度，并于2019年开放了扩展指令集。</p><p> Still the problem is that it wasn’t made for this from the onset. The whole ARM toolchain is going to assume you got the whole large ARM instruction set implemented. That is fine for the main CPU of a Mac or an iPhone.</p><p> 仍然存在的问题是，它不是一开始就为此目的而设计的。整个ARM工具链将假定您已实现了整个大型ARM指令集。这对于Mac或iPhone的主CPU来说很好。</p><p> But for a coprocessor you don’t want or need this large instruction-set. You want an eco-system of tools that have been built around the idea of a minimal fixed base instruction-set with extensions.</p><p> 但是对于协处理器，您不需要或不需要这么大的指令集。您需要一个以最小的固定基础指令集和扩展为基础的工具生态系统。</p><p> Why is that such a benefit?  Nvidia’s use of RISC-V offers some insight. On their big GPUs they need some kind of general purpose CPU to be used as a controller. However the amount of silicon they can set aside for this, and the amount of heath it is allowed to produce is minimal. Keep in mind that lots of things are competing for space.</p><p> 为什么会有这样的好处？ Nvidia对RISC-V的使用提供了一些见识。在大型GPU上，他们需要某种通用CPU用作控制器。但是，他们可以为此预留一定数量的硅，并且允许产生的热量极小。请记住，许多事物正在争夺空间。</p><p> Because RISC-V has such a small and simple instruction-set it beat all the competition, including ARM. Nvidia found they could make smaller chips by going for RISC-V than for anybody else. They also reduced watt usage to a minimum.</p><p> 由于RISC-V的指令集如此小巧，简单，因此它击败了包括ARM在内的所有竞争对手。 Nvidia发现，选择RISC-V可以制造出比其他任何产品都小的芯片。他们还将功耗降至最低。 </p><p> Thus with the extension mechanism you can limit yourself to adding only the instructions crucial for the job you need done. A controller for a GPU likely needs other extensions than a controller on an encryption coprocessor e.g.</p><p>因此，通过扩展机制，您可以将自己限制为仅添加对您需要完成的工作至关重要的指令。用于GPU的控制器可能需要除加密协处理器上的控制器以外的其他扩展，例如</p><p>  Thus ironically we may see a future where Macs and PCs are powered by ARM processors. But where all the custom hardware around them, all their coprocessors will be dominated by RISC-V. As coprocessor get more popular more silicon in your System-on-a-Chip (SoC) may be running RISC-V than ARM.</p><p>  因此，具有讽刺意味的是，我们可能会看到Mac和PC由ARM处理器驱动的未来。但是在所有定制硬件周围，所有协处理器将由RISC-V主导。随着协处理器越来越流行，片上系统（SoC）中的硅可能比ARM在运行RISC-V。</p><p>  When I wrote the story above, I had not actually fully grasped what RISC-V was all about. I though the future would be about ARM or RISC-V. Instead it will likely be ARM and RISC-V.</p><p>  当我写上面的故事时，我实际上并没有完全理解RISC-V的全部含义。尽管未来将与ARM或RISC-V有关。相反，它可能是ARM和RISC-V。</p><p> General purpose ARM processors will be at the center with an army of RISC-V powered coprocessors accelerating every possible task from graphics, encryption, video encoding, machine learning, signal processing to processing network packages.</p><p> 通用ARM处理器将以RISC-V驱动的协处理器为中心，以加速从图形，加密，视频编码，机器学习，信号处理到处理网络程序包的所有可能任务。</p><p> Prof. David Patterson and his team at UC Berkeley saw this future coming and that is why RISC-V is so well tailored to meet this new world.</p><p> David Patterson教授和他在加州大学伯克利分校的团队看到了这一未来的来临，这就是RISC-V如此精心定制以迎接这个新世界的原因。</p><p> We are seeing such a massive uptake and buzz around RISC-V in all sorts of specialized hardware and micro-controllers that I think a lot of the areas dominated by ARM today will go RISC-V.</p><p> 我们看到RISC-V在各种专用硬件和微控制器中得到了如此广泛的应用和关注，我认为当今ARM主导的许多领域都将成为RISC-V。</p><p>  Imagine something like Raspberry Pi. Now it runs ARM. But future RISC-V variants could offer a host of variants tailored for different needs. There could be machine learning microcontrollers. Another can be image processing oriented. A third could be for encryption. Basically you could pick your own a little micro-controller with its own little flavor. You may be able to run Linux on it and do all the same tasks, except the performance profile will be different.</p><p>  想象一下类似Raspberry Pi的东西。现在它运行ARM。但是未来的RISC-V变体可能会提供满足不同需求的大量变体。可能有机器学习微控制器。另一个可以是面向图像处理的。三分之一可能用于加密。基本上，您可以选择自己的带有微弱风味的微控制器。您可能可以在其上运行Linux并执行所有相同的任务，只是性能配置文件会有所不同。 </p><p> RISC-V microcontrollers with special machine learning instructions will train neural networks faster than the RISC-V microcontroller with instructions for video encoding.</p><p>具有特殊机器学习指令的RISC-V微控制器将比具有视频编码指令的RISC-V微控制器更快地训练神经网络。</p><p> Nvidia has already ventured down that path with their Jetson Nano, shown below. It is a Raspberry Pi sized microcontroller with specialized hardware for machine learning, so you can do object detection, speech recognition and other machine learning tasks.</p><p> 英伟达已经通过他们的Jetson Nano冒险走这条路，如下所示。它是Raspberry Pi大小的微控制器，具有用于机器学习的专用硬件，因此您可以执行对象检测，语音识别和其他机器学习任务。</p><p>   Let me know what you think. There is a lot going on here which is hard to guess. We see e.g. now there are claims of RISC-V CPUs which really beats ARM on watt and performance. This also makes you wonder if there is indeed a chance that RISC-V becomes the central CPU of computers.</p><p>   让我知道你的想法。这里有很多事情很难猜测。我们看到例如现在，有人声称RISC-V CPU在功耗和性能方面确实胜过ARM。这也使您想知道RISC-V是否确实有可能成为计算机的中央CPU。</p><p> I must admit it has not been obvious to me why RISC-V would outperform ARM. By their own admission, RISC-V is a fairly conservative design. They don’t use much instructions which have not already been used in some other older design.</p><p> 我必须承认，为什么RISC-V会胜过ARM尚不为人所知。经他们自己承认，RISC-V是一个相当保守的设计。他们使用的指令不多，而其他一些较旧的设计尚未使用。</p><p> However there seems to be a major gain from pairing everything down to a minimum. It makes it possible to make exceptionally small and simple implementations or RISC-V CPUs. This again makes it possible to reduce Watt usage and increase clock frequency.</p><p> 但是，将所有内容配对到最小似乎是一个很大的收获。这使得可以实现非常小的和简单的实现或RISC-V CPU。这再次使得可以减少瓦特使用并增加时钟频率。 </p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://erik-engheim.medium.com/apple-m1-foreshadows-risc-v-dd63a62b2562">https://erik-engheim.medium.com/apple-m1-foreshadows-risc-v-dd63a62b2562</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/m1/">#m1</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/risc/">#risc</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/分享/">#分享</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy; 2020 diglog.com </div></div></body></html>