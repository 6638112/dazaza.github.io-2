<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>解释变压器语言模型的接口 Interfaces for Explaining Transformer Language Models</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">Interfaces for Explaining Transformer Language Models<br/>解释变压器语言模型的接口 </h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2020-12-23 04:21:15</div><div class="page_narrow text-break page_content"><p>The Transformer architecture  has been powering a number of the recent advances in NLP. A breakdown of this architecture is provided  here  . Pre-trained language models based on the architecture, in both its auto-regressive  (models that use their own output as input to next time-steps and that process tokens from left-to-right, like GPT2) and denoising  (models trained by corrupting/masking the input and that process tokens bidirectionally, like BERT) variants continue to push the envelope in various tasks in NLP and, more recently, in computer vision . Our understanding of why these models work so well, however, still lags behind these developments.</p><p>Transformer体系结构为NLP的最新进展提供了动力。这里提供了此体系结构的详细信息。基于架构的预训练语言模型，包括自动回归模型（使用自己的输出作为下一个时间步长的输入以及从左到右处理令牌的模型，例如GPT2）和降噪（模型训练后的模型）破坏/屏蔽输入并双向处理令牌，例如BERT变种，在NLP和最近的计算机视觉的各种任务中继续推动着发展。但是，我们对这些模型为何如此有效的理解仍然落后于这些发展。</p><p> This exposition series continues the pursuit to interpret  and visualize  the inner-workings of transformer-based language models.We illustrate how some key interpretability methods apply to transformer-based language models. This article focuses on auto-regressive models, but these methods are applicable to other architectures and tasks as well.</p><p> 该博览会系列继续致力于解释和可视化基于转换器的语言模型的内部工作。我们说明了一些关键的可解释性方法如何应用于基于转换器的语言模型。本文重点介绍自动回归模型，但是这些方法也适用于其他体系结构和任务。</p><p> This is the first article in the series. In it, we present explorables and visualizations aiding the intuition of:</p><p> 这是该系列的第一篇文章。在其中，我们提供了可探索性和可视化效果，有助于直观地了解：</p><p> Neuron Activations and how individual and groups of model neurons spike in response to inputs and to produce outputs.</p><p> 神经元激活以及模型神经元的个体和组如何响应输入并产生输出而突增。</p><p> The next article addresses  Hidden State Evolution across the layers of the model and what it may tell us about each layer&#39;s role.</p><p> 下一篇文章介绍了模型各层之间的隐藏状态演化，以及它可能告诉我们有关每一层角色的信息。</p><p> In the language of Interpretable Machine Learning (IML) literature like Molnar et al. , input saliency is a method that explains individual predictions. The latter two methods fall under the umbrella of &#34;analyzing components of more complex models&#34;, and are better described as increasing the transparency   of transformer models.</p><p> 在可解释机器学习（IML）的语言中，例如Molnar等人的文献。 ，输入显着性是一种解释单个预测的方法。后两种方法属于“分析更复杂的模型的组件”的范畴，并且可以更好地描述为增加变压器模型的透明度。</p><p> Moreover, this article is accompanied by  reproducible notebooks and  Ecco - an open source library to create similar interactive interfaces directly in Jupyter notebooks  for GPT-based  models from the HuggingFace transformers library .</p><p> 此外，本文还附带了可复制的笔记本和Ecco（一个开放源代码库），可直接在Jupyter笔记本中为来自HuggingFace变压器库的基于GPT的模型创建类似的交互界面。 </p><p> If we&#39;re to impose the three components we&#39;re examining to explore the architecture of the transformer, it would look like the following figure.</p><p>如果我们要强加三个要检查的组件以探索变压器的体系结构，则它看起来如下图所示。</p><p>    When a computer vision model classifies a picture as containing a husky, saliency maps can tell us whether the classification was made due to the visual properties of the animal itself, or because of the snow in the background . This is a method of  attribution explaining the relationship between a model&#39;s output and inputs -- helping us detect errors and biases, and better understand the behavior of the system.</p><p>    当计算机视觉模型将图片分类为包含沙哑时，显着度图可以告诉我们分类是由于动物本身的视觉特性还是由于背景中的雪。这是一种归因方法，用于解释模型的输出和输入之间的关系-帮助我们检测错误和偏差，并更好地了解系统的行为。</p><p>  Multiple methods exist for assigning importance scores to the inputs of an NLP model . The literature is most often concerned with this application for classification tasks, rather than natural language generation. This article focuses on language generation. Our first interface calculates feature importance after each token is generated, and by hovering or tapping on an output token, imposes a saliency map on the tokens responsible for generating it.</p><p>  存在多种用于将重要性得分分配给NLP模型的输入的方法。文献最常与分类任务而不是自然语言生成相关。本文重点介绍语言生成。我们的第一个接口在生成每个令牌后计算功能重要性，并通过悬停或点击输出令牌将显着性图强加于负责生成令牌的令牌。</p><p> The first example for this interface asks GPT2-XL  for William Shakespeare&#39;s date of birth. The model is correctly able to produce the date (1564, but broken into two tokens: &#34; 15&#34; and &#34;64&#34;, because the model&#39;s vocabulary does not include &#34; 1564&#34; as a single token). The interface shows the importance of each input token when generating each output token:</p><p> 该界面的第一个示例向GPT2-XL询问威廉·莎士比亚的出生日期。该模型能够正确生成日期（1564，但分为两个标记：＆＃34; 15＆＃34;和＆＃34; 64＆＃34 ;，因为该模型的词汇表不包含＆＃34 ; 1564＆＃34;作为单个令牌）。该界面显示了生成每个输出令牌时每个输入令牌的重要性：</p><p>  Our second example attempts to both probe a model&#39;s world knowledge, as well as to see if the model repeats the patterns in the text (simple patterns like the periods after numbers and like new lines, and slightly more involved patterns like completing a numbered list). The model used here is DistilGPT2 .</p><p>  我们的第二个示例试图探究模型的世界知识，并查看模型是否重复文本中的模式（简单的模式，如数字后的句点和换行，以及涉及更多的模式，如完成编号列表）。这里使用的模型是DistilGPT2。</p><p> This explorable shows a more detailed view that displays the attribution percentage for each token -- in case you need that precision.</p><p> 此探索图显示了一个更详细的视图，该视图显示了每个令牌的归因百分比，以防您需要这种精度。</p><p>  Another example that we use illustratively in the rest of this article is one where we ask the model to complete a simple pattern:</p><p>  在本文的其余部分中，我们将使用另一个示例进行说明，其中一个示例是要求模型完成一个简单的模式： </p><p>  It is also possible to use the interface to analyze the responses of a transformer-based conversational agent. In the following example, we pose an existential question to DiabloGPT :</p><p>也可以使用该接口来分析基于转换器的会话代理的响应。在下面的示例中，我们向DiabloGPT提出了一个存在的问题：</p><p>    Demonstrated above is scoring feature importance based on Gradients X Inputs -- a gradient-based saliency method shown by Atanasova et al.  to perform well across various datasets for text classification in transformer models.</p><p>    上面展示的是基于Gradients X Inputs评分功能的重要性-Atanasova等人展示的基于梯度的显着性方法。在各种数据集中表现出色，以在变压器模型中进行文本分类。</p><p> To illustrate how that works, let&#39;s first recall how the model generates the output token in each time step. In the following figure, we see how  ① the language model&#39;s final hidden state is projected into the model&#39;s vocabulary resulting in a numeric score for each token in the model&#39;s vocabulary. Passing that scores vector through a softmax operation results in a probability score for each token.  ② We proceed to select a token (e.g. select the highest-probability scoring token, or sample from the top scoring tokens) based on that vector.</p><p> 为了说明它是如何工作的，我们首先回顾一下模型在每个时间步中如何生成输出令牌。在下图中，我们将看到①语言模型的最终隐藏状态如何投射到模型词汇表中，从而为模型词汇表中的每个标记生成一个数字分数。通过softmax运算将得分矢量传递给每个令牌会得出概率得分。 ②我们根据该向量选择令牌（例如，选择最高概率评分令牌，或从最高评分令牌中抽样）。</p><p>  ③ By calculating the gradient of the selected logit (before the softmax) with respect to the inputs by back-propagating it all the way back to the input tokens, we get a signal of how important each token was in the calculation resulting in this generated token. That assumption is based on the idea that the smallest change in the input token with the highest feature-importance value makes a large change in what the resulting output of the model would be.</p><p>  ③通过将所选logit一直反向传播回输入令牌来计算所选logit（在softmax之前）相对于输入的梯度，我们得到一个信号，表明每个令牌在计算中的重要性，导致生成令牌。该假设基于这样的思想，即输入令牌中具有最高特征重要性值的最小变化会对模型的最终输出产生较大的变化。</p><p>  The resulting gradient vector per token is then multiplied by the input embedding of the respective token. Taking the L2 norm of the resulting vector results in the token&#39;s feature importance score. We then normalize the scores by dividing by the sum of these scores.</p><p>  然后将每个令牌的所得梯度向量乘以相应令牌的输入嵌入。采用所得向量的L2范数会得出令牌的特征重要性得分。然后，我们将这些分数除以这些分数的总和来对其进行归一化。</p><p>  ∥  ∇  X i  f c (  X  1 : n )  X i  ∥ 2  \lVert \nabla _{X_i} f_c (X_{1:n}) X_i\lVert_2    ∥  ∇          X        i ​    ​     f        c ​    (  X         1 : n ​    )  X        i ​     ∥        2 ​</p><p>  if X ifc（X 1：n）X i∥2 \ lVert \ nabla _ {X_i} f_c（X_ {1：n}）X_i \ lVert_2∇X i�fc（X 1：n）X我∥2</p><p> Where   is the embedding vector of the input token at timestep  i, and   is the back-propagated gradient of the score of the selected token unpacked as follows:</p><p> 其中，输入令牌在时间步i处的嵌入向量在哪里，是所选令牌得分的反向传播梯度，解压缩如下： </p><p> is the list of input token embedding vectors in the input sequence (of length  )</p><p>是输入序列（长度为）中输入令牌嵌入向量的列表</p><p>  is the score of the selected token after a forward pass through the model (selected through any one of a number of methods including greedy/argmax decoding, sampling, or beam search). With the  c standing for &#34;class&#34; given this is often described in the classification context. We&#39;re keeping the notation even though in our case, &#34;token&#34; is more fitting.</p><p>  是前向通过模型（通过包括贪婪/ argmax解码，采样或波束搜索在内的多种方法中的任意一种选择）之后所选令牌的分数。用c代表＆＃34; class＆＃34;鉴于此通常在分类上下文中进行描述。即使在我们的案例中，我们仍保留该符号＆＃34; token＆＃34;更合适。</p><p>  This formalization is the one stated by Bastings et al.  except the gradient and input vectors are multiplied element-wise. The resulting vector is then aggregated into a score via calculating the  L2 norm as this was empirically shown in Atanasova et al.  to perform better than other methods (like averaging).</p><p>  这种形式化是Bastings等人所说的。除了梯度和输入向量是逐元素相乘的。然后，通过计算L2范数，将所得向量汇总为一个分数，如Atanasova等人的经验所示。比其他方法（例如求平均值）要好。</p><p>   The Feed Forward Neural Network (FFNN) sublayer is one of the two major components inside a transformer block (in addition to self-attention). It accounts for 66% of the parameters of a transformer block and thus provides a significant portion of the model&#39;s representational capacity. Previous work  has examined neuron firings inside deep neural networks in both the NLP and computer vision domains. In this section we apply that examination to transformer-based language models.</p><p>   前馈神经网络（FFNN）子层是变压器模块内的两个主要组件之一（除了自我关注之外）。它占变压器块参数的66％，因此提供了模型表示能力的很大一部分。先前的工作已经检查了NLP和计算机视觉领域中深层神经网络内部的神经元激发。在本节中，我们将该检查应用于基于转换器的语言模型。</p><p>  To guide our neuron examination, let&#39;s present our model with the input &#34;1, 2, 3&#34; in hopes it would echo the comma/number alteration, yet also keep incrementing the numbers.</p><p>  为了指导我们的神经元检查，让我们用输入的＆＃34; 1、2、3＆＃34;希望它会回覆逗号/数字的更改，同时还要继续增加数字。</p><p>   By using the methods we&#39;ll discuss in Article #2 (following the lead of  nostalgebraist ), we can produce a graphic that exposes the probabilities of output tokens after each layer in the model. This looks at the hidden state after each layer, and displays the ranking of the ultimately produced output token in that layer.</p><p>   通过使用我们将在第2条中讨论的方法（遵循怀旧吉他手的方法），我们可以生成一个图形，该图形在模型的每一层之后显示输出令牌的概率。这将查看每层之后的隐藏状态，并显示该层中最终产生的输出令牌的排名。</p><p> For example, in the first step, the model produced the token &#34; 4&#34;. The first column tells us about that process. The bottom most cell in that column shows that the token &#34; 4&#34; was ranked #1 in probability after the last layer. Meaning that the last layer (and thus the model) gave it the highest probability score. The cells above indicate the ranking of the token &#34; 4&#34; after each layer.</p><p> 例如，在第一步中，模型产生了令牌＆＃34;。 4＆＃34;。第一列介绍了该过程。该列最底部的单元格显示令牌＆＃34; 4＆＃34;在最后一层之后的概率排名第一。这意味着最后一层（以及模型）给予它最高的概率分数。上方的单元格表示令牌的排名＆＃34; 4＆＃34;每层之后。 </p><p> By looking at the hidden states, we observe that the model gathers confidence about the two patterns of the output sequence (the commas, and the ascending numbers) at different layers.</p><p>通过查看隐藏状态，我们观察到该模型收集了有关不同层上输出序列的两种模式（逗号和升序数字）的置信度。</p><p>  What happens at Layer 4 which makes the model elevate the digits (4, 5, 6) to the top of the probability distribution?</p><p>  在第4层会发生什么，使模型将数字（4、5、6）提升到概率分布的顶部？</p><p> We can plot the activations of the neurons in layer 4 to get a sense of neuron activity. That is what the first of the following three figures shows.</p><p> 我们可以绘制第4层中神经元的激活图，以获得对神经元活动的感觉。这就是下面三个图中的第一个显示的内容。</p><p> It is difficult, however, to gain any interpretation from looking at activations during one forward pass through the model.</p><p> 但是，很难通过对模型进行前向传递期间的激活来获得任何解释。</p><p> The figures below show neuron activations while five tokens are generated (&#39; 4 , 5 , 6&#39;). To get around the sparsity of the firings, we may wish to cluster the firings, which is what the subsequent figure shows.</p><p> 下图显示了神经元的激活，同时生成了五个令牌（＆＃39; 4，5，6＆＃39;）。为了避开射击的稀疏性，我们不妨对射击进行聚类，下图显示了这一点。</p><p>  If visualized and examined properly, neuron firings can reveal the complementary and compositional roles that can be played by individual neurons, and groups of neurons .</p><p>  如果可视化并正确检查，神经元放电可以揭示单个神经元和神经元组可以发挥的互补和组成作用。</p><p> Even after clustering, looking directly at activations is a crude and noisy affair. As presented in Olah et al. , we are better off reducing the dimensionality using a matrix decomposition method. We follow the authors&#39; suggestion to use Non-negative Matrix Factorization (NMF) as a natural candidate for reducing the dimensionality into groups that are potentially individually more interpretable. Our first experiments were with Principal Component Analysis (PCA), but NMF is a better approach because it&#39;s difficult to interpret the negative values in a PCA component of neuron firings.</p><p> 即使是在聚类之后，直接查看激活也是一个粗略而嘈杂的事情。如Olah等人所述。 ，我们最好使用矩阵分解方法降低维数。我们跟随作者建议使用非负矩阵分解（NMF）作为自然的选择，以将维数减少为可能单独解释的组。我们的第一个实验是使用主成分分析（PCA），但是NMF是一种更好的方法，因为它难以解释神经元激发的PCA成分中的负值。 </p><p>  By first capturing the activations of the neurons in FFNN layers of the model, and then decomposing them into a more manageable number of factors (using ) using NMF, we are able to shed light on how various neurons contributed towards each generated token.</p><p>通过首先捕获模型FFNN层中神经元的激活，然后使用NMF将它们分解为更易于控制的因素（使用），我们可以阐明各种神经元如何对每个生成的令牌做出贡献。</p><p> The simplest approach is to break down the activations into two factors. In our next interface, we have the model generate thirty tokens, decompose the activations into two factors, and highlight each token with the factor with the highest activation when that token was generated:</p><p> 最简单的方法是将激活分为两个因素。在我们的下一个界面中，我们让模型生成三十个令牌，将激活分解为两个因子，并在生成该令牌时以激活程度最高的因子突出显示每个令牌：</p><p>  This interface is capable of compressing a lot of data that showcase the excitement levels of factors composed of groups of neurons. The sparklines  on the left give a snapshot of the excitement level of each factor across the entire sequence. Interacting with the sparklines (by hovering with a mouse or tapping on touchscreens) displays the activation of the factor on the tokens in the sequence on the right.</p><p>  此接口能够压缩大量数据，这些数据展示了由神经元组组成的因子的兴奋程度。左侧的迷你图提供了整个序列中每个因素的兴奋程度的快照。与迷你图进行交互（通过将鼠标悬停或点击触摸屏）会按右侧序列显示标记上因子的激活。</p><p> We can see that decomposing activations into two factors resulted in factors that correspond with the alternating patterns we&#39;re analyzing (commas, and incremented numbers). We can increase the resolution of the factor analysis by increasing the number of factors. The following figure decomposes the same activations into five factors.</p><p> 我们可以看到，将激活分解为两个因素会导致与我们正在分析的交替模式（逗号和递增数字）相对应的因素。我们可以通过增加因子数量来提高因子分析的分辨率。下图将相同的激活分解为五个因素。</p><p>  We can start extending this to input sequences with more content, like the list of EU countries:</p><p>  我们可以开始将此扩展到具有更多内容的输入序列，例如欧盟国家/地区列表：</p><p>  Another example, of how DistilGPT2 reacts to XML, shows a clear distinction of factors attending to different components of the syntax. This time we are breaking down the activations into ten components:</p><p>  另一个有关DistilGPT2对XML的反应方式的示例清楚地表明了影响语法不同组成部分的因素。这次我们将激活分为十个部分：</p><p>   This interface is a good companion for hidden state examinations which can highlight a specific layer of interest, and using this interface we can focus our analysis on that layer of interest. It is straight-forward to apply this method to specific layers of interest. Hidden-state evolution diagrams, for example, indicate that layer #0 does a lot of heavy lifting as it often tends to shortlist the tokens that make it to the top of the probability distribution. The following figure showcases ten factors applied to the activations of layer 0 in response to a passage by Fyodor Dostoyevsky:</p><p>   该界面是隐藏状态检查的良好伴侣，它可以突出显示特定的关注层，使用该界面，我们可以将分析重点放在该关注层上。将这种方法直接应用于感兴趣的特定层很简单。例如，隐藏状态演化图表明第0层做了很多繁重的工作，因为它通常倾向于将使它排在概率分布顶部的令牌入围。下图展示了响应Fyodor Dostoyevsky的通过而应用于第0层激活的十个因素： </p><p>  We can crank up the resolution by increasing the number of factors. Increasing this to eighteen factors starts to reveal factors that light up in response to adverbs, and other factors that light up in response to partial tokens. Increase the number of factors more and you&#39;ll start to identify factors that light up in response to specific words (&#34;nothing&#34; and &#34;man&#34; seem especially provocative to the layer).</p><p>我们可以通过增加因素数量来提高分辨率。将其增加到18个因素开始揭示响应副词而亮起的因素，以及响应于部分标记而亮起的其他因素。进一步增加因素的数量，您将开始识别响应于特定单词而亮起的因素（“没什么”和“人”似乎对该层特别挑衅）。</p><p>  The explorables above show the factors resulting from decomposing the matrix holding the activations values of FFNN neurons using Non-negative Matrix Factorization. The following figure sheds light on how that is done:</p><p>  上面的可探究结果显示了使用非负矩阵分解分解包含FFNN神经元激活值的矩阵所导致的因素。下图阐明了如何完成此操作：</p><p>  Beyond dimensionality reduction, Non-negative Matrix Factorization can reveal underlying common behaviour of groups of neurons. It can be used to analyze the entire network, a single layer, or groups of layers.</p><p>  除了降维以外，非负矩阵分解还可以揭示神经元组的潜在常见行为。它可用于分析整个网络，单个层或一组层。</p><p>   This concludes the first article in the series. Be sure to click on  the  notebooks and play with  Ecco! I would love your feedback on this article, series, and on Ecco in  this thread. If you find interesting factors or neurons, feel free to post them there as well. I welcome all feedback!</p><p>   本系列的第一篇文章到此结束。请务必单击笔记本并与Ecco一起玩！我希望您对本系列文章和Ecco的反馈。如果您发现有趣的因素或神经元，也可以将它们张贴在这里。欢迎所有反馈！</p><p>  This article was vastly improved thanks to feedback on earlier drafts provided by Abdullah Almaatouq, Ahmad Alwosheel, Anfal Alatawi, Christopher Olah, Fahd Alhazmi, Hadeel Al-Negheimish, Isabelle Augenstein, Jasmijn Bastings, Najla Alariefy, Najwa Alghamdi, Pepa Atanasova, and Sebastian Gehrmann.</p><p>  感谢Abdullah Almaatouq，Ahmad Alwosheel，Anfal Alatawi，Christopher Olah，Fahd Alhazmi，Hadeel Al-Negheimish，Isabelle Augenstein，Jasmijn Bastings，Najla Alariefy，Najwa Alghamdi，盖尔曼。 </p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://jalammar.github.io/explaining-transformers/">https://jalammar.github.io/explaining-transformers/</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/变压器/">#变压器</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/模型/">#模型</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/分享/">#分享</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy; 2020 diglog.com </div></div></body></html>