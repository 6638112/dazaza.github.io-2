<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Python中的压缩感知（2016）Compressed Sensing in Python (2016)</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">Compressed Sensing in Python (2016)<br/>Python中的压缩感知（2016）</h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2022-02-25 21:35:54</div><div class="page_narrow text-break page_content"><p>In this post I’ll be investigating  compressed sensing (also known as compressive sensing, compressive sampling, and sparse sampling) in Python. Since the idea of compressed sensing can be applied in wide array of subjects, I’ll be focusing mainly on how to apply it in one and two dimensions to things like sounds and images. Specifically, I will show how to take a highly incomplete data set of signal samples and reconstruct the underlying sound or image. It is a very powerful technique.</p><p>在本文中，我将研究Python中的压缩感知（也称为压缩感知、压缩采样和稀疏采样）。由于压缩感知的概念可以应用于各种各样的主题，我将主要关注如何将其应用于声音和图像等一维和二维领域。具体来说，我将展示如何获取高度不完整的信号样本数据集，并重建底层的声音或图像。这是一种非常强大的技术。</p><p>   As you might know, there are many different types of norms. Perhaps the most common and widely recognized one is the  $L^2$ norm:</p><p>你可能知道，有许多不同类型的规范。也许最常见和最广泛认可的是$L^2$norm：</p><p>  The  $L^2$ norm is nice because it is easily calculated, easily differentiated, and it has intuitive appeal (e.g., the norm of a vector is its length). A lot of very important algorithms and methods rely on the  $L^2$, including least squares fitting.</p><p>$L^2$norm很好，因为它易于计算、易于区分，并且具有直观的吸引力（例如，向量的norm是其长度）。许多非常重要的算法和方法都依赖于$L^2$，包括最小二乘拟合。</p><p> That said, the  $L^2$ norm isn’t the goto solution for everything. The other norms also have many interesting and useful properties. Consider the  $L^1$ norm:</p><p>也就是说，L^2$norm并不是所有东西的goto解决方案。其他规范也有许多有趣和有用的特性。考虑$^ ^ 1美元的标准：</p><p>  Instead of squaring each element, it simply takes its absolute value. Although the absolute value is annoying in the sense that it often introduces discontinuities in its derivatives, it does have some unique properties when compared to the squaring that takes place in the  $L^2$ norm. Compressed sensing is all about exploiting these properties.</p><p>它不求每个元素的平方，只取其绝对值。尽管绝对值令人恼火，因为它经常在其导数中引入不连续性，但与在$L^2$norm中发生的平方相比，它确实有一些独特的性质。压缩感知就是利用这些特性。</p><p> Let’s visualize some data with Python to see what I’m talking about.</p><p>让我们用Python可视化一些数据，看看我在说什么。</p><p> # make sure you&#39;ve got the following packages installed import  numpy  as  np import  matplotlib  as  mpl import  matplotlib.pyplot  as  plt import  scipy.optimize  as  spopt import  scipy.fftpack  as  spfft import  scipy.ndimage  as  spimg import  cvxpy  as  cvx</p><p>#确保你&#39；我们安装了以下软件包import numpy as np import matplotlib as mpl import matplotlib。pyplot作为plt导入scipy。优化为spopt import scipy。FFT包装为spfft导入scipy。ndimage为spimg导入cvxpy为cvx</p><p> First what we’re going to do is create some arbitrary linear data including some noise. Let’s use the made-up equation:</p><p>首先我们要做的是创建一些任意的线性数据，包括一些噪声。让我们使用合成方程式：</p><p>   # generate some data with noise x  =  np . sort ( np . random . uniform ( 0 ,  10 ,  15 )) y  =  3  +  0.2  *  x  +  0.1  *  np . random . randn ( len ( x ))</p><p>#生成一些噪声x=np的数据。排序（np.random.uniform（0,10,15））y=3+0.2*x+0.1*np。随机的兰登（兰（x））</p><p> Now let’s fit two lines to the data samples. For the first line, we’ll use the  $L^1$ norm as the criterion for a good fit; for the second line, we’ll use the  $L^2$ norm.</p><p>现在让我们在数据样本上拟合两行。对于第一行，我们将使用$L^1$norm作为良好匹配的标准；对于第二行，我们将使用$L^2$norm。</p><p> # find L1 line fit l1_fit  =  lambda  x0 ,  x ,  y :  np . sum ( np . abs ( x0 [ 0 ]  *  x  +  x0 [ 1 ]  -  y )) xopt1  =  spopt . fmin ( func = l1_fit ,  x0 = [ 1 ,  1 ],  args = ( x ,  y )) # find L2 line fit l2_fit  =  lambda  x0 ,  x ,  y :  np . sum ( np . power ( x0 [ 0 ]  *  x  +  x0 [ 1 ]  -  y ,  2 )) xopt2  =  spopt . fmin ( func = l2_fit ,  x0 = [ 1 ,  1 ],  args = ( x ,  y ))</p><p>#求L1直线拟合L1_拟合=λx0，x，y:np。求和（np.abs（x0[0]*x+x0[1]-y））xopt1=spopt。fmin（func=l1_-fit，x0=[1,1]，args=（x，y））#查找L2直线拟合L2_-fit=lambda x0，x，y:np。求和（np.幂（x0[0]*x+x0[1]-y，2））xopt2=spopt。fmin（func=l2_-fit，x0=[1,1]，args=（x，y））</p><p>  Notice that both of the fits seem to do a pretty good job fitting the data. Sure, they don’t line up exactly, but they both are reasonable approximations given the noise.</p><p>请注意，这两种拟合似乎都能很好地拟合数据。当然，它们并不完全对齐，但考虑到噪音，它们都是合理的近似值。</p><p> Now, let’s get a tad crazy and add some outliers. In other words, let’s perturb a couple of the points, moving them far away from the lines. This isn’t actually all that out of the ordinary if you think about it. Outliers frequently occur in real world data, causing all kinds of headaches.</p><p>现在，让我们疯狂一点，添加一些异常值。换句话说，让我们扰动几个点，将它们远离直线。如果你仔细想想，这其实并不是那么不同寻常。异常值经常出现在现实世界的数据中，造成各种各样的麻烦。</p><p> # adjust data by adding outlyers y2  =  y . copy () y2 [ 3 ]  +=  4 y2 [ 13 ]  -=  3 # refit the lines xopt12  =  spopt . fmin ( func = l1_fit ,  x0 = [ 1 ,  1 ],  args = ( x ,  y2 )) xopt22  =  spopt . fmin ( func = l2_fit ,  x0 = [ 1 ,  1 ],  args = ( x ,  y2 ))</p><p>#通过添加输出y2=y来调整数据。复制（）y2[3]+=4 y2[13]=3#重新安装线xopt12=spopt。fmin（func=l1_-fit，x0=[1,1]，args=（x，y2））xopt22=spopt。fmin（func=l2_-fit，x0=[1,1]，args=（x，y2））</p><p>  When we re-plot the  $L^1$ and  $L^2$ fits we see something interesting: the  $L^1$ fit remained true to the overall trend in the data, while the  $L^2$ fit seemed to get “corrupted” by the outliers. Why does this happen? It comes down to the fact that  $L^2$ error gets squared, while  $L^1$ error does not. When you fit a line to data using an  $L^2$ interpretation of error, the displacement of outliers has a disproportional impact because their already-big errors are get getting squared. Just look at the distance of the two outliers in our example and imagine squaring them – of course it’s not surprising that the  $L^2$ line gets skewed!</p><p>当我们重新绘制$L^1$和$L^2$拟合曲线时，我们看到了一些有趣的现象：$L^1$拟合曲线与数据的总体趋势保持一致，而$L^2$拟合曲线似乎被异常值“破坏”。为什么会这样？归根结底，$L^2$error得到平方，而$L^1$error没有得到平方。当你用一个$L^2$的误差解释来拟合一行数据时，异常值的位移会产生不成比例的影响，因为它们已经很大的误差正在得到平方。只要看看我们示例中两个异常值的距离，想象一下将它们平方——当然，$L^2$线发生倾斜也就不足为奇了！</p><p> However, when using an  $L^1$ interpretation of error, the outliers contribute no more than their displacement. The result is a cleaner fit that more closely matches our intuition of what a good fit should look like. It’s this interesting property that opens the door to compressed sensing.</p><p>然而，当使用$L^1$错误解释时，异常值的贡献不超过其位移。结果是一个更干净的适合，更符合我们的直觉，一个好的适合应该是什么样子。正是这种有趣的特性为压缩感知打开了大门。</p><p>   In this example (borrowed from Kutz  1), we will create an artificial sound wave, sample 10% of it, and reconstruct the original signal from the sample of 10%. This is one dimensional compressed sensing.</p><p>在这个例子中（借用Kutz 1），我们将创建一个人造声波，对其进行10%的采样，并从10%的采样中重建原始信号。这是一维压缩传感。</p><p>  # sum of two sinusoids n  =  5000 t  =  np . linspace ( 0 ,  1 / 8 ,  n ) y  =  np . sin ( 1394  *  np . pi  *  t )  +  np . sin ( 3266  *  np . pi  *  t ) yt  =  spfft . dct ( y ,  norm = &#39;ortho&#39; )</p><p>#两个正弦波之和n=5000 t=np。linspace（0，1/8，n）y=np。sin（1394*np.pi*t）+np。sin（3266*np.pi*t）yt=spfft。dct（y，norm=&#39；正交&#39；）</p><p>  In the plots above, we see that the signal has a clear pattern, yet is non-trivial. The plots in the top row are of the signal in the temporal domain at different scales. The plots in the bottom row are of the signal in the spectral domain (i.e., the signal’s frequency content). Considering the frequency domain in particular, we note that the spectrum is mostly zero except for the two spikes representing the two sine frequencies.</p><p>在上面的图中，我们看到信号有一个清晰的模式，但不是微不足道的。最上面一行的曲线图是不同尺度下时域中的信号。最下面一行中的图是频谱域中的信号（即信号的频率内容）。特别是考虑到频域，我们注意到除了代表两个正弦频率的两个尖峰之外，频谱大部分为零。</p><p> Now imagine sampling 10% of the temporal signal (see below). You’d have a data set that, to the naked eye, would look like nonsense. The underlying signal is would still be the same, as would be its frequency content (mostly zeros, with the exception of two spikes). One might ask if it is somehow possible to extract those two dominant frequencies from the incomplete data so that we might reconstruct the signal? The answer is yes!</p><p>现在想象一下对10%的时间信号进行采样（见下文）。你会有一个数据集，在肉眼看来，看起来像胡说八道。基本信号仍然是相同的，其频率内容也是相同的（除两个尖峰外，大部分为零）。有人可能会问，是否有可能从不完整的数据中提取这两个主频，以便我们重建信号？答案是肯定的！</p><p> # extract small sample of signal m  =  500  # 10% sample ri  =  np . random . choice ( n ,  m ,  replace = False )  # random sample of indices ri . sort ()  # sorting not strictly necessary, but convenient for plotting t2  =  t [ ri ] y2  =  y [ ri ]</p><p>#提取信号m=500的小样本#10%样本ri=np。随机的选择（n，m，replace=False）#指数ri的随机样本。排序（）#排序不是严格必要的，但便于绘制t2=t[ri]y2=y[ri]</p><p>  Compressed sensing in this context is made possible by the fact that the signal’s frequency content is highly sparse. This is where the  $L^1$ norm comes into play. What we want to do is, out of all possible signals, locate the  simplest one that matches up with the known data. In other words, we want to use a minimization routine to find a set of frequencies satisfying two conditions: (a) the underlying signal matches up exactly (or as closely as possible) with that of our data; and (b) the  $L^1$ norm of the frequencies is minimized. Such a routine will yield a sparse solution – exactly what we want.</p><p>在这种情况下，由于信号的频率内容非常稀疏，压缩感知成为可能。这就是$L^1$norm发挥作用的地方。我们要做的是，在所有可能的信号中，找到与已知数据匹配的最简单的信号。换句话说，我们希望使用一个最小化例程来找到一组满足两个条件的频率：（a）基本信号与我们的数据完全匹配（或尽可能接近）；（b）频率的$L^1$norm最小化。这样的例行程序将产生一个稀疏的解决方案——这正是我们想要的。</p><p> In Python, there are a couple ways to accomplish this. Perhaps the easiest is to utilize the convex optimization library  CVXPY. Use the code below to minimize the norm of the signal’s frequencies with the constraint that candidate signals should match up exactly with our incomplete samples.</p><p>在Python中，有几种方法可以实现这一点。也许最简单的方法是利用凸优化库CVXPY。使用下面的代码最小化信号频率的范数，并限制候选信号应与我们的不完整样本完全匹配。</p><p> # create idct matrix operator A  =  spfft . idct ( np . identity ( n ),  norm = &#39;ortho&#39; ,  axis = 0 ) A  =  A [ ri ] # do L1 optimization vx  =  cvx . Variable ( n ) objective  =  cvx . Minimize ( cvx . norm ( vx ,  1 )) constraints  =  [ A * vx  ==  y2 ] prob  =  cvx . Problem ( objective ,  constraints ) result  =  prob . solve ( verbose = True )</p><p>#创建idct矩阵运算符A=spfft。idct（np.同一性（n），常模=&#39；正交&#39，轴=0）A=A[ri]#进行L1优化vx=cvx。变量（n）目标=cvx。最小化（cvx.norm（vx，1））约束=[A*vx==y2]prob=cvx。问题（目标、约束）结果=问题。求解（verbose=True）</p><p> You might be asking:  what the hell is that  $A$ matrix? Well, it’s the key to the whole party. Let me explain.</p><p>你可能会问：那该死的$A$matrix是什么？这是整个派对的关键。让我解释一下。</p><p> In order to perform the minimization, we must somehow finagle our problem into a linear system of equations:</p><p>为了实现极小化，我们必须以某种方式将问题转化为线性方程组：</p><p>  Specifically, we want to derive a matrix  $A$ that can be multiplied with a solution candidate  $x$ to yield  $b$, a vector containing the data samples. In the context of our current problem, the candidate solution  $x$ exists in the frequency domain, while the known data  $b$ exists in the temporal domain. Clearly, the matrix  $A$ performs both a sampling and a transformation from spectral to temporal domains.</p><p>具体来说，我们想要导出一个矩阵$a$，它可以与一个候选解决方案$x$相乘，得到$b$，一个包含数据样本的向量。在我们当前问题的上下文中，候选解决方案$x$存在于频域中，而已知数据$b$存在于时域中。显然，矩阵$A$执行采样和从光谱到时间域的转换。</p><p> Compressed sensing really comes down to being able to correctly derive the  $A$ operator. Fortunately, there’s a methodology. Start off by letting  $f$ be the target signal in vector form (if your signal is 2-dimensional or higher, flatten it) and  $\phi$ be the sampling matrix. Then:</p><p>压缩感知实际上可以归结为能够正确推导$A$运算符。幸运的是，有一种方法。首先，让$f$作为矢量形式的目标信号（如果信号是二维或更高的，则将其展平），并将$\phi$作为采样矩阵。然后：</p><p>  Now let  $\psi$ be the matrix that transforms a signal from the spectral domain to the temporal domain. Given the solution  $x$ in the frequency domain, it follows that:</p><p>现在，让$\psi$成为将信号从光谱域转换到时域的矩阵。考虑到频域中$x$的解决方案，它如下所示：</p><p>    So,  $A$ is simply made up of rows sampled from the domain transform matrix  $\psi$. The  $\psi$ matrix is easy to construct – it is the inverse discrete cosine transform acting upon the columns of the identity matrix. The matrix product  $\psi x$ is the equivalent to doing  idct(x).</p><p>所以，$A$只是由从域变换矩阵$\psi$中采样的行组成。$\psi$矩阵易于构造——它是作用于单位矩阵列的逆离散余弦变换。矩阵积$\psi x$相当于执行idct（x）。</p><p> Now that we’ve constructed the  $A$ matrix and run the minimization, we can reconstruct the signal by transforming the solution out of the frequency domain and back into the temporal. Below, on the left, is the original signal and its frequency content. On the right is our  $L^1$ approximation. I’d say that’s pretty good for only using 10% of the data!</p><p>现在我们已经构建了$A$矩阵并运行了最小化，我们可以通过将解从频域转换到时域来重建信号。下面左侧是原始信号及其频率内容。右边是我们的$L^1$近似值。我想说，只使用10%的数据是非常好的！</p><p>   One problem that stands out is that the quality of the reconstruction degrades noticeably at and around  $t=0$. This is probably due to our sample interval violating the periodic boundary condition requirements of the cosine transform. Of course, given an arbitrary signal sample without any prior knowledge of its nature, it would be hard  not to violate periodic boundary conditions. The good news is that now we have some very clear indications of the true signal’s frequencies. If desired, we could go back and resample the signal within an interval that satisfies periodic boundaries.</p><p>一个突出的问题是，重建质量在$t=0$左右明显下降。这可能是因为我们的采样间隔违反了余弦变换的周期边界条件要求。当然，给定一个任意的信号样本，事先不知道其性质，很难不违反周期性边界条件。好消息是，现在我们对真实信号的频率有了一些非常清晰的指示。如果需要，我们可以返回并在满足周期边界的间隔内重新采样信号。</p><p>   Now let’s use what we learned from the 1-dimensional case to do compressed sensing in 2-dimensions. This is where the real fun begins because we can now try and reconstruct images.</p><p>现在，让我们使用我们从一维案例中学到的知识，在二维中进行压缩感知。这才是真正有趣的开始，因为我们现在可以尝试重建图像。</p><p> Below, we will use exactly the same methodology as before to randomly sample and reconstruct the image  Waterfall by M. C. Escher (approx. 1200 by 1600 pixels). Due to memory limitations imposed by the  $A$ matrix, we’ll start off by considering a downsized version of the image (approx. 50 by 65 pixels). In the section that follows we’ll extend the routine to handle large images.</p><p>下面，我们将使用与之前完全相同的方法对M.C.Escher的图像瀑布进行随机采样和重建（约1200×1600像素）。由于$A$矩阵带来的内存限制，我们将首先考虑缩小版本的图像（约50×65像素）。在接下来的部分中，我们将扩展例程以处理大型图像。</p><p> Note that SciPy doesn’t provide 2D versions of  dct or  idct. However, they can be easily constructed by recognizing that the 2D discrete cosine transform is nothing more than a  dct acting upon the rows of  $x$ followed by a second  dct action upon its columns (or vice versa):</p><p>请注意，SciPy不提供dct或idct的2D版本。然而，通过认识到2D离散余弦变换只不过是作用于$x$行的dct，然后是作用于其列的第二个dct（反之亦然），可以很容易地构造它们：</p><p>  As a personal preference, I like to tell SciPy’s  dct and  idct methods to act on the columns of a matrix (as opposed to the default behavior of acting on the rows). First of all, this keeps the Python code consistent with that of MATLAB. Second, it makes building matrix operators more intuitive (to me at least). For example, if we let  $Y$ be an  $m$ by  $n$ matrix, with  $I_m$ and  $I_n$ being identity matrices of size  $m$ and  $n$ respectively, then</p><p>作为个人偏好，我喜欢告诉SciPy的dct和idct方法对矩阵的列进行操作（而不是对行进行操作的默认行为）。首先，这使Python代码与MATLAB代码保持一致。其次，它使构建矩阵运算符更直观（至少对我来说）。例如，如果我们让$Y$是一个$m$乘$n$矩阵，其中$I_m$和$I_n$分别是大小为$m$和$n$的单位矩阵，那么</p><p>    Either version can be made to work, but I feel like the first one is cleaner because it naturally keeps the matrix operator in front of the operand. Whenever I refer to the  dct or  idct, assume that I mean the  axis=0 variety.</p><p>这两个版本都可以使用，但我觉得第一个版本更干净，因为它自然地将矩阵运算符放在操作数前面。每当我提到dct或idct时，假设我指的是轴=0。</p><p> def  dct2 ( x ):  return  spfft . dct ( spfft . dct ( x . T ,  norm = &#39;ortho&#39; ,  axis = 0 ) . T ,  norm = &#39;ortho&#39; ,  axis = 0 ) def  idct2 ( x ):  return  spfft . idct ( spfft . idct ( x . T ,  norm = &#39;ortho&#39; ,  axis = 0 ) . T ,  norm = &#39;ortho&#39; ,  axis = 0 ) # read original image and downsize for speed Xorig  =  spimg . imread ( &#39;escher_waterfall.jpeg&#39; ,  flatten = True ,  mode = &#39;L&#39; )  # read in grayscale X  =  spimg . zoom ( Xorig ,  0.04 ) ny , nx  =  X . shape</p><p>def dct2（x）：返回spfft。dct（spfft.dct（x.T，范数=&#39；正交&#39；，轴=0）。T，norm=&#39；正交&#39，轴=0）def idct2（x）：返回spfft。idct（spfft.idct（x.T，norm=&#39；正交&#39；，轴=0）。T，norm=&#39；正交&#39，axis=0）#读取原始图像并缩小尺寸以获得速度xOrg=spimg。imread（&#39；escher#u瀑布.jpeg&#39；，flatte=True，mode=&#39；L&#39；）#读取灰度X=spimg。缩放（Xorig，0.04）ny，nx=X。形状</p><p>  As in the previous section, we’ll take a random sample of image indices, forming our  $b$ matrix. Then, we’ll generate our  $A$ matrix.</p><p>与上一节一样，我们将随机抽取图像索引样本，形成我们的$b$矩阵。然后，我们将生成$A$矩阵。</p><p> Creating the  $A$ matrix for 2D image data takes a little more ingenuity than it did in the 1D case. In the derivation that follows, we’ll use the Kronecker product  $\otimes$ and the fact that the 2D discrete cosine transform is  separable to produce our operator  $A$.</p><p>为2D图像数据创建$A$矩阵需要比在1D情况下更巧妙的技巧。在接下来的推导中，我们将使用Kronecker乘积$\otimes$和2D离散余弦变换是可分离的这一事实来生成运算符$A$。</p><p> Let  $X$ be an image in the spectral domain and  $D_i=\textit{idct}(I_i)$, where  $I_i$ is the identity matrix of size  $i$. Then:</p><p>假设$X$是光谱域中的图像，$D_i=\textit{idct}（i_i）$，其中$i_i$是大小为$i$的单位矩阵。然后：</p><p>  If  $\textit{vec}(X)$ is the vector operator that stacks columns of  $X$ on top of each other, then:</p><p>如果$\textit{vec}（X）$是将$X$的列堆叠在彼此之上的向量运算符，则：</p><p>  Clearly, the Kronecker product is our desired transformation matrix  $\psi$. Therefore, our matrix  $A$ becomes  $A=\phi (D_n\otimes D_m)$, where  $\phi$ is the sampling matrix. You can calculate the Kronecker product in  Numpy with  numpy.kron. The main problem with this method is that the Kronecker product can become truly massive very quickly. If your target image is  $m$ by  $n$ and you’re taking  $k$ samples, then the  $A$ matrix has a size of  $(mnk)^2$. That said, for small images it will be fine.</p><p>显然，Kronecker产品是我们想要的转换矩阵$\psi$。因此，我们的矩阵$A$变成了$A=\phi（D_n\otimes D_m）$，其中$\phi$是采样矩阵。你可以用Numpy计算Kronecker积。克朗。这种方法的主要问题是Kronecker产品可以很快变得非常巨大。如果你的目标图像是$m$乘$n$，并且你要采集$k$样本，那么$A$矩阵的大小为$（mnk）^2$。这就是说，对于小图像来说，这是很好的。</p><p> # extract small sample of signal k  =  round ( nx  *  ny  *  0.5 )  # 50% sample ri  =  np . random . choice ( nx  *  ny ,  k ,  replace = False )  # random sample of indices b  =  X . T . flat [ ri ] b  =  np . expand_dims ( b ,  axis = 1 ) # create dct matrix operator using kron (memory errors for large ny*nx) A  =  np . kron (  spfft . idct ( np . identity ( nx ),  norm = &#39;ortho&#39; ,  axis = 0 ),  spfft . idct ( np . identity ( ny ),  norm = &#39;ortho&#39; ,  axis = 0 )  ) A  =  A [ ri ,:]  # same as phi times kron # do L1 optimization vx  =  cvx . Variable ( nx  *  ny ) objective  =  cvx . Minimize ( cvx . norm ( vx ,  1 )) constraints  =  [ A * vx  ==  b ] prob  =  cvx . Problem ( objective ,  constraints ) result  =  prob . solve ( verbose = True ) Xat2  =  np . array ( vx . value ) . squeeze ()</p><p>#提取信号k=round（nx*ny*0.5）#50%样本ri=np的小样本。随机的选择（nx*ny，k，replace=False）#指数b=X的随机样本。T平坦[ri]b=np。展开_dims（b，轴=1）#使用kron（大ny*nx的内存错误）A=np创建dct矩阵运算符。kron（spfft.idct）（np.identity（nx），norm=&#39；正交&#39，轴=0），spfft。idct（np.身份（ny），常模=&#39；正交&#39，轴=0）A=A[ri，：]#与φ乘以kron相同#进行L1优化vx=cvx。变量（nx*ny）目标=cvx。最小化（cvx.norm（vx，1））约束=[A*vx==b]prob=cvx。问题（目标、约束）结果=问题。求解（verbose=True）Xat2=np。数组（vx.value）。挤压（）</p><p>  # reconstruct signal Xat  =  Xat2 . reshape ( nx ,  ny ) . T  # stack columns Xa  =  idct2 ( Xat ) # confirm solution if  not  np . allclose ( X . T . flat [ ri ],  Xa . T . flat [ ri ]):  print ( &#39;Warning: values at sample indices don \&#39; t match original.&#39; ) # create images of mask (for visualization) mask  =  np . zeros ( X . shape ) mask . T . flat [ ri ]  =  255 Xm  =  255  *  np . ones ( X . shape ) Xm . T . flat [ ri ]  =  X . T . flat [ ri ]</p><p>#重建信号Xat=Xat2。重塑（nx，ny）。T#堆栈列Xa=idct2（Xat）#如果不是np，则确认解决方案。allclose（X.T.flat[ri]，Xa.T.flat[ri]）：打印（&#39；警告：样本索引处的值与原始值不匹配。&#39；）创建蒙版图像（用于可视化）蒙版=np。零（X形状）遮罩。T平坦[ri]=255 Xm=255*np。一个（X.形状）Xm。T平坦[ri]=X。T平[里]</p><p>  Okay, the results aren’t fabulous. The original image on the far left is barely intelligible as it is. Resolution was low, so we had to take a large-ish sample of 50% (the boolean mask is shown middle left; the masked image is middle right). Regardless, it is clear the procedure worked: the reconstructed image on the far right definitely approximates the original, be it poorly.</p><p>好吧，结果不太好。最左边的原始图像几乎无法理解。分辨率很低，所以我们必须取50%的大ish样本（布尔掩码显示在左中；掩码图像显示在右中）。不管怎样，这一过程显然奏效了：最右边的重建图像肯定与原始图像很接近，尽管效果很差。</p><p>   Considering our working proof-of-concept, there are a lot of ways it might be improved. The Kronecker-based method, although easy to implement, proves unusable for large images. What other methods are there?</p><p>考虑到我们正在进行的概念验证，有很多方法可以改进。基于Kronecker的方法虽然易于实现，但对于大型图像来说是不可用的。还有什么其他方法？</p><p> Convex optimization using  CVXPY isn’t necessarily the only way to find the  $L^1$ minimum. A little bit of online research led me to the L-BFGS algorithm  6 and its variant, the OWL-QN  3. The OWL-QN algorithm is of particular interest to us, as it allows one to fit a  $L^1$ regularized model by minimizing a function of the form:</p><p>使用CVXPY的凸优化不一定是找到$L^1$最小值的唯一方法。通过一点在线研究，我找到了L-BFGS算法6及其变体OWL-QN3。我们对OWL-QN算法特别感兴趣，因为它允许通过最小化以下形式的函数来拟合$L^1$正则化模型：</p><p>  where  $f$ is a differentiable convex loss function and  $C$ is a constant. In our case, we might define  $f$ to be the least squares objective function, which is simply the  $L^2$ norm of the residual squared:</p><p>其中，$f$是可微凸损失函数，$C$是常数。在我们的例子中，我们可以将$f$定义为最小二乘目标函数，它只是剩余平方的$L^2$范数：</p><p>    Now all that remains is to code it up! After trying several different options, I ended up settling on using  libLBFGS (written in C) for its OWL-QN implementation. To make it accessible from Python, I wrapped it using the C APIs for  Python and  Numpy. You can find my implementation at  PyLBFGS. See the project README for installation instructions and basic use. Let me know if you encounter bugs.</p><p>现在剩下的就是编码了！在尝试了几个不同的选项后，我最终决定使用libLBFGS（用C编写）来实现OWL-QN。为了从Python中访问它，我使用Python和Numpy的C API对其进行了包装。你可以在PyLBFGS找到我的实现。有关安装说明和基本用法，请参阅项目自述。如果你遇到虫子，请告诉我。</p><p> The nice thing about  libLBFGS (and by extension  PyLBFGS) is that you can define the objective function anyway you like. In other words, we aren’t constrained to follow the  $Ax=b$ model blindly. All that matters is the we are able to calculate the norm of the residual squared and its gradient. We need not generate  $A$ at all!</p><p>libLBFGS（扩展为PyLBFGS）的好处在于，您可以随意定义目标函数。换句话说，我们不必盲目遵循$Ax=b$模型。重要的是我们能够计算剩余平方的范数及其梯度。我们根本不需要生成$A$！</p><p> The following code explains what I mean better than I could with words. Take special note of the  evaluate callback passed to the OWL-QN algorithm.</p><p>下面的代码比用文字更好地解释了我的意思。请特别注意传递给OWL-QN算法的evaluate回调。</p><p> from  pylbfgs  import  owlqn def  evaluate ( x ,  g ,  step ):  &#34;&#34;&#34;An in-memory evaluation callback.&#34;&#34;&#34;  # we want to return two things:   # (1) the norm squared of the residuals, sum((Ax-b).^2), and  # (2) the gradient 2*A&#39;(Ax-b)  # expand x columns-first  x2  =  x . reshape (( nx ,  ny )) . T  # Ax is just the inverse 2D dct of x2  Ax2  =  idct2 ( x2 )  # stack columns and extract samples  Ax  =  Ax2 . T . flat [ ri ] . reshape ( b . shape )  # calculate the residual Ax-b and its 2-norm squared  Axb  =  Ax  -  b  fx  =  np . sum ( np . power ( Axb ,  2 ))  # project residual vector (k x 1) onto blank image (ny x nx)  Axb2  =  np . zeros ( x2 . shape )  Axb2 . T . flat [ ri ]  =  Axb  # fill columns-first  # A&#39;(Ax-b) is just the 2D dct of Axb2  AtAxb2  =  2  *  dct2 ( Axb2 )  AtAxb  =  AtAxb2 . T . reshape ( x . shape )  # stack columns  # copy over the gradient vector  np . copyto ( g ,  AtAxb )  return  fx # fractions of the scaled image to randomly sample at sample_sizes  =  ( 0.1 ,  0.01 ) # read original image Xorig  =  spimg . imread ( &#39;escher_waterfall.jpeg&#39; ) ny , nx , nchan  =  Xorig . shape # for each sample size Z  =  [ np . zeros ( Xorig . shape ,  dtype = &#39;uint8&#39; )  for  s  in  sample_sizes ] masks  =  [ np . zeros ( Xorig . shape ,  dtype = &#39;uint8&#39; )  for  s  in  sample_sizes ] for  i , s  in  enumerate ( sample_sizes ):  # create random sampling index vector  k  =  round ( nx  *  ny  *  s )  ri  =  np . random . choice ( nx  *  ny ,  k ,  replace = False )  # random sample of indices  # for each color channel  for  j  in  range ( nchan ):  # extract channel  X  =  Xorig [:,:, j ] . squeeze ()  # create images of mask (for visualization)  Xm  =  255  *  np . ones ( X . shape )  Xm . T . flat [ ri ]  =  X . T . flat [ ri ]  masks [ i ][:,:, j ]  =  Xm  # take random samples of image, store them in a vector b  b  =  X . T . flat [ ri ] . astype ( float )  # perform the L1 minimization in memory  Xat2  =  owlqn ( nx * ny ,  evaluate ,  None ,  5 )  # transform the output back into the spatial domain  Xat  =  Xat2 . reshape ( nx ,  ny ) . T  # stack columns  Xa  =  idct2 ( Xat )  Z [ i ][:,:, j ]  =  Xa . astype ( &#39;uint8&#39; )</p><p>从pylbfgs导入owlqn def评估（x，g，步骤）：&34&#34;&#34;内存中的求值回调&#34;&#34;&#34;  # 我们想要返回两件事：#（1）残差的范数平方，和（（Ax-b）^2） 和#（2）梯度2*A和#39；（Ax-b）#首先展开x列x2=x。重塑（（nx，ny））。T#Ax只是x2 Ax2=idct2（x2）#堆栈列和提取样本Ax=Ax2的逆2D dct。T平坦[ri]。重塑（b.形状）#计算剩余的Ax-b及其2-范数平方Axb=Ax-bfx=np。求和（np.power（Axb，2））#将剩余向量（kx1）投影到空白图像（ny x nx）上Axb2=np。零（x2.形状）Axb2。T扁平[ri]=Axb#先填充列#A和#39；（Ax-b）只是Axb2 AtAxb2=2*dct2（Axb2）AtAxb=AtAxb2的2D dct。T重塑（x.shape）#堆叠列#复制渐变向量np。copyto（g，AtAxb）返回fx#缩放图像的分数，以随机采样，采样大小=（0.1,0.01）#读取原始图像Xorig=spimg。imread（&#39；escher#u瀑布.jpeg&#39；）ny，nx，nchan=xOrg。形状#对于每个样本大小Z=[np.zero（Xorig.shape，dtype=&#39；uint8&#39；）对于样本大小为[u]的s，掩码=[np.zero（Xorig.shape，dtype=&#39；uint8&#39；）对于样本大小中的s]对于i，枚举中的s（样本大小）：#创建随机抽样索引向量k=round（nx*ny*s）ri=np。随机的选择（nx*ny，k，replace=False）#索引的随机样本#范围内j的每个颜色通道（nchan）：#提取通道X=Xorig[：，：，j]。挤压（）#创建遮罩图像（用于可视化）Xm=255*np。一个（X.形状）Xm。T平坦[ri]=X。T平面[ri]掩模[i][：，：，j]=Xm#对图像进行随机采样，将其存储在向量b=X中。T平坦[ri]。astype（float）#在内存Xat2=owlqn（nx*ny，evaluate，None，5）中执行L1最小化#将输出转换回空间域Xat=Xat2。重塑（nx，ny）。T#stack columns Xa=idct2（Xat）Z[i][：，：，j]=Xa。aType（&#39；uint8&#39；）</p><p>  The fast C implementation of OWL-QN allows us to process samples of the entire  Waterfall image without any scaling required. And instead of doing everything in gray-scale like earlier, we can now afford to process each of the image’s three color channels. The solution shown above really demonstrates the power of compressed sensing. The original, full-color image is shown on the left. The middle image is the random 10% sample. The solution image is on the right. Although the solution contains some noticeable blemishes due to bad color channel mixing, the overall accuracy is uncanny. Furthermore, with a little extra care and attention, those blemishes might be removed – either via post-processing (e.g., a Gaussian filter) or via an improved compressed sensing implementation that takes into account color channels. One possibility is to try and determine the probable color palette beforehand and then incorporate it into the compressed sensing routine.</p><p>OWL-QN的快速C实现允许我们处理整个瀑布图像的样本，而无需任何缩放。我们现在可以处理图像的三个颜色通道中的每一个，而不是像以前那样在灰度中进行所有操作。上面显示的解决方案真正展示了压缩感知的威力。原始的全彩图像显示在左侧。中间的图像是随机的10%样本。解决方案图像位于右侧。虽然该解决方案包含一些明显的瑕疵，由于不良的颜色通道混合，整体精度是不可思议的。此外，只要格外小心和注意，这些瑕疵可能会被去除——要么通过后处理（例如高斯滤波器），要么通过考虑颜色通道的改进压缩感知实现。一种可能性是尝试预先确定可能的调色板，然后将其纳入压缩感知例程。</p><p> Just for kicks and giggles, I also included an image reconstructed from 1% of the available data. It’s definitely blurred, but nonetheless recognizable!</p><p>我还包括了一张根据1%的可用数据重建的图像，这只是为了好玩和咯咯笑。它肯定是模糊的，但仍然可以辨认！</p><p>   Kutz, J. N. “Data-driven modeling and scientific computing: Methods for Integrating Dynamics of Complex Sys-tems and Big Data.” (2013).  ↩</p><p>数据驱动的建模和科学计算：整合复杂系统动力学和大数据的方法(2013).  ↩</p><p> Candè, Emmanuel J., and Michael B. Wakin. “An introduction to compressive sampling.” Signal Processing Magazine, IEEE 25.2 (2008): 21-30.  ↩</p><p>坎德、伊曼纽尔·J.和迈克尔·B·沃金。“压缩采样简介。”信号处理杂志，IEEE 25.2（2008）：21-30。  ↩</p><p> Andrew, Galen, and Jianfeng Gao. “Scalable training of L1-regularized log-linear models.” Proceedings of the 24th international conference on Machine learning. ACM, 2007.  ↩</p><p>安德鲁、盖伦和高剑锋。“L1正则对数线性模型的可扩展训练。”第24届国际机器学习会议记录。ACM，2007年。  ↩</p><p> Wikipedia contributors. “Compressed sensing.” Wikipedia, The Free Encyclopedia. Wikipedia, The Free Encyclopedia, 26 Mar. 2016. Web. 26 May. 2016.  ↩</p><p>维基百科撰稿人。“压缩感知。”维基百科，免费的百科全书。维基百科，免费百科全书，2016年3月26日。网状物5月26日。2016.  ↩</p><p> Wikipedia contributors. “Kronecker product.” Wikipedia, The Free Encyclopedia. Wikipedia, The Free Encyclopedia, 1</p><p>维基百科撰稿人。“克罗内克产品。”维基百科，免费的百科全书。维基百科，免费百科全书，1</p><p>......</p><p>......</p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/python/">#python</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/压缩/">#压缩</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/sensing/">#sensing</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/图像/">#图像</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/谷歌/">#谷歌</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy;2012-2021 diglog.com </div></div></body></html>