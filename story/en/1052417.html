<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>现代GPU的2D图形（2019） 2D Graphics on Modern GPU (2019)</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">2D Graphics on Modern GPU (2019)<br/>现代GPU的2D图形（2019） </h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2021-03-15 12:14:54</div><div class="page_narrow text-break page_content"><p>Is the traditional 2D imaging model nearing the end of its usefulness, or does it have a shiny future in the “modern graphics” world? I spent a week on a research retreat in a  cottage in the woods to answer this question, as it shapes the future of UI toolkits. Performant UI  must use GPU effectively, and it’s increasingly common to write UI directly in terms of GPU rendering, without a 2D graphics API as in the intermediate layer. Is that the future, or perhaps a mistake?</p><p>是传统的2D成像模型接近其有用的结束，还是在“现代图形”世界中有一个闪亮的未来？我在树林里的一个小屋的研究中度过了一周，以回答这个问题，因为它塑造了UI工具包的未来。表演UI必须有效地使用GPU，并且在GPU渲染方面直接写UI越来越常见，而没有2D图形API，如中间层。是未来，或者也许是一个错误？</p><p> I have found that, if you can depend on modern compute capabilities, it seems quite viable to implement 2D rendering directly on GPU, with very promising quality and performance. The prototype I built strongly resembles a software renderer, just running on an outsized multicore GPU with wide SIMD vectors, much more so than rasterization-based pipelines.</p><p> 我已经发现，如果你可以依靠现代计算能力，它似乎可以直接在GPU上实现2D渲染，具有非常有前途的质量和性能。我构建的原型类似于软件渲染器，刚刚在具有宽SIMD向量的超出多核GPU上运行，比基于光栅化的流水线更多。</p><p> Writing a 2D renderer is a fairly ambitious project, doubly so to make it run efficiently on GPU. I deliberately reduced the scope of the project in a number of ways to make it viable. Most importantly, I targeted  only Metal 2.1, which is only a year old and only at  42.5% share among worldwide macOS users. Thus, I am targeting the near future of GPU and ignoring the past. My faithful readers will no doubt be curious how much of this work can be adapted to older GPUs, but I believe that’s a much more complex question, and one I deliberately did not address. (Other work like  PathFinder is more appropriate.)</p><p> 写一个2D渲染器是一个相当雄心勃勃的项目，双倍地使其在GPU上有效地运行。我故意以许多方式减少项目的范围，以使其可行。最重要的是，我只针对金属2.1，这只是一年的历史，只有在全球麦克斯用户中的42.5％。因此，我瞄准了GPU的不久的未来，忽略了过去。我的忠实读者毫无疑问会好奇这项工作可以适应年龄较大的GPU，但我相信这是一个更复杂的问题，我故意没有地解决。 （探路者这样的其他工作更合适。）</p><p> That said, I think the capabilities of Metal 2.1 are fairly mainstream and more so in coming years. From my perspective, it finally lets us program a GPU as if it were a big SIMD computer, which is basically what it’s been under the hood for a long time. Looking at newer features in, for example,  CUDA 10, I don’t see anything that would profoundly change the way I would approach this problem. I believe this is a very attractive target for research and practice in efficient GPU implementation of classical algorithms.</p><p> 也就是说，我认为金属2.1的能力是公平的主流，因此即将到来，即将到来。从我的角度来看，它终于让我们编程了一个GPU，好像它是一个大型SIMD电脑，这基本上很长一段时间就在引擎盖上。看着更新的功能，例如，CUDA 10，我看不到任何事情会对我接近这个问题的方式变化。我相信这是一个非常有吸引力的经典算法的GPU实现中的研究和实践目标。</p><p> It’s not surprising that 2D graphics can be efficiently implemented on GPU. The excellent 2014  Massively-Parallel Vector Graphics was a major inspiration to this work, and there have been follow-ups such as  Li 2016 that promise even more performance. But both of these papers seemed very complex and focused narrowly on path rendering.</p><p> 它并不奇怪，2D图形可以在GPU上有效地实现。优秀的2014年大型平行向量图形是这项工作的主要灵感，并有后续行动如Li 2016，甚至更具表现。但这两篇论文都似乎非常复杂，并在路径渲染上狭隘地聚焦。</p><p> I had great fun implementing my prototype and learned a lot. Along the way I kept a  notes document that recounts some of my struggles and touches on some deeper topics that I will only briefly touch on in this blog post. The  code is available and could be fun to play with or look at.</p><p> 我很有乐趣实施我的原型并学到了很多东西。一路上，我保留了一个备注文件，述评我的一些斗争并触及一些更深入的主题，即我将在这个博客帖子中短暂地触摸。代码可用，可以很有趣或查看。</p><p> I’ll stress again that this is a research prototype, not a finished product. The most promising use case for the work is likely CAD tools, where there might be quite complex scenes and it’s not necessarily practical to organize the UI drawing around GPU primitives (as opposed to 3D games, for example).</p><p> 我会再次强调这是一个研究原型，而不是成品。最有希望的工作用例可能是CAD工具，在那里可能存在相当复杂的场景，组织周围的GPU基元（例如3D游戏）的UI绘制不一定是实际的。 </p><p>  Rendering starts with a “scene graph,” which is an on-GPU serialization of 2D drawing operations. It has a tree structure, in that operations like clipping are represented as a node with children; in the case of clipping, one child for the clip mask and another for the contents being clipped. It also has a graph structure, in that multiple instances can be shared by reference (with appropriate transform nodes to change their position). (Note: I didn’t get around to implementing much of the graph structure, but the prototype is designed to accommodate it without much trouble. I’m describing it anyway because it’s important to the motivation).</p><p>渲染从“场景图”开始，这是2D绘图操作的ON-GPU序列化。它具有树结构，在该操作中，剪辑等操作表示为带子节点;在剪切的情况下，一个孩子用于剪辑掩模，另一个用于被剪裁的内容。它还具有图形结构，因为可以通过引用共享多个实例（具有适当的变换节点以改变其位置）。 （注意：我没有绕过实现大部分图形结构，但原型旨在容纳它，而不会遇到很多麻烦。我无论如何都在描述它，因为它对动机很重要）。</p><p> The imaging model allows per-pixel operations only; operations like blur are purposefully excluded. Thus, a simplistic approach to parallel rendering would be for each pixel in the target framebuffer to traverse the scene graph, applying the computation at each node (each of which can be seen as a small functional program), and finally writing the pixel color computed at the root node. That approach is of course quite inefficient, but forms the basis of what the code actually does.</p><p> 成像模型仅允许每个像素操作;有目的被排除在外的操作。因此，并行渲染的简单方法是针对目标帧缓冲区中的每个像素来遍历场景图，将计算应用于每个节点（每个节点（每个可以被视为小功能程序），并且最终写入计算的像素颜色在根节点。这种方法当然是非常低效的，但是构成了代码实际的所作的基础。</p><p> To achieve performance, the code divides the target framebuffer into fixed size  tiles, currently 16x16 pixels each. There are two passes, a  tiling pass that creates a command list for each tile, and a  rendering pass that consumes the command list, evaluating all 256 pixels of the tile in parallel, each pixel sequentially evaluating the commands for the tile.</p><p> 为了实现性能，代码将目标帧缓冲区划分为固定大小的图块，目前为16x16像素。有两个通过，一个平铺通过，它为每个区块创建命令列表，以及消耗命令列表的渲染通过，并行地评估所有256个像素，每个像素顺序地评估图块的命令。</p><p> Note that the approach to tiling is similar to  PathFinder, but with important differences in the details. PathFinder renders intermediate alpha masks to a mask texture buffer, requiring a write and a read of global device memory, but I do all the blending in local memory in the rendering shader, as in  MPVG. Minimizing global memory traffic is a major shared theme.</p><p> 请注意，平铺的方法类似于Pathfinder，但细节的重要差异。 Pathfinder将中间alpha掩模呈现给掩模纹理缓冲区，要求写入和读取全局设备内存，但是我在渲染着色器中的本地内存中的所有混合都在MPVG中进行。最小化全局内存流量是一个主要的共享主题。</p><p> A 16x16 tile should be close to the sweet spot. It results in 128x96 (12k total) tiles for a typical 2048x1536 window. It’s not a huge amount of work to generate the tiles, but with fewer tiles it would be harder to exploit parallelism in the tiling phase. Similarly, if graphic elements are much smaller than the tile size, there would be wasted work during rendering, as (for the most part) the entire tile needs to be rendered for any element that touches the tile. But again, 16x16 is a good size for a threadgroup dispatch, to exploit parallelism within the tile, and the savings from the leftover parts of a tile would be offset by per-tile overhead as tiles get smaller. It’s always possible to tune such things, but it’s not reasonable to expect any big wins. (I will note, though, that  MPVG uses a quadtree structure, which basically amounts to adapting tile size to the workload. There are potential savings, but I also think it adds a lot to their overall complexity.)</p><p> 16x16瓷砖应该接近甜点。它导致典型的2048x1536窗口128x96（总计）瓷砖。它不是一个巨大的工作要生成瓷砖，但差别较少，在平铺相中剥削并行性更难。类似地，如果图形元素小于区块大小，则在渲染过程中会有浪费的工作，因为（大多数情况下，对于触及瓦片的任何元素，需要呈现整个图块。但是，16x16是线程组调度的很大尺寸，以利用瓦片内的并行性，并且从瓦片的剩余部分的节省将被每块开销偏移，因为瓷砖变小。它总是可以调整这样的东西，但预计任何大胜利都不是合理的。 （但是，我将注意到，MPVG使用Quadtree结构，这些结构基本上适应工作量的瓷砖大小。潜在的节省，但我也认为它对他们的整体复杂性增加了很多。）</p><p> The rendering kernel (similar to a fragment shader) is fairly straightforward - it’s basically just computing signed area coverage for fills, distance fields for strokes, texture sampling for images and pre-rendered glyphs, and blends for clipping and compositing. The functional program represented by the scene graph is flattened into a linear sequence of operations, filtered of course to only those elements that touch the tile. For blend groups, nesting in the scene graph is represented by push/pop operations, with an explicit, local stack. (Again disclosure: I didn’t get too far into actually implementing blend groups, but it should be easy to see how they’d work).</p><p> 渲染内核（类似于片段着色器）相当简单 - 它基本上只是计算填充，距离场的符号区域覆盖，用于描绘的距离字段，用于图像的纹理采样和预渲染的字形，以及用于剪切和合成的融合。场景图表示的功能程序被展平到线性操作序列，当然仅触及触摸瓦片的那些元素。对于混合组，嵌套在场景图中由Push / Pop操作表示，具有显式，本地堆栈。 （再次披露：我没有太远，实际上实施混合群体，但应该很容易看出他们的工作方式）。</p><p> Thus, most of the interesting parts are in tiling. That’s all about efficiently traversing the scene graph, quickly skipping over parts of the graph that don’t touch the tile being generated.</p><p> 因此，大多数有趣的部分都在平铺。这完全是关于有效地遍历场景图，快速跳过图表的部分，不触摸正在生成的图块。 </p><p> Similar to the simplistic rendering strategy above, a simple approach to tile generation would be to have a thread per tile (~12k threads), each of which sequentially traverses the scene graph. That’s a lot less work than doing a per-pixel traversal, but is still not great. As I’ll describe in the next section, the key to performance is a good serialization format for the scene graph, and SIMD techniques for extracting more parallelism from the traversal. The basic structure is there, though; the traversal of the scene graph and generation of tiles is at heart sequential, not relying on tricky GPU-compute techniques such as sorting.</p><p>类似于上面的简单渲染策略，瓷砖生成的简单方法是每个图块（〜12k线程）的螺纹，每个线程顺序地遍历场景图。这比每像素遍历更少的工作，但仍然不太好。正如我将在下一部分描述的那样，性能的关键是场景图的良好序列化格式，以及用于从遍历中提取更多并行性的SIMD技术。但基本结构是存在的;场景图和瓷砖的生成的遍历是心顺序，而不是依赖于棘手的GPU计算技术，例如排序。</p><p>  It’s often said that GPU is bad at data structures, but I’d turn that around. Most, but not all, data structures are bad at GPU. An extreme example is a linked list, which is still considered reasonable on CPU, and is the backbone of many popular data structures. Not only does it force sequential access, but it also doesn’t hide the latency of global memory access, which can be as high as 1029 cycles on a modern GPU such as  Volta.</p><p>  经常说GPU对数据结构不好，但我会转过身来。大多数，但不是全部，数据结构在GPU都不糟糕。一个极端的例子是链接列表，仍然是CPU的合理，并且是许多流行数据结构的骨干。它不仅强制顺序访问，而且它也不会隐藏全局内存访问的延迟，这可以高达现代GPU等1029个周期，如Volta。</p><p> Well known to game developers, what  is efficient on GPU is a structure-of-arrays approach. In particular, the tiling phase spends a lot of time looking at bounding boxes, to decide what belongs in each tile. Each group node in the graph has an array of bounding boxes of its children, 8 bytes each, and a separate array for the child contents. The core of the tiling pass is consuming those bounding box arrays, only dropping down to traverse the child when there’s an intersection.</p><p> 众所周知的游戏开发人员，在GPU上有效的是一种阵列方法。特别是，平铺阶段花费大量时间来看线框，决定每个瓷砖属于什么。图中的每个组节点都有一系列绑定框，每个子项，每个字节为8字节，以及用于子内容的单独数组。平铺通过的核心是消耗那些边界盒子阵列，只有在有交叉点时才能下降以遍历孩子。</p><p> Other than that, the serialization format is not that exotic, broadly similar to  FlatBuffers or  Cap’n Proto. As a digression, I find it amusing that the word for packing a data structure into a byte buffer is “serialization” even when it’s designed to be accessed in parallel. Maybe we should come up with a better term, as “parallel-friendly serialization” is an oxymoron.</p><p> 除此之外，序列化格式并不像异国情调，大致相似，与FlinBuffers或Cap'n ProLo相似。作为次要次数，我发现它有助于将数据结构包装到字节缓冲区的单词即使在旨在并行访问它时，也是“序列化”。也许我们应该提出一个更好的术语，因为“并行友好的序列化”是矛盾。</p><p> While I mostly focused on parallel read access, I’m also intrigued by the possibility of  generating the scene graph in parallel, which obviously means doing allocations in a multithread-friendly way. Nical has a good  blog post on some of the issues.</p><p> 虽然我大部分都专注于并行读取访问，但我也涉及并行生成场景图的可能性，这显然意味着以多线程友好的方式进行分配。 Nical在一些问题上有一个很好的博客文章。</p><p>  Now we get to the heart of the algorithm: going through an array of bounding boxes, looking for those that intersect a subset of tiles.</p><p>  现在我们达到算法的核心：通过一系列边界框，寻找那些与图块子集相交的框。</p><p> The core computational model provided by shader languages is an independent thread per tiny grain of work (vertex, fragment, etc.), and the compiler and hardware conspire mightily in support of that illusion. You’ll hear numbers like 2560 cores, and it’s very difficult to wrap one’s mind around that. For workloads typical of  shadertoy, you don’t have to think too much about it, it magically gets through an impressive amount of computation per pixel.</p><p> 由着色器语言提供的核心计算模型是每个小麦片（顶点，片段等）的独立线程，编译器和硬件领域强大地支持该幻觉。你会听到像2560核心这样的号码，并且很难包围一个人的思想。对于典型的Shadertoy的工作负载，您不必考虑太多，它神奇地通过每个像素的令人印象深刻的计算量。 </p><p> The reality is very different. It’s also useful to think of a GPU as a SIMD computer with dozens of cores, each of which has a SIMD width of hundreds of bits. If you write code optimized for, say, a 24 core computer with 512 bit SIMD, or 12 cores x 1024 bits wide, that’s likely to run well on an Intel Iris 640. That’s not actually what it is, but the details are shrouded in mystery, so I tell myself these simplified stories to keep myself comfortable. Note that these numbers aren’t that different than a high end desktop or server chip. (Also see the  notes doc for why I have two different numbers here, kind of a fun story that kept me up a bit one night)</p><p>现实是非常不同的。将GPU视为具有数十个核心的SIMD计算机也很有用，每种核心都具有数百位的SIMD宽度。如果您编写了优化的代码，例如，具有512位SIMD的24个核心计算机，或者12个核心x 1024位，这可能会在英特尔虹膜640上运行。实际上并非如此，但细节笼罩着神秘，所以我告诉自己这些简化的故事让自己保持舒适。请注意，这些数字与高端桌面或服务器芯片不同。 （还要看看Notes Doc为什么我在这里有两个不同的数字，那种有趣的故事让我一晚一晚）</p><p> In keeping with the 3D graphics tradition of clear and consistent naming, the SIMD concept is called SIMD groups on Metal, warps on Nvidia, wavefronts on AMD, and subgroups on Vulkan. (But note that there is an important distinction between pure SIMD and the “SIMT” concept in newer Nvidia models, see this presentation on  cooperative groups for more detail.)</p><p> 在保持明确和一致的命名的3D图形传统中，SIMD概念被称为Metal，NVIDIA的Metps上的SIMD组，在AMD上的波前，以及vulkan上的子组。 （但请注意，纯SIMD和“SIMT”概念在较新的NVIDIA模型中有一个重要的区别，请参阅合作群体的此演示文稿以获取更多细节。）</p><p> So for running the tiling kernel, instead of having a few hundred or a couple thousand independent threads traversing the bounding box array, there are actually a few dozen “SIMD groups”, each of which is, say, 16 wide. In the simple version of the code, all the ALU’s in a SIMD group load the same bounding box, test against it, and go to the next iteration of the loop. We want to do better.</p><p> 所以对于运行划线内核，而不是拥有几百或几千个独立的线程，遍历边界框阵列，实际上有几十个“SIMD组”，每一个都是，说，16宽。在代码的简单版本中，所有ALU在SIMD组中加载了相同的边界框，对其进行测试，然后转到循环的下一次迭代。我们想要做得更好。</p><p> The current code gives the 16-wide SIMD group responsibility for a block of tiles (16 wide, 1 tall, in a typical threadgroup geometry). On an iteration of the loop, each ALU loads a  different bounding box, then tests for intersection against a 256x16 region of the target frame buffer. It then shares the result of that test with the other ALU’s in the SIMD group (using the  simd_ballot intrinsic). There’s another pass with finer grained checking, but in the common case where no bounding boxes intersect the 256x16 region, it can immediately go to the next iteration. This is literally a 16x increase in theoretical bandwidth for consuming the bounding boxes, and I see that borne out by measurement.</p><p> 目前的代码为瓷砖块（16宽，1高，典型的线程几何）提供了16宽的SIMD组责任。在循环的迭代中，每个ALU加载不同的边界框，然后测试针对目标帧缓冲器的256x16区域的交叉点。然后它与SIMD组中的其他ALU（使用SIMD_ballot内部）共享该测试的结果。还有另一盏细粒度检查，但在常见的情况下没有边界框与256x16区域相交，可以立即转到下一次迭代。这实际上是为了消耗边界盒的理论带宽增加16倍，并且我看到通过测量来承受。</p><p> In similar fashion, the SIMD approach crunches through the segments of filled and stroked paths, quickly sifting to assign them to the relevant tiles. Inside the tiler are a number of other optimizations; for example tiles in the interior of a filled path just get a constant color. (This logic is similar to  PathFinder and was inspired by it).</p><p> 在类似的方式中，SIMD方法通过填充和抚摸路径的段缩放，快速筛选将它们分配给相关的瓷砖。在铺层内部是许多其他优化;例如，填充路径内部的图块只需持续颜色即可。 （此逻辑与Pathfinder类似，并由其启发）。</p><p> The performance is impressive. I haven’t done careful benchmarking yet, but the  Ghostscript tiger, the standard benchmark of 2D graphics renders in a 2048x1536 window in 2.8ms of GPU time on Intel Iris 640 integrated graphics. (A fun fact, this is a 500x speedup over results I got  20 years ago). More careful empirical evaluation is needed, especially as methodology of GPU performance can be quite tricky. Also, there are a bunch more things that can be done to improve performance further.</p><p> 表现令人印象深刻。我还没有完成仔细的基准测试，而是GhostScript Tiger，2D图形的标准基准在英特尔IRIS 640集成图形上的2.8ms的GPU时间内为2048x1536窗口。 （一个有趣的事实，这是我20多年前的结果500倍的加速）。需要更加仔细的经验评估，特别是因为GPU性能的方法可能非常棘手。此外，还有一堆可以做更多的事情来提高性能进一步。</p><p> Basically, I have confidence that it will render any reasonable UI scene, up to a high level of complexity, smoothly at 60 frames per second. It should be especially nice for data visualization, CAD, and of course tools for graphic artists. An especially nice feature is that the GPU does basically all the heavy lifting, freeing up the CPU for application logic.</p><p> 基本上，我有信心它将渲染任何合理的UI场景，高达高水平的复杂性，平稳地在每秒60帧。对于数据可视化，CAD以及图形艺术家的工具应该特别好。一个特别好的特征是GPU基本上都是沉重的升降，释放CPU的应用逻辑。 </p><p>  The prototype mostly does just does fills and strokes of vector paths, but the  architecture of the renderer is designed to accommodate a full 2D graphics imaging model. Basically, it can handle any operation that works on a pixel at a time. Those include:</p><p>原型刚刚确实刚刚填充和中风，但渲染器的架构旨在容纳完整的2D图形成像模型。基本上，它可以处理一次在像素上工作的任何操作。那些包括：</p><p>  Probably the most important effect that is not included in this set is image-based blurring. That said, it is possible to get analytic or approximate blurring of many shapes, for example this  approximate blurred rounded rectangle, which can easily be adapted.</p><p>  可能是本集中不包含的最重要的效果是基于图像的模糊。也就是说，可以获得许多形状的分析或近似模糊，例如这种近似模糊的圆角矩形，其可以容易地适应。</p><p> I’m particularly interested in the rendering quality. All antialiasing and blending in the prototype is done in a  linear sRGB colorspace, which makes for especially clear vector shapes without rope-like visual artifacts. In the notes document are more ideas about improving distance field rendering (hint: never use smoothstep).</p><p> 我对渲染质量特别感兴趣。在原型中的所有抗锯齿和混合都是在线性SRGB色彩空间完成，这使得特别清楚的载体形状没有绳索样的视觉伪影。在Notes文档中是关于改进距离字段渲染的更多想法（提示：切勿使用SpranseStep）。</p><p> I’m mostly focused on making high resolution (4k and even higher) rendering fast, but an intriguing topic is to lavish compute power on making the finest possible images for lower resolution. One idea is to apply RGB  subpixel rendering techniques (similar to ClearType), but for general vector graphics, not just fonts. There are more ideas (including a link to a code sketch) in the notes doc.</p><p> 我主要专注于使高分辨率（4K甚至更高）快速渲染，但有趣的话题是为了使最佳图像更低的分辨率进行宽容。一个想法是应用RGB子像素渲染技术（类似于ClearType），但对于一般矢量图形，而不仅仅是字体。 Notes Doc中还有更多的想法（包括代码草图的链接）。</p><p>  The 2D rendering engine is a fairly central component of any graphics-intensive application. Its performance and quality characteristics can have profound implication for the rest of the system. As one example, if rendering is very slow, the system around it develops workarounds like rendering layers to textures and compositing them, which generally solves smooth scrolling but creates other problems. This work reopens the question: what should a system look like when rendering is really fast?</p><p>  2D渲染引擎是任何图形密集型应用的相当中心组件。它的性能和质量特征可以对系统的其余部分具有深远的含义。作为一个示例，如果渲染非常慢，它周围的系统会开发出渲染层的解决方法，如纹理和复合它们，这通常解决了平滑滚动但是创造了其他问题。这项工作重新打开了问题：当渲染真的快速时，系统应该是什么样的？</p><p> One such related topic is immediate mode vs retained mode UI, a longstanding controversy, with passionate defenders on both sides. To be very clear, this renderer will work well with both. But I think there’s a special affinity for retained mode, as I hope to explain briefly.</p><p> 一个这样的相关主题是立即模式与保留模式UI，这是一种长期争议，双方都有激情的防守者。要非常清楚，这两个渲染器将适用于两者。但我认为对保留模式有一个特殊的亲和力，因为我希望简单地解释。</p><p> Very often in UI, the biggest challenge in performance is traversing the entire UI state in order to determine the new appearance. Immediate mode GUI solves this by writing the UI logic in a fast language, so that it reliably comes in under the time budget. But another approach is to minimize the work by only touching the parts of UI state that actually changed. In classical 2D, that often manifests as “damage regions,” so that only a subregion of the screen is repainted. That’s not very effective for scrolling or things like animation of layer opacity, and many people believe that damage regions are obsolete (I disagree, mostly for reasons of power consumption, but that’s a story for another day).</p><p> 通常在UI中，性能中的最大挑战是遍历整个UI状态，以便确定新的外观。立即模式GUI通过以快速语言编写UI逻辑来解决此问题，以便在时间预算下可靠地进入。但另一种方法是通过仅触摸实际改变的UI状态的部分来最小化工作。在古典2D中，通常表现为“损坏区域”，因此只有屏幕的子区域重新绘制。这对滚动或类似于层不透明度的动画，而且许多人认为损坏地区已经过时了（我不同意，大多是出于电力消耗的原因，但这是另一天的故事）。 </p><p> A related approach is to retain parts of the scene graph (also commonly called “display list”), updating only those that have actually changed. Then the renderer redraws the screen based on the updated graph. Updated parameters can include translation (for scrolling) or alpha, so only a tiny amount of data need be uploaded to the GPU from frame to frame.  Flutter is a good modern approach to this, and its “layers” are one of the keys to its performance.</p><p>相关方法是保留场景图的部分（也通常称为“显示列表”），仅更新实际更改的部分。然后渲染器根据更新的图形重绘屏幕。更新的参数可以包括翻译（用于滚动）或alpha，因此只需要从帧到帧上载到GPU的微小数据。颤动是一种良好的现代方法，它的“层”是其性能的关键之一。</p><p> The piet-metal approach is designed to support this approach, by hosting the scene graph on the GPU, so that the process of painting a frame does  not rely on replaying the scene graph data structure resident on the CPU into GPU drawing commands. For simple scenes, this may not matter much, but for very complex visuals the difference might be significant.</p><p> Piet-Metal方法旨在通过托管GPU上的场景图来支持这种方法，使得绘制帧的过程不​​依赖于将驻留在CPU上的场景图数据结构重放到GPU绘图命令。对于简单的场景，这可能并不重要，但对于非常复杂的视觉效果可能是显着的。</p><p>  The week in the woods was extremely rewarding, and I recommend the format. Stones Throw Farm was a great setting for the research retreat.</p><p>  树林里的一周非常有益，我推荐了格式。石头扔农场是研究撤退的伟大环境。</p><p> To be clear, what I have now is a research prototype. It only implements a subset of the imaging model, and only works on relatively recent GPU hardware. But I believe it has some very appealing properties, making it especially useful as the groundwork for next-generation UI.</p><p> 很清楚，我现在拥有的是一个研究原型。它只实现了成像模型的子集，并且仅适用于相对近期的GPU硬件。但我相信它具有一些非常有吸引力的属性，使其特别是作为下一代UI的基础。</p><p> I believe the venerable 2D imaging model has lots of life left in it, as there is compelling evidence (not just my own work) that it can be implemented efficiently on GPU. I did the work largely to inform what to include and exclude in the  piet API - anything that  cannot efficiently be implemented on GPU is off the table. I plan to go forward on the existing piet/druid plans, confident that I can use existing platform-based drawing libraries like Direct2D for now, and that highly performant GPU-based implementations are at least possible.</p><p> 我相信古老的2D成像模型有很多生命，因为它有令人信服的证据（不仅仅是我自己的工作），它可以有效地在GPU上实现。我的工作很大程度上是为了通知在PIET API中包含和排除的内容 - 任何无法在GPU上实现的东西都关闭了桌面。我计划在现有的Piet / DruID计划上前进，相信我现在可以使用像Direct2D这样的基于平台的绘图库，并且至少表现了高度性能的GPU实现。</p><p> This work has benefitted from discussions with many, though of course the mistakes I’ve made are my own. In particular, thanks to Allan MacKinnon and his Spinel work for inspiring me to consider compute for rendering, Patrick Walton for many stimulating discussions, and Brian Merchant (our Google Summer of Code student on this project) for asking provoking questions.</p><p> 这项工作有利于许多讨论，但当然当然我所犯的错误是我自己的。特别是，感谢Allan Mackinnon和他的尖晶石的努力，鼓励我考虑渲染的计算，帕特里克沃尔顿为许多刺激讨论，以及Brian Merchant（我们在这个项目上的代码学生的谷歌夏季），以便提出挑衅性问题。 </p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://raphlinus.github.io/rust/graphics/gpu/2019/05/08/modern-2d.html">https://raphlinus.github.io/rust/graphics/gpu/2019/05/08/modern-2d.html</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/现代/">#现代</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/modern/">#modern</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/gpu/">#gpu</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/分享/">#分享</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy;2012 - 2021 diglog.com </div></div></body></html>