<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Microsoft Open Sources逆决，AI安全风险评估工具预装了可用于逃避和窃取AI型号的算法 Microsoft open sources Counterfit, an AI security risk assessment tool that comes preloaded with algorithms that can be used to evade and steal AI models</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">Microsoft open sources Counterfit, an AI security risk assessment tool that comes preloaded with algorithms that can be used to evade and steal AI models<br/>Microsoft Open Sources逆决，AI安全风险评估工具预装了可用于逃避和窃取AI型号的算法 </h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2021-05-05 21:08:31</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2021/5/9ea2077a8dc7080a59a3698f97256050.jpg"><img src="http://img2.diglog.com/img/2021/5/9ea2077a8dc7080a59a3698f97256050.jpg" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>Microsoft today  open-sourced Counterfit, a tool designed to help developers test the security of AI and machine learning systems. The company says that Counterfit can enable organizations to conduct assessments to ensure that the algorithms used in their businesses are robust, reliable, and trustworthy.</p><p>Microsoft今天开放式逆行，旨在帮助开发人员测试AI和机器学习系统的安全性的工具。该公司表示，逆决可以使组织能够进行评估，以确保其业务中使用的算法是强大的，可靠和值得信赖的。</p><p> AI is being increasingly deployed in regulated industries like health care, finance, and defense. But organizations are lagging behind in their adoption of risk mitigation strategies. A  Microsoft survey found that 25 out of 28 businesses indicated they don’t have the right resources in place to secure their AI systems, and that security professionals are looking for specific guidance in this space.</p><p> AI正在越来越多地部署在保健，金融和防御等政策行业。但组织在采用风险缓解策略时落后于落后。 Microsoft调查发现，25个业务中的25个表示，他们没有正确的资源来保护他们的AI系统，并且安全专业人员正在寻找此空间的具体指导。</p><p>  Microsoft says that Counterfit was born out the company’s need to assess AI systems for vulnerabilities with the goal of proactively securing AI services. The tool started as a corpus of attack scripts written specifically to target AI models and then morphed into an automation product to benchmark multiple systems at scale.</p><p>  微软表示，逆行诞生了公司需要评估AI系统的漏洞，以获得积极保护AI服务的目标。该工具始于专门编写的攻击脚本语料库，然后将AI模型变形为自动化产品，以按比例进行基准多个系统。</p><p> Under the hood, Counterfit is a  command-line utility that provides a layer for adversarial frameworks, preloaded with algorithms that can be used to evade and steal models. Counterfit seeks to make published attacks accessible to the security community while offering an interface from which to build, manage, and launch those attacks on models.</p><p> 在引擎盖下，逆决是一个命令行实用程序，为对抗性框架提供一层，预先加载可用于逃避和窃取模型的算法。逆决寻求向安全社区提供发布的攻击，同时提供从中构建，管理和启动模型的攻击的接口。</p><p> When conducting penetration testing on an AI system with Counterfit, security teams can opt for the default settings, set random parameters, or customize each for broad vulnerability coverage. Organizations with multiple models can use Counterfit’s built-in automation to scan — optionally multiple times in order to create operational baselines.</p><p> 在使用逆决的AI系统上进行穿透测试时，安全团队可以选择默认设置，设置随机参数，或为广泛漏洞覆盖进行自定义。具有多种型号的组织可以使用USTIONFIT内置自动化来扫描 - 可选地多次才能创建运营基线。</p><p> Counterfit also provides logging to record the attacks against a target model. As Microsoft notes, telemetry might drive engineering teams to improve their understanding of a failure mode in a system.</p><p> 逆机还提供日志记录以记录针对目标模型的攻击。随着Microsoft Notes，遥测可能会驱动工程团队，以提高他们对系统中失败模式的理解。</p><p>  Internally, Microsoft says that it uses Counterfit as a part of its AI red team operations and in the AI development phase to catch vulnerabilities before they hit production. And the company says it’s tested Counterfit with several customers, including aerospace giant Airbus, which is developing an AI platform on Azure AI services. “AI is increasingly used in industry; it is vital to look ahead to securing this technology particularly to understand where feature space attacks can be realized in the problem space,” Matilda Rhode, a senior cybersecurity researcher at Airbus, said in a statement.</p><p>  在内部，微软表示，它使用逆端作为其AI红色团队运营的一部分，并在AI开发阶段捕获漏洞，在他们击中生产之前。该公司表示，它与多个客户进行了测试，包括航空航天巨头空中客车，该航空公司正在开发AI澳大利亚州AI服务的AI平台。 “AI越来越多地用于工业;展望保护这项技术是至关重要的，特别是了解在问题空间中可以实现特征空间攻击的地方，“空中客车的高级网络安全研究员Matilda罗德·罗德在陈述中表示。 </p><p> The value of tools like Counterfit is quickly becoming apparent. A  study by Capgemini found that customers and employees will reward organizations that practice  ethical AI with greater loyalty, more business, and even a willingness to advocate for them — and in turn, punish those that don’t. The study suggests that there’s both reputational risk and a direct impact on the bottom line for companies that don’t approach the issue thoughtfully.</p><p>像逆天度这样的工具的价值很快就会变得显而易见。 Capgemini的一项研究发现，客户和员工将奖励练习具有更大忠诚，更多业务，更多业务甚至愿意为他们提倡的道德AI的组织 - 而且惩罚那些没有的忠诚。该研究表明，声誉风险既有声誉风险也是对底线的直接影响，这些公司不会仔细接近问题。</p><p> Basically, consumers want confidence that AI is secure from manipulation. One of the recommendations from Gartner’s  Top 5 Priorities for Managing AI Risk framework, published in January, is that organizations “[a]dopt specific AI security measures against adversarial attacks to ensure resistance and resilience.” The research firm estimates that by 2024, organizations which implement dedicated AI risk management controls will avoid negative AI outcomes twice as often as those that don’t.”</p><p> 基本上，消费者希望信心从操纵中获得安全。 Gartner在1月份发布的AI风险框架的5个优先事项的建议之一是，组织“[a] Dopt特定的AI安全措施，防止对抗攻击，以确保阻力和抵御能力。”研究公司估计，到2024年，实施专门的AI风险管理管制的组织将避免两倍的负面AI成果，因为那些没有。“</p><p> According to a Gartner  report, through 2022, 30% of all AI cyberattacks will leverage training-data poisoning, model theft, or  adversarial samples to attack machine learning-powered systems.</p><p> 根据Gartner报告，到2022年，30％的AI Cyber​​attacks将利用培训 - 数据中毒，模型盗窃或对抗样本来攻击机器学习动力系统。</p><p> Counterfit is a part of Microsoft’s broader push toward explainable, secure, and “fair” AI systems. The company’s attempts at solutions to those and other challenges include  AI bias-detecting tools, an  open adversarial AI framework, internal efforts to reduce  prejudicial errors, AI ethics checklists, and a committee ( Aether) that advises on AI pursuits. Recently, Microsoft debuted  WhiteNoise, a toolkit for differential privacy, as well as  Fairlearn, which aims to assess AI systems’ fairness and mitigate any observed unfairness issues with algorithms.</p><p> 逆决是微软更广泛推动解释，安全和“公平”AI系统的一部分。该公司对这些挑战的解决方案的尝试包括AI偏见检测工具，一个开放的对抗性AI框架，减少偏见错误，AI伦理清单和委员会（Aether）的内部努力，建议A​​I追求。近日，微软首次借鉴了白启，一个用于差异隐私的工具包，以及Fairlearn，旨在评估AI系统的公平性，并减轻任何观察到的算法的不公平问题。</p><p> VentureBeat&#39;s mission is to be a digital town square for technical decision-makers to gain knowledge about transformative technology and transact.Our site delivers essential information on data technologies and strategies to guide you as you lead your organizations. We invite you to become a member of our community, to access: gated thought-leader content and discounted access to our prized events, such as   Transform 2021: Learn More</p><p> VidtureBeat＆＃39; S使命是成为技术决策者的数字城市广场，以获得有关转型技术和Transact的知识。您网站提供有关数据技术和策略的基本信息，以指导您的领导您的组织。我们邀请您成为社区的成员，访问：门控思想领导者内容和对我们奖化事件的折扣访问，如转换2021：了解更多</p><p> Become a member</p><p> 成为会员 </p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://venturebeat.com/2021/05/04/microsoft-open-sources-counterfit-an-ai-security-risk-assessment-tool/">https://venturebeat.com/2021/05/04/microsoft-open-sources-counterfit-an-ai-security-risk-assessment-tool/</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/microsoft/">#microsoft</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/算法/">#算法</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/ai/">#ai</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/分享/">#分享</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy;2012-2021 diglog.com </div></div></body></html>