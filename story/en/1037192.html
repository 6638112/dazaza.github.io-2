<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>运动事件的冷酷现实The cold reality of the Kinesis Incident</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">The cold reality of the Kinesis Incident<br/>运动事件的冷酷现实</h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2020-11-30 05:30:20</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2020/11/14bfb0dfc2dd7e8ef9442b3adafa8838.jpg"><img src="http://img2.diglog.com/img/2020/11/14bfb0dfc2dd7e8ef9442b3adafa8838.jpg" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>This holiday season, give your non-technical friends and family the gift of finally understanding what you do for a living.  The Read Aloud Cloud is suitable for all ages and is 20% off at Amazon right now!</p><p>这个假期，给您的非技术朋友和家人一个礼物，让他们最终了解您的生活。朗读云适用于所有年龄段，并且现在在Amazon享有20％的折扣！</p><p> One of my pet hobbies is collecting examples of complex systems that people spend lots of time making resilient to  independent error, but which are instead brought down by  systematic error that nobody saw coming.</p><p> 我的宠物爱好之一是收集复杂系统的示例，人们花费大量时间来使自己对独立错误产生抵抗力，但这些错误却被没有人看到的系统错误所压倒。</p><p> Systematic error - as opposed to a random, isolated fault - is error that infects and skews every aspect of the system. In a laboratory, it could be a calibration mistake in the equipment itself, making all observations useless.</p><p> 与随机的，孤立的故障相反，系统性错误是会感染并歪曲系统各个方面的错误。在实验室中，这可能是设备本身的校准错误，使所有观察都无用。</p><p> Outside the laboratory, systematic error can mean the difference between life and death, sometimes literally. The hull of the  Titanic comprised sixteen “watertight” compartments that were supposed to seal off a breach, preventing individual failures from spreading. That’s why the shipbuilders bragged that the  Titanic was unsinkable. Instead,  systematic design error let water spill from one compartment to the next. The moment an iceberg compromised one section of the hull, the whole ship was doomed .</p><p> 在实验室之外，系统错误可能意味着生与死之间的差异，有时甚至是字面上的差异。泰坦尼克号的船体包括16个“水密”舱室，这些舱室应能封堵漏洞，防止个别故障扩散。这就是造船厂吹嘘泰坦尼克号不沉的原因。相反，系统设计错误使水从一个隔间溢出到另一个隔间。冰山一撞到船体的一部分时，整个船就注定了。</p><p> Or take election forecasting. In 2016, pretty much every poll predicted a landslide win for Hillary Clinton — a chorus of consensus that seemed safely beyond any mistake in an individual poll’s methodology. But it turned out that pollsters systemically underestimated enthusiasm for Donald Trump in key states — maybe because of shy Trump voters or industry bias, nobody really knows. If they had known, then maybe every poll wouldn’t have made the same mistakes.  But they did. Four years later,  nobody trusts the election modeling industry anymore.</p><p> 或进行选举预测。 2016年，几乎每项民意调查都预示了希拉里·克林顿（Hillary Clinton）的压倒性胜利。但是事实证明，民意测验员系统地低估了关键州对唐纳德·特朗普的热情-也许是由于特朗普选民的害羞或行业偏见，没人真正知道。如果他们知道，那么也许每个民意调查都不会犯同样的错误。但是他们做到了。四年后，没有人再信任选举建模行业了。</p><p> That brings us to Wednesday. Several AWS services in us-east-1 took a daylong Thanksgiving break due to what shall be henceforth known around my house as The Kinesis Incident — which sounds like a novel in an airport bookstore, if Clive Cussler wrote thrillers about ulimit.</p><p> 那把我们带到星期三。 us-east-1中的几项AWS服务因一天的感恩节休息而来，原因是此后在我家附近被称为Kinesis事件-如果Clive Cussler写了关于ulimit的惊悚片，这听起来像是一本机场书店的小说。</p><p> Please read AWS’s  excellent blow-by-blow explanation for the full postmortem, but to sum up quickly: on Wednesday afternoon, AWS rolled out some new capacity to the Kinesis Data Streams control plane, which breached an operating system thread limit; because that part of KDS was not sufficiently architected for high availability, it went down hard and took a long time to come back up; and in the meantime several other AWS services that depend on Kinesis took baths of varying temperature and duration.</p><p> 请阅读AWS全面的死后详尽解释，但请快速总结：在周三下午，AWS向Kinesis Data Streams控制平面推出了一些新功能，这违反了操作系统线程限制；由于KDS的这一部分架构不足以实现高可用性，因此它崩溃了很长时间并且需要很长时间才能恢复。同时，其他几项依赖于Kinesis的AWS服务也进行了不同温度和持续时间的沐浴。</p><p>  Plenty of hot takes have been swirling around AWS Twitter over the long weekend, just as they did after the great S3 outage of 2017. Depending on who you listen to, The Kinesis Incident is …</p><p>在整个漫长的周末中，AWS Twitter上不断涌动着许多热门话题，就像在2017年S3发生严重故障之后一样。根据您听的对象，Kinesis事件是…</p><p> A morality tale about OS configs! (I mean, sure, but that’s not the interesting part of this.)</p><p> 关于操作系统配置的道德故事！ （我是说，当然，但这不是有趣的部分。）</p><p> Yet another argument for multi-cloud! (No it isn’t, multi-cloud at the workload level remains expensive nonsense; please see  the previous Cloud Irregular for an explanation of when multi-cloud makes sense at the  organization level.)</p><p> 多云的另一个论点！ （不是的，在工作负载级别的多云仍然是昂贵的废话；请参阅先前的Cloud Unregular，以获取何时在组织级别使用多云的解释。）</p><p> An argument for building multi-region applications! (This sounds superficially more reasonable, but probably isn’t. Multi-region architectures — and I’ve built a few! — are expensive, have lots of moving parts, and limit your service options almost as much as multi-cloud. Multi-region is multi-cloud’s creepy little brother. Don’t babysit it unless you have to.)</p><p> 建立多区域应用程序的争论！ （从表面上看，这听起来更合理，但可能并非如此。多区域架构-我已经建造了一些！-价格昂贵，有很多活动部件，并且几乎限制了多云的服务选择。区域是多云的令人毛骨悚然的小弟弟。除非必须，否则请不要照看。</p><p> An argument for *AWS’s internal service architectures* being multi-region! (I have no idea how this would work compliance-wise. And I think it would just make everything worse, weirder, and more confusing for everyone.)</p><p> * AWS内部服务架构*是多区域的论点！ （我不知道这将如何在合规性方面发挥作用。我认为这只会使一切变得更糟，更古怪，并使每个人更加困惑。）</p><p> Forget the hot takes. Here’s the cold reality: The Kinesis Incident is not a story of independent, random error. It’s not a one-off event that we can put behind us with a config update or an architectural choice.</p><p> 忘了热门。这是一个冷酷的现实：Kinesis事件不是一个独立的，随机错误的故事。这不是一次性的事件，我们可以通过配置更新或架构选择来抛弃我们。</p><p>   Reading between the lines of the AWS postmortem, Scott Piper has attempted to map out the internal dependency tree of last week’s affected services:</p><p>   在读过AWS验尸报告后，Scott Piper试图绘制出上周受影响服务的内部依赖关系树：</p><p>  The graphic in Scott’s tweet actually understates the problem — for example, no Kinesis also means no AWS IoT, which in turn meant  a bad night for Ben Kehoe and his army of serverless Roombas, not to mention malfunctioning doorbells and ovens and who knows what else.</p><p>Scott的推文中的图形实际上低估了该问题-例如，没有Kinesis也就意味着没有AWS IoT，这反过来对Ben Kehoe和他的无服务器Roombas军来说是一个糟糕的夜晚，更不用说门铃和烤箱故障了，谁知道呢？ 。</p><p> Now, IoT teams understand that their workloads are deeply intertwined with Kinesis streams. But who would have expected a Kinesis malfunction to wipe out AWS Cognito, a critical but seemingly unrelated service? The Cognito-Kinesis integration happens under the hood; the Cognito team apparently uses KDS to analyze API usage patterns. There’s no reason a customer would ever need to know that … until someone has to explain why Kinesis took down Cognito.</p><p> 现在，物联网团队已经了解到，他们的工作负载与Kinesis流紧密地交织在一起。但是谁能想到Kinesis故障会消灭AWS Cognito（一项关键但看似无关的服务）呢？ Cognito-Kinesis集成发生在后台。 Cognito团队显然使用KDS分析API使用模式。客户没有理由永远不需要知道……直到有人必须解释为什么Kinesis拒绝了Cognito。</p><p> But it gets worse. According to the postmortem, the Cognito team actually had some caching in place to guard against Kinesis disappearing; it just didn’t work quite right in practice. So these individual service teams are rolling their own fault-tolerance systems to mitigate unexpected behavior from upstream dependencies that they may not fully understand. What do you want to bet Cognito isn’t the only service whose failsafes aren’t quite perfect?</p><p> 但情况变得更糟。根据验尸报告，Cognito团队实际上有一些缓存可以防止Kinesis的消失。在实践中只是效果不佳。因此，这些单独的服务团队正在滚动他们自己的容错系统，以减轻他们可能无法完全理解的上游依赖性带来的意外行为。您想打赌什么？Cognito并不是唯一一个故障保护功能不够完善的服务吗？</p><p> (This is not a story of random error, this is a story of systematic failure.)</p><p> （这不是一个随机错误的故事，这是一个系统故障的故事。）</p><p>  The edges in AWS’s internal service graph are increasing at a geometric rate as new higher-level services appear, often directly consuming core services from Kinesis, DynamoDB, and so on. Some bricks in this Jenga tower of dependencies will be legible to customers, like IoT’s white-labeling of Kinesis; others will use internal connectors and middleware that nobody sees until the next outage.</p><p>  随着新的更高级别服务的出现，AWS内部服务图中的边缘正以几何级数增长，通常直接使用Kinesis，DynamoDB等的核心服务。客户可以清楚地看到这座叠叠塔中的一些砖块，例如物联网的Kinesis白标；其他人将使用内部连接器和中间件，直到下一次中断，这些人和人才看到。</p><p> Cognito depends on Kinesis. AppSync integrates with Cognito. Future high-level services will no doubt use AppSync under the hood. Fixing one config file, hardening one failure mode, doesn’t shore up the entire tower.</p><p> Cognito取决于Kinesis。 AppSync与Cognito集成。毫无疑问，将来的高级服务将在后台使用AppSync。修复一个配置文件，强化一种故障模式并不能支撑整个塔。</p><p> The only conclusion is that we should expect future Kinesis Incidents, and we should expect them to be progressively bigger in scope and harder to resolve.</p><p> 唯一的结论是，我们应该期待未来的Kinesis事件，并且我们希望它们的范围逐渐扩大，并且难以解决。</p><p> What’s the systematic failure here? Two-pizza teams. “ Two is better than zero.” A “ worse is better” product strategy that prioritizes shipping new features over cross-functional collaboration. These are the principles that helped AWS eat the cloud. They create services highly resilient to independent failures. But it’s not clear that they are a recipe for  systematic resilience across all of AWS. And over time, while errors in core services become less likely, the probability builds that a single error in a core service will have snowballing, Jenga-collapsing implications.</p><p>这是什么系统性故障？两人披萨队。 “二比零好。” “越糟越好”的产品策略优先于交付新功能而不是跨功能协作。这些是帮助AWS吃云的原理。它们创建对独立故障具有高度弹性的服务。但是尚不清楚它们是否构成了整个AWS的系统弹性的秘诀。随着时间的流逝，虽然核心服务中的错误发生的可能性越来越小，但建立核心服务中的单个错误将产生滚雪球般的，叠叠式崩溃的可能性。</p><p> Really, the astonishing thing is that these cascading outages don’t happen twice a week, and that’s a testament to the outstanding engineering discipline at AWS as a whole.</p><p> 确实，令人惊讶的是，这些级联中断每周不会发生两次，这证明了AWS整体上杰出的工程学科。</p><p> But still, as the explosion of new, higher-level AWS services continues (‘tis the season — we’re about to meet a few dozen more at re:Invent!) and that dependency graph becomes more complex, more fragile,  we should only expect cascading failures to increase. It’s inherent in the system.</p><p> 但是，随着新的，更高级别的AWS服务的爆炸式增长（该季节到来了–我们将在re：Invent上再见到几十个），并且依赖图变得更加复杂，更加脆弱，我们应该只期望级联故障会增加。它是系统固有的。</p><p>  AWS’s own postmortem, when it’s not promising more vigilance around OS thread hygiene, does allude to ongoing efforts to “ cellularize” critical services to limit blast radius. I don’t fully understand how that protects against bad assumptions made by dependent services, and I’d be willing to bet that plenty of AWS PMs don’t either. But it’s time to build some trust with customers about exactly what to expect.</p><p>  AWS自己的验尸计划不承诺对OS线程的卫生状况保持更高的警惕，但它暗示了正在进行的努力，即“蜂窝化”关键服务以限制爆炸半径。我不完全了解如何避免依赖服务造成的错误假设，并且我敢打赌大量的AWS PM也不这样做。但是是时候与客户建立对确切期望的信任。</p><p> I’ve  called for AWS to release a full, public audit of their internal dependencies on their own services, as well as their plan to isolate customers from failures of services the customer is not using. Maybe everything’s fine. Maybe the Kinesis Incident was a single chink in the armor, and AWS won’t suffer another outage of this magnitude for years. But right now I don’t see a reason to believe that, and I’m sure I’m not alone.</p><p> 我已经要求AWS对他们对自己的服务的内部依赖性进行全面的公开审核，并制定将客户与未使用的服务失败隔离开来的计划。也许一切都很好。也许Kinesis事件只是装甲中的一个漏洞，而且AWS多年来不会再遭受这种程度的中断。但是，现在我还没有理由相信这一点，而且我确定我并不孤单。</p><p>  On that note, re:Invent starts on Monday! It’s three weeks long! It’s free, it’s virtual, it’s just. so. much. I’m going to try to send out a short executive summary of each day via email at A Cloud Guru. Make sure you follow  the blog over there for lots of analysis and new feature deep dives from me, other AWS Heroes, and even some special AWS service team guests. I’ll probably pop up in a few other places as well.</p><p>  关于这一点，re：Invent从星期一开始！已经三个星期了！它是免费的，它是虚拟的，它只是。所以。许多。我将尝试在A Cloud Guru通过电子邮件发送每天的简短执行摘要。确保您关注那里的博客，以获取我，其他AWS Heroes甚至某些特殊的AWS服务团队来宾的大量分析和新功能的深入介绍。我可能还会在其他几个地方弹出。</p><p> Irish Tech News has a nice review out of   The Read Aloud Cloud. “For the most part, the rhyming works”, they concede. I’ll take it!</p><p> 爱尔兰科技新闻对The Read Aloud Cloud进行了很好的评论。他们承认：“在大多数情况下，押韵是有效的”。我要买它！</p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/运动/">#运动</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/reality/">#reality</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/kinesis/">#kinesis</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/分享/">#分享</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy; 2020 diglog.com </div></div></body></html>