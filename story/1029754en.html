<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>学习排序算法的情况</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">学习排序算法的情况</h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2020-10-19 17:18:16</div><div class="page_narrow text-break page_content"><p>We’ve watched  machine learning thoroughly pervade the web giants, make  serious headway in large consumer companies, and begin its  push into the traditional enterprise. ML, then, is rapidly becoming an integral part of how we build applications of all shapes and sizes. But what about systems software? It’s earlier days there, but ‘The case for learned index structures’( Part 1  Part 2),  SageDB and others are showing the way.</p><p>我们已经看到机器学习彻底渗透到网络巨头，在大型消费者公司取得了重大进展，并开始向传统企业推进。因此，ML正迅速成为我们构建各种形状和大小的应用程序不可或缺的一部分。但是系统软件呢？这还是早期的事情，但是“学习索引结构的案例”(第1部分，第2部分)、SageDB和其他公司正在为我们指明方向。</p><p> Today’s paper choice builds on the work done in SageDB, and focuses on a classic computer science problem: sorting. On a 1 billion item dataset,  Learned Sort outperforms the next best competitor, RadixSort, by a factor of 1.49x. What really blew me away, is that this result  includes the time taken to train the model used!</p><p>今天的论文选择建立在SageDB所做工作的基础上，并集中在一个经典的计算机科学问题上：排序。在10亿个项目的数据集上，Learned Sort的性能比第二好的竞争对手RadixSort高出1.49倍。真正让我大吃一惊的是，这个结果包括训练使用的模型所花费的时间！</p><p>  Suppose you had a model that given a data item from a list, could predict its position in a sorted version of that list. 0.239806? That’s going to be at position 287! If the model had 100% accuracy, it would give us a completed sort just by running over the dataset and putting each item in its predicted position. There’s a problem though. A model with 100% accuracy would essentially have to see every item in the full dataset and memorise its position – there’s no way training and then using such a model can be faster than just sorting, as sorting is a part of its training! But maybe we can sample a subset of the data and get a model that is a useful approximation, by learning an approximation to the CDF (cumulative distribution function).</p><p>假设您有一个模型，该模型给定一个列表中的数据项，可以预测它在该列表的排序版本中的位置。0.239806？它将在287号位置！如果模型有100%的准确率，那么只需遍历数据集并将每个项目放到其预测位置，就可以给我们一个完整的排序。不过，这有个问题。一个100%准确率的模型基本上必须看到整个数据集中的每一项并记住它的位置-没有办法训练，然后使用这样的模型比仅仅排序更快，因为排序是其训练的一部分！但也许我们可以通过学习对CDF(累积分布函数)的近似，来采样数据的子集，并得到一个有用的近似模型。</p><p> If we can build a useful enough version of such a model quickly (we can, we’ll discuss how later), then we can make a fast sort by first scanning the list and putting each item into its approximate position using the model’s predictions, and then using a sorting algorithm that works well with nearly-sorted arrays (Insertion Sort) to turn the almost-sorted list into a fully sorted list. This is the essence of Learned Sort.</p><p>如果我们可以快速构建这样一个模型的足够有用的版本(我们可以，我们稍后将讨论如何构建)，那么我们可以通过以下方式进行快速排序：首先扫描列表，使用模型的预测将每一项放到其近似位置，然后使用与接近排序的数组配合良好的排序算法(插入排序)将几乎排序的列表转换为完全排序的列表。这就是学问分类的本质。</p><p>  The base version of Learned Sort is an  out-of-place sort, meaning that it copies the sorted elements into a new destination array. It uses the model to predict the slot in the destination array for each item in the list. What should happen though if the model predicts (for example) slot 287, but there’s already an entry in the destination array in that slot? This is a  collision. The candidate solutions are:</p><p>学习排序的基本版本是位置不正确的排序，这意味着它将排序的元素复制到新的目标数组中。它使用该模型为列表中的每一项预测目标数组中的槽。但是，如果模型预测(例如)插槽287，但该插槽的目标数组中已经有一个条目，该怎么办呢？这是一次碰撞。候选解决方案包括：</p><p> A  Spill bucket: if the destination slot is already full, just put the item into a special spill bucket. At the end of the pass, sort and merge the spill bucket with the destination array.</p><p>溢出桶：如果目的地槽已经满了，只需将物品放入一个特殊的溢出桶中即可。在传递结束时，将溢出桶与目标数组排序并合并。</p><p> The authors experimented with all three, and found that the spill bucket approach worked best for them.</p><p>作者对这三种方法都进行了实验，发现溢油桶方法对他们最有效。</p><p>  The resulting performance depends on the quality of the model predictions, a higher quality model leads to fewer collisions, and fewer out-of-order items to be patched in the final Insertion Sort pass. Since we’re punting on the details of the model for the moment, an interesting question is what happens when you give this learned sort a perfect, zero-overhead oracle as the model? Say we want to sort all the numbers from zero to one billion. A perfect zero-overhead oracle can be built by just using the item value as the position prediction. 1456? That will go in position 1456…</p><p>最终的性能取决于模型预测的质量，更高质量的模型导致更少的冲突，以及在最终插入排序过程中要修补的无序项目更少。由于我们目前只讨论模型的细节，一个有趣的问题是，当您为这种学习过的类型提供一个完美的、零开销的先知作为模型时会发生什么？假设我们要对从0到10亿的所有数字进行排序。只需将项值作为位置预测，就可以建立一个完美的零开销预言书。1456？它将放在1456年…的位置</p><p> And what did happen when the authors tried to sort the numbers using this perfect zero-overhead oracle?</p><p>当作者试图使用这个完美的零开销神谕对数字进行排序时，发生了什么？</p><p> To our astonishment, in this micro-experiment we observed that the time take to distributed the keys into their final sorted position, despite a zero-overhead oracle function, took 38.7 sec and RadixSort took 37.5 sec.</p><p>令我们惊讶的是，在这个微型实验中，我们观察到，尽管使用了零开销的Oracle函数，但将密钥分发到其最终排序位置所需的时间为38.7秒，RadixSort为37.5秒。</p><p> Why? If it’s high performance you’re after, you can’t ignore mechanical sympathy. Radix Sort is carefully designed to make effective use of the L2 cache and sequential memory accesses, whereas Learned Sort is making random accesses all over the destination array.</p><p>为什么？如果你追求的是高性能，你不能忽视机械的同情。基数排序经过精心设计，可有效利用二级缓存和顺序内存访问，而学习排序则在目标数组中进行随机访问。</p><p>  How can learned sort be adapted to make it cache-efficient? The solution is to change the first pass of Learned Sort into a cascading Bucket Sort. Instead of determining the final position in the destination array, the model prediction is used to ascertain which bucket (or bin) the element should go into.</p><p>如何调整学习排序以使其缓存效率更高？解决方案是将学习排序的第一遍更改为级联桶排序。不是确定目标数组中的最终位置，而是使用模型预测来确定元素应该进入哪个桶(或桶)。</p><p> Let $f$ be the number of buckets ($f$ for fan-out). The first phase of learned sort is a cascading Bucket Sort. The initial pass uses the model predictions to place input elements into one of $f$ ordered buckets. Then each of these buckets is partitioned into a further $f$ buckets, and so on recursively until a threshold bucket size $t$ is reached. If at any stage a model prediction places in a item in a bucket that is already full, this item is just moved to a spill bucket instead.</p><p>假设$f$是存储桶的数量($f$用于扇出)。学习排序的第一阶段是级联桶排序。第一次传递使用模型预测将输入元素放入$f$有序存储桶中的一个。然后，这些存储桶中的每个都被分成另外的$f$存储桶，依此类推，直到达到阈值存储桶大小$t$。如果在任何阶段，模型预测放置在已经满的桶中的项中，则该项只是被移到溢出桶中。</p><p> Once we’re down to buckets of size $t$, each of these is approximately sorted using the model predictions to place elements at an exact predicted position within the bucket.</p><p>一旦我们到达大小为$t$的存储桶，就会使用模型预测对每个存储桶进行大致排序，以便将元素放置在存储桶中准确的预测位置。</p><p> Concatenate the sorted buckets in order (some may have less than $t$ elements in them), and use Insertion Sort to patch up any discrepancies in ordering.</p><p>按顺序连接已排序的存储桶(有些存储桶中的元素可能少于$t$)，并使用插入排序来修补排序中的任何差异。</p><p> The secret to good performance with Learned Sort is choosing $f$ and $t$ so that at least one cache-line per bucket fits into the cache, making memory access patterns more sequential. The trade-off in setting $f$ is as follows: larger $f$ allows us to make more use of the predictive power of the model at each step, smaller $f$ increases the chances that we can append to a given bucket without causing a cache miss. For best performance, $f$ should be set so that all the hot memory locations fit in the L2 cache. For the evaluation set-up, this meant $f$ was around 1,000.</p><p>使用学习排序获得良好性能的秘诀是选择$f$和$t$，这样每个存储桶中至少有一个缓存线可以放入缓存中，从而使内存访问模式更加顺序化。设置$f$的权衡如下：较大的$f$允许我们在每一步更多地利用模型的预测能力，较小的$f$增加了我们可以在不导致缓存未命中的情况下附加到给定存储桶的机会。为获得最佳性能，应设置$f$，以便所有热内存位置都能放入二级缓存中。对于评估设置来说，这意味着$f$大约是1,000美元。</p><p> The parameter $t$ influences the number of elements likely to end up in the spill bucket. Empirically the authors found that maximum performance is obtained when fewer than 5% of the elements end up in the spill bucket, which equates to a $t$ of around 100 for large datasets (see §3.1.2).</p><p>参数$t$影响可能在溢出桶中结束的元素的数量。经验性地，作者发现，当少于5%的元素最终出现在溢出桶中时，获得最大性能，这相当于对于大型数据集来说，$t$约为100(见§3.1.2)。</p><p> With these changes in place, if the number of elements to sort is close to the key domain size (e.g. sorting $2^{32}$ elements with 32-bit keys), then Learned Sort performs almost identically to Radix Sort. But when the number of elements is much smaller than the key domain size, Learne Sort can significantly outperform Radix Sort.</p><p>有了这些更改后，如果要排序的元素数量接近键域大小(例如，使用32位键对$2^{32}$元素进行排序)，则学习排序的执行方式与基数排序几乎相同。但当元素数远小于键域大小时，Learne排序的性能明显优于基数排序。</p><p>  All of this depends of course on being able to train a sufficiently accurate model that can make sufficiently fast predictions, so that the total runtime for Learned Sort,  including the training time still beats Radix Sort. For this, the authors use the Recursive Model Index (RMI) architecture as first introduced in ‘ The case for learned index structures‘. In brief, RMI uses layers of simple linear models arranged in a hierarchy a bit like a mixture of experts.</p><p>当然，所有这一切都依赖于能够训练出足够精确的模型，该模型可以做出足够快的预测，以便学习排序的总运行时间(包括训练时间)仍然胜过基数排序。为此，作者使用了递归模型索引(Recursive Model Index，RMI)体系结构，如“学习索引结构的情况”中首次介绍的那样。简而言之，RMI使用层次分明的简单线性模型，有点像专家的混合体。</p><p> During inference, each layer of the model takes the key as an input and linearly transforms it to obtain a value, which is used as an index to pick a model in the next layer.</p><p>在推理过程中，模型的每一层都将关键字作为输入，并对其进行线性变换以获得一个值，该值用作选择下一层模型的索引。</p><p>  The main innovation the authors introduce here is the use of linear spline fitting for training (as opposed to e.g. linear regression with an MSE loss function). Spline fitting is cheaper to compute and gives better monotonicity (reducing the time spent in the Insertion Sort phase). Each individual spline model fits worse than its closed-form linear regression counterpart, but the hierarchy compensates. Linear splines result in 2.7x faster training, and up to 35% fewer key swaps during Insertion Sort.</p><p>作者在这里介绍的主要创新是使用线性样条拟合进行训练(而不是使用MSE损失函数的线性回归)。样条曲线拟合的计算成本更低，单调性更好(减少了插入排序阶段所花费的时间)。每个单独的样条线模型比其闭合形式的线性回归模型拟合得更差，但层次会进行补偿。线性样条的训练速度提高了2.7倍，在插入排序过程中最多减少了35%的键交换。</p><p>  On synthetic datasets containing double-precision keys following a standard normal distribution, the authors compared Learned Sort to a variety of cache-optimized and highly tuned C++ implementations of alternative sorting algorithms, presenting the most competitive alternatives in their results. The following chart shows sorting rates over input dataset sizes varying from one million to one billion items</p><p>在包含服从标准正态分布的双精度键的合成数据集上，作者将学习的排序与各种缓存优化和高度调优的替代排序算法的C++实现进行了比较，在结果中呈现了最具竞争力的替代算法。下图显示了输入数据集大小(从100万到10亿个项目)的排序率。</p><p>  Learned Sort outperforms the alternative at all sizes, but the advantage is most significant when the data no longer fits into the L3 cache – an average of 30% higher throughput than the next best algorithm.</p><p>学习排序在所有大小上都优于备选排序，但当数据不再适合L3缓存时，优势最为显著-平均吞吐量比次优算法高30%。</p><p> The results show that our approach yields an average 3.38x performance improvement over C++ STL sort, which is an optimized Quick- sort hybrid, 1.49x improvement over sequential Radix Sort, and 5.54x improvement over a C++ implementation of Tim- sort, which is the default sorting function for Java and Python.</p><p>结果表明，与优化的快速排序混合算法C++STL Sort相比，我们的方法平均提高了3.38倍的性能，比顺序基数排序提高了1.49倍，比Java和Python的默认排序函数Tim-Sort的C++实现提高了5.54倍。</p><p> Learned Sort’s advantage holds over real datasets as well (§6.1 for datasets included in the test), and for different element types:</p><p>与真实数据集相比，学习排序的优势同样存在(§6.1适用于测试中包含的数据集)，并且适用于不同的元素类型：</p><p>  [Learned Sort] results in significant performance improvements as compared to the most competitive and widely used sorting algorithms, and marks an important step into building ML-enhanced algorithms and data structures.</p><p>与竞争最激烈、使用最广泛的排序算法相比，[学习排序]带来了显著的性能改进，并标志着在构建ML增强的算法和数据结构方面迈出了重要的一步。</p><p>  The paper also describes several extensions to Learned Sort including sorting in-place, sorting on other key types (strings initially), and improving performance for datasets with many duplicate items.</p><p>本文还描述了学习排序的几个扩展，包括就地排序、对其他键类型(初始为字符串)进行排序，以及提高包含许多重复项的数据集的性能。</p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://blog.acolyer.org/2020/10/19/the-case-for-a-learned-sorting-algorithm/">https://blog.acolyer.org/2020/10/19/the-case-for-a-learned-sorting-algorithm/</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/算法/">#算法</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/排序/">#排序</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/learned/">#learned</a></button></div></div><div class="shadow p-3 mb-5 bg-white rounded clearfix"><div class="container"><div class="row"><div class="col-sm"><div><a target="_blank" href="/story/1029675.html"><img src="http://img2.diglog.com/img/2020/10/thumb_ecc9d9527948101d4aea4b96b256094d.jpg" class="img-fluid" onerror="this.style.display='none'"></a></div><div class="item_title"><a target="_blank" href="/story/1029675.html">一种新的人工智能算法快速准确地预测材料性能</a></div><span class="my_story_list_date">2020-10-19 6:31</span></div><div class="col-sm"><div><a target="_blank" href="/story/1029653.html"><img src="http://img2.diglog.com/img/2020/10/thumb_f6147cc989cdb4ae0205fc85e0d093b9.png" class="img-fluid" onerror="this.style.display='none'"></a></div><div class="item_title"><a target="_blank" href="/story/1029653.html">人类决策的计算机科学</a></div><span class="my_story_list_date">2020-10-19 3:15</span></div><div class="col-sm"><div><a target="_blank" href="/story/1029544.html"><img src="http://img2.diglog.com/img/2020/10/thumb_df0d842f1a580058be3af72d247653bf.png" class="img-fluid" onerror="this.style.display='none'"></a></div><div class="item_title"><a target="_blank" href="/story/1029544.html">算法和共识协议</a></div><span class="my_story_list_date">2020-10-18 9:33</span></div><div class="col-sm"><div><a target="_blank" href="/story/1029242.html"><img src="http://img2.diglog.com/img/2020/10/thumb_99e735e8cee777344144cdc8c2da0b76.jpg" class="img-fluid" onerror="this.style.display='none'"></a></div><div class="item_title"><a target="_blank" href="/story/1029242.html">在英国的调查中，Instagram表示，它将促使有影响力的人披露他们是否收到激励，改进检测算法，并报告不当行为</a></div><span class="my_story_list_date">2020-10-16 21:44</span></div></div></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/美国/">#美国</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/谷歌/">#谷歌</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/linux/">#linux</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/程序/">#程序</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy; 2020 diglog.com </div></div></body></html>