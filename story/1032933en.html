<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Scipio：适用于Rust和Linux的每核线程机箱</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">Scipio：适用于Rust和Linux的每核线程机箱</h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2020-11-03 14:45:35</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2020/11/0803f67b2dea838dffa8a2a38c7afff6.png"><img src="http://img2.diglog.com/img/2020/11/0803f67b2dea838dffa8a2a38c7afff6.png" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>When it comes to reducing cloud costs, optimizing bottlenecks in your code can only take you so far. It may be time to rethink your architecture. Perhaps you’re looking for a new architecture that takes into account the capabilities that modern hardware and software make available. One such architecture is called “thread-per-core”. Research recently demonstrated that a thread-per-core architecture can  improve tail latencies of applications by up to 71%. That sounds fantastic, but the machine efficiency gains of thread-per-core can easily be negated by the loss of developer productivity when your application developers have to adjust to a completely new way of doing things and deal with a set of arcane challenges that are specific to this particular model.</p><p>在降低云成本方面，优化代码中的瓶颈只能做到这一点。可能是时候重新考虑您的体系结构了。也许您正在寻找一种考虑到现代硬件和软件提供的功能的新体系结构。一种这样的体系结构被称为“每核线程”。最近的研究表明，每核线程架构可以将应用程序的尾部延迟提高高达71%。这听起来很棒，但是当您的应用程序开发人员必须调整到一种全新的工作方式并处理一组特定于此特定模型的神秘挑战时，开发人员生产力的损失很容易抵消每核线程的机器效率收益。</p><p> Datadog is not immune to those problems. We run a variety of datastores at scale, which ingest metrics at a very high throughput. And we, too, were starting to see how some of our components’ existing architecture was beginning to show limitations. Metrics data, with its very high distribution in space, looks like a prime candidate for a thread-per-core architecture—but we were concerned about keeping the effort manageable.</p><p>Datadog也不能幸免于这些问题。我们大规模运行各种数据存储区，这些数据存储区以非常高的吞吐量接收指标。我们也开始看到我们的一些组件的现有架构开始显示出局限性。度量数据在空间上的分布性非常高，看起来像是每核线程架构的主要候选者-但我们关心的是保持工作的可管理性。</p><p> This article will explore the thread-per-core model with its advantages and challenges, and introduce  Scipio (you can also find it on  crates.io), our solution to this problem. Scipio allows Rust developers to write thread-per-core applications in an easy and manageable way.</p><p>本文将探讨每核线程模型及其优势和挑战，并介绍我们针对此问题的解决方案Scipio(您也可以在crates.io上找到它)。Scipio允许Rust开发人员以一种简单和可管理的方式编写按内核线程的应用程序。</p><p>  We know that thread-per-core can deliver significant efficiency gains. But what is it? In simple terms, any moderately complex application has many tasks that it needs to perform: it may need to read data from a database, feed that data through a machine learning model, and then pass that result along the pipeline. Some of those tasks are naturally sequential, but many can be done in parallel. And since modern hardware keeps increasing the number of cores available for applications, it is important to efficiently use them to achieve good performance numbers.</p><p>我们知道，每核线程可以带来显著的效率提升。但这是什么呢？简而言之，任何中等复杂的应用程序都有许多需要执行的任务：它可能需要从数据库读取数据，通过机器学习模型提供数据，然后沿管道传递结果。其中一些任务自然是连续的，但许多任务可以并行完成。由于现代硬件不断增加可用于应用程序的核心数量，因此有效地使用它们以实现良好的性能数字非常重要。</p><p> The simplest and most time-tested way of doing that is by employing threads: for each of its internal tasks, the application may use a different thread. If a thread has available work to do, it will do it; otherwise, it will go to sleep and allow the next one to run.</p><p>要做到这一点，最简单且经过最多时间考验的方法是使用线程：对于每个内部任务，应用程序可能使用不同的线程。如果一个线程有可用的工作要做，它就会去做；否则，它将进入休眠状态，并允许下一个线程运行。</p><p>  When multiple threads need to manipulate the same data, they need to acquire locks to guarantee that just one of these threads will make progress at a time. Locks are notoriously expensive, not only because the locking operation itself is expensive, but also because they increase the time the application is doing nothing but waiting.</p><p>当多个线程需要操作相同的数据时，它们需要获取锁以保证每次只有一个线程取得进展。锁是出了名的昂贵，不仅因为锁定操作本身很昂贵，而且还因为它们增加了应用程序除了等待之外什么都不做的时间。</p><p> Every time a thread needs to give way to another thread, there is a context switch. Context switches are expensive, costing around five microseconds. That doesn’t sound expensive, but if we take into account that famed Linux Developer Jens Axboe just  recently published results for his new io_uring kernel infrastructure with Storage I/O times below four microseconds, that means that we are now at a point where a context switch between threads is more expensive than an I/O operation!</p><p>每次一个线程需要让路给另一个线程时，都会进行上下文切换。上下文切换非常昂贵，成本约为5微秒。这听起来并不昂贵，但是如果我们考虑到著名的Linux开发人员Jens Axboe最近发布了他的新IO内核基础设施的结果，其存储I/O时间不到4微秒，这意味着我们现在处于线程之间的上下文切换比I/O操作更昂贵的时刻！</p><p> Not all threaded programming needs to be  blocking: recently, languages and frameworks like Go, Node.js, and many others brought asynchronous programming into full force. Even C++ has futures and more recently  coroutines as part of its standard, and so does Rust, our star of the day.</p><p>并不是所有的线程编程都需要阻塞：最近，Go、Node.js等语言和框架充分发挥了异步编程的作用。甚至连C++都有期货和最近的协程作为其标准的一部分，我们今天的明星Rust也是如此。</p><p> Asynchronous programming is a step in the right direction, allowing programmers to check for work instead of blocking waiting for work. But asynchronous support for those languages often still depends on thread pools for operations like file I/O, and on separate tasks inside the application in their own threads.</p><p>异步编程是朝着正确方向迈出的一步，它允许程序员检查工作，而不是阻塞等待工作。但是对这些语言的异步支持通常仍然依赖于文件I/O等操作的线程池，以及应用程序内部各自线程中的单独任务。</p><p> Thread-per-core programming eliminates threads from the picture altogether. Each core, or CPU, runs a single thread, and often (although not necessarily), each of these threads is pinned to a specific CPU. As the Operating System Scheduler cannot move these threads around, and there is never another thread in that same CPU, there are no context switches.</p><p>每核线程编程完全消除了画面中的线程。每个内核或CPU都运行一个线程，并且通常(尽管不一定)，这些线程中的每个线程都固定在一个特定的CPU上。由于操作系统调度程序不能移动这些线程，并且同一CPU中永远不会有另一个线程，因此不存在上下文切换。</p><p> There are still context switches coming from hardware interrupts, and other helper tasks, like agents, that may share the machine. For maximum performance, operators can configure the operating system so that some CPUs are not given to the application and are instead dedicated to those tasks.</p><p>仍然有来自硬件中断的上下文切换，以及可能共享机器的其他助手任务(如代理)。为了获得最高性能，操作员可以配置操作系统，使某些CPU不会分配给应用程序，而是专用于这些任务。</p><p>  To take advantage of thread-per-core, developers should employ  sharding: each of the threads in the thread-per-core application becomes responsible for a subset of the data. For example, it could be that each thread will read from a different Kafka partition, or that each thread is responsible for a subset of the keys in a database. Anything is possible, so long as two threads never share the responsibility of handling a particular request. As scalability concerns become the norm rather than the exception, sharding is usually already present in modern applications in one form or another: thread-per-core, in this case, becomes the cherry on top.</p><p>要利用单核线程的优势，开发人员应该使用分片：单核线程应用程序中的每个线程负责数据的一个子集。例如，可能是每个线程将从不同的Kafka分区读取，或者每个线程负责数据库中键的子集。只要两个线程从不分担处理特定请求的责任，任何事情都是可能的。随着对可伸缩性的关注成为标准而不是例外，分片通常已经以这样或那样的形式出现在现代应用程序中：在这种情况下，每个核心的线程成为最重要的樱桃。</p><p> Each asynchronous callback, now assigned unequivocally to a single thread, also runs to completion: since there are no other threads, nobody can preempt the running request: it either finishes or explicitly and cooperatively yields.</p><p>现在明确分配给单个线程的每个异步回调也会运行到完成：因为没有其他线程，所以没有人可以抢占正在运行的请求：它要么完成，要么显式地和协作地产生结果。</p><p> The biggest advantage of this model is that locks are  never necessary. Think about it: if there is a single thread of execution, two things can’t be happening (for that request) at the same time.</p><p>这种模式最大的优点是永远不需要锁。想想看：如果只有一个执行线程，那么(对于该请求)不可能同时发生两件事。</p><p> Take, as an example, adding an element to a cache. In a simple threaded environment, updates to the cache can be happening from multiple threads, so one needs to obtain a lock like we see below:</p><p>以向缓存添加元素为例。在简单的线程化环境中，缓存更新可以从多个线程进行，因此需要获得如下所示的锁：</p><p>  By itself, sharding already presents advantages: by splitting the big cache into smaller parts, we can reduce lock contention. Now it is possible to access Key 1 and Key 3 at the same time, and each shard will have its own lock. But because each thread can still be removed from the CPU by the operating system, and the new thread that takes its place can access Key 4—which lives in the same shard as Key 3—there is still a need to hold a lock to coordinate updates.</p><p>就其本身而言，分片已经带来了优势：通过将大缓存拆分成较小的部分，我们可以减少锁争用。现在可以同时访问Key 1和Key 3，每个分片都有自己的锁。但是，因为操作系统仍然可以将每个线程从CPU中移除，并且取代它的新线程可以访问与密钥3位于同一碎片中的密钥4，所以仍然需要持有一个锁来协调更新。</p><p>  The thread-per-core design takes this one step further: we know that updates to Key 3 and Key 4 are serialized. They have to be! If they run in the same thread, then we are either operating on Key 3 or Key 4, never both. So long as we finish the update before declaring the task complete, the locks are gone. As we can see in the figure below, all possible update tasks for each of the cache shards are naturally serialized, and only one (in purple) runs at a time. So as long as it finishes its update before leaving the thread, locks are not necessary.</p><p>每核线程设计更进一步：我们知道对键3和键4的更新是序列化的。必须是这样的！如果它们在同一线程中运行，则我们要么在键3上操作，要么在键4上操作，而不是同时在这两个键上操作。只要我们在宣布任务完成之前完成更新，锁就会消失。正如我们在下图中看到的，每个缓存碎片的所有可能的更新任务都是自然序列化的，并且一次只运行一个(紫色)。因此，只要它在离开线程之前完成更新，就不需要锁。</p><p>   I wish! Thread-per-core has been around for a while. As a matter of fact, for many years before I joined Datadog, I worked in a thread-per-core framework for C++ called  Seastar, the engine that is behind the  ScyllaDB NoSQL database. ScyllaDB managed to leverage the thread-per-core model to provide more efficient implementations of existing databases like Apache Cassandra, so I knew that the model would work for our datastores too while keeping the complexity manageable.</p><p>我希望如此！每核线程数已经存在一段时间了。事实上，在我加入Datadog之前的许多年里，我一直在一个名为Seastar的C++每核线程框架中工作，Seastar是ScyllaDB NoSQL数据库背后的引擎。ScyllaDB设法利用每核线程模型来提供Apache Cassandra等现有数据库的更高效实现，因此我知道该模型也适用于我们的数据存储，同时保持复杂性可控。</p><p> However, it is not my intention to go into a language flamewar here. We had reasons not to pick C++ for this particular problem and chose Rust. The next step was to enhance the Rust ecosystem so that we could have a similar tool. If you are curious to read more about my take on how C++ and Rust compares for this particular task, you can check  my writeup on the subject.</p><p>然而，我并不打算在这里讨论语言火箭筒。对于这个特定的问题，我们有理由不选择C++，而选择了Rust。下一步是加强铁锈生态系统，这样我们就可以有一个类似的工具。如果您想了解更多关于我对C++和Rust在这一特定任务中的比较情况的看法，您可以查看我关于这个主题的文章。</p><p>  Consider the example of an  LSM tree, a data structure commonly used in modern databases. Data sits in a memory area for a while and is then written to immutable files. There is sometimes a need to combine those files together to prevent reads from becoming too expensive.</p><p>以LSM树为例，它是现代数据库中常用的一种数据结构。数据在内存区域停留一段时间，然后写入不可变文件。有时需要将这些文件组合在一起，以防止读取变得过于昂贵。</p><p> Some of those operations can be quite expensive and long-lived—which is why, traditionally, threads are employed. By using threads, the application can count on the operating system to preempt long-lived tasks and make sure important tasks are not starved. And all the locking is just considered the fair price to pay.</p><p>其中一些操作可能相当昂贵且寿命很长-这就是传统上使用线程的原因。通过使用线程，应用程序可以依靠操作系统抢占长时间的任务，并确保重要任务不会匮乏。所有的锁定都被认为是要付出的公平代价。</p><p> But how does that work in a thread-per-core application? Scipio allows the application to create different queues of execution:</p><p>但是，这在每个核心的线程应用程序中是如何工作的呢？Scipio允许应用程序创建不同的执行队列：</p><p>  In the example above, two queues are present. Tasks, when created, can be spawned in any one of them. Aside from its name, we can specify two things about each class:</p><p>在上面的示例中，存在两个队列。创建任务时，可以在其中的任何一个中派生任务。除了名称之外，我们还可以为每个类指定两件事：</p><p> Its latency requirements: Scipio behaves differently in the presence of  latency sensitive tasks, prioritizing their I/O operations.</p><p>其延迟要求：Scipio在存在延迟敏感型任务时的行为有所不同，对它们的I/O操作进行优先排序。</p><p> Its shares: in the example above, both classes have equal shares. Scipio has its own internal scheduler, which selects which task queue to run and provides each with time proportional to its shares. A task queue with twice as many shares as another will, over time, run for twice as long. In this example, they should both use 50% of the system’s resources as they have an equal number of shares.</p><p>其份额：在上面的示例中，两个类别的份额相等。Scipio有自己的内部调度器，它选择要运行的任务队列，并为每个任务队列提供与其份额成比例的时间。共享数量是另一个任务队列的两倍的任务队列，随着时间的推移，其运行时间将是另一个任务队列的两倍。在本例中，它们都应该使用50%的系统资源，因为它们拥有相同数量的共享。</p><p>  Linux dominates modern cloud infrastructure. And Linux has recently seen a revolution in its I/O capabilities driven by a new asynchronous API called io_uring. I have written at length about its capabilities  in the past. Io_uring is capable of not only processing file I/O, but also network sockets, timers, and many other events over a single common API.</p><p>Linux在现代云基础设施中占据主导地位。Linux最近在名为io_uring的新异步API的推动下，在其I/O能力方面迎来了一场革命。我过去曾详细地写过关于它的能力的文章。IO_INGING不仅能够处理文件I/O，还能够在单个通用API上处理网络套接字、计时器和许多其他事件。</p><p> By leveraging io_uring from its inception, Scipio can take a fresh look at how I/O is supposed to look like in Rust. Let’s dive deeper in the architecture.</p><p>通过从一开始就利用io_uring，Scipio可以重新审视Rust中的I/O应该是什么样子。让我们更深入地研究一下架构。</p><p> Usually, a normal threaded application registers a single io_uring for the entire application, which can create contention when adding or completing requests. This is the approach taken by other Rust io_uring crates like  ringbahn and  rio (Tokio, as of this writing, employs normal threads pools for file I/O).</p><p>通常，普通线程化应用程序为整个应用程序注册单个IO，这可能会在添加或完成请求时引起争用。这是Ringbahn和Rio等其他Rust IO板条箱所采用的方法(在撰写本文时，Tokio使用普通线程池进行文件I/O)。</p><p> For each thread of execution, Scipio registers its own set of independent rings that can be operated locklessly. Sets? Yes! Each thread operates with not one, but three rings, each playing a different role.</p><p>对于每个执行线程，Scipio注册它自己的一组独立的环，这些环可以无锁操作。套装？是!。每个线程使用的不是一个环，而是三个环，每个环扮演不同的角色。</p><p>  A normal request, like opening or closing a file, sending or receiving data from a socket, will go on either the  Main or  Latency rings, depending on its latency needs.</p><p>一个正常的请求，如打开或关闭文件，从套接字发送或接收数据，将根据其延迟需求，在主或延迟环上进行。</p><p> When those requests are ready, they post into io_uring’s completion ring and Scipio can consume them. Due to io_uring’s architecture, there is not even a need to issue a system call. The events are present in a shared memory area between Linux and the application and managed by a ring buffer.</p><p>当这些请求准备就绪时，它们将发送到io_uring的完成环中，Scipio可以使用它们。由于io_uring的体系结构，甚至不需要发出系统调用。这些事件存在于Linux和应用程序之间的共享内存区域中，并由环形缓冲区管理。</p><p> What is the difference between those two rings? By its nature, the thread-per-core model is cooperative when it comes to scheduling: if tasks could be yanked from the CPU without noticing, we wouldn’t be able to employ lock-free programming. So they have to voluntarily yield control whenever they have run for too long.</p><p>这两个戒指有什么不同？从本质上讲，每核线程模型在调度方面是协作的：如果任务可以在没有察觉的情况下从CPU中拖出，我们就不能使用无锁编程。因此，每当他们运行太长时间时，他们都必须自愿放弃控制权。</p><p> How long is too long? A task that is going to do some long-lived operation (like a loop of unknown size), should call a Scipio function called  yield_if_needed(). Here is an example:</p><p>多长时间才算太长呢？要执行一些长期操作(比如大小未知的循环)的任务应该调用一个名为Year_if_Need()的Scipio函数。下面是一个例子：</p><p> // Now busy loop and make sure that we yield when we have too.loop { if *(lat_status.borrow()) { break; // Success! } Local::yield_if_needed().await;}</p><p>//现在正忙着循环，请确保我们在必须时让步。loop{if*(lat_status.borrow()){Break；//Success！}Local：：Year_if_Needed().aWait；}。</p><p> This code employs a loop until a certain condition holds true, which can take a long time. Other tasks may become starved if the user doesn’t call  yield_if_needed(). This function takes direct advantage of io_uring’s architecture. Let’s recall how a ring buffer is supposed to operate:</p><p>此代码使用循环，直到某个条件成立，这可能需要很长时间。如果用户不调用Year_If_Needed()，其他任务可能会变得饥肠辘辘。该函数直接利用了Iouring的体系结构。让我们回想一下循环缓冲区应该是如何操作的：</p><p>  Applications consume events from the  head of the buffer and move its position when done. Linux posts events to the tail of the buffer and similarly moves its position when done. Because that happens in a shared memory area, we can, at any time, know if there are pending events in the ring. This is also very cheap: all we need to do is read two integers and compare them, which doesn’t add a significant amount of cost to those loops.</p><p>应用程序使用缓冲区头部的事件，并在完成后移动其位置。Linux将事件发布到缓冲区的尾部，并在完成后类似地移动其位置。因为这发生在共享内存区，所以我们可以随时知道环中是否有挂起的事件。这也非常便宜：我们所需要做的就是读取两个整数并比较它们，这不会给这些循环增加很大的开销。</p><p> But our implementation of  yield_if_needed() only looks at the  Latency ring. An application could, for instance, listen on two sockets: one of them for queries that have to be served as soon as possible with good latency, and another for queries for which throughput matters more.</p><p>但是我们的Year_if_Need()实现只考虑了延迟环。例如，应用程序可以侦听两个套接字：一个套接字用于必须以良好的延迟尽快提供服务的查询，另一个套接字用于吞吐量更为重要的查询。</p><p> If a query arrives in the throughput oriented socket, other running tasks will not yield immediately. When the query does have control of the CPU, it will have it for longer. Over time, Scipio’s scheduler will ensure that each class runs for a fair amount of time, but each block of time will be longer.</p><p>如果查询到达面向吞吐量的套接字，其他正在运行的任务将不会立即放弃。当查询确实控制了CPU时，它将拥有更长的时间。随着时间的推移，Scipio的调度器将确保每个类运行相当长的时间，但是每个时间块都会更长。</p><p> But if a query arrives in the latency oriented socket, other tasks will know about it and yield.</p><p>但是，如果查询到达面向延迟的套接字，其他任务就会知道并产生结果。</p><p> The attentive reader will have noticed a link between the main ring and the latency ring in the figure. Although a bit of implementation detail, that is the cherry on top of this architecture. When there is no work left to do, the thread where the executor lives goes to sleep. It is possible to go to sleep by blocking in the io_uring: it will automatically wake up when there are events. However, a blocking call will, by definition, block and won’t execute anything else. So it is only possible to wait for  one of the rings.</p><p>细心的读者会注意到图中主环和延迟环之间的链接。虽然有一些实现细节，但这是此体系结构之上的樱桃。当没有剩余的工作要做时，执行器所在的线程进入休眠状态。可以通过阻塞IO进入睡眠状态：当发生事件时，它将自动唤醒。但是，根据定义，阻塞调用将阻塞，不会执行任何其他操作。所以只能等待其中一个戒指。</p><p> One of the many operations that io_uring supports is poll, which notifies us of activity in any file descriptor. And because io_uring itself has a file descriptor, it is possible to poll on that too. So before Scipio issues a blocking call for the main ring, it registers the latency ring’s file descriptor for poll onto the main ring. If there are any events in the latency ring, it will generate activity in the main ring which will in turn wake up.</p><p>Io_uring支持的众多操作之一是轮询，它通知我们任何文件描述符中的活动。因为io_uring本身有一个文件描述符，所以也可以对其进行轮询。因此，在Scipio发出对主环的阻塞调用之前，它会注册延迟环的文件描述符，以便轮询到主环上。如果延迟环中有任何事件，它将在主环中生成活动，进而唤醒主环。</p><p>  The last ring is the poll ring. It is used for read and write requests coming from an NVMe device. Usually, storage I/O requests generate an  interrupt when they are ready, causing Linux to stop what it is doing to handle them, which generates yet another context switch.</p><p>最后一个戒指是投票戒指。它用于来自NVMe设备的读写请求。通常，存储I/O请求在准备就绪时会生成中断，导致Linux停止正在处理它们的操作，这会生成另一个上下文切换。</p><p> Requests that go through the poll ring do not generate interrupts, but instead rely on Scipio to explicitly  poll, or ask the kernel, at its own time and discretion when they are ready. That reduces the context switch penalty even more and is especially important for workloads that can generate small requests. For example, if a user wants to generate an alert on a specific point in a timeseries, which is no bigger than a couple of bytes.</p><p>通过轮询环的请求不会生成中断，而是依赖于Scipio在自己的时间显式轮询或在内核准备就绪时请求内核。这进一步降低了上下文切换的代价，对于可能生成小请求的工作负载尤其重要。例如，如果用户想要在时间序列中的特定时间点生成警报，其大小不超过几个字节。</p><p> Because requests in this ring do not generate interrupts, that means that we cannot go to sleep if there are pending I/O requests that haven’t been completed. So it doesn’t need to be linked to the other rings.Does that work with Kubernetes?</p><p>因为此环中的请求不会生成中断，这意味着如果有挂起的I/O请求尚未完成，我们将无法进入睡眠状态。所以它不需要和其他戒指联系起来。库伯内斯也可以吗？</p><p> Linux is ubiquitous in the modern datacenter, to the point that we can take advantage of Linux-only APIs like io_uring to bring things like Scipio to fruition. But another technology that is slowly but surely reaching that status is Kubernetes. Kubernetes is a flexible abstraction, where pods can be running everywhere. That begs the question: will a thread-per-core architecture do well on Kubernetes?</p><p>Linux在现代数据中心中无处不在，以至于我们可以利用仅限Linux的API(如io_uring)来实现像Scipio这样的东西。但另一项正在缓慢但肯定地达到这一地位的技术是Kubernetes。Kubernetes是一个灵活的抽象，其中pod可以在任何地方运行。这就回避了一个问题：每核线程架构在Kubernetes上能做得很好吗？</p><p> The answer is yes: thread-per-core applications will run on any Kubernetes infrastructure. However, best performance will come from matching the application to the physical cores available in the underlying hardware. To do that effectively:</p><p>答案是肯定的：每核线程应用程序可以在任何Kubernetes基础设施上运行。但是，最佳性能将来自将应用程序与底层硬件中可用的物理核心相匹配。要有效地做到这一点，请执行以下操作：</p><p>  Most of those things are already done by many organizations when running stateful sets, which is where the need for reliable and consistent performance comes from.</p><p>在运行有状态集时，许多组织已经完成了其中的大部分工作，这就是对可靠和一致性能的需求所在。</p><p>  As hardware gets faster and more feature rich, it is important to bring applications in line with new techniques to take full advantage of what the hardware provides. Modern applications that need to be sharded for scalability are prime candidates for using a thread-per-core architecture, where each CPU will have sole control over a fragment of the dataset.</p><p>随着硬件变得更快、功能更丰富，使应用程序与新技术保持一致以充分利用硬件提供的功能非常重要。需要为可伸缩性进行分片的现代应用程序是使用按核线程体系结构的主要候选者，在这种体系结构中，每个CPU将独家控制数据集的一个片段。</p><p> Thread-per-core architectures are friendly to modern hardware, as their local nature helps the application to take advantage of the fact that processors ship with more and more cores while storage gets faster, with modern NVMe devices having response times in the ballpark of an operating system context switch.</p><p>每核线程体系结构对现代硬件很友好，因为它们的本地特性有助于应用程序利用这样一个事实，即处理器附带越来越多的核心，而存储变得更快，现代NVMe设备的响应时间与操作系统上下文切换大致相当。</p><p> For all the advantages, thread-per-core architectures can be daunting and complex, which is why we wrote Scipio. Scipio builds upon Rust’s native asynchronous support and Linux’s innovative event-based io_uring API to build a thread-per-core library that is easy to consume.</p><p>尽管有这些优点，每核线程架构可能会令人望而生畏且复杂，这就是我们编写Scipio的原因。Scipio构建在Rust的本地异步支持和Linux创新的基于事件的Iouring API之上，以构建易于使用的每核线程库。</p><p> Scipio is an open source project,  available on Github, and on  crates.io. If you find a use for it, we’d love to hear about it! We now have community at  Zulip Chat. As you can see, Datadog is pushing the envelope in terms of what the modern datacenter looks like. If this kind of problem interests you, we’re always  looking for talented engineers to join us!</p><p>Scipio是一个开源项目，可以在Github和crates.io上获得。如果你发现它的用处，我们很乐意听听！我们现在在Zulip聊天上有了社区。如您所见，Datadog正在挑战现代数据中心的面貌。如果您对这类问题感兴趣，我们一直在寻找有才华的工程师加入我们！</p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://www.datadoghq.com/blog/engineering/introducing-scipio/">https://www.datadoghq.com/blog/engineering/introducing-scipio/</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/rust/">#rust</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/线程/">#线程</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/linux/">#linux</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/适用/">#适用</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/thread/">#thread</a></button></div></div><div class="shadow p-3 mb-5 bg-white rounded clearfix"><div class="container"><div class="row"><div class="col-sm"><div><a target="_blank" href="/story/1032908.html"><img src="http://img2.diglog.com/img/2020/11/thumb_be7c5ac7c26fb279aed5af0ebbacaf23.jpeg" class="img-fluid" onerror="this.style.display='none'"></a></div><div class="item_title"><a target="_blank" href="/story/1032908.html">OX是一个用Rust编写的快速文本编辑器，可以在您的终端上运行</a></div><span class="my_story_list_date">2020-11-3 12:4</span></div><div class="col-sm"><div><a target="_blank" href="/story/1032258.html"><img src="http://img2.diglog.com/img/2020/10/thumb_b5d0f1167a86fdbbb8945644fc4c54f6.png" class="img-fluid" onerror="this.style.display='none'"></a></div><div class="item_title"><a target="_blank" href="/story/1032258.html">古物鉴定师的铁锈</a></div><span class="my_story_list_date">2020-10-30 19:30</span></div><div class="col-sm"><div><a target="_blank" href="/story/1032252.html"><img src="http://img2.diglog.com/img/2020/10/thumb_32a6a18f6a7b3db994451021b6994b68.png" class="img-fluid" onerror="this.style.display='none'"></a></div><div class="item_title"><a target="_blank" href="/story/1032252.html">铁锈网到了吗？是的，而且它跑得太快了</a></div><span class="my_story_list_date">2020-10-30 18:37</span></div><div class="col-sm"><div><a target="_blank" href="/story/1031806.html"><img src="http://img2.diglog.com/img/2020/10/thumb_26bcb0bc85f464453de16206c6403500.jpeg" class="img-fluid" onerror="this.style.display='none'"></a></div><div class="item_title"><a target="_blank" href="/story/1031806.html">在IAB意大利提出申诉后，意大利反垄断机构调查谷歌涉嫌滥用其在在线展示广告市场的主导地位</a></div><span class="my_story_list_date">2020-10-29 9:40</span></div></div></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/美国/">#美国</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/谷歌/">#谷歌</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/linux/">#linux</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/程序/">#程序</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy; 2020 diglog.com </div></div></body></html>