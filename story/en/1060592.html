<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>$ 1 unistroke认可（2007） $1 Unistroke Recognizer (2007)</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">$1 Unistroke Recognizer (2007)<br/>$ 1 unistroke认可（2007） </h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2021-05-05 20:54:27</div><div class="page_narrow text-break page_content"><p>$1 source code:  JavaScript,  C# 		 Dynamic time warping:  C# 		 Rubine classifier:  C# 		 Pseudocode:  $1,  Protractor 		 Unistroke gesture logs:  XML 		 Paper:  PDF</p><p>$ 1源代码：javascript，c＃动态时间翘曲：c＃rumine分类器：c＃pseudocode：$ 1，protractor unistroke手势日志：XML纸：PDF</p><p>      The  $1 Unistroke Recognizer is a 2-D single-stroke recognizer designed for rapid prototyping of gesture-based			user interfaces. In machine learning terms, $1 is an instance-based nearest-neighbor classifier with a 2-D Euclidean			distance function, i.e., a geometric template matcher. $1 is a significant extension of the proportional shape matching			approach used in  SHARK 2, which itself is			an adaptation of  Tappert&#39;s elastic matching approach			with zero look-ahead. Despite its simplicity, $1 requires very few templates to perform well and is only about			100 lines of code, making it easy to deploy.			An optional enhancement called  Protractor improves $1&#39;s speed.</p><p>      $ 1 Unistroke识别器是一个二维单行识别器，专为基于手势的用户界面的快速原型设计而设计。在机器学习条款中，1美元是基于实例的最近邻分类，具有2-D欧几里德距离功能，即几何模板匹配器。 US $ 1是鲨鱼2中使用的比例形状匹配方法的重要延伸，它本身就是零食的适应性零点展开。尽管它很简单，但是1美元需要很少的模板来表现良好，并且只有100行代码，使得部署易于部署。称为Promractor的可选增强改善了1美元＆＃39; S速度。</p><p>  The  $N Multistroke Recognizer extends $1 to gestures with multiple strokes.			The  $P Point-Cloud Recognizer performs unistroke and multistroke recognition without the			combinatoric overhead of $N, as it ignores stroke number, order, and direction. The  $Q Super-Quick Recognizer			extends $P for use on low-powered mobiles and wearables, as it is a whopping 142× faster and slightly more accurate.</p><p>  $ n MultiSroke识别器将1美元扩展到多个笔划的手势。 $ P Point-Cloud识别器在没有N $的组合overhe上的情况下执行Unistroke和MultiStroke识别，因为它忽略了笔划号，订单和方向。 $ Q超快速识别器可延长$ P用于低功耗手机和可穿戴设备，因为它的距重142×更快，更准确。</p><p>  The $-family recognizers have been built into numerous projects and even industry prototypes,		 and have had many follow-ons by others.  Read about the $-family&#39;s impact.</p><p>  $ -Family识别人员已建立在众多项目甚至行业原型中，并有许多其他人的后续行动。阅读关于$ -Family＆＃39的影响。</p><p>    In the demo below, only one unistroke template is loaded for each of the 16 gesture types. You can add additional			unistrokes as you wish, and even define your own custom unistrokes.			  Make strokes on this canvas. If a misrecognition occurs,						add the misrecognized unistroke as an example of the intended gesture.</p><p>    在下面的演示中，仅为16种手势类型中的每一种加载一个Unistroke模板。您可以根据需要添加其他unistrokes，甚至可以定义自己的自定义unistrokes。在这个画布上进行笔触。如果发生误重，则将误识别的Unistroke添加为预期手势的示例。</p><p>        Vatavu, R.-D., Anthony, L. and Wobbrock, J.O. (2018).			 $Q: A super-quick, articulation-invariant stroke-gesture recognizer for low-resource devices.			Proceedings of the ACM Conference on Human-Computer Interaction with Mobile Devices and Services (MobileHCI &#39;18).			Barcelona, Spain (September 3-6, 2018).			New York: ACM Press. Article No. 23.</p><p>        Vatavu，R.-D.，Anthony，L.和Wobbrock，J.O. （2018）。 $问：低资源设备的超快速，铰接 - 不变的笔触手势识别器。与移动设备和服务的人机互动的ACM会议常规（MobileHCI＆＃39; 18）。巴塞罗那，西班牙（2018年9月3日至6日）。纽约：ACM媒体。第23条。</p><p>  Vatavu, R.-D. (2017).			 Improving gesture recognition accuracy on touch screens for users with low vision.			Proceedings of the ACM Conference on Human Factors in Computing Systems (CHI &#39;17).			Denver, Colorado (May 6-11, 2017).			New York: ACM Press, pp. 4667-4679.</p><p>  Vatavu，R.-D。 （2017）。提高触摸屏的手势识别准确性，为具有低视野的用户。 CHI＆＃39; 17）中的人类因素的ACM会议诉讼程序。丹佛，科罗拉多州（2017年5月6日至11日）。纽约：ACM按，PP。4667-4679。 </p><p>  Vatavu, R.-D. and Wobbrock, J.O. (2016).			 Between-subjects elicitation studies: Formalization and tool support.			Proceedings of the ACM Conference on Human Factors in Computing Systems (CHI &#39;16).			San Jose, California (May 7-12, 2016).			New York: ACM Press, pp. 3390-3402.</p><p>Vatavu，R.-D。和Wobbrock，J.O. （2016）。主题之间的阐述研究：形式化和工具支持。 CHI＆＃39; 16）中的ACM人类因素会议的诉讼程序。圣何塞，加利福尼亚州（2016年5月7日至12日）。纽约：ACM按，PP。3390-3402。</p><p>  Vatavu, R.-D. and Wobbrock, J.O. (2015).			 Formalizing agreement analysis for elicitation studies: New measures, significance test, and toolkit.			Proceedings of the ACM Conference on Human Factors in Computing Systems (CHI &#39;15).			Seoul, Korea (April 18-23, 2015).			New York: ACM Press, pp. 1325-1334.</p><p>  Vatavu，R.-D。和Wobbrock，J.O. （2015）。阐明研究的正式协议分析：新措施，意义测试和工具包。 Chi＆＃39; 15）中的人类因素的ACM会议的诉讼程序。首尔，韩国（2015年4月18日至23日）。纽约：ACM按，PP。1325-1334。</p><p>  Vatavu, R.-D., Anthony, L. and Wobbrock, J.O. (2014).			 Gesture heatmaps: Understanding gesture performance with colorful visualizations.			Proceedings of the ACM International Conference on Multimodal Interfaces (ICMI &#39;14).			Istanbul, Turkey (November 12-16, 2014).			New York: ACM Press, pp. 172-179.</p><p>  Vatavu，R.-D.，Anthony，L.和Wobbrock，J.O. （2014）。手势热插拔：了解炫彩可视化的手势性能。 ACM多式界面国际会议的诉讼程序（ICMI＆＃39; 14）。伊斯坦布尔，土耳其（2014年11月12日至16日）。纽约：ACM按，PP。172-179。</p><p>  Vatavu, R.-D., Anthony, L. and Wobbrock, J.O. (2013).			 Relative accuracy measures for stroke gestures.			Proceedings of the ACM International Conference on Multimodal Interfaces (ICMI &#39;13).			Sydney, Australia (December 9-13, 2013).			New York: ACM Press, pp. 279-286.</p><p>  Vatavu，R.-D.，Anthony，L.和Wobbrock，J.O. （2013）。中风手势的相对准确度措施。 ACM多式界面国际会议的诉讼程序（ICMI＆＃39; 13）。悉尼，澳大利亚（2013年12月9日至13日）。纽约：acm按，pp。279-286。</p><p>  Anthony, L., Vatavu, R.-D. and Wobbrock, J.O. (2013).			 Understanding the consistency of users&#39; pen and finger stroke gesture articulation.			Proceedings of Graphics Interface (GI &#39;13).			Regina, Saskatchewan (May 29-31, 2013).			Toronto, Ontario: Canadian Information Processing Society, pp. 87-94.</p><p>  安东尼，L.，Vatavu，R.-D。和Wobbrock，J.O. （2013）。了解用户的一致性＆＃39;笔和手指冲程手势铰接。图形界面的程序（GI＆＃39; 13）。 Regina，萨斯喀彻温省（2013年5月29日至31日）。多伦多，安大略省：加拿大信息处理协会，第87-94页。</p><p>  Vatavu, R.-D., Anthony, L. and Wobbrock, J.O. (2012).			 Gestures as point clouds: A $P recognizer for user interface prototypes.			Proceedings of the ACM International Conference on Multimodal Interfaces (ICMI &#39;12).			Santa Monica, California (October 22-26, 2012).			New York: ACM Press, pp. 273-280.</p><p>  Vatavu，R.-D.，Anthony，L.和Wobbrock，J.O. （2012）。手势作为点云：用户界面原型的$ p识别器。 ACM多式联合界面国际会议的诉讼程序（ICMI＆＃39; 12）。 Santa Monica，加利福尼亚（2012年10月22日至26日）。纽约：ACM按，PP。273-280。</p><p>  Anthony, L. and Wobbrock, J.O. (2012).			 $N-Protractor: A fast and accurate multistroke recognizer.			Proceedings of Graphics Interface (GI &#39;12).			Toronto, Ontario (May 28-30, 2012).			Toronto, Ontario: Canadian Information Processing Society, pp. 117-120.</p><p>  Anthony，L.和Wobbrock，J.O. （2012）。 $ n-protractor：快速准确的MultiSroke识别器。图形界面的程序（GI＆＃39; 12）。多伦多，安大略省（2012年5月28日）。多伦多，安大略省：加拿大信息处理协会，第117-120页。 </p><p>  Anthony, L. and Wobbrock, J.O. (2010).			 A lightweight multistroke recognizer for user interface prototypes.			Proceedings of Graphics Interface (GI &#39;10).			Ottawa, Ontario (May 31-June 2, 2010).			Toronto, Ontario: Canadian Information Processing Society, pp. 245-252.</p><p>Anthony，L.和Wobbrock，J.O. （2010）。用于用户界面原型的轻量级MultiSroke识别器。图形界面的程序（GI＆＃39; 10）。渥太华，安大略省（2010年6月21日至6月2日）。多伦多，安大略省：加拿大信息处理协会，第245-252页。</p><p>  Wobbrock, J.O., Wilson, A.D. and Li, Y. (2007).			 Gestures without libraries, toolkits or training: A $1 recognizer for user interface prototypes.			Proceedings of the ACM Symposium on User Interface Software and Technology (UIST &#39;07).			Newport, Rhode Island (October 7-10, 2007).			New York: ACM Press, pp. 159-168.</p><p>  Wobbrock，J.O.，Wilson，A.D.和Li，Y.（2007）。没有库，工具包或培训的手势：用户界面原型的1美元识别器。 ACM用户界面软件和技术的ACM研讨会（UIST＆＃39; 07）。罗德岛（罗德岛（2007年10月7日至10日）。纽约：ACM按，PP。159-168。</p><p>    Li, Y. (2010).			 Protractor: A fast and accurate gesture recognizer.			Proceedings of the ACM Conference on Human Factors in Computing Systems (CHI &#39;10).			Atlanta, Georgia (April 10-15, 2010).			New York: ACM Press, pp. 2169-2172.</p><p>    李，y。（2010）。 Protractor：一种快速准确的手势识别器。计算系统中的人类因素会议的诉讼程序（Chi＆＃39; 10）。亚特兰大，格鲁吉亚（2010年4月10日至15日）。纽约：ACM按，PP。2169-2172。</p><p>  Kristensson, P. and Zhai, S. (2004).			 SHARK 2: A large vocabulary shorthand writing system for pen-based computers.			Proceedings of the ACM Symposium on User Interface Software and Technology (UIST &#39;04).			Santa Fe, New Mexico (October 24-27, 2004).			New York: ACM Press, pp. 43-52.</p><p>  Kristensson，P.和Zhai，S。（2004）。鲨鱼2：基于笔的笔的大型词汇书写系统。 ACM用户界面软件和技术的ACM研讨会（UIST＆＃39; 04）。圣达菲，新墨西哥州（2004年10月24日至27日）。纽约：ACM按，PP。43-52。</p><p>  Rubine, D. (1991).			 Specifying gestures by example.			Proceedings of the ACM Conference on Computer Graphics and Interactive Techniques (SIGGRAPH &#39;91).			Las Vegas, Nevada (July 28 - August 2, 1991).			New York: ACM Press, pp. 329-337.</p><p>  Rubine，D。（1991）。按示例指定手势。计算机图形学和交互式技术的ACM会议的程序（Siggraph＆＃39; 91）。拉斯维加斯，内华达州（1991年7月28日 -  8月28日）。纽约：ACM按，PP。329-337。</p><p>  Tappert, C.C. (1982).			 Cursive script recognition by elastic matching.			IBM Journal of Research and Development 26 (6), pp. 765-771.</p><p>  Tappert，C.C. （1982）。弹性匹配的法学脚本识别。 IBM研究与开发学报2​​6（6），第765-771页。 </p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="http://depts.washington.edu/acelab/proj/dollar/index.html">http://depts.washington.edu/acelab/proj/dollar/index.html</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/unistroke/">#unistroke</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/手势/">#手势</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/分享/">#分享</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy;2012-2021 diglog.com </div></div></body></html>