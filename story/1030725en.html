<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Microsoft、IBM、NVIDIA和其他公司发布了一个开放式框架，以帮助安全分析人员检测、应对和补救机器学习系统面临的威胁</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">Microsoft、IBM、NVIDIA和其他公司发布了一个开放式框架，以帮助安全分析人员检测、应对和补救机器学习系统面临的威胁</h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2020-10-23 12:13:17</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2020/10/c78511cfa32eec81e26c7eb3ea637e02.jpg"><img src="http://img2.diglog.com/img/2020/10/c78511cfa32eec81e26c7eb3ea637e02.jpg" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>Microsoft, the nonprofit MITRE Corporation, and 11 organizations including IBM, Nvidia, Airbus, and Bosch today  released the  Adversarial ML Threat Matrix, an industry-focused open framework designed to help security analysts to detect, respond to, and remediate threats against machine learning systems. Microsoft says it worked with MITRE to build a schema that organizes the approaches employed by malicious actors in subverting machine learning models, bolstering monitoring strategies around organizations’ mission-critical systems.</p><p>微软、非营利性组织MITRE Corporation以及IBM、NVIDIA、空中客车和博世等11家组织今天发布了敌意ML威胁矩阵，这是一个专注于行业的开放框架，旨在帮助安全分析师检测、响应和补救针对机器学习系统的威胁。微软表示，它与MITRE合作建立了一个模式，将恶意行为者在颠覆机器学习模型时使用的方法组织起来，支持围绕组织的关键任务系统的监控策略。</p><p> According to a Gartner  report, through 2022, 30% of all AI cyberattacks will leverage training-data poisoning, model theft, or  adversarial samples to attack machine learning-powered systems. Despite these reasons to secure systems, Microsoft claims its internal studies find most industry practitioners have yet to come to terms with adversarial machine learning. Twenty-five out of the 28 businesses responding to the Seattle company’s recent survey indicated they don’t have the right tools in place to secure their machine learning models.</p><p>根据Gartner的一份报告，到2022年，所有人工智能网络攻击中的30%将利用训练数据中毒、模型盗窃或对手样本来攻击机器学习支持的系统。尽管有这些保护系统的原因，微软声称其内部研究发现，大多数行业从业者还没有接受对抗性的机器学习。在对西雅图公司最近的调查做出回应的28家企业中，有25家表示，他们没有合适的工具来保护他们的机器学习模型。</p><p>  The Adversarial ML Threat Matrix — which was modeled after the  MITRE ATT&amp;CK Framework — aims to address this with a curated set of vulnerabilities and adversary behaviors that Microsoft and MITRE vetted to be effective against production systems. With input from researchers at the University of Toronto, Cardiff University, and the Software Engineering Institute at Carnegie Mellon University, Microsoft and MITRE created a list of tactics that correspond to broad categories of adversary action. Techniques in the schema fall within one tactic and are illustrated by a series of case studies covering how well-known attacks such as the  Microsoft Tay poisoning, the  Proofpoint evasion attack, and other attacks could be analyzed using the Threat Matrix.</p><p>敌意ML威胁矩阵仿照MITRE ATT&amp；CK框架，旨在通过一组经过精心策划的漏洞和敌方行为来解决这一问题，微软和MITRE都认为这些漏洞和敌方行为对生产系统是有效的。在多伦多大学、卡迪夫大学和卡内基梅隆大学软件工程研究所的研究人员的帮助下，微软和MITRE创建了一个与广泛类别的对手行动相对应的战术列表。架构中的技术属于一种策略，并通过一系列案例研究进行了说明，这些案例研究涵盖了如何使用威胁矩阵分析众所周知的攻击(如Microsoft Tay中毒、Proofpoint规避攻击和其他攻击)。</p><p>  “The Adversarial Machine Learning Threat Matrix will … help security analysts think holistically. While there’s excellent work happening in the academic community that looks at specific vulnerabilities, it’s important to think about how these things play off one another,” Mikel Rodriguez, who oversees MITRE’s decision science research programs, said in a  statement. “Also, by giving a common language or taxonomy of the different vulnerabilities, the threat matrix will spur better communication and collaboration across organizations.”</p><p>“对抗性机器学习威胁矩阵将…。帮助安全分析师进行整体思考。监管MITRE决策科学研究项目的米克尔·罗德里格斯(Mikel Rodriguez)在一份声明中表示：“虽然学术界在研究特定漏洞方面进行了出色的工作，但重要的是要考虑这些事情是如何相互影响的。”此外，通过提供不同漏洞的共同语言或分类，威胁矩阵将促进组织间更好的沟通和协作。</p><p> Microsoft and MITRE say they will solicit contributions from the community via GitHub, where the Adversarial ML Threat Matrix is now available. Researchers can submit studies detailing exploits that compromise the confidentiality, integrity, or availability of machine learning systems running on Amazon Web Services, Microsoft Azure, Google Cloud AI, or IBM Watson, or embedded in client or edge device. Those who submit research will retain the permission to share and republish their work, Microsoft says.</p><p>微软和MITRE表示，他们将通过GitHub向社区征求意见，GitHub现在提供了敌对的ML威胁矩阵。研究人员可以提交详细的研究报告，详细说明危害在Amazon Web服务、Microsoft Azure、Google Cloud AI或IBM Watson上运行或嵌入到客户端或边缘设备中的机器学习系统的机密性、完整性或可用性的漏洞。微软表示，那些提交研究的人将保留分享和重新发布他们的工作的许可。</p><p> “We think that securing machine learning systems is an infosec problem,” Microsoft Azure engineer Ram Shankar Siva Kumar and corporate VP Ann Johnson wrote in a blog post. “The goal of the Adversarial ML Threat Matrix is to position attacks on machine learning systems in a framework that security analysts can orient themselves in these new and upcoming threat … It’s aimed at security analysts and the broader security community: the matrix and the case studies are meant to help in strategizing protection and detection; the framework seeds attacks on machine learning systems, so that they can carefully carry out similar exercises in their organizations and validate the monitoring strategies.”</p><p>微软Azure工程师Ram Shankar Siva Kumar和公司副总裁Ann Johnson在一篇博客文章中写道：“我们认为保护机器学习系统是一个信息安全问题。”对抗性ML威胁矩阵的目标是将针对机器学习系统的攻击定位在一个框架中，使安全分析师能够将自己定位于这些新的和即将到来的威胁…。它针对的是安全分析师和更广泛的安全社区：矩阵和案例研究旨在帮助制定保护和检测的战略；该框架为对机器学习系统的攻击埋下种子，这样他们就可以在他们的组织中谨慎地进行类似的练习，并验证监控策略。“。</p><p> The audio problem:Learn how new cloud-based API solutions are solving imperfect, frustrating audio in video conferences.  Access here</p><p>音频问题：了解基于云的新API解决方案如何解决视频会议中不完美、令人沮丧的音频问题。访问此处</p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://venturebeat.com/2020/10/22/microsoft-and-mitre-release-framework-to-help-fend-off-adversarial-ai-attacks/">https://venturebeat.com/2020/10/22/microsoft-and-mitre-release-framework-to-help-fend-off-adversarial-ai-attacks/</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/microsoft/">#microsoft</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/发布/">#发布</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/nvidia/">#nvidia</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/ibm/">#ibm</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/研究/">#研究</a></button></div></div><div class="shadow p-3 mb-5 bg-white rounded clearfix"><div class="container"><div class="row"><div class="col-sm"><div><a target="_blank" href="/story/1030677.html"><img src="http://img2.diglog.com/img/2020/10/thumb_0a22586bf7d8868fa2ef9cb9944c28ff.png" class="img-fluid" onerror="this.style.display='none'"></a></div><div class="item_title"><a target="_blank" href="/story/1030677.html">我的世界将需要一个微软帐户才能在2021年玩</a></div><span class="my_story_list_date">2020-10-23 5:39</span></div><div class="col-sm"><div><a target="_blank" href="/story/1030393.html"><img src="http://img2.diglog.com/img/2020/10/thumb_529756b5b6e7f80ae9f6575bf6232f85.jpg" class="img-fluid" onerror="this.style.display='none'"></a></div><div class="item_title"><a target="_blank" href="/story/1030393.html">微软称关闭了TrickBot 94%的命令和控制服务器</a></div><span class="my_story_list_date">2020-10-22 9:11</span></div><div class="col-sm"><div><a target="_blank" href="/story/1030372.html"><img src="http://img2.diglog.com/img/2020/10/thumb_ae47cbde18fd13b9c47aa4bdd514a8fb.jpg" class="img-fluid" onerror="this.style.display='none'"></a></div><div class="item_title"><a target="_blank" href="/story/1030372.html">美国司法部起诉谷歌的案件依赖于证明限制性合同保护了其主导地位，这与针对微软的反垄断案类似</a></div><span class="my_story_list_date">2020-10-22 9:6</span></div><div class="col-sm"><div><a target="_blank" href="/story/1030230.html"><img src="http://img2.diglog.com/img/2020/10/thumb_b2b61d45369d8f9bcf5c99a9d21b817c.jpg" class="img-fluid" onerror="this.style.display='none'"></a></div><div class="item_title"><a target="_blank" href="/story/1030230.html">Trickbot-微软攻击的雇佣僵尸网络-正在争先恐后地生存</a></div><span class="my_story_list_date">2020-10-21 10:6</span></div></div></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/美国/">#美国</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/谷歌/">#谷歌</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/linux/">#linux</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/程序/">#程序</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy; 2020 diglog.com </div></div></body></html>