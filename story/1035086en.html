<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>科学家批评人工智能研究缺乏透明度，列举了研究中的复制问题，以及对代码、专有数据和硬件的不平等访问</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">科学家批评人工智能研究缺乏透明度，列举了研究中的复制问题，以及对代码、专有数据和硬件的不平等访问</h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2020-11-14 15:50:59</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2020/11/079e1dbe739a7a00a080c1c5f1e4c7a0.jpg"><img src="http://img2.diglog.com/img/2020/11/079e1dbe739a7a00a080c1c5f1e4c7a0.jpg" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>Last month Nature published a  damning response written by 31 scientists to a  study from Google Health that had appeared in the journal earlier this year. Google was describing successful trials of an AI that looked for signs of breast cancer in medical images. But according to its critics, the Google team provided so little information about its code and how it was tested that the study amounted to nothing more than a promotion of proprietary tech.</p><p>上个月，《自然》杂志发表了一篇由31名科学家撰写的文章，对谷歌健康今年早些时候发表在该杂志上的一项研究进行了谴责。谷歌描述了一种人工智能的成功试验，该人工智能在医学图像中寻找乳腺癌的迹象。但根据批评者的说法，谷歌团队提供的关于其代码以及如何测试的信息非常少，以至于这项研究无异于推广专有技术。</p><p> “We couldn’t take it anymore,” says Benjamin Haibe-Kains, the lead author of the response, who studies computational genomics at the University of Toronto. “It’s not about this study in particular—it’s a trend we’ve been witnessing for multiple years now that has started to really bother us.”</p><p>在多伦多大学研究计算基因组学的本杰明·海贝-凯恩斯(Benjamin Haibe-Kines)说：“我们再也受不了了。”“这与这项研究无关--这是我们多年来一直观察到的一种趋势，现在已经开始真正困扰我们了。”</p><p> Haibe-Kains and his colleagues are among a growing number of scientists pushing back against a perceived lack of transparency in AI research. “When we saw that paper from Google, we realized that it was yet another example of a very high-profile journal publishing a very exciting study that has nothing to do with science,” he says. “It’s more an advertisement for cool technology. We can’t really do anything with it.”</p><p>海贝-凯恩斯和他的同事是越来越多的科学家中的一员，他们反对人工智能研究中被认为缺乏透明度的问题。他说：“当我们看到谷歌的那篇论文时，我们意识到这是一个非常引人注目的期刊发表一项与科学无关的非常令人兴奋的研究的又一个例子。”“这更像是一个炫酷科技的广告。我们真的无能为力。“。</p><p> Science is built on a bedrock of trust, which typically involves sharing enough details about how research is carried out to enable others to replicate it, verifying results for themselves. This is how science self-corrects and weeds out results that don’t stand up. Replication also allows others to build on those results, helping to advance the field. Science that can’t be replicated falls by the wayside.</p><p>科学是建立在信任的基础上的，这通常包括分享足够的细节，说明研究是如何进行的，以便其他人能够复制它，自己验证结果。这就是科学如何自我纠正和剔除站不住脚的结果。复制还允许其他公司在这些成果的基础上再接再厉，帮助推动这一领域的发展。无法复制的科学已经半途而废。</p><p> At least, that’s the idea. In practice, few studies are fully replicated because most researchers are more interested in producing new results than reproducing old ones. But in fields like biology and physics—and computer science overall—researchers are typically expected to provide the information needed to rerun experiments, even if those reruns are rare.</p><p>至少，这是我们的想法。在实践中，很少有研究是完全重复的，因为大多数研究人员对产生新的结果比复制旧的结果更感兴趣。但在生物学和物理学--以及整个计算机科学--等领域，研究人员通常被期望提供重新运行实验所需的信息，即使这种重新运行的情况很少见。</p><p>  AI is feeling the heat for several reasons. For a start, it is a newcomer. It has only really become an experimental science in the past decade, says Joelle Pineau, a computer scientist at Facebook AI Research and McGill University, who coauthored the complaint. “It used to be theoretical, but more and more we are running experiments,” she says. “And our dedication to sound methodology is lagging behind the ambition of our experiments.”</p><p>人工智能感受到压力有几个原因。首先，它是一个新来者。Facebook AI Research和麦吉尔大学(McGill University)的计算机科学家乔尔·皮诺(Joelle Pineau)表示，在过去十年里，它才真正成为一门实验科学。皮诺是这份申诉的合著者。她说：“这曾经是理论上的，但现在我们越来越多地在做实验。”“我们对完善方法论的投入远远落后于我们实验的雄心壮志。”</p><p> The problem is not simply academic. A lack of transparency prevents new AI models and techniques from being properly assessed for robustness, bias, and safety. AI moves quickly from research labs to real-world applications, with direct impact on people’s lives. But machine-learning models that work well in the lab can fail in the wild—with potentially dangerous consequences. Replication by different researchers in different settings would expose problems sooner, making AI stronger for everyone.</p><p>这个问题不仅仅是学术问题。缺乏透明度阻碍了对新的人工智能模型和技术进行健壮性、偏倚和安全性的适当评估。人工智能迅速从研究实验室转向现实世界的应用，对人们的生活产生了直接影响。但是，在实验室中运行良好的机器学习模型可能会在野外失败--带来潜在的危险后果。不同的研究人员在不同的环境下进行复制会更快地暴露问题，使人工智能对每个人都更强大。</p><p>  AI already suffers from the black-box problem: it can be impossible to say exactly how or why a machine-learning model produces the results it does. A lack of transparency in research makes things worse. Large models need as many eyes on them as possible, more people testing them and figuring out what makes them tick. This is how we make AI in health care safer, AI in  policing more fair, and  chatbots less hateful.</p><p>人工智能已经受到黑匣子问题的困扰：无法确切地说出机器学习模型如何或为什么会产生这样的结果。研究缺乏透明度让事情变得更糟。大型模型需要尽可能多的人关注它们，更多的人对它们进行测试，找出是什么让它们运转起来。这就是我们如何让医疗保健中的人工智能更安全，让警务中的人工智能更公平，让聊天机器人不那么仇恨。</p><p> What’s stopping AI replication from happening as it should is a lack of access to three things: code, data, and hardware. According to the  2020 State of AI report, a well-vetted annual analysis of the field by investors Nathan Benaich and Ian Hogarth, only 15% of AI studies share their code. Industry researchers are bigger offenders than those affiliated with universities. In particular,  the report calls out OpenAI and DeepMind for keeping code under wraps.</p><p>阻止人工智能复制发生的原因是缺乏对三样东西的访问：代码、数据和硬件。根据投资者内森·贝纳奇(Nathan Benaich)和伊恩·霍加斯(Ian Hogarth)对该领域的年度分析--2020年国家人工智能报告(State Of AI Report)，只有15%的人工智能研究共享了他们的代码。行业研究人员比那些附属于大学的人犯的错更大。该报告特别指责OpenAI和DeepMind对代码保密。</p><p> Then there’s the growing gulf between the haves and have-nots when it comes to the two pillars of AI, data and hardware. Data is often proprietary, such as the information Facebook collects on its users, or sensitive, as in the case of personal medical records. And tech giants carry out more and more research on enormous, expensive clusters of computers that few universities or smaller companies have the resources to access.</p><p>然后，在人工智能的两大支柱--数据和硬件--方面，富人和穷人之间的鸿沟越来越大。数据通常是专有的，比如Facebook收集的用户信息，或者是敏感的，比如个人医疗记录。科技巨头对庞大而昂贵的计算机集群进行了越来越多的研究，而很少有大学或小公司有资源访问这些集群。</p><p> To take one example, training the language generator GPT-3 is  estimated to have cost OpenAI $10 to $12 million—and that’s just the final model, not including the cost of developing and training its prototypes. “You could probably multiply that figure by at least one or two orders of magnitude,” says Benaich, who is founder of Air Street Capital, a VC firm that invests in AI startups. Only a tiny handful of big tech firms can afford to do that kind of work, he says: “Nobody else can just throw vast budgets at these experiments.”</p><p>举个例子，培训语言生成器GPT-3估计花费了OpenAI 1000万至1200万美元-这只是最终的模型，还不包括开发和培训原型的成本。投资人工智能初创企业的风投公司Air Street Capital的创始人贝奈奇说：“这个数字至少可以乘以一两个数量级。”只有极少数大型科技公司才能负担得起这样的工作，他说：“没有人能在这些实验上投入巨额预算。”</p><p> Hypothetical question. Some people have access to GPT-3 and others do not. What happens when we start seeing papers in which GPT-3 is used by non-OpenAI researchers to achieve SOTA results?</p><p>假设问题。一些人可以获得GPT-3，而另一些人则没有。当我们开始看到非OpenAI研究人员使用GPT-3来实现SOTA结果的论文时，会发生什么？</p><p> The rate of progress is dizzying, with thousands of papers published every year. But unless researchers know which ones to trust, it is hard for the field to move forward. Replication lets other researchers check that results have not been cherry-picked and that new AI techniques really do work as described. “It’s getting harder and harder to tell which are reliable results and which are not,” says Pineau.</p><p>进展之快令人眼花缭乱，每年发表的论文数以千计。但是，除非研究人员知道哪些是值得信任的，否则该领域很难取得进展。复制可以让其他研究人员检查结果是否是精心挑选的，以及新的人工智能技术是否真的像描述的那样起作用。皮诺说：“区分哪些是可靠的结果，哪些是不可靠的结果变得越来越难。”</p><p> What can be done? Like many AI researchers, Pineau divides her time between university and corporate labs. For the last few years, she has been the driving force behind a change in how AI research is published. For example, last year she helped introduce a checklist of things that researchers must provide, including code and detailed descriptions of experiments, when they submit papers to NeurIPS, one of the biggest AI conferences.</p><p>我们能做什么？像许多人工智能研究人员一样，皮诺将她的时间分配在大学和企业实验室之间。在过去的几年里，她一直是人工智能研究发表方式改变的推动力。例如，去年，她帮助介绍了一份清单，列出了研究人员在向最大的人工智能会议之一NeurIPS提交论文时必须提供的东西，包括代码和实验的详细描述。</p><p>  Pineau has also helped launch a handful of reproducibility challenges, in which researchers try to replicate the results of published studies. Participants select papers that have been accepted to a conference and compete to rerun the experiments using the information provided. But the only prize is kudos.</p><p>皮诺还帮助发起了几项重现性挑战，研究人员试图复制已发表的研究结果。参与者选择已经被会议接受的论文，并利用提供的信息竞争重新进行实验。但唯一的奖品是荣誉。</p><p> This lack of incentive is a barrier to such efforts throughout the sciences, not just in AI. Replication is essential, but it isn’t rewarded. One solution is to get students to do the work. For the last couple of years, Rosemary Ke, a PhD student at Mila, a research institute in Montreal founded by Yoshua Bengio, has organized a  reproducibility challenge where students try to replicate studies submitted to NeurIPS as part of their machine-learning course. In turn, some successful replications are peer-reviewed and published in the journal ReScience.</p><p>这种缺乏激励是整个科学界此类努力的障碍，而不仅仅是在人工智能领域。复制是必要的，但它不会得到回报。一种解决方案是让学生来做这项工作。过去几年，约书亚·本吉奥(Yoshua Bengio)在蒙特利尔创办的研究机构Mila的博士生罗斯玛丽·柯(Rosemary Ke)组织了一项可重复性挑战，要求学生复制作为机器学习课程的一部分提交给NeurIPS的研究。反过来，一些成功的复制会经过同行评审，并发表在《科学》杂志(ReScience)上。</p><p> “It takes quite a lot of effort to reproduce another paper from scratch,” says Ke. “The reproducibility challenge recognizes this effort and gives credit to people who do a good job.” Ke and others are also spreading the word at AI conferences via workshops set up to encourage researchers to make their work more transparent. This year Pineau and Ke extended the reproducibility challenge to seven of the top AI conferences, including ICML and ICLR.</p><p>“要从零开始复制另一张纸，需要付出相当大的努力，”柯晓东说。“可再现性挑战认可了这一努力，并将功劳归功于那些做得很好的人。”柯震东和其他人还在人工智能会议上通过研讨会传播这一信息，这些研讨会旨在鼓励研究人员让他们的工作更加透明。今年，Pineau和Ke将可重复性挑战扩展到了七个顶级人工智能会议，包括ICML和ICLR。</p><p> Another push for transparency is the  Papers with Code project, set up by AI researcher Robert Stojnic when he was at the University of Cambridge. (Stojnic is now a colleague of Pineau’s at Facebook.) Launched as a stand-alone website where researchers could link a study to the code that went with it, this year Papers with Code started a collaboration with arXiv, a popular preprint server. Since October, all machine-learning papers on arXiv have come with a Papers with Code section that links directly to code that authors wish to make available. The aim is to make sharing the norm.</p><p>另一个推动透明度的项目是人工智能研究人员罗伯特·斯托伊尼奇(Robert Stojnic)在剑桥大学(University Of Cambridge)时建立的带代码的文件项目(Papers With Code)。(斯托伊尼奇现在是皮诺在Facebook的同事。)。作为一个独立的网站，研究人员可以在这个网站上将一项研究链接到随之而来的代码上。今年，《代码与论文》(Papers With Code)开始与广受欢迎的预印服务器arxiv合作。从10月份开始，所有关于arxiv的机器学习论文都有一个代码论文部分，直接链接到作者希望提供的代码。这样做的目的是让分享成为一种常态。</p><p> Do such efforts make a difference? Pineau found that last year, when the checklist was introduced, the number of researchers including code with papers submitted to NeurIPS jumped  from less than 50% to around 75%. Thousands of reviewers say they used the code to assess the submissions. And the number of participants in the reproducibility challenges is increasing.</p><p>这样的努力会有什么不同吗？皮诺发现，去年，当清单被引入时，包括提交给NeurIPS的论文的代码在内的研究人员数量从不到50%跃升至75%左右。数以千计的评审员表示，他们使用代码来评估提交的内容。参加可再生性挑战的人数正在增加。</p><p>  But it is only a start. Haibe-Kains points out that code alone is often not enough to rerun an experiment. Building AI models involves making many small changes—adding parameters here, adjusting values there. Any one of these can make the difference between a model working and not working. Without metadata describing how the models are trained and tuned, the code can be useless. “The devil really is in the detail,” he says.</p><p>但这只是一个开始。海贝-凯恩斯指出，仅仅靠代码往往不足以重启一项实验。构建人工智能模型需要进行许多小的更改-在这里添加参数，在那里调整数值。这些因素中的任何一个都可以决定模型工作和不工作之间的差别。如果没有描述如何训练和调优模型的元数据，代码就会变得毫无用处。“真正的魔鬼在于细节，”他说。</p><p>   It’s also not always clear exactly what code to share in the first place. Many labs use special software to run their models; sometimes this is proprietary. It is hard to know how much of that support code needs to be shared as well, says Haibe-Kains.</p><p>而且，一开始并不总是很清楚应该共享哪些代码。许多实验室使用特殊的软件来运行他们的模型；有时这是专有的。海贝-凯恩斯说，很难知道有多少支持代码也需要共享。</p><p> Pineau isn’t too worried about such obstacles. “We should have really high expectations for sharing code,” she says. Sharing data is trickier, but there are solutions here too. If researchers cannot share their data, they might give directions so that others can build similar data sets. Or you could have a process where a small number of independent auditors were given access to the data, verifying results for everybody else, says Haibe-Kains.</p><p>皮诺并不太担心这些障碍。“我们应该对共享代码抱有很高的期望，”她说。共享数据比较棘手，但这里也有解决方案。如果研究人员不能分享他们的数据，他们可能会给出方向，这样其他人就可以建立类似的数据集。或者，海贝-凯恩斯说，你也可以有一个流程，让少数独立审计师接触数据，为其他所有人核实结果。</p><p> Hardware is the biggest problem. But DeepMind claims that big-ticket research like AlphaGo or GPT-3 has a trickle-down effect, where money spent by rich labs eventually leads to results that benefit everyone. AI that is inaccessible to other researchers in its early stages, because it requires a lot of computing power, is often made more efficient—and thus more accessible—as it is developed. “AlphaGo Zero surpassed the original AlphaGo using far less computational resources,” says Koray Kavukcuoglu, vice president of research at DeepMind.</p><p>硬件是最大的问题。但DeepMind声称，像AlphaGo或GPT-3这样的高额研究具有涓滴效应，有钱的实验室花的钱最终会产生对每个人都有利的结果。其他研究人员在早期阶段无法接触到的人工智能，因为它需要大量的计算能力，随着它的发展，它往往会变得更有效率，因此更容易获得。DeepMind研究副总裁Koray Kavukcuoglu说：“AlphaGo Zero比原来的AlphaGo使用了更少的计算资源。”</p><p> In theory, this means that even if replication is delayed, at least it is still possible. Kavukcuoglu notes that Gian-Carlo Pascutto, a Belgian coder at Mozilla who writes chess and Go software in his free time, was able to re-create a version of AlphaGo Zero called Leela Zero, using algorithms outlined by DeepMind in its papers. Pineau also thinks that flagship research like AlphaGo and GPT-3 is rare. The majority of AI research is run on computers that are available to the average lab, she says. And the problem is not unique to AI. Pineau and Benaich both point to particle physics, where some experiments can only be done on expensive pieces of equipment such as the Large Hadron Collider.</p><p>从理论上讲，这意味着即使复制被推迟，至少它仍然是可能的。Kavukcuoglu指出，Mozilla的比利时程序员吉安-卡洛·帕斯卡托在业余时间编写国际象棋和围棋软件，他使用DeepMind在论文中概述的算法，重新创建了AlphaGo Zero的一个版本，名为Leela Zero。皮诺还认为，像AlphaGo和GPT-3这样的旗舰研究非常罕见。她说，大多数人工智能研究都是在普通实验室可用的计算机上进行的。而且这个问题并不是人工智能独有的。皮诺和贝奈奇都提到了粒子物理学，其中一些实验只能在昂贵的设备上进行，比如大型强子对撞机(Large Hadron Collider)。</p><p> In physics, however, university labs run joint experiments on the LHC. Big AI experiments are typically carried out on hardware that is owned and controlled by companies. But even that is changing, says Pineau. For example, a group called Compute Canada is putting together computing clusters to let universities run large AI experiments. Some companies, including Facebook, also give universities limited access to their hardware. “It’s not completely there,” she says. “But some doors are opening.”</p><p>然而，在物理学方面，大学实验室对大型强子对撞机进行联合实验。大型人工智能实验通常是在公司拥有和控制的硬件上进行的。但皮诺表示，即便是这种情况也在改变。例如，一个名为加拿大计算(Compute Canada)的组织正在组装计算集群，让大学进行大型人工智能实验。包括Facebook在内的一些公司也限制大学使用他们的硬件。“它并不完全存在，”她说。“但一些大门正在打开。”</p><p> 10/Let&#39;s face it: following good practices for sharing code, data, and other materials can be inconvenient for authors anywhere (although some practices can make it more convenient). But it&#39;s essential for the scientific enterprise. For-profit businesses don&#39;t get a free pass.</p><p>10/让我们面对现实吧：遵循分享代码、数据和其他材料的良好实践可能会给任何地方的作者带来不便(尽管有些实践可以让它变得更方便)。但对于科学事业来说，这是必不可少的。营利性企业不能获得免费通行证。</p><p> Haibe-Kains is less convinced. When he asked the Google Health team to share the code for its cancer-screening AI, he was told that it needed more testing. The team repeats this justification in a  formal reply to Haibe-Kains’s criticisms, also published in Nature: “We intend to subject our software to extensive testing before its use in a clinical environment, working alongside patients, providers and regulators to ensure efficacy and safety.” The researchers also said they did not have permission to share all the medical data they were using.</p><p>海贝-凯恩斯则不那么信服。当他要求谷歌健康团队分享其癌症筛查人工智能的代码时，他被告知需要更多的测试。该团队在对海贝-凯恩斯的批评的正式回复中重申了这一理由，该批评也发表在《自然》(Nature)杂志上：“我们打算在将我们的软件用于临床环境之前，对其进行广泛的测试，与患者、供应商和监管机构合作，以确保有效性和安全性。”研究人员还表示，他们没有获得分享他们正在使用的所有医疗数据的许可。</p><p> It’s not good enough, says Haibe-Kains: “If they want to build a product out of it, then I completely understand they won’t disclose all the information.” But he thinks that if you publish in a scientific journal or conference, you have a duty to release code that others can run. Sometimes that might mean sharing a version that is trained on less data or uses less expensive hardware. It might give worse results, but people will be able to tinker with it. “The boundaries between building a product versus doing research are getting fuzzier by the minute,” says Haibe-Kains. “I think as a field we are going to lose.”</p><p>这还不够好，海贝-凯恩斯说：“如果他们想用它来制造产品，那么我完全理解他们不会披露所有信息。”但他认为，如果你在科学期刊或会议上发表文章，你就有责任发布其他人可以运行的代码。有时，这可能意味着共享一个使用较少数据或使用较便宜硬件的版本。这可能会带来更糟糕的结果，但人们将能够对其进行修修补补。海贝-凯恩斯说：“制造产品和做研究之间的界限一分钟比一分钟模糊。”“我认为，作为一个领域，我们将会失败。”</p><p>  If companies are going to be criticized for publishing, why do it at all? There’s a degree of public relations, of course. But the main reason is that the best corporate labs are filled with researchers from universities. To some extent the culture at places like Facebook AI Research, DeepMind, and OpenAI is shaped by traditional academic habits. Tech companies also win by participating in the wider research community. All big AI projects at private labs are built on layers and layers of public research. And few AI researchers haven’t made use of open-source machine-learning tools like Facebook’s PyTorch or Google’s TensorFlow.</p><p>如果公司会因为出版而受到批评，那为什么要这样做呢？当然，也有一定程度的公关。但最主要的原因是，最好的企业实验室里挤满了来自大学的研究人员。在某种程度上，Facebook AI Research、DeepMind和OpenAI等机构的文化是由传统学术习惯塑造的。科技公司也通过参与更广泛的研究社区而获胜。私人实验室的所有大型人工智能项目都建立在层层公共研究的基础上。而且，很少有人工智能研究人员没有使用过Facebook的PyTorch或谷歌的TensorFlow等开源机器学习工具。</p><p> As more research is done in house at giant tech companies, certain trade-offs between the competing demands of business and research will become inevitable. The question is how researchers navigate them. Haibe-Kains would like to see journals like Nature split what they publish into separate streams: reproducible studies on one hand and tech showcases on the other.</p><p>随着大型科技公司进行更多的内部研究，商业和研究之间相互竞争的需求之间的某些权衡将不可避免。问题是研究人员如何驾驭它们。海贝-凯恩斯希望看到像《自然》这样的期刊将它们发表的内容分成不同的流：一方面是可重复的研究，另一方面是技术展示。</p><p> But Pineau is more optimistic. “I would not be working at Facebook if it did not have an open approach to research,” she says.</p><p>但皮诺更为乐观。她说：“如果Facebook没有一种开放的研究方法，我就不会在它工作。”</p><p> Other large corporate labs stress their commitment to transparency too. “Scientific work requires scrutiny and replication by others in the field,” says Kavukcuoglu. “This is a critical part of our approach to research at DeepMind.”</p><p>其他大型企业实验室也强调他们对透明度的承诺。Kavukcuoglu说：“科学工作需要该领域其他人的仔细检查和复制。”“这是我们在DeepMind进行研究的关键部分。”</p><p> “OpenAI has grown into something very different from a traditional laboratory,” says Kayla Wood, a spokesperson for the company. “Naturally that raises some questions.” She notes that OpenAI works with more than 80 industry and academic organizations in the Partnership on AI to think about long-term publication norms for research.</p><p>该公司发言人凯拉·伍德(Kayla Wood)表示：“OpenAI已经成长为与传统实验室截然不同的东西。”“这自然会引发一些问题。”她指出，OpenAI与人工智能伙伴关系中的80多个行业和学术组织合作，考虑研究的长期出版规范。</p><p> Pineau believes there’s something to that. She thinks AI companies are demonstrating a third way to do research, somewhere between Haibe-Kains’s two streams. She contrasts the intellectual output of private AI labs with that of pharmaceutical companies, for example, which invest billions in drugs and keep much of the work behind closed doors.</p><p>皮诺认为这是有原因的。她认为，人工智能公司正在展示第三种进行研究的方式，介于海贝-凯恩斯的两种方式之间。她将私营人工智能实验室的智力产出与制药公司的智力产出进行了对比，例如，制药公司在药物上投资数十亿美元，并将大部分工作关起门来。</p><p> The long-term impact of the practices introduced by Pineau and others remains to be seen. Will habits be changed for good? What difference will it make to AI’s uptake outside research? A lot hangs on the direction AI takes. The trend for ever larger models and data sets—favored by OpenAI, for example—will continue to make the cutting edge of AI inaccessible to most researchers. On the other hand, new techniques, such as  model compression and  few-shot learning, could reverse this trend and allow more researchers to work with smaller, more efficient AI.</p><p>皮诺和其他人引入的做法的长期影响仍有待观察。习惯会永远改变吗？这将对人工智能在研究之外的吸收产生什么影响？这在很大程度上取决于人工智能的发展方向。越来越大的模型和数据集的趋势-例如，OpenAI所青睐的-将继续使大多数研究人员无法接触到人工智能的前沿。另一方面，新的技术，如模型压缩和少镜头学习，可以扭转这一趋势，并允许更多的研究人员与更小、更高效的人工智能合作。</p><p> Either way, AI research will still be dominated by large companies. If it’s done right, that doesn’t have to be a bad thing, says Pineau: “AI is changing the conversation about how industry research labs operate.” The key will be making sure the wider field gets the chance to participate. Because the trustworthiness of AI, on which so much depends, begins at the cutting edge.</p><p>无论哪种方式，人工智能研究仍将由大公司主导。皮诺说，如果做得对，这不一定是件坏事：“人工智能正在改变有关行业研究实验室如何运作的对话。”关键是确保更广泛的领域有机会参与进来。因为人工智能的可信性在很大程度上取决于它的可信度，它始于尖端。</p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://www.technologyreview.com/2020/11/12/1011944/artificial-intelligence-replication-crisis-science-big-tech-google-deepmind-facebook-openai/">https://www.technologyreview.com/2020/11/12/1011944/artificial-intelligence-replication-crisis-science-big-tech-google-deepmind-facebook-openai/</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/硬件/">#硬件</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/科学家/">#科学家</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/代码/">#代码</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/人工智能/">#人工智能</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/research/">#research</a></button></div></div><div class="shadow p-3 mb-5 bg-white rounded clearfix"><div class="container"><div class="row"><div class="col-sm"><div><a target="_blank" href="/story/1035066.html"><img src="http://img2.diglog.com/img/2020/11/thumb_21b814492d1bc1bb845e807af2d1680f.png" class="img-fluid" onerror="this.style.display='none'"></a></div><div class="item_title"><a target="_blank" href="/story/1035066.html">大浪可能损坏Native Instruments硬件</a></div><span class="my_story_list_date">2020-11-14 11:47</span></div><div class="col-sm"><div><a target="_blank" href="/story/1034917.html"><img src="http://img2.diglog.com/img/2020/11/thumb_48c8187db4e8d7358e9b3ba2566febcb.png" class="img-fluid" onerror="this.style.display='none'"></a></div><div class="item_title"><a target="_blank" href="/story/1034917.html">骑行硬件彩票</a></div><span class="my_story_list_date">2020-11-13 19:36</span></div><div class="col-sm"><div><a target="_blank" href="/story/1034844.html"><img src="http://img2.diglog.com/img/2020/11/thumb_7e158e30fd4e364ef3ccf9b99a500622.png" class="img-fluid" onerror="this.style.display='none'"></a></div><div class="item_title"><a target="_blank" href="/story/1034844.html">苹果公司的Greg Joswiak、Craig Federighi和John Ternus就M1的开发、Mac的未来、购买第一版硬件等问题进行了采访</a></div><span class="my_story_list_date">2020-11-13 19:0</span></div><div class="col-sm"><div><a target="_blank" href="/story/1032932.html"><img src="http://img2.diglog.com/img/2020/11/thumb_658894646018d3332aa745e8ce20f3d5.jpg" class="img-fluid" onerror="this.style.display='none'"></a></div><div class="item_title"><a target="_blank" href="/story/1032932.html">FPGA PS2键盘打字机(硬件历险记，第8部分)</a></div><span class="my_story_list_date">2020-11-3 14:45</span></div></div></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/美国/">#美国</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/谷歌/">#谷歌</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/linux/">#linux</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/程序/">#程序</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy; 2020 diglog.com </div></div></body></html>