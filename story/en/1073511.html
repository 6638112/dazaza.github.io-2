<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>人工智能合成的人脸与真实人脸无法区分，而且更可信AI-synthesized faces are indistinguishable from real faces and more trustworthy</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">AI-synthesized faces are indistinguishable from real faces and more trustworthy<br/>人工智能合成的人脸与真实人脸无法区分，而且更可信</h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2022-02-15 20:07:10</div><div class="page_narrow text-break page_content"><p>Edited by William Press, Computer Sciences and Integrative Biology, University of Texas at Austin, Austin, TX; received November 11, 2021; accepted December 20, 2021</p><p>William Press，计算机科学和综合生物学，德克萨斯大学，奥斯丁，奥斯丁，TX编辑；2021年11月11日收到；接受2021年12月20日</p><p>    Artificial intelligence (AI)–synthesized text, audio, image, and video are being weaponized for the purposes of nonconsensual intimate imagery, financial fraud, and disinformation campaigns. Our evaluation of the photorealism of AI-synthesized faces indicates that synthesis engines have passed through the uncanny valley and are capable of creating faces that are indistinguishable—and more trustworthy—than real faces.</p><p>人工智能（AI）——合成文本、音频、图像和视频正在被武器化，用于非感官亲密图像、金融欺诈和虚假信息活动。我们对人工智能合成人脸照片真实性的评估表明，合成引擎已经穿过了神秘的山谷，能够创建出比真实人脸更难以区分、更可信的人脸。</p><p>  Artificial intelligence (AI)–powered audio, image, and video synthesis—so-called deep fakes—has democratized access to previously exclusive Hollywood-grade, special effects technology. From synthesizing speech in anyone’s voice ( 1) to synthesizing an image of a fictional person ( 2) and swapping one person’s identity with another or altering what they are saying in a video ( 3), AI-synthesized content holds the power to entertain but also deceive.</p><p>人工智能（AI）——由音频、图像和视频合成（即所谓的深度假货）驱动的技术，已经使人们对之前独家使用的好莱坞级特效技术的使用民主化。从合成任何人声音中的语音（1）到合成虚构人物的图像（2），再到将一个人的身份与另一个人的身份交换，或改变他们在视频中所说的内容（3），人工智能合成的内容既有娱乐的力量，也有欺骗的力量。</p><p> Generative adversarial networks (GANs) are popular mechanisms for synthesizing content. A GAN pits two neural networks—a generator and discriminator—against each other. To synthesize an image of a fictional person, the generator starts with a random array of pixels and iteratively learns to synthesize a realistic face. On each iteration, the discriminator learns to distinguish the synthesized face from a corpus of real faces; if the synthesized face is distinguishable from the real faces, then the discriminator penalizes the generator. Over multiple iterations, the generator learns to synthesize increasingly more realistic faces until the discriminator is unable to distinguish it from real faces (see  Fig. 1 for example real and synthetic faces).</p><p>生成性对抗网络（GAN）是合成内容的常用机制。GAN使两个神经网络——生成器和鉴别器——相互对立。要合成虚构人物的图像，生成器从随机像素阵列开始，迭代学习合成真实人脸。在每次迭代中，鉴别器学习将合成人脸与真实人脸库区分开来；如果合成的人脸可以与真实人脸区分开来，那么鉴别器会惩罚生成器。在多次迭代中，生成器学习合成越来越真实的人脸，直到鉴别器无法将其与真实人脸区分开来（参见图1，例如真实人脸和合成人脸）。</p><p>  Much has been written in the popular press about the potential threats of deep fakes, including the creation of nonconsensual intimate imagery (more commonly referred to by the misnomer “revenge porn”), small- to large-scale fraud, and adding jet fuel to already dangerous disinformation campaigns. Perhaps most pernicious is the consequence that, in a digital world in which any image or video can be faked, the authenticity of any inconvenient or unwelcome recording can be called into question.</p><p>大众媒体已经写了很多关于深度造假的潜在威胁的文章，包括创造非感官的亲密形象（通常被误称为“复仇色情”）、小规模到大规模的欺诈，以及为本已危险的虚假信息活动添加喷气燃料。也许最有害的后果是，在任何图像或视频都可能被伪造的数字世界中，任何不方便或不受欢迎的记录的真实性都可能受到质疑。</p><p> Although progress has been made in developing automatic techniques to detect deep-fake content (e.g., refs.  4  ⇓– 6), current techniques are not efficient or accurate enough to contend with the torrent of daily uploads ( 7). The average consumer of online content, therefore, must contend with sorting out the real from the fake. We performed a series of perceptual studies to determine whether human participants can distinguish state-of-the-art GAN-synthesized faces from real faces and what level of trust the faces evoked.</p><p>尽管在开发自动技术以检测深度虚假内容方面取得了进展（例如，参考文献4）⇓– 6） ，目前的技术没有足够的效率或准确性来应对每日上传的洪流（7）。因此，网络内容的普通消费者必须努力区分真假。我们进行了一系列感性研究，以确定人类参与者是否能够区分最先进的合成人脸和真实人脸，以及这些人脸引发的信任程度。</p><p> In this study, 315 participants classified, one at a time, 128 of the 800 faces as real or synthesized. Shown in  Fig. 2 A is the distribution of participant accuracy (blue bars). The average accuracy is 48.2% (95% CI [47.1%, 49.2%]), close to chance performance of 50%, with no response bias:      d ′ = − 0.09;      β = 0.99. Two repeated-measures binary logistic regression analyses were conducted—one for real and one for synthetic faces—to examine the effect of stimuli gender and race on accuracy. For real faces, there was a significant gender × race interaction,       χ 2 ( 3 , N = 315 ) = 95.03 , P &lt; 0.001. Post hoc Bonferroni-corrected comparisons revealed that mean accuracy was higher for male East Asian faces than female East Asian faces and higher for male White faces than female White faces. For synthetic faces, there was also a significant gender × race interaction,       χ 2 ( 3 , N = 315 ) = 68.41 , P &lt; 0.001. For both male and female synthetic faces, White faces were the least accurately classified, and male White faces were less accurately classified than female White faces. We hypothesize that White faces are more difficult to classify because they are overrepresented in the StyleGAN2 training dataset and are therefore more realistic.</p><p>在这项研究中，315名参与者将800张脸中的128张分类为真实或合成。图2A显示了参与者准确度的分布（蓝色条）。平均准确率为48.2%（95%CI[47.1%，49.2%），接近50%的偶然表现，无反应偏差：d′=− 0.09;      β = 0.99. 两次重复测量二元logistic回归分析，一次用于真实人脸，另一次用于合成人脸，以检验刺激物性别和种族对准确性的影响。对于真实面孔，存在显著的性别×种族交互作用，χ2（3，N=315）=95.03，P&lt；0.001. 事后Bonferroni校正的比较显示，东亚男性面孔的平均准确率高于东亚女性面孔，而白人男性面孔的平均准确率高于白人女性面孔。对于合成面孔，也存在显著的性别×种族交互作用，χ2（3，N=315）=68.41，P&lt；0.001. 对于男性和女性合成人脸而言，白脸的分类最不准确，而男性白脸的分类精度低于女性白脸。我们假设白脸更难分类，因为它们在StyleGAN2训练数据集中的比例过高，因此更真实。</p><p> In this study, 219 new participants, with training and trial-by-trial feedback, classified 128 faces taken from the same 800 set of faces as in experiment 1. Shown in  Fig. 2 A is the distribution of participant accuracy (orange bars). The average accuracy improved slightly to 59.0% (95% CI [57.7%, 60.4%]), with no response bias:      d ′ = 0.46;      β = 0.99. Despite providing trial-by-trial feedback, there was no improvement in accuracy over time, with an average accuracy of 59.3% (95% CI [57.8%, 60.7%]) for the first set of 64 faces and 58.8% (95% CI [57.4%, 60.3%]) for the second set of 64 faces. Further analyses to examine the effect of gender and race on accuracy replicated the primary findings of experiment 1. This analysis again revealed that, for both male and female synthetic faces, White faces were the most difficult to classify.</p><p>在这项研究中，219名新参与者通过训练和逐次试验反馈，从实验1中的800组面孔中，对128张面孔进行了分类。图2A显示了参与者准确度的分布（橙色条）。平均准确率略微提高到59.0%（95%可信区间[57.7%，60.4%），无反应偏差：d′=0.46；β = 0.99. 尽管提供了一次又一次的试验反馈，但随着时间的推移，准确率没有提高，第一组64张脸的平均准确率为59.3%（95%可信区间[57.8%，60.7%]），第二组64张脸的平均准确率为58.8%（95%可信区间[57.4%，60.3%]）。进一步分析性别和种族对准确性的影响，重复了实验1的主要发现。这项分析再次表明，对于男性和女性合成面孔，白色面孔是最难分类的。</p><p> When made aware of rendering artifacts and given feedback, there was a reliable improvement in accuracy; however, overall performance remained only slightly above chance. The lack of improvement over time suggests that the impact of feedback is limited, presumably because some synthetic faces simply do not contain perceptually detectable artifacts.</p><p>当了解渲染工件并给出反馈时，准确度有了可靠的提高；然而，总体表现仅略高于预期。随着时间的推移，缺乏改善表明反馈的影响是有限的，可能是因为一些合成人脸根本不包含可感知的伪影。</p><p> Faces provide a rich source of information, with exposure of just milliseconds sufficient to make implicit inferences about individual traits such as trustworthiness ( 8). We wondered whether synthetic faces activate the same judgements of trustworthiness. If not, then a perception of trustworthiness could help distinguish real from synthetic faces.</p><p>面部表情提供了丰富的信息来源，仅仅几毫秒的曝光时间就足以对个体特征（如可信度）做出隐含推断（8）。我们想知道合成面孔是否也会激活同样的可信度判断。如果不是，那么信任感可以帮助区分真实面孔和合成面孔。</p><p> In this study, 223 participants rated the trustworthiness of 128 faces taken from the same set of 800 faces on a scale of 1 (very untrustworthy) to 7 (very trustworthy) ( 9). Shown in  Fig. 2 B is the distribution of average ratings (by averaging the ordinal ratings, we are assuming a linear rating scale). The average rating for real faces (blue bars) of 4.48 is less than the rating of 4.82 for synthetic faces (orange bars). Although only 7.7% more trustworthy, this difference is significant [     t ( 222 ) = 14.6 , P &lt; 0.001 , d = 0.49]. Although a small effect, Black faces were rated more trustworthy than South Asian faces, but, otherwise, there was no effect across race. Women were rated as significantly more trustworthy than men, 4.94 as compared to 4.36 [     t ( 222 ) = 19.5 , P &lt; 0.001 , d = 0.82].</p><p>在这项研究中，223名参与者对同一组800张脸中的128张脸的可信度进行了评分，评分范围为1（非常不可信）到7（非常可信）（9）。图2b所示为平均评分的分布（通过平均顺序评分，我们假设为线性评分量表）。真实面（蓝色条）的平均评级为4.48，低于合成面（橙色条）的评级为4.82。虽然只有7.7%的可信度更高，但这种差异是显著的[t（222）=14.6，P&lt；0.001，d=0.49]。虽然影响很小，但黑人面孔比南亚面孔更值得信任，但除此之外，在整个种族中没有影响。女性比男性更值得信赖，分别为4.94和4.36[t（222）=19.5，P&lt；0.001，d=0.82]。</p><p> Shown in  Fig. 3 are the four most ( Fig. 3,  Top) and four least ( Fig. 3,  Bottom) trustworthy faces. The top three most trustworthy faces are synthetic (S), while the bottom four least trustworthy faces are real (R). A smiling face is more likely to be rated as trustworthy, but 65.5% of our real faces and 58.8% of synthetic faces are smiling, so facial expression alone cannot explain why synthetic faces are rated as more trustworthy.</p><p>图3显示了四个最值得信赖的面孔（图3，上图）和四个最不值得信赖的面孔（图3，下图）。前三个最值得信任的人脸是合成的（S），而后四个最不值得信任的人脸是真实的（R）。笑脸更有可能被评为值得信赖的面孔，但65.5%的真实面孔和58.8%的合成面孔都在微笑，因此单凭面部表情无法解释为什么合成面孔被评为更值得信赖。</p><p> Synthetically generated faces are not just highly photorealistic, they are nearly indistinguishable from real faces and are judged more trustworthy. This hyperphotorealism is consistent with recent findings ( 10,  11). These two studies did not contain the same diversity of race and gender as ours, nor did they match the real and synthetic faces as we did to minimize the chance of inadvertent cues. While it is less surprising that White male faces are highly realistic—because these faces dominate the neural network training—we find that the realism of synthetic faces extends across race and gender. Perhaps most interestingly, we find that synthetically generated faces are more trustworthy than real faces. This may be because synthesized faces tend to look more like average faces which themselves are deemed more trustworthy ( 12). Regardless of the underlying reason, synthetically generated faces have emerged on the other side of the uncanny valley. This should be considered a success for the fields of computer graphics and vision. At the same time, easy access ( https://thispersondoesnotexist.com) to such high-quality fake imagery has led and will continue to lead to various problems, including more convincing online fake profiles and—as synthetic audio and video generation continues to improve—problems of nonconsensual intimate imagery ( 13), fraud, and disinformation campaigns, with serious implications for individuals, societies, and democracies.</p><p>合成生成的人脸不仅具有高度的照片真实感，而且几乎无法与真实人脸区分开来，而且被认为更可信。这种超写实主义与最近的研究结果一致（10,11）。这两项研究的种族和性别多样性与我们的研究不同，也没有像我们那样匹配真实和合成的面孔，以尽量减少无意中的线索。虽然白人男性面部高度逼真并不令人惊讶，因为这些面部在神经网络训练中占主导地位，但我们发现，合成面部的真实感跨越种族和性别。也许最有趣的是，我们发现合成人脸比真实人脸更可信。这可能是因为合成人脸看起来更像普通人脸，而普通人脸本身被认为更可信（12）。不管背后的原因是什么，人工合成的人脸已经出现在神秘山谷的另一边。这应该被认为是计算机图形学和视觉领域的成功。同时，方便访问（https://thispersondoesnotexist.com)这些高质量的虚假图像已经并将继续导致各种问题，包括更具说服力的在线虚假个人资料，以及合成音频和视频生成继续改善非感官亲密图像（13）、欺诈和虚假信息活动的问题，这些问题对个人、社会和个人都有严重影响，民主国家。</p><p> We, therefore, encourage those developing these technologies to consider whether the associated risks are greater than their benefits. If so, then we discourage the development of technology simply because it is possible. If not, then we encourage the parallel development of reasonable safeguards to help mitigate the inevitable harms from the resulting synthetic media. Safeguards could include, for example, incorporating robust watermarks into the image and video synthesis networks that would provide a downstream mechanism for reliable identification ( 14). Because it is the democratization of access to this powerful technology that poses the most significant threat, we also encourage reconsideration of the often laissez-faire approach to the public and unrestricted releasing of code for anyone to incorporate into any application.</p><p>因此，我们鼓励开发这些技术来考虑相关风险是否大于它们的收益。如果是这样的话，那么我们仅仅因为技术的发展是可能的，就不鼓励技术的发展。如果没有，那么我们鼓励平行开发合理的保障措施，以帮助减轻由此产生的合成介质不可避免的危害。例如，保护措施可能包括将鲁棒水印纳入图像和视频合成网络，从而提供可靠识别的下游机制（14）。由于这项强大技术的使用民主化构成了最大的威胁，我们还鼓励重新考虑对公众采取的通常是自由放任的方式，以及不受限制地发布代码，以便任何人将其纳入任何应用程序。</p><p> At this pivotal moment, and as other scientific and engineering fields have done, we encourage the graphics and vision community to develop guidelines for the creation and distribution of synthetic media technologies that incorporate ethical guidelines for researchers, publishers, and media distributors.</p><p>在这个关键时刻，正如其他科学和工程领域所做的那样，我们鼓励图形和视觉界为合成媒体技术的创造和传播制定指导方针，其中包括研究人员、出版商和媒体分销商的道德准则。</p><p> We selected 400 faces synthesized using the state-of-the-art StyleGAN2 ( 2), ensuring diversity across gender (200 women; 200 men), estimated age (ensuring a range of ages from children to older adults), and race (100 African American or Black, 100 Caucasian, 100 East Asian, and 100 South Asian). To reduce extraneous cues, we only included images with a mostly uniform background, and devoid of any obvious rendering artifacts. This culling of obvious artifacts makes the perceptual task harder. Because the synthesis process is so easy, however, it is reasonable to assume that any intentionally deceptive use of a synthetic face will not contain obvious visual artifacts.</p><p>我们选择了400张使用最先进样式2（2）合成的脸，确保性别（200名女性；200名男性）、估计年龄（确保从儿童到老年人的年龄范围）和种族（100名非裔美国人或黑人、100名白人、100名东亚人和100名南亚人）的多样性。为了减少额外的线索，我们只包括背景基本一致的图像，并且没有任何明显的渲染瑕疵。这种对明显工件的剔除使得感知任务更加困难。然而，由于合成过程非常简单，因此可以合理地假设，任何故意欺骗合成人脸的使用都不会包含明显的视觉伪影。</p><p> For each synthesized face, we collected a matching real face (in terms of gender, age, race, and overall appearance) from the underlying face database used in the StyleGAN2 learning stage. A standard convolutional neural network descriptor ( 15) was used to extract a low-dimensional, perceptually meaningful ( 16) representation of each synthetic face. The extracted representation for each synthetic face—a 4,096-D real-valued vector        v → s—was compared with all other facial representations in the data set of 70,000 real faces to find the most similar face. The real face with representation        v → r with minimal Euclidean distance to        v → s, and satisfying our qualitative selection criteria, is selected as the matching face. As with the synthetic faces, to reduce extraneous cues, we only included images 1) with a mostly uniform background, 2) with unobstructed faces (e.g., no hats or hands in front of face), 3) in focus and high resolution, and 4) with no obvious writing or logos on clothing. We visually inspected up to 50 of the best matched faces and selected the one that met the above criteria and was also matched in terms of overall face position, posture, and expression, and presence of glasses and jewelry. Shown in  Fig. 4 are representative examples of these matched real and synthetic faces.</p><p>对于每个合成的人脸，我们从StyleGAN2学习阶段使用的基础人脸数据库中收集了一张匹配的真实人脸（性别、年龄、种族和整体外观）。使用标准卷积神经网络描述符（15）提取每个合成人脸的低维、有感知意义（16）表示。每个合成人脸的提取表示——4096-D实值向量v→ 在70000张真实人脸的数据集中，s-与所有其他人脸表示进行比较，以找到最相似的人脸。代表v的真实面孔→ r与v的欧氏距离最小→ s、 并满足我们的定性选择标准，被选为匹配面。与合成人脸一样，为了减少外部线索，我们只包括1）背景基本一致的图像，2）无障碍的人脸（例如脸前没有帽子或手），3）聚焦和高分辨率，以及4）衣服上没有明显的文字或标志。我们目测了多达50张最匹配的脸，选择了一张符合上述标准的脸，并且在整体面部位置、姿势、表情以及眼镜和珠宝的存在方面也匹配。图4所示为这些匹配的真实面和合成面的代表性示例。</p><p> For experiment 1 (baseline), we recruited 315 participants from Amazon’s Mechanical Turk Master Workers. Each participant first read a brief introduction explaining the purpose of the study and a brief explanation of what a synthetic face is. Before beginning, each participant was informed they would be paid $5 for their time, and an extra $5 if their overall accuracy was in the top 20% of response accuracies. Participants were also informed they would see 10 catch trials of obviously synthetic faces with glaring rendering errors. A failure to respond correctly to at least nine of these trials led to the participants not being paid and their data being excluded from our study. Each participant then saw 128 images, one at a time, and specified whether the image was real or synthetic. Participants had an unlimited amount of time to respond and were not provided with feedback after each response.</p><p>对于实验1（基线），我们从亚马逊的机械土耳其人大师那里招募了315名参与者。每位参与者首先阅读一篇简短的介绍，解释研究的目的，并简要解释什么是合成脸。在开始之前，每个参与者都被告知，他们将获得5美元的时间报酬，如果他们的总体准确度在回答准确度的前20%，则额外获得5美元。参与者还被告知，他们将看到10个明显合成的脸的抓捕试验，这些脸有明显的渲染错误。在这些试验中，至少有九次未能做出正确反应，导致参与者没有获得报酬，他们的数据被排除在我们的研究之外。然后每个参与者看到128张图片，一次一张，并指定图片是真实的还是合成的。参与者有无限的时间回复，每次回复后都没有收到反馈。</p><p> For experiment 2 (training and feedback), we recruited another 219 Mechanical Turk Master Workers (we had fewer participants in this study because we excluded any participants who completed the first study). Each participant first read a brief introduction explaining the purpose of the study and a brief explanation of what a synthetic face is. Participants were then shown a short tutorial describing examples of specific rendering artifacts that can be used to identify synthetic faces. All other experimental conditions were the same as in experiment 1, except that participants received feedback after each response.</p><p>在实验2（培训和反馈）中，我们又招募了219名土耳其机械大师（本研究参与者较少，因为我们排除了任何完成第一项研究的参与者）。每位参与者首先阅读一篇简短的介绍，解释研究的目的，并简要解释什么是合成脸。然后向参与者展示了一个简短的教程，描述了可用于识别合成人脸的特定渲染工件的示例。所有其他实验条件与实验1相同，只是参与者在每次回答后都会收到反馈。</p><p> For experiment 3 (trustworthiness), we recruited 223 Mechanical Turk Master Workers. Each participant first read a brief introduction explaining that the purpose of the study was to assess the trustworthiness of a face on a scale of 1 (very untrustworthy) to 7 (very trustworthy). Because there was no correct answer here, no trial-by-trial feedback was provided. Participants were also informed they would see 10 catch trials of faces in which the numeric trustworthy rating was directly overlaid atop the face. A failure to correctly report the specified rating on at least nine of these trials led to the participants not being paid and their data being excluded from our study. Each participant then saw 128 images, one at a time, and was asked to rate the trustworthiness. Participants had an unlimited amount of time to respond.</p><p>在实验3（可信度）中，我们招募了223名土耳其机械大师。每位参与者首先阅读了一篇简短的介绍，说明该研究的目的是在1（非常不可信）到7（非常可信）的范围内评估一张脸的可信度。因为这里没有正确的答案，所以没有提供逐个试验的反馈。参与者还被告知，他们将看到10个面部抓捕试验，其中数字可信评级直接覆盖在面部。在这些试验中，至少有九次未能正确报告指定的评分，导致参与者没有获得报酬，他们的数据被排除在我们的研究之外。然后每个参与者看到128张图片，一次一张，并被要求对可信度进行评分。参与者有无限的时间做出回应。</p><p> All experiments were carried out with the approval of the University of California, Berkeley’s Office for Protection of Human Subjects (Protocol ID 2019-07-12422) and Lancaster University’s Faculty of Science and Technology Research Ethics Committee (Protocol ID FST20076). Participants gave fully informed consent prior to taking part in the study.</p><p>所有实验都是在加利福尼亚大学、伯克利保护人类学科办公室（协议ID 2019-0712422）和兰开斯特大学科学技术研究伦理委员会（协议ID FST200 76）的批准下进行的。参与者在参与研究前给予充分知情同意。</p><p> Images have been deposited in GitHub ( https://github.com/NVlabs/stylegan2 and  https://github.com/NVlabs/ffhq-dataset). Anonymized experimental stimuli and data have been deposited in the Open Science Framework ( https://osf.io/ru36d/).</p><p>图像已存放在GitHub（https://github.com/NVlabs/stylegan2和https://github.com/NVlabs/ffhq-dataset).匿名实验刺激和数据已存储在开放科学框架（https://osf.io/ru36d/).</p><p> We thank Erik Härkönen, Jaakko Lehtinen, and David Luebke for their masterful synthesis of faces.</p><p>我们感谢Erik Härkönen、Jaakko Lehtinen和David Luebke对人脸的巧妙合成。</p><p> Author contributions: S.J.N. and H.F. designed research, performed research, contributed new reagents/analytic tools, analyzed data, and wrote the paper.</p><p>作者贡献：S.J.N.和H.F.设计研究，执行研究，贡献新试剂/分析工具，分析数据，并撰写论文。</p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/人工智能/">#人工智能</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/rust/">#rust</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/合成/">#合成</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/faces/">#faces</a></button></div></div><div class="shadow p-3 mb-5 bg-white rounded clearfix"><div class="container"><div class="row"><div class="col-sm"><div><a target="_blank" href="/story/1072773.html"><img src="http://img2.diglog.com/img/2022/2/thumb_1aa7e3bf64e0d6f7ea1885110c50d25f.png" class="img-fluid" onerror="this.style.display='none'"></a></div><div class="item_title"><a target="_blank" href="/story/1072773.html">GPT-3人工智能能写喜剧吗？</a></div><span class="my_story_list_date">2022-2-13 1:34</span></div><div class="col-sm"><div><a target="_blank" href="/story/1072442.html"><img src="http://img2.diglog.com/img/2021/8/thumb_84854ed0e861b1a34390a064a6d80277.jpg" class="img-fluid" onerror="this.style.display='none'"></a></div><div class="item_title"><a target="_blank" href="/story/1072442.html">人工智能帮助缓解全球航运危机的 5 种方式</a></div><span class="my_story_list_date">2021-8-10 7:4</span></div><div class="col-sm"><div><a target="_blank" href="/story/1072189.html"><img src="http://img2.diglog.com/img/2021/8/thumb_f1652b5e3202f62a36a3343aeb4fe94e.jpg" class="img-fluid" onerror="this.style.display='none'"></a></div><div class="item_title"><a target="_blank" href="/story/1072189.html">以苹果、亚马逊和优步为客户的呼叫中心运营商 Teleperformance 希望通过人工智能摄像头监控在哥伦比亚在家工作的员工</a></div><span class="my_story_list_date">2021-8-9 5:4</span></div><div class="col-sm"><div><a target="_blank" href="/story/1071993.html"><img src="http://img2.diglog.com/img/2021/8/thumb_9123c8c8e5365ee273a45e21dcec25a5.jpg" class="img-fluid" onerror="this.style.display='none'"></a></div><div class="item_title"><a target="_blank" href="/story/1071993.html">在人工智能的推动下，氯胺酮成为一种潜在的罕见疾病治疗方法</a></div><span class="my_story_list_date">2021-8-8 1:15</span></div></div></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/谷歌/">#谷歌</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy;2012-2021 diglog.com </div></div></body></html>