<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>为确保包容性，拜登管理局必须对AI发展举措加倍 
				To ensure inclusivity, the Biden administration must double down on AI development initiatives			</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">
				To ensure inclusivity, the Biden administration must double down on AI development initiatives			<br/>为确保包容性，拜登管理局必须对AI发展举措加倍 </h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2021-04-23 00:39:18</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2021/4/f57913c8a09852bc754a1a4e97ef0011.jpg"><img src="http://img2.diglog.com/img/2021/4/f57913c8a09852bc754a1a4e97ef0011.jpg" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>Miriam Vogel is the president and CEO of  EqualAI, a nonprofit organization focused on reducing unconscious bias in artificial intelligence.</p><p>Miriam Vogel是班达总统兼首席执行官，这是一个非营利组织，一个非营利组织专注于减少人工智能中的无意识偏见。</p><p>  Left unchecked, seemingly neutral artificial intelligence (AI) tools can and will perpetuate inequalities and, in effect, automate discrimination. Tech-enabled harms have already surfaced in credit decisions,  health care services, and  advertising.</p><p>  留下未选中，看似中立的人工智能（AI）工具可以延续不平等，实际上是自动的歧视。支持技术的危害已经符合信贷决策，医疗保健服务和广告。</p><p> To prevent this recurrence and growth at scale, the Biden administration must clarify current laws pertaining to AI and machine learning models — both in terms of how we will evaluate use by private actors and how we will govern AI usage within our government systems.</p><p> 为了防止这种复发和增长以规模，拜登管理必须澄清与AI和机器学习模式有关的现行法律 - 无论如何我们将如何评估私人行为者以及我们如何管理我们的政府系统内的AI使用。</p><p>  The administration has put a strong foot forward, from key appointments in the tech space to issuing an  Executive Order on the first day in office that established an Equitable Data Working Group. This has comforted skeptics concerned both about the U.S. commitment to AI development and to ensuring equity in the digital space.</p><p>  政府在技术领域的关键任命中迈出了强势势头，以在办公室的第一天发出一项行政命令，该组织建立了一个公平的数据工作组。这让我们对美国对AI发展的承诺以及确保数字空间股权的承诺，这令人怀疑。</p><p> But that will be fleeting unless the administration shows strong resolve in making AI funding a reality and establishing leaders and structures necessary to safeguard its development and use.</p><p> 但这将是短暂的，除非管理局表现出强烈的决心使AI为实现现实和建立保护其开发和使用所需的领导者和建筑物，否则就是强烈的决心。</p><p>  There has been a seismic shift at the federal level in AI policy and in stated commitments to equality in tech. A number of high profile appointments by the Biden administration — from Dr. Alondra Nelson as Deputy of OSTP, to Tim Wu at the NEC, to (our former senior advisor) Kurt Campbell at the NSC — signal that significant attention will be paid to inclusive AI development by experts on the inside.</p><p>  在AI政策的联邦水平和技术方面的平等承诺中存在地震转变。 Biden Administration的许多高调预约 - 从Alondra Nelson博士作为OSTP副议员，即在NEC的蒂姆吴，到（我们的前高级顾问）Kurt Campbell在NSC  - 信号中将支付重大关注AI通过内部专家开发。</p><p> The  NSCAI final report includes recommendations that could prove critical to enabling better foundations for inclusive AI development, such as creating new talent pipelines through a  U.S. Digital Service Academy to train current and future employees.</p><p> NSCAI的最终报告包括可能向能够为包容性AI开发实现更好的基础，例如通过美国数字服务学院创建新的人才管道来培养当前和未来员工的建议。 </p><p> The report also recommends establishing a new  Technology Competitiveness Council led by the Vice President. This could prove essential in ensuring that the nation’s commitment to AI leadership remains a priority at the highest levels. It makes good sense to have the administration’s leadership on AI spearheaded by VP Harris in light of her strategic partnership with the President, her  tech policy savvy and her focus on civil rights.</p><p>该报告还建议建立由副总统领导的新技术竞争力委员会。这可能证明是确保国家对AI领导力的承诺仍然是最高水平的优先事项。凭借与总统，她的技术政策稳定的战略伙伴关系和焦点公民权利，将政府对VP哈里斯担任Spearhead的领导，使政府对哈里斯的武器头发的领导有所了解。</p><p>  We know AI is powerful in its ability to create efficiencies, such as plowing through thousands of resumes to identify potentially suitable candidates. But it can also scale discrimination, such as the  Amazon hiring tool that prioritized male candidates or “ digital redlining” of credit based on race.</p><p>  我们知道AI在创造效率的能力方面是强大的，例如借导数千次恢复以确定潜在合适的候选人。但它还可以扩展歧视，例如基于比赛的信用的优先考虑男性候选人或“数字红线”的亚马逊招聘工具。</p><p> The Biden administration should issue an Executive Order (EO) to agencies inviting ideation on ways AI can improve government operations. The EO should also mandate checks on AI used by the USG to ensure it’s not spreading discriminatory outcomes unintentionally.</p><p> 拜登政府应向邀请IDEATION的机构发出一项行政命令（EO），以改善政府运营。 EO还应要求USG使用的AI支票，以确保它没有无意地传播歧视性结果。</p><p> For instance, there must be a routine schedule in place where AI systems are evaluated to ensure embedded, harmful biases are not resulting in recommendations that are discriminatory or inconsistent with our democratic, inclusive values — and reevaluated routinely given that AI is constantly iterating and learning new patterns.</p><p> 例如，在评估AI系统以确保嵌入的有害偏差没有导致与我们民主，包容价值不一致的建议没有导致歧视或不一致的建议，并且谨慎地重新评估AI，因此必须存在常规时间表 - 并常常重新评估AI不断迭代和学习新模式。</p><p>  Putting a responsible AI governance system in place is particularly critical in the U.S. Government, which is required to offer  due  process protection when denying certain benefits. For instance, when AI is used to determine allocation of  Medicaid benefits, and such benefits are modified or denied based on an algorithm, the government must be able to explain that outcome,  aptly termed technological due process.</p><p>  将负责任的AI治理系统置于美国政府中特别关键，在拒绝某些福利时需要提供适当的过程保护。例如，当AI用于确定医疗补助福利的分配时，并根据算法修改或拒绝这种益处，政府必须能够解释该结果，适当称为技术到期过程。</p><p> If decisions are delegated to automated systems without  explainability, guidelines and human oversight, we find ourselves in the untenable situation where this basic constitutional right is being denied.</p><p> 如果在没有解释性，指导和人类监督的情况下委派给自动化系统的决策，我们发现自己在这种基本宪法权利被拒绝的地方。</p><p> Likewise, the administration has immense power to ensure that AI safeguards by key corporate players are in place through its procurement power. Federal contract spending was expected to  exceed $600 billion in fiscal 2020, even before including pandemic economic stimulus funds. The USG could effectuate tremendous impact by issuing a checklist for federal procurement of AI systems — this would ensure the government’s process is both rigorous and universally applied, including relevant civil rights considerations.</p><p> 同样，政府有巨大的力量，以确保按主要企业参与者通过其采购权力取得均衡的AI保障措施。联邦合同支出预计将超过2020财年超过6000亿美元，甚至在包括大流行经济刺激基金之前。 USG可以通过发布AI系统的联邦采购清单来实现巨大的影响 - 这将确保政府的进程既严谨和普遍应用，包括相关的民权考虑。 </p><p>  The government holds another powerful lever to protect us from AI harms: its investigative and prosecutorial authority. An Executive Order instructing agencies to clarify applicability of current laws and regulations (e.g., ADA, Fair Housing, Fair Lending, Civil Rights Act, etc.) when determinations are reliant on AI-powered systems could result in a global reckoning. Companies operating in the U.S. would have unquestionable motivation to check their AI systems for harms against protected classes.</p><p>政府持有另一种强大的杠杆来保护我们免受伤害：其调查和检察机构。行政命令指示机构澄清当前法律法规的适用性（例如，ADA，公平住房，公平贷款，民权行为等）当决定依赖于AI动力系统可能导致全球估算。在美国经营的公司会有毫无疑问的动机，以检查他们的AI系统是否有针对受保护的课程的危害。</p><p> Low-income individuals are disproportionately vulnerable to many of the negative effects of AI. This is especially apparent with regard to  credit and loan creation, because they are less likely to have access to traditional financial products or the ability to obtain high scores based on traditional frameworks. This then becomes the data used to create AI systems that automate such decisions.</p><p> 低收入个体不成比例地易受AI的许多负面影响。这对信贷和贷款创造特别明显，因为它们不太可能获得传统金融产品或基于传统框架获得高分的能力。然后，这成为用于创建自动执行此类决策的AI系统的数据。</p><p> The Consumer Finance Protection Bureau (CFPB) can play a pivotal role in holding financial institutions accountable for discriminatory lending processes that result from reliance on discriminatory AI systems. The mandate of an EO would be a forcing function for statements on how AI-enabled systems will be evaluated, putting companies on notice and better protecting the public with clear expectations on AI use.</p><p> 消费者财务保护局（CFPB）可以在持有依赖歧视性AI系统的歧视性贷款过程中持有歧视性贷款流程的金融机构中发挥关键作用。 EO的授权将是关于如何评估AI的系统的陈述，并将公司推出通知，并更好地保护公众对AI使用的明确预期。</p><p> There is a clear path to liability when an individual acts in a discriminatory way and  a due process violation when a public benefit is denied arbitrarily, without explanation. Theoretically, these liabilities and rights would transfer with ease when an AI system is involved, but a review of agency action and legal precedent (or rather, the lack thereof) indicates otherwise.</p><p> 当个人以歧视性方式和适当的过程违反行动时，违反公共利益被任意拒绝，没有解释，就有明确的责任。从理论上讲，这些负债和权利将在涉及AI系统时轻松转移，但对代理行动和法律先例（或者相反，缺乏）的审查另有说明。</p><p> The administration is off to a good start, such as rolling back a  proposed HUD rule that would have made legal challenges against discriminatory AI essentially unattainable. Next, federal agencies with investigative or prosecutorial authority should clarify which AI practices would fall under their review and current laws would be applicable — for instance, HUD for illegal housing discrimination; CFPB on AI used in credit lending; and the Department of Labor on AI used in determinations made in hiring, evaluations and terminations.</p><p> 政府处于良好的开端，例如回滚拟议的HUD规则，这将对歧视性AI产生法律挑战，基本上是无法实现的。接下来，具有调查或检察机关的联邦机构应澄清其在审查中将落入哪些AI实践，目前的法律将适用 - 例如，非法住房歧视的HUD;在信用贷款中使用的AI上的CFPB;和聘用的劳动部用于招聘，评估和终止的确定。</p><p> Such action would have the added benefit of establishing a  useful precedent for plaintiff actions in complaints.</p><p> 这些行动将有增加的益处，为抱怨的原告行动建立一个有用的先例。</p><p> The Biden administration has taken encouraging first steps signaling its intent to ensure inclusive, less discriminatory AI. However, it must put its own house in order by directing that federal agencies require the development, acquisition and use of AI — internally and by those it does business with — is done in a manner that protects privacy, civil rights, civil liberties, and American values.</p><p> 拜登政府鼓励第一次措施发出其目的，以确保包容性，歧视性较少的AI。然而，它必须通过指导联邦机构要求艾美的发展，收购和使用，在内部和所在的人中，以保护隐私，公民权利，公民自由的方式完成，以诉诸于AI的发展，收购和使用美国价值观。 </p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://techcrunch.com/2021/04/22/to-ensure-inclusivity-the-biden-administration-must-double-down-on-ai-development-initiatives/">https://techcrunch.com/2021/04/22/to-ensure-inclusivity-the-biden-administration-must-double-down-on-ai-development-initiatives/</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/发展/">#发展</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/ai/">#ai</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/分享/">#分享</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy;2012-2021 diglog.com </div></div></body></html>