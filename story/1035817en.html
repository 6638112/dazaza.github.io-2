<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>使用jemalloc在Go中手动进行内存管理Manual Memory Management in Go using jemalloc</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">Manual Memory Management in Go using jemalloc<br/>使用jemalloc在Go中手动进行内存管理</h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2020-11-22 06:10:32</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2020/11/9b245f67c3b3cbeea18876c89a1c8070.png"><img src="http://img2.diglog.com/img/2020/11/9b245f67c3b3cbeea18876c89a1c8070.png" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>Dgraph Labs has been a user of the Go language since our inception in 2015. Fiveyears and 200K lines of Go code later, we&#39;re happy to report that we are stillconvinced Go was and remains the right choice. Our excitement for Go has gonebeyond building systems, and has led us to even write scripts in Go that wouldtypically be written in Bash or Python. We find that using Go has helped usbuild a codebase that is clean, readable, maintainable and - most importantly -efficient and concurrent.</p><p>自2015年成立以来，Dgraph Labs一直是Go语言的用户。五年后，Go代码达到20万行，我们很高兴地报告，我们仍然坚信Go过去并且仍然是正确的选择。我们对Go的兴奋已经超出了构建系统的范围，甚至使我们甚至可以使用Go编写脚本，而这些脚本通常是用Bash或Python编写的。我们发现使用Go可以帮助我们构建干净，可读，可维护并且最重要的是高效并发的代码库。</p><p> However, there&#39;s one area of concern that we have had since the early days: memory management. We have nothing against the Go garbage collector, but whileit offers a convenience to developers, it has the same issue that other memorygarbage collectors do:  it simply cannot compete with the efficiency of manualmemory management.</p><p> 但是，自早期以来，我们一直关注的一个领域是：内存管理。我们没有反对Go垃圾收集器的方法，但是尽管它为开发人员提供了便利，但是它具有其他内存垃圾收集器所面临的相同问题：它根本无法与手动内存管理的效率竞争。</p><p> When you manage memory manually, the memory usage is lower, predictable andallows bursts of memory allocation to not cause crazy spikes in memory usage.For Dgraph using Go memory, all of those have been a problem  1. In fact, Dgraphrunning out of memory is a very common complaint we hear from our users.</p><p> 当您手动管理内存时，内存使用率较低，可预测并且允许内存分配的突发事件不会导致内存使用率的疯狂飙升。对于使用Go内存的Dgraph，所有这些都是一个问题1.实际上，Dgraphr用尽内存是我们收到了用户的非常普遍的投诉。</p><p> Languages like Rust have been gaining ground partly because it allows safemanual memory management. We can completely empathize with that.</p><p> 诸如Rust之类的语言之所以得到发展，部分原因在于它允许安全手动进行内存管理。我们可以完全理解。</p><p> In our experience, doing manual memory allocation and chasing potential memoryleaks takes less effort than trying to optimize memory usage in a language withgarbage collection  2. Manual memory management is well worth the trouble whenbuilding database systems that are capable of virtually unlimited scalability.</p><p> 根据我们的经验，与尝试用垃圾回收语言优化内存使用情况相比，进行手动内存分配和追踪潜在的内存泄漏所花费的精力更少。手动内存管理在构建具有几乎无限的可伸缩性的数据库系统时值得付出麻烦。</p><p> Our love of Go and our need to avoid Go GC led us to find  novel ways to domanual memory management in Go. Of course,  most Go users will never need to domanual memory management; and we would recommend against it unless you need it. And when you do need it, you&#39;ll know.</p><p>我们对Go的热爱和避免使用Go GC的需求使我们找到了Go中进行手动内存管理的新颖方法。当然，大多数Go用户将永远不需要手动内存管理。除非您需要，否则我们建议您不要这样做。当您确实需要它时，您就会知道。</p><p> In this post, I&#39;ll share what we have learned at Dgraph Labs from ourexploration of manual memory management, and explain how we manually managememory in Go.</p><p> 在这篇文章中，我将分享我们在Dgraph Labs中从手动内存管理的探索中学到的知识，并说明我们如何在Go中手动管理内存。</p><p>  The inspiration came from the Cgo wiki section about  Turning C arrays into Goslices. We could use  malloc to allocate memory in C and use unsafe to pass it over to Go, without any interference from Go GC.</p><p>  灵感来自Cgo Wiki的有关将C数组转换为Goslices的部分。我们可以使用malloc在C中分配内存，并使用不安全的内存将其传递给Go，而不会受到Go GC的干扰。</p><p> import &#34;C&#34;import &#34;unsafe&#34;... var theCArray *C.YourType = C.getTheArray() length := C.getTheArrayLength() slice := (*[1 &lt;&lt; 28]C.YourType)(unsafe.Pointer(theCArray))[:length:length]</p><p> 导入“ C”导入“不安全” ... var theCArray * C.YourType = C.getTheArray（）长度：= C.getTheArrayLength（）slice：=（* [1 << 28] C.YourType）（unsafe.Pointer （theCArray））[：length：length]</p><p>  Note: the current implementation has a bug. While Go code is permitted to write nil or a C pointer (but not a Go pointer) to C memory, the current implementation may sometimes cause a runtime error if the contents of the C memory appear to be a Go pointer. Therefore, avoid passing uninitialized C memory to Go code if the Go code is going to store pointer values in it. Zero out the memory in C before passing it to Go.</p><p>  注意：当前的实现存在一个错误。尽管允许Go代码向C存储器写入nil或C指针（而不是Go指针），但是如果C存储器的内容似乎是Go指针，则当前实现有时可能会导致运行时错误。因此，如果Go代码要在其中存储指针值，请避免将未初始化的C内存传递给Go代码。将C中的内存清零，然后再传递给Go。</p><p> So, instead of using  malloc, we use its slightly more expensive sibling, calloc.  calloc works the same way as  malloc, except it zeroes outthe memory before returning it to the caller.</p><p>因此，我们不使用malloc，而是使用其价格稍高的同级Calloc。 calloc的工作方式与malloc相同，除了在将内存返回给调用方之前将内存清零。</p><p> We started out by just implementing basic  Calloc and  Free functions, whichallocate and de-allocate byte slices for Go via Cgo. To test these functions, wedeveloped and ran a continuous  memory usage test. This testendlessly repeated an allocate/de-allocate cycle in which it first allocatedvarious randomly-sized memory chunks until it had allocated 16GB of memory, andthen freed these chunks until just 1GB of memory was left allocated.</p><p> 我们首先实现基本的Calloc和Free函数，它们通过Cgo为Go分配和取消分配字节片。为了测试这些功能，我们开发并运行了连续的内存使用测试。这个测试无休止地重复了一个分配/取消分配循环，在该循环中，它首先分配了各种随机大小的内存块，直到分配了16GB的内存，然后释放了这些块，直到仅分配了1GB的内存。</p><p> The C equivalent of this program behaved as expected. We would see the RSSmemory in our  htop increasing to 16GB, then going down to 1GB, increasing backto 16GB, and so on. However, the Go program using  Calloc and  Free woulduse progressively more memory after each cycle (see chart below).</p><p> 此程序的C等效行为符合预期。我们会看到htop中的RSSmemory增加到16GB，然后下降到1GB，再增加回16GB，依此类推。但是，使用Calloc和Free的Go程序在每个周期后会逐渐使用更多的内存（请参见下表）。</p><p> We attributed this behavior to memory fragmentation due to lack of threadawareness in the default  C.calloc calls. After some help from the Go #dark-arts Slack channel (particular thanks to Kale Blankenship), we decidedto give  jemalloc a try.</p><p> 由于默认的C.calloc调用中缺乏线程意识，我们将此行为归因于内存碎片。在Go＃dark-arts Slack频道提供了一些帮助（特别感谢Kale Blankenship）之后，我们决定尝试jemalloc。</p><p>  jemalloc is a general purpose malloc(3) implementation that emphasizesfragmentation avoidance and scalable concurrency support. jemalloc first cameinto use as the FreeBSD libc allocator in 2005, and since then it has found itsway into numerous applications that rely on its predictable behavior. — http://jemalloc.net</p><p>  jemalloc是通用的malloc（3）实现，它强调避免碎片整理和可扩展的并发支持。 jemalloc于2005年首次成为FreeBSD libc分配器，此后它便进入了许多依赖其可预测行为的应用程序。 — http://jemalloc.net</p><p> We switched our APIs over to use jemalloc  3 for  calloc and  free calls.  And itperformed beautifully: jemalloc supports threads natively with little memoryfragmentation. The allocation-deallocation cycles from our memory usagemonitoring test were circulating between expected limits, ignoring a smalloverhead required to run the test.</p><p>我们将API切换为使用jemalloc 3进行calloc和免费调用。而且它表现出色：jemalloc原生支持线程而几乎没有内存碎片。来自我们的内存使用情况监视测试的分配-解除分配周期在预期的限制之间循环，而忽略了运行测试所需的少量开销。</p><p> Just to ensure that we&#39;re using jemalloc and avoid a name clash, we added a je_ prefix during installation, so our APIs are now calling  je_calloc and je_free, instead of  calloc and  free.</p><p> 为了确保我们正在使用jemalloc并避免名称冲突，我们在安装过程中添加了je_前缀，因此我们的API现在正在调用je_calloc和je_free，而不是calloc和free。</p><p>   In the above chart, allocating Go memory via C.calloc resulted in major memoryfragmentation, causing the program to hog on to 20GBs of memory by the 11thcycle. Equivalent code with jemalloc had no noticeable fragmentation,going down close to 1GB on every cycle.</p><p>   在上图中，通过C.calloc分配Go内存导致主要的内存碎片，导致该程序在第11个周期内占用了20GB的内存。与jemalloc等效的代码没有明显的碎片，每个周期下降到接近1GB。</p><p> At the end of the program (small dips on far right), after all theallocated memory was released, C.calloc program resulted in still hogging justunder 20GB of memory, while jemalloc showed 400MB of memory usage.</p><p> 在程序结束时（最右边的小凹处），释放了所有分配的内存之后，C.calloc程序仍然占用了不到20GB的内存，而jemalloc则显示了400MB的内存使用量。</p><p>     ptr := C.je_calloc(C.size_t(n), 1)	if ptr == nil {		// NB: throw is like panic, except it guarantees the process will be		// terminated. The call below is exactly what the Go runtime invokes when		// it cannot allocate memory.		throw(&#34;out of memory&#34;)	}	uptr := unsafe.Pointer(ptr)	atomic.AddInt64(&amp;numBytes, int64(n))	// Interpret the C pointer as a pointer to a Go array, then slice.	return (*[MaxArrayLen]byte)(uptr)[:n:n]</p><p>     ptr：= C.je_calloc（C.size_t（n），1）如果ptr == nil {//注意：throw就像是恐慌，除了它保证进程将//终止。下面的调用正是Go运行时无法//分配内存时调用的。 throw（“内存不足”）} uptr：= unsafe.Pointer（ptr）atomic.AddInt64（＆numBytes，int64（n））//将C指针解释为指向Go数组的指针，然后进行切片。返回（* [MaxArrayLen] byte）（uptr）[：n：n]</p><p> We made this code part of  Ristretto‘s z package, so both Dgraph and Badgercan use it. To allow our code to switch to using jemalloc to allocate the byteslices, we added a build tag  jemalloc. To further simplify our deployments, wemade the  jemalloc library be statically linked in any resulting Go binary bysetting the right LDFLAGS.</p><p>我们将此代码作为Ristretto的z软件包的一部分，因此Dgraph和Badgercan都可以使用它。为了使我们的代码切换到使用jemalloc分配字节片，我们添加了一个构建标签jemalloc。为了进一步简化我们的部署，我们通过设置正确的LDFLAGS，使jemalloc库在任何生成的Go二进制文件中静态链接。</p><p>  Now that we have a way to allocate and free a byte slice, the next stepis to use it to layout a Go struct. We can start with a basic one ( full code).</p><p>  现在我们有了分配和释放字节片的方法，下一步是使用它来布局Go结构。我们可以从一个基本的（完整的代码）开始。</p><p> type node struct { val int next *node}var nodeSz = int(unsafe.Sizeof(node{}))func newNode(val int) *node { b := z.Calloc(nodeSz) n := (*node)(unsafe.Pointer(&amp;b[0])) n.val = val return n}func freeNode(n *node) { buf := (*[z.MaxArrayLen]byte)(unsafe.Pointer(n))[:nodeSz:nodeSz] z.Free(buf)}</p><p> 类型node struct {val int next * node} var nodeSz = int（unsafe.Sizeof（node {}））func newNode（val int）* node {b：= z.Calloc（nodeSz）n：=（* node）（ unsafe.Pointer（＆b [0]））n.val = val return n} func freeNode（n * node）{buf：=（* [z.MaxArrayLen] byte）（unsafe.Pointer（n））[：nodeSz： nodeSz] z.Free（buf）}</p><p> In the code above, we laid out a Go struct on C allocated memory using  newNode.We created a corresponding  freeNode function, which can free up the memory oncewe were done with the struct. The Go struct has the basic data type  int and apointer to the next node struct, all of which were set and accessed in theprogram.We allocated 2M node objects and created a linked list out of them todemonstrate the proper functioning of jemalloc.</p><p> 在上面的代码中，我们使用newNode在C分配的内存上布置了Go结构，并创建了一个对应的freeNode函数，一旦完成了该结构，就可以释放内存。 Go结构体具有基本数据类型int和指向下一个节点结构体的指针，所有这些结构体均在程序中设置和访问。我们分配了2M个节点对象，并从其中创建了一个链接列表，以演示jemalloc的正常运行。</p><p> With default Go memory, we see 31 MiB of heap allocated for the linked list with2M objects, but nothing allocated via jemalloc.</p><p> 使用默认的Go内存，我们看到有2M个对象为链表分配了31 MiB的堆，但没有通过jemalloc分配任何东西。</p><p> $ go run .Allocated memory: 0 Objects: 2000001node: 0...node: 2000000After freeing. Allocated memory: 0HeapAlloc: 31 MiB</p><p>$ go run。分配的内存：0对象：2000001node：0 ... node：2000000释放后。分配的内存：0 HeapAlloc：31 MiB</p><p> Using the jemalloc build tag, we see 30 MiB of memory allocated via jemalloc,which goes down to zero after freeing the linked list. The Go heap allocation isonly a tiny 399 KiB, which probably comes from the overhead of running theprogram.</p><p> 使用jemalloc build标签，我们看到通过jemalloc分配了30 MiB的内存，在释放链接列表后，该内存下降为零。 Go堆分配仅为399 KiB，这可能来自运行程序的开销。</p><p> $ go run -tags=jemalloc .Allocated memory: 30 MiB Objects: 2000001node: 0...node: 2000000After freeing. Allocated memory: 0HeapAlloc: 399 KiB</p><p> $ go run -tags = jemalloc。分配的内存：30 MiB对象：2000001node：0 ... node：2000000释放后。分配的内存：0 HeapAlloc：399 KiB</p><p>  The above code works great to avoid allocating memory via Go.  But, it comes at acost: lower performance. Running both the instances with  time, we see thatwithout jemalloc, the program ran in 1.15s. With jemalloc, it ran ~5x slower at5.29s.</p><p>  上面的代码可以很好地避免通过Go分配内存。但是，这样做是有代价的：降低性能。随着时间运行两个实例，我们看到没有jemalloc，该程序在1.15s内运行。使用jemalloc时，它在5.29s时的速度慢了约5倍。</p><p> $ time go run .go run . 1.15s user 0.25s system 162% cpu 0.861 total$ time go run -tags=jemalloc .go run -tags=jemalloc . 5.29s user 0.36s system 108% cpu 5.200 total</p><p> $时间去运行。去运行。 1.15s用户0.25s系统162％cpu 0.861 total $ time go run -tags = jemalloc .go run -tags = jemalloc。 5.29s用户0.36s系统108％cpu 5.200总计</p><p> We attribute the slower performance to the fact that Cgo calls were made eachtime that memory was allocated, and each Cgo call comes with some overhead. Todeal with this, we wrote an  Allocator library in  ristretto/z package. This library allocates bigger chunks of memory in one call, which can then beused to allocate many small objects, avoiding expensive Cgo calls.</p><p>我们将性能降低归因于这样的事实，即每次分配内存时都会进行Cgo调用，并且每个Cgo调用都会带来一些开销。为此，我们在ristretto / z包中编写了一个Allocator库。该库在一个调用中分配了更大的内存块，然后可用于分配许多小对象，从而避免了昂贵的Cgo调用。</p><p> Allocator starts with a buffer and when exhausted, creates a new buffer oftwice the size. It maintains an internal list of all the allocated buffers.Finally, when the user is done with the data, they can call  Release to free upall these buffers in one go. Note that  Allocator does not do any memory movement.This helps ensure that any  struct pointers we have stay valid.</p><p> 分配器从缓冲区开始，用尽后创建一个两倍大小的新缓冲区。它维护着所有已分配缓冲区的内部列表。最后，当用户处理完数据后，他们可以调用Release一次释放所有这些缓冲区。请注意，分配器不执行任何内存移动操作，这有助于确保我们拥有的所有结构指针保持有效。</p><p> While this might look a bit like the slab-style memory management that tcmalloc/ jemalloc use, this is a lot simpler. Once allocated, you can notfree up just one struct. You can only free up all of the memory used by Allocator  4.</p><p> 尽管这看起来有点像tcmalloc / jemalloc使用的平板式内存管理，但这要简单得多。一旦分配，您将无法仅释放一个结构。您只能释放分配器4使用的所有内存。</p><p> What Allocator does well is to layout millions of structs for cheap and freethem when done, without involving the Go heap. The same program shownabove, when run with a new  allocator build tag, runs even faster thanthe Go memory version.</p><p> 分配器做得很好的是在完成时以便宜和免费的方式布局数百万个结构，而无需涉及Go堆。上面显示的同一程序在使用新的分配器构建标记运行时，其运行速度甚至比Go内存版本还要快。</p><p> $ time go run -tags=&#34;jemalloc,allocator&#34; .go run -tags=&#34;jemalloc,allocator&#34; . 1.09s user 0.29s system 143% cpu 0.956 total</p><p> $ time go运行-tags =“ jemalloc，allocator” .go运行-tags =“ jemalloc，allocator”。 1.09s用户0.29s系统143％cpu 0.956</p><p> Starting in Go 1.14, the  -race flag turns on memory alignment checks forstructs.  Allocator has an  AllocateAligned method which returns memorystarting with the right pointer alignment to pass those checks. Depending uponthe size of the struct, this could result in some memory waste butmakes CPU instructions more efficient due to correct word boundaries.</p><p>从Go 1.14开始，-race标志打开内存对齐检查forstructs。分配器具有一个AllocateAligned方法，该方法返回以正确的指针对齐开始的内存，以通过这些检查。根据结构的大小，这可能会导致一些内存浪费，但由于正确的字边界，会使CPU指令更高效。</p><p> We faced another memory management problem: Sometimes memory allocation happensat a very different place from deallocation. The only communication betweenthese two places might be the structs allocated with no way to pass down theactual  Allocator object. To deal with this, we assign a unique ID to each Allocator object, which the objects store in a  uint64 reference. Each new Allocator object is stored on a global map against its reference.  Allocatorobjects can then be recalled using this reference and released when the data isno longer required.</p><p> 我们面临另一个内存管理问题：有时内存分配发生在与释放不同的地方。这两个地方之间唯一的通信可能是分配的结构，无法传递实际的分配器对象。为了解决这个问题，我们为每个分配器对象分配一个唯一的ID，这些对象存储在uint64引用中。每个新的分配器对象都会根据其引用存储在全局地图上。然后可以使用此引用来调用分配对象，并在不再需要数据时将其释放。</p><p>   When allocating a struct manually, as shown above, it is important to ensurethat there&#39;s no reference within the struct to Go-allocated memory. Consider aslight modification to the struct above:</p><p>   如上所示，在手动分配结构时，重要的是要确保结构内没有对Go分配内存的引用。考虑对上述结构进行轻微修改：</p><p>  Let&#39;s use the  root := newNode(val) func defined above to allocate a nodemanually. If, however, we then set  root.next = &amp;node{val: val}, whichallocates all the other nodes in the linked list via Go memory, we are bound toget the following segmentation fault:</p><p>  让我们使用上面定义的root：= newNode（val）函数来手动分配节点。但是，如果我们然后设置root.next =＆node {val：val}，它通过Go内存分配链表中的所有其他节点，则必然会遇到以下分段错误：</p><p> $ go run -race -tags=&#34;jemalloc&#34; .Allocated memory: 16 B Objects: 2000001unexpected fault address 0x1cccb0fatal error: fault[signal SIGSEGV: segmentation violation code=0x1 addr=0x1cccb0 pc=0x55a48b]</p><p> $ go run -race -tags =“ jemalloc”。分配的内存：16 B对象：2000001意外的故障地址0x1cccb0严重错误：fault [信号SIGSEGV：分段违规代码= 0x1 addr = 0x1cccb0 pc = 0x55a48b]</p><p> The memory allocated by Go gets garbage collected because no valid Go struct ispointing to it. Only C-allocated memory is referencing it, and the Go heap doesnot have any reference to it, resulting in the above fault. So, if youcreate a struct and manually allocate memory to it, it&#39;s important to ensurethat  all the recursively accessible fields are allocated manually as well.</p><p>Go分配的内存会被垃圾回收，因为没有有效的Go结构指向它。只有C分配的内存在引用它，而Go堆对此没有任何引用，从而导致上述错误。因此，如果您创建一个结构并手动为其分配内存，那么确保所有递归可访问字段也都被手动分配非常重要。</p><p> For example, if the above struct was using a byte slice, we allocate that byteslice using  Allocator as well to avoid mixing Go memory with C memory.</p><p> 例如，如果上面的结构使用一个字节片，我们也将使用分配器分配该字节片，以避免将Go内存与C内存混合。</p><p>   Allocator is great for manually allocating millions of structs. However, we haveuse cases where we need to create billions of small objects and sort them. Theway one would do that in Go, even with  Allocator, looks something like this:</p><p>   分配器非常适合手动分配数百万个结构。但是，在某些情况下，我们需要创建数十亿个小对象并对它们进行排序。即使使用Allocator，也可以在Go中做到这一点，就像这样：</p><p> var nodes []*nodefor i := 0; i &lt; 1e9; i++ { b := allocator.AllocateAligned(nodeSz) n := (*node)(unsafe.Pointer(&amp;b[0])) n.val = rand.Int63() nodes = append(nodes, n)}sort.Slice(nodes, func(i, j int) bool { return nodes[i].val &lt; nodes[j].val})// nodes are now sorted in increasing order of val.</p><p> var个节点[] * nodefor i：= 0;我<1e9; i ++ {b：= allocator.AllocateAligned（nodeSz）n：=（* node）（unsafe.Pointer（＆b [0]））n.val = rand.Int63（）nodes = append（nodes，n）} sort.Slice （节点，func（i，j int）bool {return节点[i] .val <节点[j] .val}）//节点现在按val的升序排序。</p><p> All these 1B nodes are manually allocated on the  Allocator, which getsexpensive. We also need to pay the cost of the slice in Go, which at 8GB ofmemory (8 bytes per node pointer, 1B entries) is itself quite expensive.</p><p> 所有这些1B节点都是在分配器上手动分配的，这很昂贵。我们还需要在Go中支付分片的成本，而分片的成本为8GB（每个节点指针8个字节，1B条目）本身就非常昂贵。</p><p> To deal with these kinds of use cases, we built  z.Buffer, which can be memorymapped on a file to allow Linux to page memory in and out as required by thesystem. It implements  io.Writer and replaces our reliance on  bytes.Buffer.</p><p>为了处理这些用例，我们构建了z.Buffer，可以将其映射到文件上，以允许Linux根据系统的需要对内存进行分页。它实现了io.Writer并取代了对bytes.Buffer的依赖。</p><p> More importantly,  z.Buffer provides a new way to allocate smaller slices ofdata. With a call to  SliceAllocate(n),  z.Buffer would write the length ofthe slice being allocated (n) followed by allocating the slice. This allows z.Buffer to understand slice boundaries and iterate over them correctly with SliceIterate.</p><p> 更重要的是，z.Buffer提供了一种分配较小数据片段的新方法。通过调用SliceAllocate（n），z.Buffer将写入要分配的切片的长度（n），然后分配切片。这使z.Buffer能够理解切片边界，并使用SliceIterate正确地对其进行迭代。</p><p>  For sorting, we initially tried to get slice offsets from  z.Buffer, access theslices to compare, but sort only the offsets. Given an offset,  z.Buffer canread the offset, find the length of the slice and return that slice. So thissystem allowed us to access the slices in sorted order, without incurring anymemory movements. While novel, that mechanism put a lot of pressure on memory,because we were still paying the 8GB memory penalty just to bring those offsetsinto Go memory.</p><p>  对于排序，我们最初尝试从z.Buffer获取切片偏移量，访问切片进行比较，但仅对偏移量进行排序。给定一个偏移量，z.Buffer可以读取该偏移量，找到切片的长度并返回该切片。因此，该系统允许我们以排序的顺序访问切片，而不会引起任何内存移动。虽然这很新颖，但是这种机制给内存带来了很大压力，因为我们仍然要付出8GB的内存罚款，只是为了将这些补偿带入Go内存。</p><p> One crucial limitation we had was that slices were not of the samesize. Moreover, we could only access these slices in sequential order, not inreverse or random order, without calculating and storing the offsets in advance.Most in-place sort algorithms assume that values are of the same size   5, can berandomly accessed and can be readily swapped. Go&#39;s  sort.Slice works the sameway, and hence wasn&#39;t a good fit for  z.Buffer.</p><p> 我们遇到的一个关键限制是切片的大小不同。此外，我们只能按顺序访问这些片段，而不能按逆序或随机顺序访问这些片段，而无需事先计算和存储偏移量。交换。 Go的排序方式.Slice的工作原理相同，因此不适用于z.Buffer。</p><p> With these limitations, we found the merge sort algorithm to be the most suitablefor this job.  With merge sort, we can operate on the buffer in sequentialorder, taking only an extra half the memory hit over the size of the buffer.This not only turned out to be cheaper than bringing offsets into memory, but itwas a lot more predictable in terms of memory usage overhead as well  (roughlyhalf the buffer size). Even better, the overhead required to run merge sort isitself memory-mapped.</p><p> 由于这些限制，我们发现合并排序算法最适合此工作。通过归并排序，我们可以按顺序操作缓冲区，只占用缓冲区大小的一半以上的内存，这不仅比将偏移量引入内存更便宜，而且在可预测性方面要好得多的内存使用开销（大约缓冲区大小的一半）。更好的是，运行合并排序所需的开销本身就是内存映射的。</p><p> Merge sort also had one very positive effect. With offset based sorting, we hadto keep the offsets in memory while iterating over and processing the buffer,which put even more pressure on memory. With merge sort,  the extra memoryneeded is released by the time iteration starts, which means more memory isavailable for buffer processing.</p><p>合并排序也有一个非常积极的作用。使用基于偏移量的排序，我们必须在遍历和处理缓冲区的同时将偏移量保留在内存中，这给内存带来了更大的压力。使用归并排序，在迭代开始时会释放所需的额外内存，这意味着更多的内存可用于缓冲区处理。</p><p> z.Buffer also supports allocating memory via  Calloc, and automaticallymemory mapping it once it exceeds a certain user-specified limit. This makes itwork really well across all sizes of data.</p><p> z.Buffer还支持通过Calloc分配内存，并在内存超过用户指定的限制时自动对其进行内存映射。这使得它在所有大小的数据上都能很好地工作。</p><p> buffer := z.NewBuffer(256&lt;&lt;20) // Start with 256MB via Calloc.buffer.AutoMmapAfter(1&lt;&lt;30) // Automatically mmap it after it becomes 1GB.for i := 0; i &lt; 1e9; i++ { b := buffer.SliceAllocate(nodeSz) n := (*node)(unsafe.Pointer(&amp;b[0])) n.val = rand.Int63()}buffer.SortSlice(func(left, right []byte) bool { nl := (*node)(unsafe.Pointer(&amp;left[0])) nr := (*node)(unsafe.Pointer(&amp;right[0])) return nl.val &lt; nr.val})// Iterate over nodes in increasing order of val.buffer.SliceIterate(func(b []byte) error { n := (*node)(unsafe.Pointer(&amp;b[0])) _ = n.val return nil})</p><p> buffer：= z.NewBuffer（256 << 20）//通过Calloc.buffer.AutoMmapAfter（1 << 30）从256MB开始//变为1GB后自动映射它。for i：= 0;我<1e9; i ++ {b：= buffer.SliceAllocate（nodeSz）n：=（* node）（unsafe.Pointer（＆b [0]））n.val = rand.Int63（）} buffer.SortSlice（func（left，right [] byte）bool {nl：=（* node）（unsafe.Pointer（＆left [0]））nr：=（* node）（unsafe.Pointer（＆right [0]））return nl.val <nr.val}） //以val.buffer.SliceIterate（func（b [] byte）error {n：=（* node）（unsafe.Pointer（＆b [0]））_ = n.val return nil}的升序对节点进行迭代。 ）</p><p>  All of this discussion would not be complete without touching on memory leaks.Now that we are using manual memory allocation, there are bound to be memoryleaks where we forgot to deallocate memory.  How do we catch those?</p><p>  如果不涉及内存泄漏，所有讨论将是不完整的。现在，我们正在使用手动内存分配，因此肯定会有内存泄漏，而我们忘记了释放内存。我们如何抓住那些？</p><p> One simple thing we did early on was to have an atomic counter track the numberof bytes allocated via these calls, so we can quickly know how much memory wehave manually allocated in the program via  z.NumAllocBytes(). If by theend of our memory test we still had any memory left, this indicated a leak.</p><p> 我们早期做的一件简单的事情是让原子计数器跟踪通过这些调用分配的字节数，因此我们可以快速知道通过z.NumAllocBytes（）在程序中手动分配了多少内存。如果在我们的内存测试结束时仍然还有剩余的内存，则表明存在泄漏。</p><p> When we did find a leak, we initially tried to use the  jemalloc memoryprofiler. But, we soon realized that it isn&#39;t helpful. It doesn&#39;t see the entirecall stack due to the Cgo boundary. All that the profiler sees are allocationsand de-allocations coming from the same  z.Calloc and  z.Free calls.</p><p>当确实发现泄漏时，我们最初尝试使用jemalloc memoryprofiler。但是，我们很快意识到这没有帮助。由于Cgo边界，它没有看到整个调用堆栈。探查器看到的只是来自相同z.Calloc和z.Free调用的分配和取消分配。</p><p> Thanks to the Go runtime, we were able to quickly build a simple system to capturethe callers into  z.Calloc and match them against  z.Free calls. Thissystem requires mutex locks, so we chose not to enable it by default. Instead,we use a  leak build flag to turn on leak debug messages for our dev builds.This automatically detects leaks, and prints out the places where any leaksoccur.</p><p> 借助Go运行时，我们能够快速构建一个简单的系统来将调用者捕获到z.Calloc中，并将其与z.Free调用进行匹配。该系统需要互斥锁，因此我们默认不选择启用它。取而代之的是，我们使用一个泄漏构建标记来为我们的开发版本打开泄漏调试消息。这会自动检测泄漏，并打印出发生泄漏的地方。</p><p> // If leak detection is enabled.pc, _, l, ok := runtime.Caller(1)if ok { dallocsMu.Lock() dallocs[uptr] = &amp;dalloc{ pc: pc, no: l, sz: n, } dallocsMu.Unlock()}// Induced leak to demonstrate leak capture. The first number shows// the size of allocation, followed by the function and the line// number where the allocation was made.$ go test -v -tags=&#34;jemalloc leak&#34; -run=TestCalloc...LEAK: 128 at func: github.com/dgraph-io/ristretto/z.TestCalloc 91</p><p> //如果启用了泄漏检测。pc，_，l，ok：= runtime.Caller（1）if ok {dallocsMu.Lock（）dallocs [uptr] =＆dalloc {pc：pc，no：l，sz：n， } dallocsMu.Unlock（）} //诱导泄漏以演示泄漏捕获。第一个数字显示//分配的大小，然后显示函数和//进行分配的行号。$ go test -v -tags =“ jemalloc泄漏” -run = TestCalloc ...泄漏：128函数：github.com/dgraph-io/ristretto/z.TestCalloc 91</p><p>  With these techniques, we get the best of both worlds: We can do  manual memoryallocation in critical, memory-bound code paths. At the same time,we can get the benefits of  automatic garbage collection in non-critical codepaths. Even if you are not comfortable using Cgo or jemalloc, you could apply thesetechniques on bigger chunks of Go memory, with similar impact.</p><p>  使用这些技术，我们可以兼得两全：在关键的，受内存限制的代码路径中，我们可以进行手动内存分配。同时，我们可以在非关键代码路径中获得自动垃圾回收的好处。即使您不习惯使用Cgo或jemalloc，也可以将这些技术应用到更大的Go内存块中，从而产生类似的影响。</p><p> All of the libraries mentioned above are available under Apache 2.0 license inthe  Ristretto/z package. The memtest and demo code is located in contrib folder.</p><p> 上面提到的所有库都可以在Ristretto / z软件包的Apache 2.0许可下获得。 memtest和演示代码位于contrib文件夹中。</p><p> Both Badger and Dgraph (particularlyBadger) have already gained immensely from using these libraries. We can nowprocess terabytes of data with limited memory usage –  in line with what you&#39;dexpect from a C++ program. We are further identifying areas where we putpressure on Go memory, and relieving it by switching to manual memorymanagement where that makes sense.</p><p>使用这些库已经使Badger和Dgraph（尤其是Badger）获得了巨大的收益。现在，我们可以在有限的内存使用情况下处理数TB的数据，这与您从C ++程序所期望的一致。我们正在进一步确定需要对Go内存施加压力的区域，并通过切换到手动内存管理来缓解压力。</p><p> Dgraph v20.11 ( T&#39;Challa) release will be the first one to include all of thesememory management features. Our goal is to ensure that Dgraph never needs morethan 32 GB of physical RAM to run any kind of workload. And using  z.Calloc, z.Free,  z.Allocator and  z.Buffer helps us achieve this goal with Go.</p><p> Dgraph v20.11（T'Challa）版本将是第一个包含所有这些内存管理功能的版本。我们的目标是确保Dgraph绝不需要超过32 GB的物理RAM来运行任何类型的工作负载。使用z.Calloc，z.Free，z.Allocator和z.Buffer可以帮助我们通过Go实现这一目标。</p><p> Over the years, we have tried all tricks of the trade within Go. Usingsync.Pool, maintaining our own freelists, avoiding allocations on heapwherever possible, using buffer arenas and so on.  ↩︎</p><p> 多年来，我们尝试了Go中所有的交易技巧。使用sync.Pool，维护我们自己的空闲列表，尽可能避免在堆上分配内存，使用缓冲区舞台等。 ↩︎</p><p> When you gain experience writing in a language with manual memorymanagement, you develop an eye towards the allocations and deallocations.Moreover, profiling tools further help you determine memory leaks toeradicate them from the code base. This is no different from gaining an eyetowards concurrency patterns when writing code in Go. Both concurrency andmanual memory management look particularly hard to outsiders, but are justpart of the game for the developers regularly working on those languages.  ↩︎</p><p> 当您获得使用手动内存管理语言编写的经验时，您会着眼于分配和释放。此外，性能分析工具还可以帮助您确定内存泄漏，以从代码库中消除它们。这与在Go中编写代码时获得令人敬畏的并发模式没有什么不同。并发和手动内存管理对于外部人员而言尤其困难，但是对于定期使用这些语言的开发人员而言，这只是游戏的一部分。 ↩︎</p><p>  In fact, some experimentation with managing freelists within allocatorproved to be slower than just using Calloc and Free, due to the need for mutexlocks.  ↩︎</p><p>  实际上，由于需要互斥锁，一些在分配器中管理自由列表的实验被证明比仅使用Calloc和Free慢。 ↩︎</p><p> A slice of variable-length strings  var buf []string is still fixed sizefrom the perception of the slice.  buf[i] and  buf[j] take exactly the sameamount of memory, because they&#39;re both pointers to string, and can be readilyswapped within  buf. That&#39;s not the case here with byte slices being laid outon a much bigger byte buffer.  ↩︎</p><p>从切片的感知来看，可变长度字符串的片段var buf [] string的大小仍然是固定的。 buf [i]和buf [j]占用的内存量完全相同，因为它们都是指向字符串的指针，并且可以很容易地在buf中交换。这里不是这种情况，因为字节片被放置在更大的字节缓冲区上。 ↩︎</p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://dgraph.io/blog/post/manual-memory-management-golang-jemalloc/?repost=1">https://dgraph.io/blog/post/manual-memory-management-golang-jemalloc/?repost=1</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/内存/">#内存</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/jemalloc/">#jemalloc</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/memory/">#memory</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/分享/">#分享</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy; 2020 diglog.com </div></div></body></html>