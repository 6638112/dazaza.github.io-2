<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Wonnx：在Rust的WebGPU上运行ONNX机器学习模型</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">Wonnx：在Rust的WebGPU上运行ONNX机器学习模型</h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2022-02-26 04:40:54</div><div class="page_narrow text-break page_content"><p>Wonnx是一款GPU加速的ONNX推理运行时软件，100%用Rust编写，可用于网络。</p><p>✅ = 一流的支持-🆗 = 全力支持-🚧 = 不支持，但正在进行支持</p><p>确保Git LFS已初始化并下载了模型文件（在wonnx/examples/data/models中）。然后，你&#39；一切都准备好了！您可以运行一个示例：</p><p>货物运输——放行——信息/数据/模型/选择压缩。MNIST货物运行——释放——推断/数据/模型/选择压缩。onnx-i数据=/数据/图像/鹈鹕。jpeg——标签/数据/模型/挤压标签。txt——前三名</p><p>从wonnx导入PySession session=PySession。来自路径（&#34；./data/models/single#relu.onnx&#34；）输入={&#34；x&#34；：[-1.0,2.0]}断言会话。运行（输入）={&#34；y&#34；：[0.0,2.0]}</p><p>fn main（）-&gt；HashMap&lt；字符串，Vec&lt；f32&gt&gt；{let mut input_data=HashMap:：new（）；let image=load_squezenet_image（）；//load image input_data.insert（&#34；data&#34；.to_string（），inputensor:：F32（image.as#slice（）.unwrap（））；let session=pollster:：block#on（wonnx:：session:：from#path（&#34；examples/data/models/opt squence/opt squence.onnx（））。预期（&#34；会话没有创建&#34；）；让result=pollster:：block_on（session.run（input_data））。展开（）；让结果=结果[&#34；挤压0#u展平0#u重塑0&#34；]；让mut概率=结果。iter（）。枚举（）。收集：&lt；Vec&lt_&gt&gt；(); 概率。按（|a，b | b.1.部分_cmp（a.1））排序。展开（）；坚持！（概率[0].0,22）；]</p><p>WGPU_ADAPTER_名称，带有要使用的适配器名称的子字符串（例如，1080将匹配NVIDIA GeForce 1080ti）。</p><p>WGPU_BACKEND，带有逗号分隔的要使用的后端列表（vulkan、metal、dx12、dx11或gl）。</p><p>WGPU_POWER_首选项，当特定适配器名称为&#39时，可选择电源首选项；t规定（高或低）</p><p>即使没有在DL、WGSL或Rust方面的丰富经验，也非常欢迎您的贡献。我希望，这个项目可以成为一个沙箱，让我们所有人都能在这个项目最初的范围之外更多地了解这些技术。</p><p>设alpha=get_属性（&#34；alpha&#34；，Some（1.0），node）；//或者没有默认值，让alpha=get_属性：：&lt；f32&gt；（&#34；alpha&#34；，无，节点）；</p><p>可用类型在结构中。wgsl，但也可以在模板中生成新模板。</p><p>遵循绑定布局，每个条目从0开始递增1，输入第一，输出最后。如果绑定数量超过4。增加绑定组。您可以在sequencer中更改输入。rs</p><p>{{i_lens[0]}：输入0的长度。这也适用于输出：{o_lens[0]}和其他输入{i_lens[1]}</p><p>{{i_shape[0]}：输入0的维度数组。要获得数组的第一维，只需使用：{i_shape[0][0]}</p><p>{{i_chunks[0]}：输入0的每个维度的块的大小。默认情况下，每个变量都表示为一个长的值数组，要获得特定的值，必须按块移动。这些块在这个变量中表示。要获得第一维度块的大小，请使用：{i_chunks[0][0]}。</p><p>{{op_type}op type与某些类似op_类型的激活使用相同的模板。</p><p>使用utils函数对其进行测试，并将其放在tests文件夹中。测试可以如下所示：</p><p>#[test]fn test_matmul_square_matrix（）{//USER INPUT let n=16；let mut INPUT_data=HashMap:：new（）；let data_a=ndarray:：Array2:：eye（n）；let mut data_b=ndarray:：Array2:&lt；f32&gt；：零（（n，n））；data_b[[0，0]=0.2；data_b[[0，1]=0（&#34；A&#34；.to_string（），data_A.as_slice（）。展开（）；输入数据。插入（&#34；B&#34；.to_string（），data_B.as_slice（）。展开（）；设n=n为i64；设model=model（图（vec！[tensor（&#34；A&#34；，&amp；[n，n]）），tensor（&#34；B&#34；，&amp；[n，n]），vec！[tensor（&#34；C&#34；，&amp；[n，n]）]，向量！[]，维克！[]，维克！[节点（vec！[&#34；A&#34；，&#34；B&#34；]，维克！[C&#34；C&#34；]&#34;马特穆尔&#34&#34;马特穆尔&#34；，维克！[])], ));  让session=pollster:：block_on（wonnx:：session:：from_model（model））。expect（&#34；会话没有创建&#34；）；让result=pollster:：block_on（session.run（input_data））。展开（）；坚持！（结果[&#34；C&#34；]）。作为_slice（），求和。如_slice（）。展开（）；}</p><p>如果在任何时候你想对几个节点进行优化，你可以在sequencer中进行。卢比。</p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/rust/">#rust</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/run/">#run</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/谷歌/">#谷歌</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy;2012-2021 diglog.com </div></div></body></html>