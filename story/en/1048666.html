<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>人工神经网络最终为大脑学习提供了线索 Artificial Neural Nets Finally Yield Clues to How Brains Learn</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">Artificial Neural Nets Finally Yield Clues to How Brains Learn<br/>人工神经网络最终为大脑学习提供了线索 </h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2021-02-21 07:51:00</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2021/2/e2c55484d9e80631288d70c54a7b46a8.jpg"><img src="http://img2.diglog.com/img/2021/2/e2c55484d9e80631288d70c54a7b46a8.jpg" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>In 2007, some of the leading thinkers behind deep neural networks organized an unofficial “satellite” meeting at the margins of a prestigious annual conference on artificial intelligence. The conference had rejected their request for an official workshop; deep neural nets were still a few years away from taking over AI. The bootleg meeting’s final speaker was  Geoffrey Hinton of the University of Toronto, the cognitive psychologist and computer scientist responsible for some of the biggest breakthroughs in deep nets. He started with a quip: “So, about a year ago, I came home to dinner, and I said, ‘I think I finally figured out how the brain works,’ and my 15-year-old daughter said, ‘Oh, Daddy, not again.’”</p><p>在2007年，深层神经网络背后的一些主要思想家在著名的人工智能年度会议的间隙组织了一次非正式的“卫星”会议。会议拒绝了他们举行正式讲习班的要求；深度神经网络距离接管人工智能还需要几年的时间。盗版会议的最终发言人是多伦多大学的杰弗里·欣顿（Geoffrey Hinton），他是认知心理学家和计算机科学家，负责深网领域的一些最大突破。他打趣道：“所以，大约一年前，我回到家吃晚饭，然后我说：'我想我终于弄清了大脑的工作原理，'而我15岁的女儿说，'哦，爸爸，不再。”</p><p> The audience laughed. Hinton continued, “So, here’s how it works.” More laughter ensued.</p><p> 观众笑了。 Hinton继续说道：“所以，这就是它的工作原理。”随之而来的是更多的笑声。</p><p> Hinton’s jokes belied a serious pursuit: using AI to understand the brain. Today, deep nets rule AI in part because of an algorithm called backpropagation, or backprop. The algorithm enables deep nets to learn from data, endowing them with the ability to classify images, recognize speech, translate languages, make sense of road conditions for self-driving cars, and accomplish a host of other tasks.</p><p> 欣顿的笑话掩盖了一个严肃的追求：使用AI来了解大脑。如今，深网统治AI的部分原因是一种称为反向传播（backpropagation）或反向传播（backprop）的算法。该算法使深层网络能够从数据中学习，使它们能够对图像进行分类，识别语音，翻译语言，了解自动驾驶汽车的路况并完成许多其他任务。</p><p> But real brains are highly unlikely to be relying on the same algorithm. It’s not just that “brains are able to generalize and learn better and faster than the state-of-the-art AI systems,” said  Yoshua Bengio, a computer scientist at the University of Montreal, the scientific director of the Quebec Artificial Intelligence Institute and one of the organizers of the 2007 workshop. For a variety of reasons, backpropagation isn’t compatible with the brain’s anatomy and physiology, particularly in the cortex.</p><p> 但是真正的大脑极不可能依靠相同的算法。蒙特利尔大学的计算机科学家，魁北克人工智能研究所的科学主任Yoshua Bengio表示，这不仅是“大脑能够比最先进的AI系统进行概括和更好，更快地学习，”以及2007年研讨会的组织者之一。由于多种原因，反向传播与大脑的解剖结构和生理学不兼容，尤其是在皮质中。</p><p>  Bengio and many others inspired by Hinton have been thinking about more biologically plausible learning mechanisms that might at least match the success of backpropagation. Three of them — feedback alignment, equilibrium propagation and predictive coding — have shown particular promise. Some researchers are also incorporating the properties of certain types of cortical neurons and processes such as attention into their models. All these efforts are bringing us closer to understanding the algorithms that may be at work in the brain.</p><p>  Bengio和许多受Hinton启发的人一直在思考更合理的生物学学习机制，这些机制至少可以与反向传播的成功相提并论。其中三个-反馈对齐，平衡传播和预测编码-已显示出特别的希望。一些研究人员还将某些类型的皮层神经元的属性和过程（例如注意力）纳入其模型。所有这些努力使我们更加了解大脑中可能起作用的算法。</p><p> “The brain is a huge mystery. There’s a general impression that if we can unlock some of its principles, it might be helpful for AI,” said Bengio. “But it also has value in its own right.”</p><p> “大脑是一个巨大的谜。人们普遍认为，如果我们能够解开其中的某些原则，那么对人工智能可能会有所帮助。” “但是它本身也具有价值。”</p><p>  For decades, neuroscientists’ theories about how brains learn were guided primarily by a rule introduced in 1949 by the Canadian psychologist Donald Hebb, which is often paraphrased as “Neurons that fire together, wire together.” That is, the more correlated the activity of adjacent neurons, the stronger the synaptic connections between them. This principle, with some modifications, was successful at explaining certain limited types of learning and visual classification tasks.</p><p>  几十年来，神经科学家关于大脑学习方式的理论主要是由1949年由加拿大心理学家唐纳德·赫布（Donald Hebb）引入的规则指导的，该规则通常被解释为“神经元一起发射，连接在一起”。也就是说，相邻神经元的活动越相关，它们之间的突触连接越强。对该原则进行了一些修改，成功地解释了某些有限类型的学习和视觉分类任务。 </p><p> But it worked far less well for large networks of neurons that had to learn from mistakes; there was no directly targeted way for neurons deep within the network to learn about discovered errors, update themselves and make fewer mistakes. “The Hebbian rule is a very narrow, particular and not very sensitive way of using error information,” said  Daniel Yamins, a computational neuroscientist and computer scientist at Stanford University.</p><p>但是，对于必须从错误中学习的大型神经元网络，它的效果要差得多。网络内部的神经元没有直接针对性的方法来了解发现的错误，更新自身并减少错误。斯坦福大学的计算神经科学家和计算机科学家丹尼尔·亚明斯（Daniel Yamins）说：“ Hebbian规则是使用错误信息的一种非常狭窄，特殊且不太敏感的方法。”</p><p> Nevertheless, it was the best learning rule that neuroscientists had, and even before it dominated neuroscience, it inspired the development of the first artificial neural networks in the late 1950s. Each artificial neuron in these networks receives multiple inputs and produces an output, like its biological counterpart. The neuron multiplies each input with a so-called “synaptic” weight — a number signifying the importance assigned to that input — and then sums up the weighted inputs. This sum is the neuron’s output. By the 1960s, it was clear that such neurons could be organized into a network with an input layer and an output layer, and the artificial neural network could be trained to solve a certain class of simple problems. During training, a neural network settled on the best weights for its neurons to eliminate or minimize errors.</p><p> 然而，这是神经科学家拥有的最好的学习规则，甚至在它支配神经科学之前，它就启发了1950年代后期第一个人工神经网络的发展。这些网络中的每个人工神经元都接收多个输入并产生输出，就像它的生物学对应物一样。神经元将每个输入乘以所谓的“突触”权重（一个数字表示分配给该输入的重要性），然后对加权的输入求和。这是神经元的输出。到1960年代，很明显，可以将此类神经元组织成具有输入层和输出层的网络，并且可以训练人工神经网络来解决特定类别的简单问题。在训练期间，神经网络为其神经元确定最佳权重，以消除或最小化错误。</p><p>  However, it was obvious even in the 1960s that solving more complicated problems required one or more “hidden” layers of neurons sandwiched between the input and output layers. No one knew how to effectively train artificial neural networks with hidden layers — until 1986, when Hinton, the late David Rumelhart and  Ronald Williams (now of Northeastern University) published  the backpropagation algorithm.</p><p>  但是，即使在1960年代，很明显，解决更复杂的问题也需要在输入和输出层之间夹一层或多层“隐藏”的神经元。没有人知道如何有效地训练带有隐藏层的人工神经网络-直到1986年，当欣顿，已故的大卫·鲁梅尔哈特（David Rumelhart）和罗纳德·威廉姆斯（Ronald Williams）（现为东北大学）出版了反向传播算法。</p><p> The algorithm works in two phases. In the “forward” phase, when the network is given an input, it infers an output, which may be erroneous. The second “backward” phase updates the synaptic weights, bringing the output more in line with a target value.</p><p> 该算法分为两个阶段。在“转发”阶段，当为网络提供输入时，它将推断出输出，这可能是错误的。第二个“后退”阶段更新突触权重，使输出更符合目标值。</p><p> To understand this process, think of a “loss function” that describes the difference between the inferred and desired outputs as a landscape of hills and valleys. When a network makes an inference with a given set of synaptic weights, it ends up at some location on the loss landscape. To learn, it needs to move down the slope, or gradient, toward some valley, where the loss is minimized to the extent possible. Backpropagation is a method for updating the synaptic weights to descend that gradient.</p><p> 要理解此过程，可以考虑一个“损失函数”，该函数将所推断出的输出与所需输出之间的差异描述为丘陵和山谷的景观。当网络根据给定的一组突触权重进行推断时，它最终会出现在损失格局中的某个位置。要学习，它需要沿着坡度或坡度朝着某个山谷移动，在该山谷中，损耗要尽可能地小。反向传播是一种更新突触权重以降低该梯度的方法。</p><p> In essence, the algorithm’s backward phase calculates how much each neuron’s synaptic weights contribute to the error and then updates those weights to improve the network’s performance. This calculation proceeds sequentially backward from the output layer to the input layer, hence the name backpropagation. Do this over and over for sets of inputs and desired outputs, and you’ll eventually arrive at an acceptable set of weights for the entire neural network.</p><p> 本质上，该算法的后退阶段计算每个神经元的突触权重对误差的贡献程度，然后更新这些权重以改善网络的性能。该计算从输出层到输入层顺序地向后进行，因此命名为反向传播。一遍又一遍地进行输入和期望输出的设置，最终您将获得整个神经网络可接受的一组权重。</p><p>  The invention of backpropagation immediately elicited an outcry from some neuroscientists, who said it could never work in real brains. The most notable naysayer was Francis Crick, the Nobel Prize-winning co-discoverer of the structure of DNA who later became a neuroscientist. In 1989  Crick wrote, “As far as the learning process is concerned, it is unlikely that the brain actually uses back propagation.”</p><p>  反向传播的发明立即引起了一些神经科学家的强烈抗议，他们说这不可能在真正的大脑中起作用。最著名的反对者是弗朗西斯·克里克（Francis Crick），他是获得诺贝尔奖的DNA结构的共同发现者，后来成为神经科学家。克里克（Crick）在1989年写道：“就学习过程而言，大脑不太可能实际使用反向传播。” </p><p> Backprop is considered biologically implausible for several major reasons. The first is that while computers can easily implement the algorithm in two phases, doing so for biological neural networks is not trivial. The second is what computational neuroscientists call the weight transport problem: The backprop algorithm copies or “transports” information about all the synaptic weights involved in an inference and updates those weights for more accuracy. But in a biological network, neurons see only the outputs of other neurons, not the synaptic weights or internal processes that shape that output. From a neuron’s point of view, “it’s OK to know your own synaptic weights,” said Yamins. “What’s not okay is for you to know some other neuron’s set of synaptic weights.”</p><p>反向传播被认为是生物学上令人难以置信的，原因有几个。首先，虽然计算机可以很容易地在两个阶段中实现该算法，但对于生物神经网络而言，这样做并非易事。第二个是计算神经科学家所说的权重传递问题：反向传播算法会复制或“传递”有关推理中所有突触权重的信息，并更新这些权重以提高准确性。但是在生物网络中，神经元只能看到其他神经元的输出，而看不到形成该输出的突触权重或内部过程。从神经元的角度来看，“知道自己的突触权重是可以的，” Yamins说。 “不能让您知道其他一些神经元的突触权重。”</p><p>  Any biologically plausible learning rule also needs to abide by the limitation that neurons can access information only from neighboring neurons; backprop may require information from more remote neurons. So “if you take backprop to the letter, it seems impossible for brains to compute,” said Bengio.</p><p>  任何生物学上合理的学习规则也必须遵守以下限制：神经元只能访问邻近神经元的信息；反向传播可能需要来自更多远程神经元的信息。因此，“如果对这封信采取反向支持，大脑似乎无法进行计算，”本吉奥说。</p><p> Nonetheless, Hinton and a few others immediately took up the challenge of working on biologically plausible variations of backpropagation. “The first paper arguing that brains do [something like] backpropagation is about as old as backpropagation,” said  Konrad Kording, a computational neuroscientist at the University of Pennsylvania. Over the past decade or so, as the successes of artificial neural networks have led them to dominate artificial intelligence research, the efforts to find a biological equivalent for backprop have intensified.</p><p> 但是，欣顿和其他一些人立即接受了研究生物学上可行的反向传播变异的挑战。宾夕法尼亚大学的计算神经科学家Konrad Kording说：“第一篇争论大脑进行反向传播的论文与反向传播的历史差不多。”在过去的十年左右的时间里，由于人工神经网络的成功带领他们在人工智能研究中占主导地位，因此为寻找反向传播器寻找生物学等效物的努力也在不断加强。</p><p>  Take, for example, one of the strangest solutions to the weight transport problem, courtesy of  Timothy Lillicrap of Google DeepMind in London and his colleagues in 2016. Their algorithm, instead of relying on a matrix of weights recorded from the forward pass, used a matrix initialized with random values for the backward pass. Once assigned, these values never change, so no weights need to be transported for each backward pass.</p><p>  例如，举重问题最奇怪的解决方案之一，由伦敦Google DeepMind的Timothy Lillicrap和他的同事在2016年提供。他们的算法不是依赖于向前传递记录的权重矩阵，而是使用用随机值初始化的矩阵用于后向传递。赋值后，这些值就永远不会改变，因此无需为每次后退传递权重。</p><p> To almost everyone’s surprise, the network learned. Because the forward weights used for inference are updated with each backward pass, the network still descends the gradient of the loss function, but by a different path. The forward weights slowly align themselves with the randomly selected backward weights to eventually yield the correct answers, giving the algorithm its name: feedback alignment.</p><p> 几乎每个人都惊讶，该网络了解到。由于用于推理的前向权重随每个后向传递而更新，因此网络仍会通过不同的路径降低损耗函数的梯度。正向权重将自己与随机选择的向后权重缓慢对齐，以最终产生正确的答案，从而将算法命名为：反馈对齐。</p><p> “It turns out that, actually, that doesn’t work as bad as you might think it does,” said Yamins — at least for simple problems. For large-scale problems and for deeper networks with more hidden layers, feedback alignment doesn’t do as well as backprop: Because the updates to the forward weights are less accurate on each pass than they would be from truly backpropagated information, it takes much more data to train the network.</p><p> Yamins说：“事实证明，这实际上并没有您想象的那么糟糕，”至少在一些简单的问题上。对于大规模问题和具有更多隐藏层的更深层网络，反馈对齐不如反向传播那么好：由于前向权重的更新每次传递的准确性都低于真实反向传播信息的准确性，因此需要花费很多时间更多数据来训练网络。</p><p>  Researchers have also explored ways of matching the performance of backprop while maintaining the classic Hebbian learning requirement that neurons respond only to their local neighbors. Backprop can be thought of as one set of neurons doing the inference and another set of neurons doing the computations for updating the synaptic weights. Hinton’s idea was to work on algorithms in which each neuron was doing both sets of computations. “That was basically what Geoff’s talk was [about] in 2007,” said Bengio.</p><p>  研究人员还探索了在保持经典的Hebbian学习要求（神经元仅对它们的本地邻居做出反应）的同时匹配反向传播器性能的方法。反向传播可以认为是一组神经元进行推理，而另一组神经元进行计算以更新突触权重。 Hinton的想法是研究每个神经元都进行两组计算的算法。本吉奥说：“基本上，这就是杰夫在2007年的讲话。” </p><p> Building on Hinton’s work, Bengio’s team proposed a learning rule in 2017 that requires a neural network with recurrent connections (that is, if neuron A activates neuron B, then neuron B in turn activates neuron A). If such a network is given some input, it sets the network reverberating, as each neuron responds to the push and pull of its immediate neighbors.</p><p>Bengio团队在Hinton的工作基础上，于2017年提出了一条学习规则，该规则要求神经网络具有经常性的联系（也就是说，如果神经元A激活神经元B，则神经元B依次激活神经元A）。如果给这样的网络一些输入，它将设置网络回响，因为每个神经元都会对其直接邻居的推拉做出响应。</p><p> Eventually, the network reaches a state in which the neurons are in equilibrium with the input and each other, and it produces an output, which can be erroneous. The algorithm then nudges the output neurons toward the desired result. This sets another signal propagating backward through the network, setting off similar dynamics. The network finds a new equilibrium.</p><p> 最终，网络达到一种状态，在这种状态下，神经元与输入端以及彼此之间处于平衡状态，并产生输出，这可能是错误的。该算法然后将输出神经元推向所需结果。这设置了另一个信号，该信号通过网络向后传播，从而引起了类似的动态变化。网络找到了新的平衡点。</p><p> “The beauty of the math is that if you compare these two configurations, before the nudging and after nudging, you’ve got all the information you need to find the gradient,” said Bengio. Training the network involves simply repeating this process of “equilibrium propagation” iteratively over lots of labeled data.</p><p> Bengio说：“数学的优点在于，如果您比较这两种配置，则在进行微调之前和之后，您将获得找到梯度所需的所有信息。”训练网络只需要简单地在大量标记数据上反复重复此“平衡传播”过程。</p><p>  The constraint that neurons can learn only by reacting to their local environment also finds expression in new theories of how the brain perceives.  Beren Millidge, a doctoral student at the University of Edinburgh and a visiting fellow at the University of Sussex, and his colleagues have been reconciling this new view of perception — called predictive coding — with the requirements of backpropagation. “Predictive coding, if it’s set up in a certain way, will give you a biologically plausible learning rule,” said Millidge.</p><p>  神经元只能通过对局部环境做出反应才能学习的约束条件也在新的大脑感知理论中得到表达。爱丁堡大学（University of Edinburgh）博士生，苏塞克斯大学（Sussex University）客座研究员Beren Millidge及其同事一直在将这种新的感知观点称为预测编码，并与反向传播的要求相协调。 Millidge说：“预测编码，如果以某种方式进行设置，将为您提供生物学上合理的学习规则。”</p><p> Predictive coding posits that the brain is constantly making predictions about the causes of sensory inputs. The process involves hierarchical layers of neural processing. To produce a certain output, each layer has to predict the neural activity of the layer below. If the highest layer expects to see a face, it predicts the activity of the layer below that can justify this perception. The layer below makes similar predictions about what to expect from the one beneath it, and so on. The lowest layer makes predictions about actual sensory input — say, the photons falling on the retina. In this way, predictions flow from the higher layers down to the lower layers.</p><p> 预测编码假定大脑不断对感觉输入的原因进行预测。该过程涉及神经处理的分层层。为了产生一定的输出，每一层都必须预测下一层的神经活动。如果最高层希望看到一张脸，则可以预测下面这一层的活动可以证明这种看法是正确的。下一层对下一层的预期做出类似的预测，依此类推。最低层可以预测实际的感觉输入，例如，落在视网膜上的光子。通过这种方式，预测从较高的层流到较低的层。</p><p>  But errors can occur at each level of the hierarchy: differences between the prediction that a layer makes about the input it expects and the actual input. The bottommost layer adjusts its synaptic weights to minimize its error, based on the sensory information it receives. This adjustment results in an error between the newly updated lowest layer and the one above, so the higher layer has to readjust its synaptic weights to minimize its prediction error. These error signals ripple upward. The network goes back and forth, until each layer has minimized its prediction error.</p><p>  但是，错误可能会在层次结构的每个级别上发生：层对预期输入的预测与实际输入之间的差异。最底层根据收到的感官信息调整其突触权重，以最大程度地减少错误。这种调整会导致新近更新的最低层与上面的层之间出现错误，因此高层必须重新调整其突触权重以最大程度地减少其预测误差。这些错误信号会向上波动。网络来回移动，直到每一层都将其预测误差降至最低。</p><p> Millidge has shown that, with the proper setup, predictive coding networks can converge on much the same learning gradients as backprop. “You can get really, really, really close to the backprop gradients,” he said.</p><p> Millidge表明，通过适当的设置，预测编码网络可以收敛于与反向传播几乎相同的学习梯度。他说：“您可以非常，非常，非常接近反向传播器的梯度。” </p><p> However, for every backward pass that a traditional backprop algorithm makes in a deep neural network, a predictive coding network has to iterate multiple times. Whether or not this is biologically plausible depends on exactly how long this might take in a real brain. Crucially, the network has to converge on a solution before the inputs from the world outside change.</p><p>但是，对于传统的反向传播算法在深度神经网络中进行的每一次反向传播，预测编码网络都必须迭代多次。这在生物学上是否合理，取决于它在真实大脑中可能需要花费多长时间。至关重要的是，在外部世界的输入改变之前，网络必须收敛于解决方案。</p><p> “It can’t be like, ‘I’ve got a tiger leaping at me, let me do 100 iterations back and forth, up and down my brain,’” said Millidge. Still, if some inaccuracy is acceptable, predictive coding can arrive at generally useful answers quickly, he said.</p><p> “不能像‘我有一只老虎在向我跳跃，让我在大脑中来回往复进行100次迭代，” Millidge说。他说，尽管如此，如果某些误差是可以接受的，则预测编码可以迅速得出普遍有用的答案。</p><p>  Some scientists have taken on the nitty-gritty task of building backprop-like models based on the known properties of individual neurons. Standard neurons have dendrites that collect information from the axons of other neurons. The dendrites transmit signals to the neuron’s cell body, where the signals are integrated. That may or may not result in a spike, or action potential, going out on the neuron’s axon to the dendrites of post-synaptic neurons.</p><p>  一些科学家承担了根据单个神经元的已知特性来构建类似反向传播模型的艰巨任务。标准神经元具有树突，该树突从其他神经元的轴突收集信息。树突将信号传输到神经元的细胞体，信号在那里被整合。这可能会或可能不会导致尖峰或动作电位在神经元的轴突上突触后突触神经元的树突。</p><p> But not all neurons have exactly this structure. In particular, pyramidal neurons — the most abundant type of neuron in the cortex — are distinctly different. Pyramidal neurons have a treelike structure with two distinct sets of dendrites. The trunk reaches up and branches into what are called apical dendrites. The root reaches down and branches into basal dendrites.</p><p> 但是，并非所有神经元都具有这种结构。特别是，锥体神经元（皮质中神经元类型最丰富的类型）截然不同。金字塔形神经元具有树状结构，具有两组不同的树突。树干伸直并分支成顶端的树突。根向下并分支成基底树突。</p><p>  Models developed independently by Kording in 2001, and more recently by  Blake Richards of McGill University and the Quebec Artificial Intelligence Institute and his colleagues, have shown that pyramidal neurons could form the basic units of a deep learning network by doing both forward and backward computations simultaneously. The key is in the separation of the signals entering the neuron for forward-going inference and for backward-flowing errors, which could be handled in the model by the basal and apical dendrites, respectively. Information for both signals can be encoded in the spikes of electrical activity that the neuron sends down its axon as an output.</p><p>  由Kording于2001年独立开发的模型，以及最近由McGill大学的Blake Richards和魁北克人工智能研究所及其同事开发的模型表明，锥体神经元可以通过同时进行正向和反向计算来形成深度学习网络的基本单元。 。关键在于分离进入神经元的信号，以进行向前的推理和向后的错误，这可以在模型中分别由基础和顶端树突处理。这两个信号的信息都可以编码为神经元沿着其轴突向下发送的电活动峰值。</p><p> In the latest work from Richards’ team, “we’ve gotten to the point where we can show that, using fairly realistic simulations of neurons, you can train networks of pyramidal neurons to do various tasks,” said Richards. “And then using slightly more abstract versions of these models, we can get networks of pyramidal neurons to learn the sort of difficult tasks that people do in machine learning.”</p><p> 理查兹说：在理查兹团队的最新工作中，“我们已经达到了这样的程度：可以证明，使用相当逼真的神经元模拟，您可以训练锥体神经元网络来完成各种任务。” “然后使用这些模型的稍微抽象的版本，我们可以获得金字塔神经元网络，以学习人们在机器学习中执行的困难任务。”</p><p>  An implicit requirement for a deep net that uses backprop is the presence of a “teacher”: something that can calculate the error made by a network of neurons. But “there is no teacher in the brain that tells every neuron in the motor cortex, ‘You should be switched on and you should be switched off,’” said  Pieter Roelfsema of the Netherlands Institute for Neuroscience in Amsterdam.</p><p>  对于使用反向传播的深层网络的一个隐含要求是“教师”的存在：可以计算神经元网络所产生的误差的东西。但是“大脑中没有老师告诉运动皮层中的每个神经元，‘您应该被打开，您应该被关闭，”阿姆斯特丹荷兰神经科学研究所的彼得·罗尔夫塞玛说。 </p><p>  Roelfsema thinks the brain’s solution to the problem is in the process of attention. In the late 1990s, he and his colleagues showed that when monkeys fix their gaze on an object, neurons that represent that object in the cortex become more active. The monkey’s act of focusing its attention produces a feedback signal for the responsible neurons. “It is a highly selective feedback signal,” said Roelfsema. “It’s not an error signal. It is just saying to all those neurons: You’re going to be held responsible [for an action].”</p><p>Roelfsema认为大脑对问题的解决方案正在关注中。在1990年代后期，他和他的同事们发现，当猴子将视线固定在一个物体上时，代表该物体在皮层中的神经元变得更加活跃。猴子集中注意力的行为会产生负责神经元的反馈信号。 “这是一个高度选择性的反馈信号，” Roelfsema说。 “这不是错误信号。这只是对所有这些神经元说的：您将要为[行为]负责。”</p><p> Roelfsema’s insight was that this feedback signal could enable backprop-like learning when combined with processes revealed in certain other neuroscientific findings. For example,  Wolfram Schultz of the University of Cambridge and others have shown that when animals perform an action that yields better results than expected, the brain’s dopamine system is activated. “It floods the whole brain with neural modulators,” said Roelfsema. The dopamine levels act like a global reinforcement signal.</p><p> Roelfsema的见解是，当与某些其他神经科学发现中揭示的过程相结合时，这种反馈信号可以实现类似反向道具的学习。例如，剑桥大学的沃尔夫拉姆·舒尔茨（Wolfram Schultz）等人的研究表明，当动物做出比预期效果更好的动作时，大脑的多巴胺系统就会被激活。 Roelfsema说：“神经调节剂淹没了整个大脑。”多巴胺水平起着整体增强信号的作用。</p><p> In theory, the attentional feedback signal could prime only those neurons responsible for an action to respond to the global reinforcement signal by updating their synaptic weights, said Roelfsema. He and his colleagues have used this idea to build a deep neural network and study its mathematical properties. “It turns out you get error backpropagation. You get basically the same equation,” he said. “But now it became biologically plausible.”</p><p> 从理论上讲，注意反馈信号只能通过更新突触权重来启动负责响应整体增强信号的神经元。他和他的同事已经使用这种想法来构建一个深度神经网络并研究其数学特性。事实证明，您会得到错误的反向传播。您得到的方程基本相同，”他说。 “但是现在它在生物学上变得合理了。”</p><p> The team presented this work at the Neural Information Processing Systems online conference in December. “We can train deep networks,” said Roelfsema. “It’s only a factor of two to three slower than backpropagation.” As such, he said, “it beats all the other algorithms that have been proposed to be biologically plausible.”</p><p> 该小组在12月的神经信息处理系统在线会议上介绍了这项工作。 “我们可以训练深层网络，” Roelfsema说。 “它只比反向传播慢两到三倍。”他说：“因此，它超越了所有其他在生物学上似乎可行的算法。”</p><p>  Nevertheless, concrete empirical evidence that living brains use these plausible mechanisms remains elusive. “I think we’re still missing something,” said Bengio. “In my experience, it could be a little thing, maybe a few twists to one of the existing methods, that’s going to really make a difference.”</p><p>  然而，关于活着的大脑使用这些合理机制的具体经验证据仍然难以捉摸。 “我认为我们仍然缺少一些东西，”本吉奥说。 “以我的经验，这可能是一件小事，可能会与现有方法中的一种发生一些曲折，这确实会有所作为。”</p><p> Meanwhile, Yamins and his colleagues at Stanford have suggestions for how to determine which, if any, of the proposed learning rules is the correct one. By analyzing 1,056 artificial neural networks implementing different models of learning, they found that the type of learning rule governing a network can be identified from the activity of a subset of neurons over time. It’s possible that such information could be recorded from monkey brains. “It turns out that if you have the right collection of observables, it might be possible to come up with a fairly simple scheme that would allow you to identify learning rules,” said Yamins.</p><p> 同时，Yamins和他在斯坦福大学的同事对如何确定所提议的学习规则中的哪一项是正确的提出了建议。通过分析1,056个实现不同学习模型的人工神经网络，他们发现可以根据一段时间后神经元子集的活动来识别控制网络的学习规则类型。此类信息可能会从猴子的大脑记录下来。 Yamins表示：“事实证明，如果您具有正确的可观测量集合，则可能会提出一个相当简单的方案，使您能够确定学习规则。”</p><p> Given such advances, computational neuroscientists are quietly optimistic. “There are a lot of different ways the brain could be doing backpropagation,” said Kording. “And evolution is pretty damn awesome. Backpropagation is useful. I presume that evolution kind of gets us there.”</p><p> 有了这样的进步，计算神经科学家就悄悄地乐观了。科尔丁说：“大脑进行反向传播的方式有很多。” “进化真是太棒了。反向传播很有用。我认为这种进化可以使我们到达那里。” </p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://www.quantamagazine.org/artificial-neural-nets-finally-yield-clues-to-how-brains-learn-20210218/">https://www.quantamagazine.org/artificial-neural-nets-finally-yield-clues-to-how-brains-learn-20210218/</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/神经网络/">#神经网络</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/学习/">#学习</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/neural/">#neural</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/神经元/">#神经元</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/分享/">#分享</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy; 2020 diglog.com </div></div></body></html>