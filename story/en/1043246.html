<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Ditherpunk：我希望我有关于单色图像抖动的文章 Ditherpunk: The article I wish I had about monochrome image dithering</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">Ditherpunk: The article I wish I had about monochrome image dithering<br/>Ditherpunk：我希望我有关于单色图像抖动的文章 </h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2021-01-05 02:11:31</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2021/1/3cfb1c23dd89084f2a7884c9e8670b50.png"><img src="http://img2.diglog.com/img/2021/1/3cfb1c23dd89084f2a7884c9e8670b50.png" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>I always loved the visual aesthetic of dithering but never knew how it’s done. So I did some research. This article may contain traces of nostaliga and none of Lena.</p><p>我一直很喜欢抖动的视觉美感，但从来不知道它是如何完成的。所以我做了一些研究。本文可能包含nostaliga的痕迹，而没有Lena的痕迹。</p><p>     I am late to the party, but I finally played  “Return of the Obra Dinn”, the most recent game by  Lucas Pope of  “Papers Please” fame. Obra Dinn is a story puzzler that I can only recommend, but what piqued my curiosity as a software engineer is that it is a 3D game (using the  Unity game engine) but rendered using only 2 colors with dithering. Apparently, this has been dubbed “Ditherpunk”, and I love that.</p><p>     我参加聚会的时间很晚，但最终我玩了卢卡斯·波普（Lucas Pope）最近以“ Papers Please”成名的游戏“ Obra Dinn的回归”。 Obra Dinn是一个我只能推荐的故事迷题者，但是引起我作为软件工程师的好奇心的是，它是3D游戏（使用Unity游戏引擎），但是仅使用2种颜色进行抖动处理。显然，它被称为“ Ditherpunk”，我很喜欢。</p><p>    Dithering, so my original understanding, was a technique to place pixels using only a  few colors from a palette in a clever way to trick your brain into seeing  many colors. Like in the picture, where you probably feel like there are multipl brightness levels when in fact there’s only two: Full brightness and black.</p><p>    颤动是我最初的理解，是一种巧妙地使用调色板中几种颜色来放置像素的技术，可以诱使您的大脑看到多种颜色。就像在图片中一样，您可能会觉得实际上存在多重亮度，而实际上只有两个：全亮度和黑色。</p><p>  The fact that I have never seen a 3D game with dithering like this probably stems from the fact that color palettes are mostly a thing of the past. You  may remember running Windows 95 with 16 colors and playing games like “Monkey Island” on it.</p><p>  我从未见过像这样的抖动的3D游戏，这可能是由于调色板已成为过去的事实。您可能还记得运行16种颜色的Windows 95并在上面玩过类似“猴子岛”的游戏。</p><p>    For a long time now, however, we have had 8 bits per channel per pixel, allowing each pixel on your screen to assume one of 16 million colors. With HDR and wide gamut on the horizon, things are moving even further away to ever requiring any form of dithering. And yet Obra Dinn used it anyway and rekindled a long forgotten love for me. Knowing a tiny bit about dithering from my work on  Squoosh, I was especially impressed with Obra Dinn’s ability to keep the dithering stable while I moved and rotated the camera through 3D space and I wanted to understand how it all worked.</p><p>    但是，很长一段时间以来，我们每个像素每个通道只有8位，因此屏幕上的每个像素都可以采用1600万种颜色中的一种。随着HDR和广泛色域的出现，事情正变得越来越远，以至于需要任何形式的抖动。但是Obra Dinn还是使用了它，并重新燃起了对我早已被遗忘的爱。我对Squoosh的工作了解到一点抖动的知识，当我在3D空间中移动和旋转相机时，Obra Dinn保持抖动稳定的能力给我留下了特别深刻的印象，我想了解这一切如何工作。</p><p>  As it turns out, Lucas Pope wrote a  forum post where he explains which dithering techniques he uses and how he applies them to 3D space. He put extensive work into making the dithering stable when camera movements occur. Reading that forum post kicked me down the rabbit hole, which this blog post tries to summarize.</p><p>  事实证明，卢卡斯·波普（Lucas Pope）在论坛上发表了一篇文章，他在其中解释了他使用的抖动技术以及如何将其应用于3D空间。他在摄像机运动发生时为使抖动稳定而进行了大量工作。阅读该论坛帖子会把我踢到兔子洞，这篇博客文章试图对此进行总结。</p><p>      According to Wikipedia, “Dither is an intentionally applied form of noise used to randomize quantization error”, and is a technique not only limited to images. It is actually a technique used to this day on audio recordings, but that is yet another rabbit hole to fall into another time. Let’s dissect that definition in the context of images. First up: Quantization.</p><p>      根据Wikipedia所说，“抖动是一种有意应用的噪声形式，用于使量化误差随机化”，并且是一种不仅限于图像的技术。这实际上是迄今为止用于录音的一种技术，但这又是另一个麻烦。让我们在图像的上下文中剖析该定义。首先：量化。 </p><p>    Quantization is the process of mapping a large set of values to a smaller, usually finite, set of values. For the remainder of this article, I am going to use two images as examples:</p><p>量化是将大量值映射到较小值（通常是有限值）的过程。对于本文的其余部分，我将使用两个图像作为示例：</p><p>      Both black-and-white photos use 256 different shades of gray. If we wanted to use fewer colors — for example just black and white to achieve monochromaticity — we have to change every pixel to be either pure black or pure white. In this scenario, the colors black and white are called our “color palette” and the process of changing pixels that do not use a color from the palette is called “quantization”. Because not all colors from the original images are in the color palette, this will inevitably introduce an error called the “quantization error”. The naïve solution is to quantizer each pixel to the color in the palette that is closest to the pixel’s original color.</p><p>      黑白照片都使用256种不同的灰色阴影。如果我们想使用更少的颜色（例如，仅使用黑色和白色以实现单色），则必须将每个像素更改为纯黑色或纯白色。在这种情况下，黑色和白色称为我们的“调色板”，而更改不使用调色板中颜色的像素的过程称为“量化”。由于并非原始图像中的所有颜色都在调色板中，因此不可避免地会引入称为“量化错误”的错误。天真的解决方案是将每个像素量化为最接近调色板原始颜色的调色板中的颜色。</p><p>  Note: Defining which colors are “close to each other” is open to interpretation and depends on how you measure the distance between two colors. I suppose ideally we’d measure distance in a psycho-visual way, but most of the articles I found simply used the euclidian distance in the RGB cube, i.e.         Δ  red 2 + Δ  green 2 + Δ  blue 2 \sqrt{\Delta\text{red}^2 + \Delta\text{green}^2 + \Delta\text{blue}^2}           Δ   red        2  +  Δ   green        2  +  Δ   blue        2      ​   .</p><p>  注意：定义哪些颜色“彼此接近”尚待解释，并且取决于您如何测量两种颜色之间的距离。我想理想的情况下，我们应该以一种心理视觉的方式来测量距离，但是我发现的大多数文章都只是在RGB立方体中使用了欧几里得距离，即Δ红色2 +Δ绿色2 +Δ蓝色2 \ sqrt {\ Delta \ text {red} ^ 2 + \ Delta \ text {green} ^ 2 + \ Delta \ text {blue} ^ 2}Δred 2 +Δgreen 2 +Δblue 2。</p><p>  With our palette only consisting of black and white, we can use the brightness of a pixel to decide which color to quantize to. A brightness of 0 means black, a brightness of 1 means white, everything else is in-between, ideally correlating with human perception such that a brightness of 0.5 is a nice mid-gray. To quantize a given color, we only need to check if the color’s brightness is greater or less than 0.5 and quantize to white and black respectively. Applying this quantization to the image above yields an... unsatisfying result.</p><p>  使用仅由黑白组成的调色板，我们可以使用像素的亮度来确定要量化的颜色。亮度0表示黑色，亮度1表示白色，其他所有东西都介于两者之间，理想情况下与人类的感知相关，因此亮度0.5代表中等灰色。要量化给定的颜色，我们只需要检查颜色的亮度是大于还是小于0.5，然后分别量化为白色和黑色。将此量化应用于上面的图像会产生令人不满意的结果。</p><p>    Note: The code samples in this article are real but built on top of a helper class  GrayImageF32N0F8 I wrote for the  demo of this article. It’s similar to the web’s   ImageData, but uses  Float32Array, only has one color channel, represents values between 0.0 and 1.0 and has a whole bunch of helper functions. The source code is available in  the lab.</p><p>    注意：本文中的代码示例是真实的，但是基于我为本文的演示编写的辅助类GrayImageF32N0F8构建。它类似于网络上的ImageData，但使用Float32Array，仅具有一个颜色通道，表示0.0到1.0之间的值，并具有大量帮助函数。源代码在实验室中可用。</p><p>      I had finished writing this article and just wanted to “quickly” look what a black-to-white gradient looks like with the different dithering algorithms. The results showed me that I failed to consider  the thing that always becomes a problem when working with images: color spaces. I had written the sentence “ideally correlating with human perception” without actually following it myself.</p><p>      我已经写完了这篇文章，只是想“快速地”了解使用不同的抖动算法时黑白渐变的外观。结果表明，我没有考虑使用图像时总是成为问题的东西：色彩空间。我写的句子“与人类的观念有理想的联系”，但我本人并没有真正跟随它。</p><p>  My  demo is implemented using web technologies, most notably  &lt;canvas&gt; and  ImageData, which are — at the time of writing — specified to use  sRGB. It’s an old color space specification (from 1996) whose value-to-color mapping was modeled to mirror the behavior of CRT monitors. While barely anyone uses CRTs these days, it’s still considered the “safe” color space that gets correctly displayed on every display. As such, it is the default on the web platform. However, sRGB is not linear, meaning that       ( 0.5 , 0.5 , 0.5 ) (0.5, 0.5, 0.5)    ( 0 . 5 ,  0 . 5 ,  0 . 5 ) in sRGB is  not the color a human sees when you mix 50% of       ( 0 , 0 , 0 ) (0, 0, 0)    ( 0 ,  0 ,  0 ) and       ( 1 , 1 , 1 ) (1, 1, 1)    ( 1 ,  1 ,  1 ). Instead, it’s the color you get when you pump half the power of full white through your Cathod-Ray Tube (CRT).</p><p>  我的演示是使用Web技术（最著名的是＆quot; canvas＆gt;和ImageData，在撰写本文时已指定使用sRGB。这是一个古老的色彩空间规范（始于1996年），其值对颜色的映射被建模为反映CRT显示器的行为。尽管如今几乎没有人使用CRT，但仍被认为是可以在每个显示器上正确显示的“安全”色彩空间。因此，它是Web平台上的默认设置。但是，sRGB不是线性的，这意味着当您混合50％时，sRGB中的（0.5，0.5，0.5）（0.5，0.5，0.5）（0.5,0.5,0.5）不是人类看到的颜色（0，0，0）（0，0，0）（0，0，0）和（1，1，1）（1，1，1）（1，1，1）中的。相反，它是通过阴极射线管（CRT）泵浦全白光一半功率时得到的颜色。 </p><p>    As this image shows, the dithered gradient gets bright way too quickly. If we want 0.5 be the color in the middle of pure black and white (as perceived by a human), we need to convert from sRGB to linear RGB space, which can be done with a process called “gamma correction”. Wikipedia lists the following formulas to convert between sRGB and linear RGB.</p><p>如该图所示，抖动渐变太亮了。如果我们想让0.5成为纯黑色和白色（如人类所感知）中间的颜色，则需要将sRGB转换为线性RGB空间，这可以通过称为“伽玛校正”的过程来完成。维基百科列出了以下公式，可在sRGB和线性RGB之间转换。</p><p>  srgbToLinear ( b )   =    {      b 12.92    b ≤ 0.04045      (   b + 0.055 1.055 ) γ   otherwise     linearToSrgb ( b )   =    {      12.92 ⋅ b    b ≤ 0.0031308     1.055 ⋅  b  1 γ − 0.055   otherwise     ( γ = 2.4 )  \begin{array}{rcl} \text{srgbToLinear}(b) &amp; = &amp; \left\{\begin{array}{ll} \frac{b}{12.92} &amp; b \le 0.04045 \\ \left( \frac{b + 0.055}{1.055}\right)^{\gamma} &amp; \text{otherwise} \end{array}\right.\\ \text{linearToSrgb}(b) &amp; = &amp; \left\{\begin{array}{ll} 12.92\cdot b &amp; b \le 0.0031308 \\ 1.055 \cdot b^\frac{1}{\gamma} - 0.055 &amp; \text{otherwise} \end{array}\right.\\ (\gamma = 2.4) \end{array}\\                srgbToLinear ( b )     linearToSrgb ( b )    ( γ  =  2 . 4 ) ​             =    = ​               {                     1 2 . 9 2        b ​           (           1 . 0 5 5        b + 0 . 0 5 5 ​      )         γ ​             b  ≤  0 . 0 4 0 4 5     otherwise ​           {           1 2 . 9 2  ⋅  b    1 . 0 5 5  ⋅   b                  γ        1 ​      −  0 . 0 5 5 ​             b  ≤  0 . 0 0 3 1 3 0 8     otherwise ​      ​</p><p>  srgbToLinear（b）= {b 12.92 b≤0.04045（b + 0.055 1.055）γ否则linearToSrgb（b）= {12.92⋅bb≤0.0031308 1.055⋅b 1γ-0.055否则（γ= 2.4）\ begin {array} {rcl } \ text {srgbToLinear}（b）＆amp; =＆amp; \ left \ {\ begin {array} {ll} \ frac {b} {12.92}＆amp; b \ le 0.04045 \\ \ left（\ frac {b + 0.055} {1.055} \ right）^ {\ gamma}＆amp; \ text {否则} \ end {array} \正确。\\ \ text {linearToSrgb}（b）＆amp; =＆amp; \ left \ {\ begin {array} {ll} 12.92 \ cdot b＆amp; b \ le 0.0031308 \\ 1.055 \ cdot b ^ \ frac {1} {\ gamma}-0.055＆amp; \ text {otherwise} \ end {array} \ right。\\（\ gamma = 2.4）\ end {array} \\ srgbToLinear（b）linearToSrgb（b）（γ= 2。4）= = {1 2 。 9 2 b（1。0 5 5 b + 0。0 5 5）γb≤0。 0 4 0 4 5否则{1 2。 9 2⋅b 1。 0 5 5⋅bγ1 − 0。 0 5 5 b≤0。 0 0 3 1 3 0 8否则</p><p>        Back to Wikipedia’s definition of dithering: “Intentionally applied form of noise used to randomize quantization error”. We got the quantization down, and now it says to add noise.  Intentionally.</p><p>        回到Wikipedia对抖动的定义：“有意应用的噪声形式，用于使量化误差随机化”。我们降低了量化，现在说增加了噪声。故意地。</p><p>  Instead of quantizing each pixel directly, we add noise with a value between -0.5 and 0.5 to each pixel. The idea is that some pixels will now be quantized to the “wrong” color, but how often that happens depends on the pixel’s original brightness. Black will  always remain black, white will  always remain white, a mid-gray will be dithered to black roughly 50% of the time. Statistically, the overall quantization error is reduced and our brains are eager to do the rest and help you see the, uh, big picture.</p><p>  代替直接量化每个像素，我们向每个像素添加值在-0.5到0.5之间的噪声。这个想法是，一些像素现在将被量化为“错误”的颜色，但是这种情况发生的频率取决于像素的原始亮度。黑色将始终保持黑色，白色将始终保持白色，中灰色大约50％的时间会抖动为黑色。从统计上讲，整体量化误差有所减少，我们的大脑急于进行其余工作，并帮助您了解大局。</p><p>      I found this quite surprising! It is by no means  good — video games from the 90s have shown us that we can do better — but this is a very low effort and quick way to get more detail into a monochrome image. And if I was to take “dithering” literally, I’d end my article here. But there’s more…</p><p>      我发现这很令人惊讶！这绝对不是一件好事— 90年代的视频游戏向我们展示了我们可以做得更好—但这是一种非常省力且快捷的方法，可以将更多细节变为单色图像。如果要按字面意义进行“抖动”，我将在这里结束我的文章。但是还有更多……</p><p>    Instead of talking about what kind of noise to add to an image before quantizing it, we can also change our perspective and talk about adjusting the quantization threshold.</p><p>    除了讨论在对图像进行量化之前要在图像上添加哪种噪声外，我们还可以更改角度并讨论调整量化阈值。</p><p>  // Adding noise grayscaleImage . mapSelf ( brightness  =&gt;  brightness  + Math . random ( )  -  0.5  &gt;  0.5    ?  1.0    :  0.0  ) ;   // Adjusting the threshold grayscaleImage . mapSelf ( brightness  =&gt;   brightness  &gt; Math . random ( )    ?  1.0    :  0.0  ) ;</p><p>  //添加噪声grayscaleImage。 mapSelf（亮度=＆gt;亮度+数学随机（）-0.5＆gt; 0.5？1.0：0.0）; //调整阈值grayscaleImage。 mapSelf（亮度=＆gt;亮度＆gt;数学随机（）？1.0：0.0）; </p><p>  In the context of monochrome dithering, where the quantization threshold is 0.5, these two approaches are equivalent:</p><p>在单色抖动的情况下，量化阈值为0.5，这两种方法是等效的：</p><p>  b r i g h t n e s s +  r a n d ( ) − 0.5   &gt;   0.5    ⇔    b r i g h t n e s s   &gt;    1.0 −  r a n d ( )    ⇔    b r i g h t n e s s   &gt;     r a n d ( ) \begin{array} {} &amp; \mathrm{brightness} + \mathrm{rand}() - 0.5 &amp; &gt; &amp; 0.5 \\ \Leftrightarrow &amp; \mathrm{brightness} &amp; &gt; &amp; 1.0 - \mathrm{rand}() \\ \Leftrightarrow &amp; \mathrm{brightness} &amp;&gt;&amp; \mathrm{rand}() \end{array}                  ⇔    ⇔ ​              b r i g h t n e s s  +   r a n d ( )  −  0 . 5     b r i g h t n e s s     b r i g h t n e s s ​             &gt;    &gt;    &gt; ​             0 . 5    1 . 0  −   r a n d ( )     r a n d ( ) ​</p><p>  b r i g h t n e s s + ra n d（）-0.5＆gt; 0.5⇔b s g＆gt; 1.0-r a n d（）⇔b r i g h t n e s s＆gt; r a n d（）\ begin {array} {}＆amp; \ mathrm {亮度} + \ mathrm {rand}（）-0.5＆amp; ＆gt; ＆amp; 0.5 \\ \ Leftrightarrow＆amp; \ mathrm {亮度}＆amp; ＆gt; ＆amp; 1.0-\ mathrm {rand}（）\\ \ Leftrightarrow＆amp; \ mathrm {brightness}＆amp;＆amp;＆amp; \ mathrm {rand}（）\ end {array}⇔⇔¬b r i g h t n e s s + ra n d（）-0。 5 b r i g h t n e s s b r i g h t n e s s＆gt; ＆gt; ＆gt; 0。 5 1。 0 − r a n d（）r a n d（）</p><p>  The upside of this approach is that we can talk about a “threshold map”. Threshold maps can be visualized to make it easier to reason about why a resulting image looks the way it does. They can also be precomputed and reused, which makes the dithering process deterministic and parallelizable per pixel. As a result, the dithering can happen on the GPU as a shader. This is what Obra Dinn does! There are a couple of different approaches to generating these threshold maps, but all of them introduce some kind of order to the noise that is added to the image, hence the name “ordered dithering”.</p><p>  这种方法的好处是我们可以讨论“阈值图”。阈值图可以可视化，以便更容易地推断出为什么最终图像看起来像它那样。它们也可以预先计算和重用，从而使抖动过程确定性且可并行化每个像素。结果，抖动可以在GPU上作为着色器发生。这就是Obra Dinn所做的！有两种不同的方法可以生成这些阈值图，但是所有这些方法都会为添加到图像的噪声引入某种顺序，因此被称为“有序抖动”。</p><p>  The threshold map for the random dithering above, literally a map full of random thresholds, is also called “white noise”. The name comes from a term in signal processing where every frequency has the same intensity, just like in white light.</p><p>  上面用于随机抖动的阈值图，字面上充满了随机阈值的图，也称为“白噪声”。该名称来自信号处理中的一个术语，其中每个频率都具有相同的强度，就像在白光中一样。</p><p>      “Bayer dithering” uses a Bayer matrix as the threshold map. They are named after Bryce Bayer, inventor of the  Bayer filter, which is in use to this day in digital cameras. Each pixel on the sensor can only detect brightness, but by cleverly arranging colored filters in front of the individual pixels, we can reconstruct color images through  demosaicing. The pattern for the filters is the same pattern used in Bayer dithering.</p><p>      “拜耳抖动”使用拜耳矩阵作为阈值图。它们以拜耳滤镜的发明者布莱斯·拜耳（Bryce Bayer）的名字命名，该滤镜如今已在数码相机中使用。传感器上的每个像素只能检测亮度，但是通过在各个像素的前面巧妙地布置彩色滤光片，我们可以通过去马赛克来重建彩色图像。过滤器的图案与拜耳抖动中使用的图案相同。</p><p>  Bayer matrices come in various sizes which I ended up calling “levels”. Bayer Level 0 is       2 × 2 2 \times 2    2  ×    2 matrix. Bayer Level 1 is a       4 × 4 4 \times 4    4  ×    4 matrix. Bayer Level       n n    n is a        2  n + 1 ×  2  n + 1 2^{n+1} \times 2^{n+1}     2         n + 1  ×     2         n + 1 matrix. A level       n n    n matrix can be recursively calcuated from level       n − 1 n-1    n  −    1 (although Wikipedia also lists an  per-cell algorithm). If your image happens to be bigger than your bayer matrix, you can tile the threshold map.</p><p>  拜耳矩阵有各种尺寸，我最终称其为“水平”。拜耳0级是2×2 2 \乘以2 2×2矩阵。拜耳1级是4×4 4 \乘以4 4×4矩阵。拜耳级n n n是2 n + 1×2 n + 1 2 ^ {n + 1} \乘以2 ^ {n + 1} 2 n + 1×2 n +1矩阵。可以从n-1 n-1 n-1级递归计算n n n级矩阵（尽管Wikipedia也列出了每单元算法）。如果图像恰好大于Bayer矩阵，则可以平铺阈值图。</p><p>  Bayer ( 0 )   =    (     0   2    3   1 ) \begin{array}{rcl} \text{Bayer}(0) &amp; = &amp; \left( \begin{array}{cc} 0 &amp; 2 \\ 3 &amp; 1 \\ \end{array} \right) \\ \end{array}                Bayer ( 0 ) ​             = ​               (           0    3 ​             2    1 ​      ) ​</p><p>  拜耳（0）=（0 2 3 1）\ begin {array} {rcl} \ text {Bayer}（0）＆amp; =＆amp; \ left（\ begin {array} {cc} 0＆amp; 2 \\ 3＆amp; 1 \\ \ end {array} \ right）\\ \ end {array}拜耳（0）=（（0 3 2 1） </p><p>  Bayer ( n ) =     (      4 ⋅ Bayer ( n − 1 ) + 0    4 ⋅ Bayer ( n − 1 ) + 2     4 ⋅ Bayer ( n − 1 ) + 3    4 ⋅ Bayer ( n − 1 ) + 1 ) \begin{array}{c} \text{Bayer}(n) = \\ \left( \begin{array}{cc} 4 \cdot \text{Bayer}(n-1) + 0 &amp; 4 \cdot \text{Bayer}(n-1) + 2 \\ 4 \cdot \text{Bayer}(n-1) + 3 &amp; 4 \cdot \text{Bayer}(n-1) + 1 \\ \end{array} \right) \end{array}                Bayer ( n )  =      (           4  ⋅   Bayer ( n  −  1 )  +  0    4  ⋅   Bayer ( n  −  1 )  +  3 ​             4  ⋅   Bayer ( n  −  1 )  +  2    4  ⋅   Bayer ( n  −  1 )  +  1 ​      ) ​</p><p>拜耳（n）=（4⋅拜耳（n − 1）+ 0 4⋅拜耳（n − 1）+ 2 4⋅拜耳（n − 1）+ 3 4⋅拜耳（n − 1）+ 1）\开始{ array} {c} \ text {Bayer}（n）= \\ \ left（\ begin {array} {cc} 4 \ cdot \ text {Bayer}（n-1）+ 0＆amp; 4 \ cdot \ text {拜耳}（n-1）+ 2 \\ 4 \ cdot \ text {拜耳}（n-1）+ 3＆amp; 4 \ cdot \ text {拜耳}（n-1）+ 1 \\ \ end {array} \ right）\ end {array}拜耳（n）=（4⋅拜耳（n − 1）+ 0 4⋅拜耳（n − 1）+ 3 4⋅拜耳（n − 1）+ 2 4⋅拜耳（n − 1）+ 1））</p><p>  A level       n n    n Bayer matrix contains the numbers       0 0    0 to        2  2 n + 2 2^{2n+2}     2         2 n + 2. Once you normalize the Bayer matrix, i.e. divide by        2  2 n + 2 2^{2n+2}     2         2 n + 2, you can use it as a threshold map:</p><p>  级别为nnn的拜耳矩阵包含数字0 0 0到2 2 n + 2 2 ^ {2n + 2} 2 2 n +2。对拜耳矩阵进行归一化后，即除以2 2 n + 2 2 ^ {2n + 2} 2 2 n + 2，您可以将其用作阈值图：</p><p>  const bayer  =  generateBayerLevel (level ) ; grayscaleImage . mapSelf ( ( brightness ,  { x , y  } )  =&gt;  brightness  &gt; bayer . valueAt (x , y ,  { wrap :  true  } )    ?  1.0    :  0.0  ) ;</p><p>  const bayer = generateBayerLevel（level）; grayscaleImage。 mapSelf（（亮度，{x，y}）=＆gt;亮度＆gt;拜耳。valueAt（x，y，{wrap：true}）1.0：0.0）;</p><p>  One thing to note: Bayer dithering using matrices as defined above will render an image lighter than it originally was. For example: An area where every pixel has a brightness of        1 255 = 0.4 % \frac{1}{255} = 0.4\%              2 5 5        1 ​      =    0 . 4 %, a level 0 Bayer matrix of size       2 × 2 2\times2    2  ×    2 will make one out of the four pixels white, resulting in an average brightness of       25 % 25\%    2 5 %. This error gets smaller with higher Bayer levels, but a fundamental bias remains.</p><p>  需要注意的一件事：使用上述定义的矩阵进行拜耳抖动处理将使图像比原来的图像更亮。例如：每个像素的亮度为1255 = 0.4％\ frac {1} {255} = 0.4 \％2 5 5 1 = 0的区域。 4％时，大小为2×2 2 \ times2 2×2的0级Bayer矩阵将使四个像素中的一个变为白色，从而产生25％25 \％2 5％的平均亮度。拜耳水平越高，该误差就越小，但是仍然存在基本偏差。</p><p>    In our dark test image, the sky is not pure black and made  significantly brighter when using Bayer Level 0. While it gets better with higher levels, an alternative solution is to flip the bias and make images render  darker by inverting the way we use the Bayer matrix:</p><p>    在我们的黑暗测试图像中，使用拜耳级别0时天空不是纯黑的，并且变得明显更亮。尽管在使用更高级别的水平时会变得更好，但是另一种解决方案是通过反转使用方法来偏移偏斜并使图像更暗。拜耳矩阵：</p><p>  const bayer  =  generateBayerLevel (level ) ; grayscaleImage . mapSelf ( ( brightness ,  { x , y  } )  =&gt;   // 👇  brightness  &gt;  1  - bayer . valueAt (x , y ,  { wrap :  true  } )    ?  1.0    :  0.0  ) ;</p><p>  const bayer = generateBayerLevel（level）; grayscaleImage。 mapSelf（（亮度，{x，y}）=＆gt; //亮度> 1拜耳。valueAt（x，y，{wrap：true}）1.0：0.0）;</p><p>  I have used the original Bayer definition for the light image and the inverted version for the dark image. I personally found Level 1 and 3 the most aesthetically pleasing.</p><p>  我将原始拜耳定义用于亮图，将反转版本用于暗图。我个人发现1级和3级在美学上最令人愉悦。 </p><p>            Both white noise and Bayer dithering have drawbacks, of course. Bayer dithering, for example, is very structured and will look quite repetitive, especially at lower levels. White noise is random, meaning that there inevitably will be clusters of bright pixels and voids of darker pixels in the threshold map. This can be made more obvious by squinting or, if that is too much work for you, through blurring the threshold map algorithmically. These clusters and voids can affect the output of the dithering process negatively. If darker areas of the image fall into one of the clusters, details will get lost in the dithered output (and vice-versa for brighter areas falling into voids).</p><p>当然，白噪声和拜耳抖动都有缺点。例如，拜耳抖动结构非常有条理，并且看起来会重复很多，尤其是在较低级别。白噪声是随机的，这意味着在阈值图中不可避免地会有亮像素的簇和暗像素的空隙。斜视或者如果对您来说太麻烦了，则可以通过算法模糊阈值图来使这种情况更加明显。这些簇和空隙会负面影响抖动过程的输出。如果图像的较暗区域落入群集之一，则抖动输出中的细节将丢失（反之，较亮区域落入空隙中则相反）。</p><p>    There is a variant of noise called “ blue noise”, that addresses this issue. It is called blue noise because higher frequencies have higher intensities compared to the lower frequencies, just like blue light. By removing or dampening the lower frequencies, cluster and voids become less pronounced. Blue noise dithering is just as fast to apply to an image as white noise dithering — it’s just a threshold map in the end — but  generating blue noise is a bit harder and expensive.</p><p>    有一种称为“蓝色噪声”的噪声变体可以解决此问题。之所以称为蓝噪声，是因为与低频相比，高频与低频相比具有更高的强度。通过去除或抑制较低的频率，簇和空隙变得不太明显。蓝噪声抖动与白噪声抖动一样快地应用到图像上（最后只是阈值图），但是生成蓝噪声的难度和成本更高。</p><p>  The most common algorithm to generate blue noise seems to be the “void-and-cluster method” by  Robert Ulichney. Here is the  original whitepaper. I found the way the algorithm is described quite unintuitive and, now that I have implemented it, I am convinced it is explained in an unnecessarily abstract fashion. But it is quite clever!</p><p>  产生蓝噪声的最常见算法似乎是Robert Ulichney提出的“无效聚类方法”。这是原始白皮书。我发现描述算法的方式非常不直观，现在，我已经实现了它，我确信它以不必要的抽象方式进行了解释。但这很聪明！</p><p>  The algorithm is based on the idea that you can find a pixel that is part of cluster or a void by applying a  Gaussian Blur to the image and finding the brightest (or darkest) pixel in the blurred image respectively. After initializing a black image with a couple of randomly placed white pixels, the algorihtm proceeds to continuously swap cluster pixels and void pixels to spread the white pixels out as evenly as possible. Afterwards, every pixel gets a number between 0 and n (where n is the total number of pixels) according to their importance for forming clusters and voids. For more details, see the  paper.</p><p>  该算法基于以下想法：可以通过对图像应用高斯模糊并分别在模糊图像中找到最亮（或最暗）的像素来找到属于群集或空隙的像素。在用几个随机放置的白色像素初始化一个黑色图像后，算法继续连续交换群集像素和空白像素，以使白色像素尽可能均匀地散开。然后，根据每个像素形成簇和空隙的重要性，每个像素得到一个介于0和n之间的数字（其中n是像素的总数）。有关更多详细信息，请参见纸张。</p><p>  My implementation works fine but is not very fast, as I didn’t spend much time optimizing. It takes about 1 minute to generate a 64×64 blue noise texture on my 2018 MacBook, which is sufficient for these purposes. If something faster is needed, a promising optimization would be to apply the Gaussian Blur not in the spatial domain but in the frequency domain instead.</p><p>  我的实施效果不错，但速度不是很快，因为我没有花太多时间进行优化。在我的2018 MacBook上花费大约1分钟的时间即可生成64×64的蓝色噪点纹理，足以满足这些目的。如果需要更快的速度，则有希望的优化将不是在空间域中而是在频域中应用高斯模糊。</p><p>  Excursion: Of  course knowing this nerd-sniped me into implementing it. The reason this optimization is so promising is because convolution (which is the underlying operation of a Gaussian blur) has to loop over each field of the Gaussian kernel  for each pixel in the image. However, if you convert both the image as well as the Gaussian kernel to the frequency domain (using one of the many Fast Fourier Transform algorithms), convolution becomes an element-wise multiplication. Since my targeted blue noise size is a power of two, I could implement the well-explored  in-place variant of the Cooley-Tukey FFT algorithm. After  some initial hickups, it did end up cutting the blue noise generation time by 50%. I still wrote pretty garbage-y code, so there’s a lot more to room for optimizations.</p><p>  游览：当然，了解这个书呆子使我无法实现它。该优化之所以如此有前途，是因为卷积（高斯模糊的基本操作）必须针对图像中的每个像素遍历高斯内核的每个字段。但是，如果将图像和高斯核都转换到频域（使用许多快速傅立叶变换算法之一），则卷积将变成逐元素乘法。由于我的目标蓝噪声大小是2的幂，因此我可以实现Cooley-Tukey FFT算法的就地开发变体。经过一些初步的讨论，最终将蓝噪声的产生时间减少了50％。我仍然编写了相当垃圾的代码，因此还有更多的优化空间。</p><p>    As blue noise is based on a Gaussian Blur, which is calculated on a torus (a fancy way of saying that Gaussian blur wraps around at the edges), blue noise will also tile seamlessly. So we can use the 64×64 blue noise and repeat it to cover the entire image. Blue noise dithering has a nice, even distribution without showing any obvious patterns, balancing rendering of details and organic look.</p><p>    由于蓝色噪声基于高斯模糊，高斯模糊是基于圆环计算的（高斯模糊在边缘处环绕的一种奇特的说法），所以蓝色噪声也会无缝平铺。因此，我们可以使用64×64的蓝色噪点并重复它以覆盖整个图像。蓝噪声抖动具有良好的均匀分布，并且没有显示任何明显的图案，平衡了细节渲染和自然外观。 </p><p>      All the previous techniques rely on the fact that quantization errors will  statistically even out because the thresholds in the threshold maps are uniformly distributed. A different approach to quantization is the concept of error diffusion, which is most likely what you have read about if you have ever researched image dithering before. In this approach we don’t just quantize and hope that on average the quantization error remains negligible. Instead, we  measure the quantization error and diffuse the error onto neighboring pixels, influencing how they will get quantized. We are effectively changing the image we want to dither as we go along. This makes the process inherently sequential.</p><p>所有先前的技术都依赖于这样一个事实，即由于阈值图中的阈值是均匀分布的，因此量化误差将在统计上均匀。量化的另一种方法是误差扩散的概念，如果您以前曾经研究过图像抖动，则很可能会读懂它。通过这种方法，我们不仅可以量化，而且希望量化误差平均可以忽略不计。取而代之的是，我们测量量化误差，然后将误差扩散到相邻像素上，从而影响像素的量化方式。我们正在有效地改变我们想要抖动的图像。这使过程本质上是顺序的。</p><p>  Foreshadowing: One big advantage of error diffusion algorithms that we won’t touch on  in this post is that they can handle arbitrary color palettes, while ordered dithering requires your color palette to be evenly spaced. More on that another time.</p><p>  预示：本文中将不涉及的误差扩散算法的一大优势是它们可以处理任意调色板，而有序抖动要求您的调色板要均匀分布。再来一次。</p><p>  Almost all error diffusion ditherings that I am going to look at use a “diffusion matrix”, which defines how the quantization error from the current pixel gets distributed across the neighboring pixels. For these matrices it is often assumed that the image’s pixels are traversed top-to-bottom, left-to-right — the same way us westerners read text. This is important as the error can only be diffused to pixels that haven’t been quantized yet. If you find yourself traversing an image in a different order than the diffusion matrix assumes, flip the matrix accordingly.</p><p>  我将要讨论的几乎所有误差扩散抖动都使用“扩散矩阵”，该矩阵定义了当前像素的量化误差如何分布在相邻像素之间。对于这些矩阵，通常假设图像的像素是从上到下，从左到右遍历的，这与我们西方人阅读文本的方式相同。这很重要，因为误差只能扩散到尚未量化的像素。如果发现遍历图像的顺序与扩散矩阵假定的顺序不同，请相应地翻转矩阵。</p><p>    The naïve approach to error diffusion shares the quantization error between the pixel below the current one and the one to the right, which can be described with the following matrix:</p><p>    幼稚的误差扩散方法在当前像素下方的像素与右侧像素之间的量化误差之间共享量化误差，可用以下矩阵描述：</p><p>  (     ∗   0.5    0.5   0 ) \left(\begin{array}{cc} * &amp; 0.5 \\ 0.5 &amp; 0 \\ \end{array} \right)       (           ∗    0 . 5 ​             0 . 5    0 ​      )</p><p>  （∗ 0.5 0.5 0）\ left（\ begin {array} {cc} *＆amp; 0.5 \\ 0.5＆amp; 0 \\ \ end {array} \ right）（∗ 0。5 0。5 0）</p><p>  The diffusion algorithm visits each pixel in the image (in the right order!), quantizes the current pixel and measures the quantization error. Note that the quantization error is signed, i.e. it can be negative if the quantization made the pixel brighter than the original brightness value. We then add fractions of the quantization error to neighboring pixels as specified by the m</p><p>  扩散算法访问图像中的每个像素（以正确的顺序！），对当前像素进行量化并测量量化误差。注意，量化误差是有符号的，即，如果量化使像素比原始亮度值更亮，则可以为负。然后，我们将量化误差的分数添加到由m指定的相邻像素</p><p>......</p><p>...... </p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://surma.dev/things/ditherpunk/">https://surma.dev/things/ditherpunk/</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/chrome/">#chrome</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/希望/">#希望</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/article/">#article</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/抖动/">#抖动</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/分享/">#分享</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy; 2020 diglog.com </div></div></body></html>