<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>我在微服务世界中看到的灾难 Disasters I've seen in a microservices world</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">Disasters I've seen in a microservices world<br/>我在微服务世界中看到的灾难 </h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2021-06-13 23:04:20</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2021/6/ff3420d221f81eb33d4f4e2e3712a408.jpeg"><img src="http://img2.diglog.com/img/2021/6/ff3420d221f81eb33d4f4e2e3712a408.jpeg" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>When Martin Fowler&#39;s post about  microservices came out in 2014, the teams where I worked were already building service-oriented architectures. That post and the subsequent hype made their way into almost every software team in the world. The &#34;Netflix OSS stack&#34; was the coolest thing back then, allowing engineers worldwide to leverage Netflix&#39;s lessons in distributed systems. More than six years later, if we look into software engineering jobs right now, most of them talk about a microservices&#39; architecture.</p><p>当Martin Fowler＆＃39;关于MicroServices的帖子于2014年出来时，我工作的团队已经建立了面向服务的架构。那篇文章和随后的炒作进入了世界上几乎每个软件团队。 ＆＃34; Netflix OSS Stack＆＃34;那是最酷的事情，允许全世界工程师利用Netflix＆＃39;在分布式系统中的课程。超过六年后，如果我们现在调查软件工程就业，他们大多数人都谈到了一个微服务和＃39;建筑学。</p><p>    In the earliest part of the 2010s, many organizations were suffering challenges regarding their software development cycle. Folks working with other 50, 100 or 200 engineers struggled with development environments, heavy QA processes and programmed deployments. While Martin Fowler&#39;s &#34; Continuous Delivery&#34; book shed light on many of those teams, they started to realize their  majestic monoliths were creating organizational problems for them. Hence, microservices were appealing for software engineers. It&#39;s more challenging to introduce continuous delivery or deployment in a big project rather than start with it.</p><p>    在2010年代的最早部分，许多组织对其软件开发周期遭受挑战。人们使用其他50,100或200名工程师，努力开发环境，重质QA流程和编程部署。虽然马丁福勒＆＃39; s＆＃34;连续交货＆＃34;书籍棚在许多团队中，他们开始意识到他们的雄伟的巨石正在为他们创造组织问题。因此，微服务对软件工程师进行了吸引力。它更具挑战性，在大项目中延续持续交付或部署而不是从它开始。</p><p>  So teams started spinning off three, ten, a hundred microservices. Most of them used &#34;JSON over HTTP&#34; — others may say RESTful 😉 — APIs for remote calls between these components. People knew well the HTTP protocol, and it seemed a relatively easy way to convert the monoliths into smaller pieces. At this point, teams started to deploy code into production in less than 15 minutes. There was no more the &#34;Oh, team A broke the CI pipeline, and I can&#39;t deploy my code&#34;, and it felt great!</p><p>  所以球队开始旋转三，十，一百个微服务。他们中的大多数人使用＆＃34; json overt http＆＃34; - 其他人可能会说依赖于这些组件之间的远程呼叫的API。人们知道HTTP协议很好，它似乎是将墨底转换成较小的碎片相对简单的方法。此时，团队开始在不到15分钟的时间内将代码部署到生产中。没有更多的＆＃34;哦，团队突破了CI管道，我可以和＃39; t部署我的代码＆＃34;它感到很棒！</p><p>  Most engineers forgot, though, that while solving an organizational problem at the software architecture&#39;s level, they also introduced a lot of complexity. The  distributed systems fallacies became more and more evident and quickly were a headache for those teams. Even for companies that were already doing client/server architectures where they already existed, this exploded in their faces once they had 10+ moving pieces in their systems.</p><p>  尽管如此，大多数工程师忘记了在软件架构中解决组织问题＆＃39; S水平，他们也介绍了很多复杂性。分布式系统贫困变得越来越明显，并且对于这些团队来说很快就会出现头疼。即使对于已经在他们已经存在的客户/服务器架构的公司提供了客户/服务器架构，它一旦它们在其系统中有10个以上的移动碎片就在其脸上爆炸。</p><p>    Going for significant architectural changes doesn&#39;t come for free. Teams started to realize that sharing a database was a single-point-of-failure. Then, they realized that separating their domains created a whole new world: eventual consistency was a thing. What about when a service where you&#39;re pulling data off is down? The number of questions and problems started to pile up. The promises of a high-speed development pace were trumped by looking for bugs, incidents, data consistency issues, etc. Another problem was that engineers needed centralized logs and observability solutions to span across tens of services to spot and correct these defects.</p><p>    为了获得重大的建筑变革，不为免费来。团队开始意识到共享数据库是一个单点故障。然后，他们意识到分离他们的域名创造了一个全新的世界：最终的一致性是一件事。当你＆＃39的服务时何时何地呢？问题和问题的数量开始堆积。通过寻找错误，事件，数据一致性问题等，突破了高速发展步伐的承诺。另一个问题是工程师需要集中日志和可观察性解决方案，以跨越几十种服务来发现并纠正这些缺陷。</p><p>    Having the ability to create new services every day came with an explosion of developer&#39;s creativity. A new feature? Bam, let&#39;s start a service! Suddenly, teams with 20 engineers were maintaining 50 services. That&#39;s more than one service per person! The problem with code, in general, is that it rots. Maintaining every service came at a cost. Imagine propagating a library upgrade across your services&#39; fleet. Imagine that these services were started at different time points, with different architectures and some entanglement between the business logic and the frameworks used. That&#39;s  bananas! Of course, there are ways to solve these problems. Most of them weren&#39;t available back in those days, and others cost a lot in FTEs work.</p><p>    有能力每天创建新服务，带来开发商的爆炸＆＃39;创造力。一个新功能？ BAM，Let＆＃39;开始服务！突然，20名工程师的团队正在维持50家服务。这个＆＃39;每个人多于一个服务！代码的问题通常是它rots。维护每项服务都是成本的。想象一下，在您的服务中传播库升级＆＃39;舰队。想象一下，这些服务在不同的时间点开始，具有不同的架构以及业务逻辑与使用的框架之间的一些纠缠。那个＆＃39; sananas！当然，有方法可以解决这些问题。他们中的大多数人都在那些日子里拿回来，其他人在FTES工作中成本很多。</p><p>  Another smell was when someone told me that deploying a new feature in service A also needed a deployment — at the same time — in service B. Or when people started to write services to generate CSVs. Why would someone introduce network hops to produce a worldwide known file format? Who would maintain that? Some teams were suffering from  servicitis. Even worse than that, it generated a lot of friction while developing. One could not just look into a project in their IDE, but it required to have multiple projects open simultaneously to make sense of all that mess.</p><p>  另一个嗅觉是当有人告诉我，在服务中部署新功能a也需要部署 - 同时 - 在服务B中，或者人们开始编写服务以生成CSV。为什么有人会介绍网络跳跃以产生全球已知的文件格式？谁将保持这种情况？一些团队患有服务性。甚至比那更糟糕，它在发展时产生了很多摩擦。一个人不能只是在他们的IDE中调查一个项目，但它需要同时打开多个项目来了解所有这些混乱。 </p><p>     Hey, João. Do you have a minute? We need to fix our development environments! People are complaining about them all the time, and this isn&#39;t working!</p><p>嘿，joão。能打扰你几分钟吗？我们需要修复我们的开发环境！人们一直在抱怨他们，这是＆＃39;工作！</p><p>  The problem crossed different dimensions. Mobile developers not developing a feature before it was in a development environment or backend developers who wanted to try their service didn&#39;t break any business flow. It was also problematic if someone wanted to test the whole flow in a mobile app before production.</p><p>  问题交叉不同的尺寸。移动开发人员未在开发环境中开发一个功能，或者在开发环境中或后端开发人员，他们想要尝试他们的服务DIDN＆＃39; t打破任何业务流程。如果有人想在生产之前测试在移动应用程序中的整个流程中，它也是有问题的。</p><p>    How much does it cost to spin 200 services in a cloud provider? Can you do it? Can you also spin up the infrastructure needed to run them?</p><p>    在云提供商中旋转200个服务是多少钱？你能做到吗？您还能旋转运行它们所需的基础架构吗？</p><p> How much time does it cost to do so? What if, when a mobile engineer starts to develop a feature, there&#39;s a set of services in a given version, and when they finish, there are ten new versions deployed into production?</p><p> 这样做是多少时间？如果移动工程师开始开发一个功能，那么在给定版本中的一套服务，以及在完成时，将有十个新版本部署到生产中？</p><p> What about test data? Do you have test data for all your services? Is it coherent across the fleet, so users and other entities match?</p><p> 测试数据怎么样？您是否有所有服务的测试数据？这是船队的一致性，所以用户和其他实体匹配吗？</p><p> If you&#39;re developing a multi-tenant, multi-region application, what about configuration and feature flags? How do you stay in sync with production? What if the defaults change meanwhile?</p><p> 如果您＆＃39; re开发多租户，多区域应用程序，那么配置和功能标志如何？您如何与生产保持同步？如果默认值改变了什么？</p><p>  That is the tip of the iceberg. One can think of throwing engineering power into this problem. It might work. But I&#39;d challenge that most organizations have the scale to do it. Doing it right is astoundingly tricky and expensive.</p><p>  这是冰山一角。人们可以想到将工程权力投入这个问题。它可能有效。但是，我＆＃39; D挑战大多数组织都有规模要做。做得对令人震惊和昂贵。 </p><p>    As you can imagine, end-to-end tests have similar problems to development environments. Before, it was relatively easy to create a new development environment using virtual machines or containers. It was also fairly simple to create a test suite using Selenium to go through business flows and assert they were working before deploying a new version. After microservices, even if we can solve all the above&#39;s problems with setting up environments, we cannot declare that a system is working anymore. At most, we can state that a system with specific versions of the services running and a given configuration is working at a particular point in time. That&#39;s a huge difference!</p><p>正如您可以想象的那样，端到端测试对开发环境具有类似的问题。之前，使用虚拟机或容器创建新的开发环境相对容易。使用Selenium创建一个测试套件，通过业务流程并断言他们在部署新版本之前正常工作是相当简单的。在微服务之后，即使我们可以解决所有上述环境和＃39;在设置环境中的问题时，我们也无法声明系统是否已再次工作。至多，我们可以说明具有特定版本的服务运行的系统和给定配置在特定时间点工作。那个巨大的差异！</p><p>  It was extraordinarily tough to convince people that we could not have more than a couple of these tests. And that it wasn&#39;t enough to run them in the Continuous Integration flow. They should run continuously. And they should run against production and produce alerts accordingly. I&#39;ve shared countless times Cindy Sridharan&#39;s article &#34; Testing in production, the safe way&#34; to try to make people understand my points.</p><p>  说服人们非常难以说服我们不能超过一些这些测试。并且它是不够在持续积分流中运行它们的＆＃39;他们应该连续运行。他们应该违反生产并相应地产生警报。我分享了无数次Cindy Sridharan＆＃39; s文章＆＃34;生产中的测试，安全的方式＆＃34;试图让人们了解我的观点。</p><p>    An easy way out of the monoliths while keeping data consistency across them is to keep using a shared database. It does not increase the operational load, and it makes it easy to slice a monolith step-by-step. However, it also comes with considerable disadvantages. Aside from being an obvious single-point-of-failure, defeating some of the service-oriented architecture&#39;s principles, there&#39;s more. Do you create a user per service? Do you have fine-grained permissions so service A can only read or write from specific tables? What if someone removes an index unintentionally? How do we know how many services are using different tables? What about scaling?</p><p>    在保持数据一致性的同时，在整体上轻松出路是继续使用共享数据库。它不会增加操作负荷，并且可以轻松地逐步切片。但是，它也具有相当大的缺点。除了一个明显的单点失败，击败了一些面向服务的建筑＆＃39;＆＃39;更多。您每项服务创建用户吗？您是否具有细粒度的权限，因此服务A只能从特定表中读取或写入？如果有人无意中删除指数怎么办？我们如何知道有多少服务使用不同的表？缩放怎么样？</p><p>  Disentangling all of this becomes a whole new problem on its own. Technically, it may not be trivial, considering that databases tend to outlive software. Solving the problem using data replication — be it Kafka, AWS DMS or whatever — creates a need for your engineering teams to understand database specifics and how to deal with duplicated events, and so on.</p><p>  解开所有这一切都成为一个全新的问题。从技术上讲，考虑到数据库倾向于最终的软件，它可能不是微不足道的。使用数据复制解决问题 - 是Kafka，AWS DMS或其他 - 创建您的工程团队需要了解数据库细节以及如何处理重复的事件，等等。</p><p>    API Gateways are a typical pattern in service-oriented architectures. They&#39;re helpful to decouple the backend from the frontend consumers. They&#39;re also beneficial when it comes to implementing endpoint aggregation, rate-limiting or authentication across your system. More recently, the industry has been leaning towards  backend-for-frontend architectures, where these gateways are deployed for every single frontend consumer — iOS, Android, web, or desktop apps —, making their evolution decoupled from each other.</p><p>    API网关是面向服务的架构中的典型模式。他们＆＃39;重新有助于从前端消费者分离后端。它们在实现系统中实现端点聚合，限速或身份验证时也有益。最近，该行业一直倾向于前端架构，其中这些网关为每一个前端消费者 -  iOS，Android，Web或桌面应用程序部署 - 使他们的进化彼此分离。</p><p>  As with everything in this world, people start to have new, creative use-cases for it. Sometimes it&#39;s a small hack to make the mobile application backwards compatible. Suddenly, you have your &#34;API gateway&#34; being a single-point-of-failure — because people find it easier to handle authentication in a single place —  and with some unintended business logic inside it. Instead of having a monolith getting all of the traffic, now you have a home-made Spring Boot service getting all of it! What could go wrong? Engineers quickly realize this is a mistake, but as there are many customizations, sometimes they cannot substitute this piece for stateless, scale-friendly ones.</p><p>  与这个世界上的一切一样，人们开始为它创造新的创造性用例。有时它＆＃39;是一个小的黑客，使移动应用程序向后兼容。突然，你有你的＆＃34; API Gateway＆＃34;作为一个失败的单点 - 因为人们发现更容易在一个地方处理身份验证 - 以及它内部的一些意外业务逻辑。而不是拥有一只巨大的交通，现在你有一个自制的春天启动服务才能获得所有的春天启动服务！什么可能出错？工程师很快意识到这是一个错误，但随着许多自定义，有时他们不能替代这件作品以无规定，级别友好的。</p><p>  The culprit of the API gateways disasters comes when it consumes endpoints that are not paginated or return massive responses. Or when you make an aggregation without fallback mechanisms in place, making one single API call burn down your gateway.</p><p>  API Gateways灾害的罪魁祸首是在消耗没有分手或返回大规模响应的端点时出现的。或者当您在没有后退机制的情况下进行聚合时，使一个单个API调用刻录到网关。 </p><p>    Distributed systems are  constantly in a partial failure mode. What happens when service A can&#39;t contact service B? We can retry our request, right? But this promptly leads us to go down the rabbit hole. I&#39;ve seen teams using circuit breakers and then increase the timeouts of an HTTP call to a service downstream. While this might be a normal reaction to buy us some time to fix the problem, it creates second-order effects. Now, all these requests that your circuit breaker would cancel because they&#39;re too long are there for more time. If there&#39;s an increase in traffic, more and more requests will get queued, leading to a worse situation than the one you wanted to fix. I&#39;ve seen that engineers struggle to understand queue theory and why there are timeouts in place. The same thing happens when teams start to discuss thread pools for their HTTP clients and whatnot. While configuring those is an art in itself, setting values based on gut feeling may set you up for a significant outage.</p><p>分布式系统始终处于部分故障模式。在罐头和＃39; T联系服务B时会发生什么？我们可以重试我们的要求，对吗？但这会及时导致我们走下兔子洞。使用断路器，然后使用断路器的团队，然后将HTTP调用的超时增加到下游的服务。虽然这可能是一个正常的反应来购买我们一些时间来解决问题，但它会产生二阶效应。现在，所有这些请求使您的断路器会取消，因为它们＆＃39; re the loce在那里有更多时间。如果有流量增加，越来越多的请求将被排队，导致比您想要修复的情况更差。我看到工程师努力了解队列理论以及为什么有超时的地方。当团队开始讨论他们的HTTP客户端和Whatnot时，就会发生同样的事情。在配置那些本身的时，基于肠道的设定值可能会使您设置为显着的中断。</p><p>  A tricky thing when recovering from a failure is that not all of them are created equal. We may expect our consumer to be idempotent in some cases. But this means that we should proactively decide what to do in each of the failure scenarios. Is the consumer idempotent? Can I retry this call? I&#39;ve seen many engineers ignoring these because it&#39;s &#34;an edge case&#34;, to realize later they have a massive data integrity problem.</p><p>  从失败中恢复时棘手的事情是并非所有这些都是相等的。在某些情况下，我们可能希望消费者能够宽容。但这意味着我们应该主动决定在每个故障情景中做些什么。消费者是个体化吗？我可以重试这个电话吗？我看到许多工程师忽略了这些，因为它＆＃39; s＆＃34;一个边缘案例＆＃34;，以稍后实现它们具有大规模的数据完整性问题。</p><p>  Retries are even trickier than all of this, even if you set up fallback mechanisms. Imagine that you have five million users in your mobile app and that your message bus that updates users preferences&#39; stopped working for a while. You set up a fallback mechanism for that case, which calls the users&#39; preferences service through an HTTP API. I guess you know where I&#39;m going. Now, this service got a massive traffic spike suddenly, and it may not be able to cope with all the traffic. It&#39;s even worse than that: your service  might be able to get all these new requests, but if the retries mechanism doesn&#39;t implement exponential backoff  and jitter, you might experience a distributed denial-of-service from your mobile applications.</p><p>  即使您设置了回退机制，重试甚至比所有这些都剧烈。想象一下，您的移动应用程序中有五百万用户，您的留言总线更新用户偏好＆＃39;停止工作一会儿。您为该案例设置了一个抵押机制，该机制调用用户＆＃39;首选项通过HTTP API服务。我猜你知道在哪里我去了。现在，这项服务突然出现了大量的交通飙升，可能无法应对所有流量。它甚至更糟糕的是：您的服务可能能够获得所有这些新请求，而是如果重试机制不受指数退避和抖动，您可能会遇到来自您的分布式拒绝服务移动应用程序。</p><p>    What if I told you that I only wrote about a fraction of the disasters I&#39;ve seen? 🤣 Distributed systems are hard to grasp, and only recently most software engineers have been consistently exposed to them.</p><p>    如果我告诉过你我只写了关于灾难的一小部分我看到了什么？ 🤣分布式系统很难掌握，最近大多数软件工程师都始终暴露于它们。</p><p>   The good thing is that many of the  disasters I&#39;ve talked about have good answers, and the industry has created better tools to make them solvable by organizations other than  FAANG.</p><p>   好事是，许多灾难我谈到了有良好的答案，行业创造了更好的工具，使他们由榴景以外的组织制定。</p><p>  I still love distributed systems, and I still think that microservices are a good solution for organizational problems. However, the problems come when we think about failures as &#34;edge cases&#34; or things that we think will never happen to us. These edge cases become the new normal at a certain scale, and we should cope with them.</p><p>  我仍然喜欢分布式系统，我仍然认为微服务是组织问题的好解决方案。但是，当我们考虑到＆＃34的故障时，问题来自于＆＃34;边缘案例＆＃34;或者我们认为永远不会发生在我们身上的事情。这些边缘案例以一定的规模变成新的正常，我们应该应对它们。 </p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://world.hey.com/joaoqalves/disasters-i-ve-seen-in-a-microservices-world-a9137a51">https://world.hey.com/joaoqalves/disasters-i-ve-seen-in-a-microservices-world-a9137a51</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/服务/">#服务</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/ve/">#ve</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/分享/">#分享</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy;2012-2021 diglog.com </div></div></body></html>