<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Nvidia Ampere与AMD RDNA 2：体系结构之战 Nvidia Ampere vs. AMD RDNA 2: Battle of the Architectures</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">Nvidia Ampere vs. AMD RDNA 2: Battle of the Architectures<br/>Nvidia Ampere与AMD RDNA 2：体系结构之战 </h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2020-12-07 11:09:02</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2020/12/b46dac1829569b617283dd3411dd3d4d.jpg"><img src="http://img2.diglog.com/img/2020/12/b46dac1829569b617283dd3411dd3d4d.jpg" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>For GPU enthusiasts, it&#39;s been a long wait. Nvidia kept the Turing line going for two years before replacing it with  Ampere in September 2020. AMD were a little kinder, leaving a 15 month gap between their  new designs, but most people weren&#39;t interested in that.</p><p>对于GPU爱好者来说，这是一个漫长的等待。 Nvidia将Turing产品线维持了两年，然后在2020年9月用Ampere取代了它。AMD有点友善，他们的新设计之间有15个月的差距，但是大多数人对此并不感兴趣。</p><p>  What they wanted to see was AMD launching a top end model to compete head-to-head with the best from Nvidia. They did just that and now that we&#39;ve seen the results, PC gamers are now spoilt for choice (at least  theoretically), when it comes to spending their dollars on the best performing graphics cards.</p><p>  他们想要看到的是AMD推出了一款高端机型，与Nvidia的顶级机型进行正面竞争。他们就是这样做的，现在我们已经看到了结果，在花钱购买性能最好的显卡时，PC游戏玩家现在被选择（至少在理论上）宠坏了。</p><p>  But what about the chips powering them? Is one of them fundamentally better than the other? Read on to see how Ampere and RDNA 2 battle it out!</p><p>  但是为它们供电的芯片又如何呢？他们中的一个人从根本上优于另一个人吗？继续阅读，以了解Ampere和RDNA 2如何与之抗衡！</p><p>            High-end GPUs have been considerably bigger than CPUs for a number of years, and they&#39;ve been steadily increasing in size. AMD&#39;s latest offering is roughly 520 mm 2 in area, more than double the size of their previous  Navi chip. It&#39;s not their largest, though -- that honor goes to the GPU in their new Instinct MI100 accelerator, at around 750 mm 2.</p><p>            高端GPU多年来已经比CPU大很多，并且它们的尺寸一直在稳定增长。 AMD的最新产品面积约为520 mm 2，是其先前Navi芯片的两倍多。不过，这并不是他们最大的荣誉，该荣誉是在他们的新型Instinct MI100加速器（约750毫米2）中获得的。</p><p>  The last time AMD made a gaming processor anywhere near the size of Navi 21 was for the Radeon R9 Fury and Nano cards, which sported the GCN 3.0 architecture in a Fiji chip. It was 596 mm 2 in die area, but it was manufactured on TSMC&#39;s 28HP process node.</p><p>  AMD上一次制造接近Navi 21尺寸的游戏处理器的原因是Radeon R9 Fury和Nano卡，它们在斐济芯片中采用GCN 3.0架构。芯片面积为596 mm 2，但它是在TSMC的28HP工艺节点上制造的。</p><p>  AMD has been using TSMC&#39;s much smaller N7 process since 2018 and the biggest chip from that production line was the Vega 20 (as found in the  Radeon VII), with an area of 331 mm 2. All of their Navi GPUs are made on a slightly updated version of that process, called N7P, so it makes to compare these products.</p><p>  自2018年以来，AMD一直在使用台积电（TSMC）较小的N7工艺，该生产线中最大的芯片是Vega 20（在Radeon VII中发现），面积为331 mm 2.所有Navi GPU均为它是在该过程的稍有更新的版本（称为N7P）上制成的，因此可以比较这些产品。</p><p>      But when it comes to sheer die size, Nvidia takes the crown, not that this is necessarily a good thing. The latest Ampere-based chip, the GA102, is 628 mm 2. That&#39;s actually about 17% smaller than its forefather, the TU102 -- that GPU was a staggering 754 mm 2 in die area.</p><p>      但是，就绝对尺寸而言，Nvidia夺冠，但这不一定是一件好事。最新的基于Ampere的芯片GA102为628 mm2。实际上，它的尺寸比其前身TU102小约17％，即GPU的芯片面积惊人地达到了754 mm 2。 </p><p>  Both pale in size when compared to Nvidia&#39;s monstrous GA100 chip - used in AI &amp; data centers, this GPU is 826 mm 2 and it&#39;s a TSMC N7 chip. While never designed to power a desktop graphics card, it does show what scale of GPU manufacturing is possible.</p><p>与Nvidia巨大的GA100芯片（用于AI和A数据中心，该GPU为826 mm 2，是台积电N7芯片。尽管从未设计过为台式机显卡供电，但它确实显示了GPU制造的规模。</p><p>  Putting them all side-by-side highlights just how bulky Nvidia&#39;s biggest GPUs are. The Navi 21 looks fairly svelte, although there&#39;s more to a processor than just die area. The GA102 is packing around 28.3 billion transistors, whereas AMD&#39;s new chip sports 5% fewer, at 26.8 billion.</p><p>  将它们放在一起可以突出显示Nvidia最大的GPU有多庞大。 Navi 21看起来相当苗条，尽管处理器的功能不仅仅是模具面积。 GA102封装了约283亿个晶体管，而AMD的新芯片则少了5％，为268亿个。</p><p>    What we don&#39;t know is how many layer each GPU is built of, so all we can compare is the ratio of transistors to die area, typically called  die density. The Navi 21 is roughly 51.5 million transistors per square mm, but the GA102 is notably lower at 41.1 -- it could be that Nvidia&#39;s chip is stacked a little higher than AMD&#39;s, but it&#39;s more likely to be an indication of process node.</p><p>    我们不知道每个GPU构建多少层，因此我们所能比较的是晶体管与裸片面积的比率，通常称为裸片密度。 Navi 21约为每平方毫米5150万个晶体管，但GA102明显低于41.1，这可能是Nvidia的芯片堆叠度比AMD高一点，但它的更可能是过程节点的指示。</p><p>  As already mentioned, the Navi 21 is manufactured by TSMC, using their N7P production method, which offers a small increase in performance over N7; but for their new offering, the GA102, Nvidia turned to Samsung for production duties. The South Korea semiconductor giant is using a tweaked version, specifically for Nvidia, of their so-called  8 nm node (labelled as 8N or 8NN).</p><p>  如前所述，Navi 21由台积电使用N7P生产方法制造，与N7相比，性能略有提高。但是对于Nvidia的GA102新产品，他们求助于三星进行生产。这家韩国半导体巨头正在使用经过调整的版本，专门针对Nvidia，即所谓的8 nm节点（标记为8N或8NN）。</p><p>  These node values, 7 and 8, have little to do with the actual size of the components with the chips: they&#39;re simply marketing terms, used to differentiate between the various production techniques. That said, even if the GA102 has more layers than the Navi 21, the die size does have one particular impact.</p><p>  这些节点值7和8与芯片组件的实际尺寸没有太大关系：它们只是市场术语，用于区分各种生产技术。也就是说，即使GA102的层数比Navi 21的层数多，裸片尺寸的确会产生特别的影响。</p><p>      Microprocessors and other chips are fabricated from large, circular discs of highly refined silicon and other materials, called  wafers. TSMC and Samsung use 300 mm wafers for AMD and Nvidia, and each disc will generate more chips using smaller dies compared to larger ones.</p><p>      微处理器和其他芯片是由大型圆形圆盘制成的，这些圆盘由高度精炼的硅和其他称为晶圆的材料制成。台积电和三星为AMD和Nvidia使用300毫米晶圆，与更大的芯片相比，使用较小的芯片，每张光盘将产生更多的芯片。</p><p>  The difference is unlikely to be huge, but when every wafer costs thousands of dollars to produce, AMD have a small advantage over Nvidia, when it comes to keeping manufacturing costs down. That&#39;s assuming, of course, Samsung or TSMC aren&#39;t doing some kind of financial deal with AMD/Nvidia.</p><p>  这种差异不可能很大，但是在降低制造成本方面，当每片晶圆的生产成本达到数千美元时，AMD相对于Nvidia而言优势较小。当然，这是假设三星或台积电没有与AMD / Nvidia进行某种财务交易。 </p><p>  All of this die size and transistor count shenanigans would be for naught, if the chips themselves weren&#39;t any good at what they&#39;re design to do. So let&#39;s dig into the layouts of each new GPU and see what&#39;s underneath their hoods.</p><p>如果芯片本身不擅长于设计工作，那么所有这些芯片尺寸和晶体管数的恶作剧将是徒劳的。因此，让我们深入研究每个新GPU的布局，看看它们背后的东西。</p><p>        We start our exploration of the architectures with a look at the overall structure of the Ampere GA102 and RDNA 2 Navi 21 GPUs -- these diagrams don&#39;t necessarily show us how everything is physically laid out, but they give a clear indication as to how many components the processors have.</p><p>        我们通过查看Ampere GA102和RDNA 2 Navi 21 GPU的整体结构来开始对体系结构的探索-这些图不一定表明我们在物理上是如何布置的，但是它们给出了明确的指示：处理器有多少个组件。</p><p>  In both cases, the layouts are very familiar, as they are essentially expanded versions of their predecessors. Adding more units to process instructions will always increase the performance of a GPU, because at high resolutions in the latest 3D blockbusters, the rendering workloads involve a huge number of parallel calculations.</p><p>  在这两种情况下，布局都是非常熟悉的，因为它们实质上是其前身的扩展版本。在处理指令中添加更多的单元将始终提高GPU的性能，因为在最新的3D大型电影中，在高分辨率下，渲染工作负载涉及大量的并行计算。</p><p>    Such diagrams are useful, but for this particular analysis, it&#39;s actually more interesting looking at where the various components are within the GPU dies themselves. When designing a large scale processor, you generally want shared resources, such as controllers and cache in a central position, to ensure every component has the same path to them.</p><p>    这样的图很有用，但是对于这种特定的分析来说，查看各个组件在GPU自身内部的位置实际上更有趣。在设计大型处理器时，通常需要将共享资源（例如控制器和缓存）放在中央位置，以确保每个组件都具有相同的路径。</p><p>  Interface systems, such as local memory controllers or video outputs, should go on the edges of the chip to make it easier to connect them to the thousands of individual wires that link the GPU to the rest of the graphics card.</p><p>  接口系统（例如本地内存控制器或视频输出）应放在芯片的边缘，以使它们更容易地连接到成千上万的将GPU与图形卡其余部分连接的独立电线。</p><p>  Below are false-color images of AMD&#39;s Navi 21 and Nvidia&#39;s GA102 dies. Both have been run through some image processing to clean up the images, and both are really only showing one layer within the chip; but they do give us a superb view of the innards of a modern GPU.</p><p>  以下是AMD Navi 21和Nvidia GA102芯片的伪彩色图像。两者都经过一些图像处理以清理图像，并且实际上都只在芯片中显示了一层。但是它们确实使我们对现代GPU的内在感觉有了极好的了解。</p><p>    The most obvious difference between the designs is that Nvidia hasn&#39;t followed a centralized approach to the chip layout -- all of the system controllers and main cache are at the bottom, with the logic units running in long columns. They&#39;ve done this in the past, but only with middle/lower end models.</p><p>    设计之间最明显的区别是Nvidia并未采用集中式的芯片布局方法-所有系统控制器和主缓存位于底部，逻辑单元排成一列。他们过去曾经这样做过，但仅限于中/低端型号。 </p><p>  For example, the Pascal GP106 (used in the likes of the  GeForce GTX 1060) was literally half of a GP104 (from the GeForce  GTX 1070). The latter was the larger chip, and had its cache and controllers in the middle; these moved to the side in its sibling, but only because of the design had been split.</p><p>例如，Pascal GP106（用于GeForce GTX 1060等）实际上是GP104（来自GeForce GTX 1070）的一半。后者是较大的芯片，其缓存和控制器位于中间。这些都移到了它的兄弟姐妹那一边，但这只是因为设计已经被拆分了。</p><p>      For all their previous top end GPU layouts, Nvidia used a classic centralized organization. So why the change here? It can&#39;t be for interface reasons, as the memory controllers and the PCI Express system all run around the edge of the die.</p><p>      对于所有以前的高端GPU布局，Nvidia使用了经典的集中式组织。那么，为什么要在这里进行更改？可能不是出于接口的原因，因为内存控制器和PCI Express系统都在裸片边缘运行。</p><p>  It won&#39;t be for thermal reasons either, because even if the cache/controller part of the die ran hotter than the logic sections, you&#39;d still want it in the middle to have more silicon around it to help absorb and dissipate the heat. Although we&#39;re not totally sure of the reason for this change, we suspect that it&#39;s to do with the changes Nvidia have implemented with the ROP ( render output) units in the chip.</p><p>  这也不是出于热学原因，因为即使芯片的缓存/控制器部分比逻辑部分的温度更高，您仍然希望它的中间有更多的硅以帮助吸收。并散发热量。尽管我们不确定此更改的原因，但我们怀疑这与Nvidia对芯片中的ROP（渲染输出）单元实施的更改有关。</p><p>  We&#39;ll look at those in more detail later on, but for now let&#39;s just say that while the change in layout looks odd, it won&#39;t make a significant difference to performance. This is because 3D rendering is riddled with lots of long latencies, typically due to having to wait for data. So the additional nanoseconds added by having some logic units further from the cache than others, all get hidden in the grand scheme of things.</p><p>  稍后我们将详细介绍这些内容，但现在让我们说的是，尽管布局更改看起来很奇怪，但不会对性能产生重大影响。这是因为3D渲染充满了很多长等待时间，通常是因为必须等待数据。因此，通过使某些逻辑单元比其他逻辑单元更远离缓存，所增加的额外纳秒都隐藏在事物的宏伟方案中。</p><p>  Before we move on, it&#39;s worth remarking on the engineering changes AMD implemented in the Navi 21 layout, compared to the Navi 10 that powered the likes of the  Radeon RX 5700 XT. Even though the new chip is double the size, both in terms of area and transistor count, than the earlier one, the designers also managed to also improve the clock speeds, without significantly increasing power consumption.</p><p>  在继续之前，值得一提的是AMD在Navi 21布局中实施的工程变更，与为Radeon RX 5700 XT之类的处理器提供动力的Navi 10相比。尽管新芯片的面积和晶体管数量都比早期芯片大了一倍，但设计人员还设法在不显着增加功耗的情况下提高了时钟速度。</p><p>  For example, the  Radeon RX 6800 XT sports a base clock and boost clock of 1825 and 2250 MHz respectively, for a TDP of 300 W; the same metrics for the Radeon RX 5700 XT were 1605 MHz, 1905 MHz, and 225 W. Nvidia raised the clock speeds with Ampere, too, but some of that can be attributed towards using a smaller and more efficient process node.</p><p>  例如，对于300 W的TDP，Radeon RX 6800 XT的基本时钟和升压时钟分别为1825和2250 MHz。 Radeon RX 5700 XT的相同指标分别是1605 MHz，1905 MHz和225W。Nvidia也提高了Ampere的时钟速度，但是其中一些可以归因于使用更小，更高效的处理节点。</p><p>    Our  performance-per-watt examination of Ampere and RDNA 2 cards showed that both vendors have made significant improvements in this area, but AMD and TSMC have achieved something quite remarkable -- compare the difference between the Radeon RX 6800 and the Radeon VII in the chart above.</p><p>    我们对Ampere和RDNA 2卡的每瓦性能检查表明，两家供应商在该领域均取得了显着改善，但AMD和TSMC取得了显着进步-比较Radeon RX 6800和Radeon VII在性能上的区别。上面的图表。 </p><p>  The latter was their first GPU collaboration using the N7 node and in the space of less than two years, they&#39;ve increased the performance-per-watt by 64%. It does beg the question as to how much better the Ampere GA102 could have been, had Nvidia stayed with TSMC for their production duties.</p><p>后者是他们首次使用N7节点进行GPU合作，并且在不到两年的时间内，他们将每瓦性能提高了64％。的确，如果英伟达（Nvidia）留在台积电（TSMC）从事生产工作，那安培GA102的性能会好得多。</p><p>          When it comes to the processing of instructions and managing data transfers, both Ampere and RDNA 2 follow a similar pattern to how everything is organized inside the chips. Game developers code their titles using a graphics API, to make all of the images; it might be Direct3D, OpenGL, or Vulkan. These are essentially software libraries, packed full of &#39;books&#39; of rules, structures, and simplified instructions.</p><p>          当涉及到指令处理和数据传输管理时，Ampere和RDNA 2都遵循类似于芯片内部所有事物组织方式的模式。游戏开发人员使用图形API对标题进行编码，以制作所有图像；它可能是Direct3D，OpenGL或Vulkan。这些本质上是软件库，里面装满了＆＃39; s＆＃39;规则，结构和简化说明。</p><p>  The drivers that AMD and Nvidia create for their chips essentially work as translators: converting the routines issued via the API into a sequence of operations that the GPUs can understand. After that, it&#39;s entirely down to the hardware to manage things, with regards to what instructions get done first, what part of the chip does them, and so on.</p><p>  AMD和Nvidia为它们的芯片创建的驱动程序本质上可以用作翻译器：将通过API发出的例程转换为GPU可以理解的一系列操作。之后，完全取决于硬件来管理事物，例如首先要完成哪些指令，执行这些指令的芯片的哪一部分等等。</p><p>  This initial stage of instruction management is handled by a collection of units, reasonably centralized in the chip. In RDNA 2, graphics and compute shaders are routed through separate pipelines, that schedule and dispatch the instructions to the rest of the chip; the former is called the  Graphics Command Processor, the latter are  Asynchronous Compute Engines (ACEs, for short).</p><p>  指令管理的初始阶段由合理地集中在芯片中的一组单元处理。在RDNA 2中，图形和计算着色器通过单独的管线进行路由，这些管线将指令调度并调度到芯片的其余部分；前者称为图形命令处理器，后者是异步计算引擎（ACE）。</p><p>    Nvidia just uses one name to describe their set of management units, the  GigaThread Engine, and in Ampere it does the same task as with RDNA 2, although Nvidia doesn&#39;t say too much about  how it actually manages things. Altogether, these command processors function rather like a production manager of a factory.</p><p>    Nvidia只是用一个名字来描述他们的一组管理单元，即GigaThread引擎，并且在Ampere中它执行与RDNA 2相同的任务，尽管Nvidia并未过多说明其实际管理方式。总之，这些命令处理器的功能类似于工厂的生产经理。</p><p>  GPUs get their performance from doing everything in parallel, so the next level of organization is duplicated across the chip. Sticking with the factory analogy, these would be akin to a business that has a central office, but multiple locations for the manufacturing of goods.</p><p>  GPU通过并行执行所有操作来获得性能，因此在整个芯片上复制了下一个组织级别。坚持工厂的类比，这类似于拥有中央办公室但在多个地点生产商品的企业。</p><p>  AMD uses the label  Shader Engine (SE), whereas Nvidia calls theirs  Graphics Processing Clusters (GPC) -- different names, same role.</p><p>  AMD使用标签Shader Engine（SE），而Nvidia则称其为图形处理集群（GPC）-不同的名称，相同的角色。 </p><p>    The reason for this partitioning of the chip is simple: the command processing units just can&#39;t handle everything, as it would end up being far too large and complex. So it makes sense to push some of the scheduling and organization duties further down the line. It also means each separation partition can be doing something completely independent of the others -- so one could be handling a raft of graphics shaders, while the others are grinding through long, complex compute shaders.</p><p>对该芯片进行分区的原因很简单：命令处理单元无法处理所有内容，因为它最终会变得太大和太复杂。因此，将一些调度和组织职责进一步推向下游是有意义的。这也意味着每个分离分区都可以做完全独立于其他分区的事情-因此一个分区可以处理大量的图形着色器，而其他分区则可以处理冗长而复杂的计算着色器。</p><p>  In the case of RDNA 2, each SE contains its own set of  fixed function units: circuits that are designed to do one specific task, that typically can&#39;t be heavily adjusted by a programmer.</p><p>  在RDNA 2的情况下，每个SE包含其自己的一组固定功能单元：设计用于执行一个特定任务的电路，通常程序员无法对其进行大量调整。</p><p>  Primitive Setup unit -- gets vertices ready for processing, as well as generating more (tessellation) and culling them</p><p>  原始设置单元-准备处理顶点，以及生成更多（镶嵌）并剔除它们</p><p>  The primitive setup unit runs at a rate of 1 triangle per clock cycle. This might not sound like very much but don&#39;t forget that these chips are running at anywhere between 1.8 and 2.2 GHz, so primitive setup shouldn&#39;t ever be a bottleneck for the GPU. For Ampere, the primitive unit is found in the next tier of organization, and we&#39;ll cover that shortly.</p><p>  基本设置单元每个时钟周期以1个三角形的速率运行。这听起来似乎不是很多，但是请不要忘记这些芯片的运行频率在1.8至2.2 GHz之间，因此原始设置永远不会成为GPU的瓶颈。对于Ampere，原始单位位于组织的下一层，我们将在短期内进行介绍。</p><p>  Neither AMD nor Nvidia say too much about their rasterizers. The latter calls them  Raster Engines, we know that they handle 1 triangle per clock cycle, and spit out a number of pixels, but there&#39;s no further information to hand, such as their sub-pixel precision, for example.</p><p>  AMD和Nvidia都没有对光栅化器说太多。后者称为Raster Engine，我们知道它们每个时钟周期处理1个三角形，并吐出许多像素，但是没有其他信息，例如其子像素精度。</p><p>  Each SE in the Navi 21 chip sports 4 banks of 8 ROPs, resulting in a total of 128 render output units; Nvidia&#39;s GA102 packs 2 banks of 8 ROPs per GPC, so the full chip sports 112 units. This might seem that AMD has the advantage here, because more ROPs means more pixels can be processed per clock. But such units need good access to cache and local memory, and we&#39;ll say more about that later in this article. For now, let&#39;s continue looking at how the SE/GPC partitions are further divided.</p><p>  Navi 21芯片中的每个SE具有4组8 ROP的库，因此总共有128个渲染输出单元。 Nvidia的GA102每个GPC包含2组8 ROP的库，因此全芯片可容纳112个单元。这似乎是AMD的优势所在，因为更多的ROP意味着每个时钟可以处理更多的像素。但是，此类单元需要良好的缓存和本地内存访问权限，我们将在本文后面详细介绍。现在，让我们继续研究如何进一步划分SE / GPC分区。</p><p>    AMD&#39;s Shader Engines are sub-partitioned in what they term  Dual Compute Units (DCUs), with the Navi 21 chip fielding ten DCUs per SE -- note that in some documents, they&#39;re also classed as  Workgroup Processors (WGP). In the case of Ampere and the GA102, they&#39;re called  Texture Processing Clusters (TPCs), with each GPU containing 6 TPCs. Every cluster in Nvidia&#39;s design houses something called a  Polymorph Engine -- essentially, Ampere&#39;s primitive setup units.</p><p>    AMD的着色器引擎被细分为双计算单元（DCU），Navi 21芯片每个SE分配了十个DCU-请注意，在某些文档中，它们也被归类为工作组处理器。 （WGP）。对于Ampere和GA102，它们称为纹理处理群集（TPC），每个GPU包含6个TPC。 Nvidia设计中的每个集群都包含一个称为Polymorph Engine的东西-本质上是Ampere的原始设置单元。 </p><p>  They too run at a rate of 1 triangle per clock, and although Nvidia&#39;s GPUs are clocked lower than AMD&#39;s, they have a lot more TPCs than Navi 21 has SEs. So for the same clock speed, the GA102 should have a notable advantage as the complete chip holds 42 primitive setup units, whereas AMD&#39;s new RDNA 2 has just 4. But since there are six TPCs per Raster Engine, the GA102 effectively has 7 complete primitive systems, to the Navi 21&#39;s four. Since the latter isn&#39;t clocked 75% higher than the former, it would seem that Nvidia takes a clear lead here, when it comes to geometry handling (though no game is likely to be limited in this area).</p><p>它们也以每个时钟1个三角形的速率运行，尽管Nvidia的GPU的时钟频率低于AMD的GPU，但它们的TPC却比Navi 21的SE多得多。因此，对于相同的时钟速度，GA102应该具有显着的优势，因为完整的芯片可容纳42个原始设置单元，而AMD的新RDNA 2只有4个。但是，由于每个光栅引擎有六个TPC，因此GA102有效拥有7个完整的原始系统，至Navi 21的四个。由于后者的时钟频率比前者高75％，因此在几何处理方面，Nvidia似乎在这一方面遥遥领先（尽管在这一领域没有游戏可能会受到限制）。</p><p>  The final tier of the chips&#39; organization are the  Compute Units (CUs) in RDNA 2 and the  Streaming Multiprocessors (SMs) in Ampere -- the production lines of our GPU factories.</p><p>  芯片的最后一层组织是RDNA 2中的计算单元（CU）和安培中的流式多处理器（SM），这是我们GPU工厂的生产线。</p><p>    These are very much the meat-and-vegetables in the GPU pie, as these hold all of the highly programmable units used to process graphics, compute, and now ray tracing shaders. As you can see in the above image, each one takes up a very small portion of the overall die space, but they are still extremely complex and highly important to the overall performance of the chip.</p><p>    这些是GPU饼图中的主要部分，因为它们包含了用于处理图形，计算以及现在的光线跟踪着色器的所有高度可编程单元。从上图中可以看到，每个芯片仅占整个芯片空间的很小一部分，但它们仍然极其复杂，对芯片的整体性能非常重要。</p><p>  Up to now, there hasn&#39;t been any serious deal-breakers, when it comes to how everything is laid out and organized in the two GPUs -- the nomenclature is all different, but their functions are much the same. And because so much of what they do is limited by programmability and flexibility, any advantages one has over the other, just comes down to a sense of scale, i.e. which one has the most of that particular thing.</p><p>  到目前为止，在两个GPU上如何布置和组织一切方面，还没有任何严肃的交易突破口—命名法都是不同的，但是它们的功能却大体相同。而且由于它们所做的很多事情都受可编程性和灵活性的限制，因此一个人相对于另一个人所具有的任何优势，都只能归结为规模感，即哪个人拥有最大的特色。</p><p>  But with the CUs and SMs, AMD and Nvidia take different approaches to how they go about processing shaders. In some areas, they share a lot in common, but there are plenty of others where that&#39;s not the case.</p><p>  但是对于CU和SM，AMD和Nvidia采用不同的方法来处理着色器。在某些领域，它们有很多共同点，但在其他许多领域则并非如此。</p><p>      Since Ampere ventured into the wild before RDNA 2, we&#39;ll take a look at Nvidia&#39;s SMs first. There&#39;s no point in looking at images of the die itself now, as they can&#39;t tell us exactly what&#39;s inside them, so let&#39;s use an organization diagram. These aren&#39;t supposed to be representations of how the various components are physically arranged in the chip, just how many of each type are present.</p><p>      由于安培（Ampere）在RDNA 2之前闯入了野外，所以我们首先来看看Nvidia的SM。现在没有必要查看芯片本身的图像，因为它们无法准确告诉我们其中的内容，因此我们使用组织图。这些不应该表示芯片中各种组件的物理排列方式，以及每种类型中存在多少个组件。</p><p>  Where Turing was a substantial change to its desktop predecessor Pascal (losing a stack of FP64 units and registers, but gaining tensor cores and ray tracing), Ampere is actually a fairly mild update -- on face value, at least. As far as Nvidia&#39;s marketing division was concerned, though, the new design more than doubled the number of CUDA cores in each SM.</p><p>  图灵对其台式机前身Pascal进行了实质性更改（丢失了一堆FP64单元和寄存器，但是获得了张量核心和光线跟踪），而Ampere实际上是一个相当温和的更新-至少在面值上。不过，就Nvidia的市场部门而言，新设计使每个SM中CUDA内核的数量增加了一倍以上。 </p><p>    In Turing, the Streaming Multiprocessors contain four partitions (sometimes called processing blocks), where each house 16x INT32 and 16x FP32 logic units. These circuits are designed to carry out very specific mathematical operations on 32-bit data values: the INT units handled integers, and the FP units worked on floating point, i.e. decimal, numbers.</p><p>在图灵中，流多处理器包含四个分区（有时称为处理块），每个分区中容纳16个INT32和16x FP32逻辑单元。这些电路旨在对32位数据值执行非常具体的数学运算：INT单元处理整数，而FP单元处理浮点数（即十进制）。</p><p>  Nvidia states that an Ampere SM has a total of 128 CUDA cores, but strictly speaking, this isn&#39;t true -- or if we must stick to this count, then so too did Turing. The INT32 units in that chip could  actually handle float values, but only in a very small number of simple operations. For Ampere, Nvidia has opened the range of floating point math operations they support to match the other FP32 units. That means the total number of CUDA cores per SM hasn&#39;t really changed; it&#39;s just that half of them now have more capability.</p><p>  英伟达（Nvidia）表示，一个Ampere SM总共有128个CUDA内核，但是严格来说，这不是真的-如果我们必须坚持这一点，那么图灵（Turing）也是如此。该芯片中的INT32单元实际上可以处理浮点值，但只能通过非常少量的简单操作进行。对于Ampere，Nvidia已开放了它们支持的浮点数学运算范围，以匹配其他FP32单元。这意味着每个SM的CUDA内核总数并未真正改变。现在只有其中一半拥有更多功能。</p><p>  All of the cores in each SM partition processes the same instruction at any one time, but since the INT/FP units can operate independently, the Ampere SM can handle up to 128x FP32 calculations per cycle  or 64x FP32 and 64x INT32 operations together. In Turing, it was just the latter.</p><p>  每个SM分区中的所有内核都可以随时处理同一条指令，但是由于INT / FP单元可以独立运行，因此Ampere SM每个周期最多可以处理128x FP32计算或一起处理64x FP32和64x INT32操作。在图灵，只是后者。</p><p>  So the new GPU has, potentially,  double the FP32 output than its predecessor. For compute workloads, especially in professional applications, this is a big step forward; but for games, the benefits will be far more muted. This was evident when we first tested the GeForce RTX 3080, which uses a GA102 chip with 68 SMs enabled.</p><p>  因此，新的GPU可能使FP32的输出量比其上一代产品大一倍。对于计算工作负载，尤其是在专业应用程序中，这是向前迈出的一大步。但是对于游戏而言，收益将远远没有达到预期。当我们首次测试GeForce RTX 3080时，这一点很明显，它使用启用了68个SM的GA102芯片。</p><p>    Despite having a peak FP32 throughput 121% over the GeForce 2080 Ti, it only averages a 31% increase in frame rates. So why is all that compute power going to waste? The simple answer is that it&#39;s not, but games aren&#39;t running FP32 instructions all the time.</p><p>    尽管FP32的峰值吞吐量比GeForce 2080 Ti高出121％，但平均帧速率仅提高了31％。那么，为什么所有这些计算能力都会浪费掉呢？一个简单的答案是，不是，但是游戏并不是一直在运行FP32指令。</p><p>  When Nvidia released Turing in 2018, they  pointed out that on average about a 36% of the instructions processed by a GPU involved INT32 routines. These calculations are typically run for working out memory addresses, comparisons between two values, and logic flow/control.</p><p>  当Nvidia在2018年发布Turing时，他们指出，GPU处理的指令平均约有36％涉及INT32例程。这些计算通常用于计算内存地址，两个值之间的比较以及逻辑流/控制。</p><p>    So for those operations, the dual rate FP32 feature doesn&#39;t come into play, as the units with the two data pathways can only do integer  or floating point. And an SM partition will only switch to this mode if all 32 threads, being handled by it at the time, have the  same FP32 operation lined up to be processed. In all other cases, the partitions in Ampere operate just as they do in Turing.</p><p>    因此，对于这些操作，双速率FP32功能没有发挥作用，因为具有两个数据路径的单元只能执行整数或浮点运算。而且，只有在当时由它处理的所有32个线程都排队处理相同的FP32操作时，SM分区才会切换到此模式。在所有其他情况下，安培中的分区与图灵中的分区一样运行。 </p><p>  This means the likes of the  GeForce RTX 3080 only has a 11% FP32 advantage over the 2080 Ti, when operating in INT+FP mode. This is why the actual performance increase seen in games isn&#39;t as high as the raw figures suggest it should be.</p><p>这意味着在INT + FP模式下运行时，GeForce RTX 3080之类的FP32仅比2080 Ti具有11％的FP32优势。这就是为什么在游戏中看到的实际性能提升没有原始数据所预期的那么高的原因。</p><p>  Other improvements? There are fewer Tensor Cores per SM partition, but each one is a lot more capable than those in Turing. These circuits perform a very specific calculations (such as multiply two FP16 values and accumulate the answer with another FP16 number), and each core now does 32 of these operations per cycle.</p><p>  其他改进？每个SM分区的Tensor Core更少，但每个都比Turing中的功能强大得多。这些电路执行非常具体的计算（例如将两个FP16值相乘并用另一个FP16编号累加答案），每个内核现在每个周期执行32次这些操作。</p><p>    They also support a new feature called   Fine-Grained Structured Sparsity and without going into the details of it all, essentially it means the math rate can be doubled, by pruning out data that doesn&#39;t affect the answer. Again, this is good news for professionals working with neural networks and AI, but at the moment, there&#39;s no significant benefit for game developers.</p><p>    他们还支持一项称为“细粒度结构化稀疏性”的新功能，并且无需赘述所有内容，从本质上讲，这意味着可以通过删除不影响答案的数据来将数学速率提高一倍。同样，对于使用神经网络和AI的专业人员来说，这是个好消息，但是目前，对于游戏开发人员而言，这还没有显着的好处。</p><p>  The ray tracing cores have also been tweaked: they can now work independently of the CUDA cores, so while they&#39;re doing BVH traversal or ray-primitive intersection math, the rest of the SM can still be processing shaders. The part of the RT Core that handles the testing of whether or not a ray intersects a primitive has doubled in performance, too.</p><p>  光线跟踪核心也已进行了调整：它们现在可以独立于CUDA核心工作，因此，在进行BVH遍历或射线原始相交数学时，SM的其余部分仍可以处理着色器。 RT Core处理光线是否与图元相交的部分的性能也提高了一倍。</p><p>    The RT Cores also sport additional hardware to help apply ray tracing to motion blur, but this feature is currently only</p><p>    RT核心还具有其他硬件，可帮助将光线跟踪应用于运动模糊，但是此功能目前仅</p><p>......</p><p>...... </p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/nvidia/">#nvidia</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/ampere/">#ampere</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/rdna/">#rdna</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/芯片/">#芯片</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/分享/">#分享</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy; 2020 diglog.com </div></div></body></html>