<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Facebook一直是白人上级主义者的自动化页面 Facebook has been autogenerating pages for white supremacists</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">Facebook has been autogenerating pages for white supremacists<br/>Facebook一直是白人上级主义者的自动化页面 </h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2021-03-26 21:00:23</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2021/3/a90383e6f42199b89ec4d0b713246314.jpg"><img src="http://img2.diglog.com/img/2021/3/a90383e6f42199b89ec4d0b713246314.jpg" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>Facebook CEO Mark Zuckerberg is testifying before Congress today, and he may have a few more uncomfortable questions to answer. Among them, why is Facebook autogenerating pages for white supremacist groups?</p><p>Facebook首席执行官Mark Zuckerberg今天在国会之前作证，他可能有一些更不舒服的问题来回答。其中，为什么Facebook自动化页面为白色至高无上的群体？</p><p> Researchers at the Tech Transparency Project  found that Facebook created dozens of pages for groups like the “Universal Aryan Brotherhood Movement” when a user did something as simple as listing it as their employer. Some of the autogenerated pages garnered thousands of likes by the time they were discovered by researchers. TTP also discovered four Facebook groups that had been created by users. The researchers shared their findings with Facebook, which removed most of the pages. Yet, two of the autogenerated pages and all four Facebook groups remained active when the group published its findings.</p><p> 科技透明度项目的研究人员发现，当一个用户在将其作为雇主列出时，Facebook为“通用aryan兄弟会移动”等群体创造了数十个页面。一些自动化的页面当研究人员发现的时间时，达到了数千个喜欢的人。 TTP还发现了用户创建的四个Facebook组。研究人员与Facebook分享了他们的发现，删除了大多数页面。然而，当集团发布其调查结果时，两个自动化的页面和所有四个Facebook组仍然活跃。</p><p> Facebook reportedly banned “white nationalist” content following the 2019 mass shooting at a New Zealand mosque, expanding on an earlier ban of white supremacist content.</p><p> 据报道，在新西兰清真寺的2019年大众射击之后，Facebook禁止了“白色民族主义者”内容，在早期禁止白天至高无上的含量。</p><p> It wasn’t hard for the researchers to find offending pages and groups. They simply searched Facebook for the names of neo-Nazi and white supremacist groups identified by the Anti-Defamation League and the Southern Poverty Law Center. More than half of the groups in their query of 221 names returned results. A total of 113 white supremacist organizations and groups had a presence on Facebook, sometimes more than one. One user-generated page that has been active for over a decade had 42,000 likes. Ten other pages and one group had more than 1,000 likes each.</p><p> 研究人员并不难以找到违法的页面和群体。他们只是在Facebook上搜索了由反诽谤联赛和南方贫困律中心确定的新纳粹和白色至高无上的群体的名称。他们查询的一半以上的组返回结果。共有113个白人至上，组织和团体在Facebook上存在了存在，有时候不止一个。一个在十年内已经活跃的一个用户生成的页面有42,000人喜欢。 10个其他页面和一组每次都有1000多个喜欢。</p><p> Much of Facebook’s moderation system  relies on artificial intelligence to flag potential violations for human moderators, a system that appears to be easily thwarted.  Simple misspellings of words—whether by adding vowels or using  $ in place of S, for example—have been enough to foil algorithmic moderation.</p><p> Facebook的审核系统大部分依赖于人工智能来销售人类主持人的潜在违规行为，这是一种似乎很容易被挫败的系统。单词的简单拼写错误 - 无论是添加元音还是使用$代替S，例如 - 已经足以融合算法适度。</p><p>    Facebook’s own user-interfacing algorithms have also been coming up short. TTP found that on a page for an organization called the “Nazi Low Riders,” Facebook recommended that users also like a page for the “Aryanbrotherhood.”</p><p>    Facebook自己的用户界面算法也在很短。 TTP发现，在一个名为“纳粹低骑手的组织的页面上，Facebook建议用户也喜欢”aryanbrothellood“的页面。</p><p> The company’s tactic for combatting rising extremism on the site also appears to be failing. Searches for known hate groups are supposed to direct users to the page for Life After Hate, a nonprofit group that seeks to  deradicalize right-wing extremists. But that only worked in 14 of the 221 searches the researchers performed.</p><p> 该公司对网站上的崛起极端主义的策略也似乎失败了。寻找已知的仇恨群体应该在仇恨之后将用户指向终身的页面，这是一种旨在嘲笑右翼极端分子的非营利组织。但是，只有在221中的14中工作，只搜索研究人员进行的。 </p><p>  Facebook has had similar problems with far-right militias, according to a  related investigation by the TTP and Buzzfeed. Facebook had banned several militant groups last August, but researchers turned up still-active autogenerated pages for some of the militias.</p><p>根据TTP和Buzzfeed的相关调查，Facebook对远方的MILITIA有类似的问题。 Facebook去年8月禁止了几个激进分子团体，但研究人员对一些民兵来说仍然活跃的自动化页面。</p><p> Earlier this year, Facebook came  under fire in the wake of the January 6 insurrection at the US Capitol for its role in the violence. Reports revealed that not only were people using Facebook to organize in advance of the rally and related attack, many were radicalized by Facebook and its platforms, including Instagram.</p><p> 今年早些时候，Facebook在美国国会大厦的1月6日起在暴力中发挥作用的第6月的叛乱之后，遭到了火灾。报告显示，由于人们在集会和相关攻击方面组织组织的人不仅是人们，而且许多人被Facebook及其平台在内的，包括Instagram。</p><p> Mentions of groups involved in the insurrection, including the Proud Boys, have been banned since 2018, yet in recent weeks TTP researchers found militia groups spreading propaganda. One included a three-minute “highlight reel” of the Capitol riot along with Proud Boys attacking Black Lives Matter protesters.</p><p> 自2018年以来禁止了包括骄傲的男孩，包括骄傲的男孩，包括骄傲的男孩的叛乱的群体提到。然而，最近几周的TTP研究人员发现民兵群体传播宣传宣传。其中包括一个三分钟的“亮点卷轴”的国会大厦骚乱以及攻击黑人生活抗议者的骄傲的男孩。</p><p> Facebook’s groups problem hasn’t gone unnoticed within the company. Facebook’s own researchers  warned top executives as early as August 2020 that 70 percent of the 100 most active US “civic” groups on the platform were “considered non-recommendable for issues such as hate, misinfo, bullying, and harassment.” One particularly large group with 58,000 members spread “enthusiastic calls for violence every day.”</p><p> Facebook的团体问题在公司内没有被忽视。 Facebook自己的研究人员早在2020年8月推出顶级高管，该平台上的100个最活跃的100个最活跃的美国“公民”团体中的70％被认为是不适合的仇恨，误导，欺凌和骚扰等问题。“一个特别大的群体，58,000名成员每天传播“热情的暴力。”</p><p> Facebook’s  stated desire to combat polarization has long been at odds with its quest to maximize engagement. In 2017, an internal task force  found that reducing polarization on the site would also reduce engagement. The task force was soon disbanded, and most of its suggested fixes were shelved.</p><p> Facebook的对抗极化的渴望长期以来一直是最大限度地获得参与的赔率。 2017年，内部任务队发现减少现场的极化也会减少参与。工作队很快被解散，其中大部分建议的修复都是搁置的。 </p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://arstechnica.com/tech-policy/2021/03/facebook-is-autogenerating-pages-for-white-supremacists/">https://arstechnica.com/tech-policy/2021/03/facebook-is-autogenerating-pages-for-white-supremacists/</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/facebook/">#facebook</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/自动化/">#自动化</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/分享/">#分享</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy;2012-2021 diglog.com </div></div></body></html>