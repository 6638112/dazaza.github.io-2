<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>FAIL-FAST失败了很快 Fail-Fast Is Failing Fast</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">Fail-Fast Is Failing Fast<br/>FAIL-FAST失败了很快 </h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2021-03-28 13:29:09</div><div class="page_narrow text-break page_content"><p>March 25, 2021   Volume 19, issue 1       For more than 40 years, fail-fast has been the dominant way of achieving fault tolerance. In this approach, some mechanism is responsible for ensuring that each component is up, functioning, and responding to work. As long as it&#39;s still alive and healthy, you continue forward; when something goes awry with the component, it is removed from the system and the remaining components reorganize themselves to continue. For many (but not all) systems, this is how you ensure the system remains alive when pieces fail.</p><p>3月25日，2021年第19卷，问题1超过40年，失败速度是实现容错的主导方式。在这种方法中，某些机制负责确保每个组件都已启动，运作和响应工作。只要它仍然活着和健康，你继续前进;当有些东西与组件开始时，它被从系统中删除，其余组件重新组件重新组件以继续。对于许多（但不是全部）系统，这就是当碎片失败时，确保系统保持活力。</p><p> As the industry moves to leverage cloud computing, this is getting more challenging. First of all, I love cloud computing and think it is an essential step forward. Still, the way we create robust solutions is under pressure as the individual components experience emerging challenges called  gray failures. In a gray failure, a server or part of the network doesn&#39;t fail fast but instead starts running slow. Running slow is WAY worse than failing fast. The slow component, sometimes running at less than one percent of its normal speed, may be healthy enough to say, &#34;I&#39;m still here!&#34; but slow enough to clog up all the work. This makes fail-fast schemes vulnerable.</p><p> 随着行业的举动效率云计算，这越来越具有挑战性。首先，我喜欢云计算，并认为这是前进的重要一步。尽管如此，我们创建强大的解决方案的方式受到压力，因为各个组件的出现挑战称为灰色故障。在灰色故障中，服务器或网络的一部分并不快速失败，而是开始运行速度。跑步缓慢是差的，而不是快速失败。缓慢的成分，有时以不到一个百分之次运行的正常速度，可能是足够的健康来说，＆＃34;我仍然在这里！＆＃34;但足够缓慢地堵塞所有的工作。这使得失败的方案易受攻击。</p><p>   Back in days of yore, hardware for your servers was in YOUR data center in tightly controlled environments. Some salesperson had convinced you that you needed the best, most expensive, and most resilient servers. You knew if you bought THOSE servers, you wouldn&#39;t get fired. Connecting those servers meant you had a local network supporting only your stuff. You could ensure that the traffic running in your local network wasn&#39;t TOO crowded. Because of this, the individual servers could respond predictably to high-priority messages such as, &#34;How&#39;re you doing, good buddy?&#34; The messages flew through the overprovisioned network like a trip down Highway 101 through San Francisco at 4 a.m. on Sunday morning.</p><p>   回到几天，服务器的硬件在您的数据中心处于紧密控制的环境中。一些销售人员确信您需要最好，最昂贵，最昂贵的服务器。你知道如果你买了那些服务器，你会被解雇。连接这些服务器意味着您只有一个仅支持您的东西的本地网络。您可以确保在当地网络中运行的流量而不是拥挤。因此，各个服务器可以响应可预测的是高优先级消息，例如，＆＃34;如何＆＃39;你在做，好朋友？＆＃34;这些消息通过过度传播的网络飞行，如在周日早上4点到旧金山乘坐101号高速公路。</p><p> Leveraging these extremely probable answers to inquiries about health, it was easy for a supervising server to impose rules for health or sickness. There was an expected time for an answer to this health check. If the response took too long, you would try again. The longer you went without an answer, the more likely the lagging server was truly sick. After a reasonably small number of attempts, you could give up and declare the party pooper was excluded from the party. Yeah, the decision was probabilistic, but the odds were really, really good, and you could decide pretty fast.</p><p> 利用这些非常可能的答案来查询健康，很容易监督服务器施加健康或疾病的规则。预计此健康检查的答案时间是答案。如果响应花了太久，你会再试一次。你没有答案的时间越长，滞后服务器就越有可能真的生病。经过合理少的尝试后，您可以放弃并宣布派对大便者被排除在派对之外。是的，这个决定是概率的，但赔率真的，真的很好，你可以做得很快。</p><p> Next, it became important to crisply evict the renegade node. Sending it a message to cease and desist may or may not have made a difference. This is often called STONITH (shoot the other node in the head). Sometimes the other node has a hard head and STONITH doesn&#39;t work. Another trick is to ensure the banished node cannot do any harm. If you can guarantee the wayward node can&#39;t make any change  outside the node, the rest of the team can move on with their lives. Let it rot in solitary.</p><p> 接下来，很重要的是排除叛徒节点。将其发送到停止和停止可能或可能没有差异的消息。这通常被称为Stonith（拍摄头部的其他节点）。有时另一个节点有一个坚硬的头部和stonith并在工作。另一个诀窍是确保放弃的节点不能造成任何伤害。如果您可以保证任性节点可以＆＃39; t在节点外部进行任何变化，团队的其余部分可以随身携带。让它在孤独腐烂。</p><p> In this fashion, you could detect the node had failed and ensure it had completely failed. In the past, it didn&#39;t take too long to do this.</p><p> 以这种方式，您可以检测到节点失败，并确保它完全失败。在过去，它没有花费太多时间来做这件事。</p><p>   There is a paradox called  Buridan&#39;s ass, named after the 14 th-century philosopher Jean Buridan. 7 Buridan&#39;s ass highlights an apparent contradiction inherent to the concept of determinism or the belief that every event is derived from previous events. The paradox proposes that a very hungry donkey is placed exactly halfway between two bales of hay. Assuming the donkey will go to the closest resource, it will starve to death.</p><p>   有一个叫Bridan＆＃39;屁股的悖论，以14世纪的哲学家吉迪达命名。 7个Bidan＆＃39; S屁股突出了一个明显的矛盾，固有的确定主义概念或相信每个活动都来自以前的事件。悖论提出，一个非常饥饿的驴子恰好位于两块干草之间。假设驴会去最近的资源，它将饿死。 </p><p> In electronics, there is a phenomenon called  metastability, which means the system may be in an unstable state for an unbounded time. To have a valid signal as an output to the circuit, it must reside within a certain voltage or current level. If the output lands in the middle gray area, wonky things happen to the next circuit. It, too, can do weird things.</p><p>在电子器件中，存在称为稳定性的现象，这意味着系统可以处于不受约束的时间不稳定状态。要使有效信号作为输出电路，它必须驻留在某个电压或电流范围内。如果输出在中间灰色区域的土地，欠下的事情发生在下一个电路。它也可以做奇怪的事情。</p><p> This metastability is inherent within asynchronous circuits. Since you don&#39;t know the timing of the input signals, some of the time the various inputs arrive simultaneously, and the circuit can&#39;t decide between the two bales of hay. Asynchronous digital systems usually add arbiters to the input signals to ensure the signals are ordered and, hence, avoid metastability. Within a clock domain on a synchronous device, the clock ensures the timing of the inputs provided to the logic circuit, avoiding metastability problems. As synchronous circuits receive incoming asynchronous signals, special synchronizers work to make the probability of metastability vanishingly small but still possible.</p><p> 此常规性是异步电路内的固有。由于您不知道输入信号的定时，因此各种输入同时到达的一些时间，电路可以在两个干草包之间决定。异步数字系统通常将仲裁器添加到输入信号以确保信号被排序，因此，避免衡量性。在同步设备上的时钟域内，时钟可确保提供给逻辑电路的输入的定时，避免了衡量性问题。由于同步电路接收传入异步信号，特殊同步器的工作使衡量变小但仍然可能的稳定性。</p><p>  Doing a lift-and-shift of a distributed system onto a complex cloud-computing environment poses a bunch of new problems for the distributed-systems design. Running a server in a virtual machine provides a  lot of valuable computing for a good price, but it may do so according to its own timeframe. The noisy neighbor problem refers to varying capacity for  your virtual machine as it competes for resources with  other virtual machines on the same physical servers. Multicore servers add to the fun as their coordination may or may not stall messages you hope to send. Trips through the cloud-networking infrastructure may experience congestion-causing communication emulating the US Postal Service. That makes timer-based fail-fast probabilistic. It always was probabilistic, but now the odds have shifted away from minuscule probabilities to simply very-hard-to-debug rare probabilities.</p><p>  在复杂的云计算环境中进行分布式系统的升力和转移为分布式系统设计构成了一堆新问题。在虚拟机中运行服务器提供了很多有价值的计算，以获得良好的价格，但它可能根据自己的时间框架进行。嘈杂的邻居问题是指虚拟机的不同容量，因为它与相同物理服务器上的其他虚拟机竞争资源。 Multicore Servers添加到您的协调可能或可能不会停止您希望发送的消息。通过云网络基础设施的旅行可能会经历造成的拥塞通信，模拟美国邮政服务。这使得基于定时器的失败概率。它始终是概率，但现在赔率已经转移了远离微量概率，以简单地是非常难以调试的罕见概率。</p><p> Before, when distributed systems were composed of predictable servers and networks, you had a darned good idea how quickly your cohort would answer a health check. Using that expectation, you could remove sick nodes quickly while only  rarely removing a healthy node. It was a probability game where the odds were  extremely high that you would make the right decision. This is much like circuits working within a clock domain to avoid metastable behavior.</p><p> 之前，当分布式系统由可预测的服务器和网络组成时，您的队列会如何回答健康检查的态度。使用该期望，您可以快速删除生病节点，同时只删除一个健康的节点。这是一个概率游戏，赔率非常高，你会做出正确的决定。这与在时钟域内工作的电路很像，以避免亚稳态行为。</p><p> Servers and/or the messages to and from them don&#39;t always work at a predictable pace. It&#39;s much the same as removing the clocking within a synchronous circuit so it is an asynchronous digital system. The probability of dampening and removing metastability has become  way lower.</p><p> 服务器和/或往返于他们的消息，不要以可预测的速度工作。它与移除同步电路内的时钟相同，所以它是一个异步数字系统的＆＃39。阻尼和去除亚稳定性的可能性变得更低。</p><p> Consider a team of jugglers handling dozens of balls on stage. If some of them are sent into slow motion in a noncorrelated way, it can be a problem. The jugglers have their own timeframes, and they see balls arrive when they arrive. For a short while this may make sense. It becomes virtually impossible to juggle time-based interactions across the team as each juggler&#39;s time speeds up and slows down unbeknownst to them.</p><p> 考虑一支戏耍者在舞台上处理数十个球的队员。如果其中一些以非相关的方式被发送到慢动作，则可能是一个问题。 jugglers拥有自己的时间框架，他们看到球到达时到达。一段短暂的虽然这可能是有意义的。每次Juggler＆＃39，几乎不可能将基于时间的时间基于时间的互动变得非常迅速，减慢了他们的时间。</p><p> When the old deployment of a distributed system is lifted-and-shifted into the cloud, it&#39;s like a trip to the fun zone at the carnival. Time and distance get distorted and fail-fast decisions become unpredictable. When servers don&#39;t march approximately to the beat of the same drummer, distributed-systems algorithms can become metastable.</p><p> 当分布式系统的旧部署被提升到云中时，它就像在嘉年华的有趣区的旅行时一样＆＃39;时间和距离变得扭曲，失败的决策变得不可预测。当服务器Don＆＃39; T 3月大约达到同一个鼓手的节拍时，分布式系统算法可以成为亚稳定性的。 </p><p> Even worse, most systems depend on other systems in the data center. HDFS (Hadoop Distributed File System) depends on Apache ZooKeeper. 1 ZooKeeper and other services depend on DNS (Domain Name System). Each of these systems has timeouts and retries, which can lead to cascading delays, timeouts, and failures. This is another form of metastability that can accentuate problems rather than dampen them.</p><p>更糟糕的是，大多数系统依赖于数据中心的其他系统。 HDFS（Hadoop分布式文件系统）取决于Apache ZooKeeper。 1个zookeeper和其他服务取决于DNS（域名系统）。这些系统中的每一个都具有超时和重试，这可能导致级联延迟，超时和故障。这是另一种形式的衡量性，可以强调问题而不是抑制它们。</p><p> When this metastability interferes with a primary or leader in your distributed system, you don&#39;t have rapid access to the &#34;perfect truth&#34; or linearizability that many systems require. Availability can suffer quite a bit.</p><p> 当这种衡量性干扰了分布式系统中的主要或领导者时，您不会迅速访问＆＃34;完美的真理＆＃34;或者是许多系统所需的线性化。可用性可能会受到相当的影响。</p><p>   Let&#39;s turn our attention to the importance of algorithms that don&#39;t mandate the perfect latest answer. When a request to a user is based on a pool of replicas containing stale state, any one of the replicas will suffice. The background work to update the replicas with new state might be quite a bit behind, and that&#39;s OK. An excellent example of &#34;pretty good&#34; can be found when you read a replica of the product catalog or of product reviews in online retail. Similarly, in a web search, you access all the shards for the search terms in the query. It is not essential that each request returns the absolutely most recent results. &#34;Pretty good&#34; is pretty darned good.</p><p>   让我们注意我们注意算法的重要性，即不授权完美的最新答案。当对用户的请求基于包含陈旧状态的副本池时，任何一个副本都足够了。用新状态更新副本的背景工作可能落后一点，而且＃39;好的。 ＆＃34的一个很好的例子;相当好＆＃34;在您在网上零售中读取产品目录或产品评论时，可以找到。同样，在Web搜索中，您可以访问查询中搜索术语的所有碎片。每个请求都不重要，每个请求返回绝对最近的结果。 ＆＃34;相当好＆＃34;很漂亮。</p><p> When sending work to a pool of servers with replicas of these caches, the client can time out and retry to bound the latency. It doesn&#39;t really care too much about the health of an individual server, as the client can get a good answer from another by retrying using a technique called  hedging. 3 The state of the unresponsive server is not too important for a while. Letting it be metastable while it lives in an uncertain state is OK. Frankly, you don&#39;t need a perfect answer about the server&#39;s membership in the cluster. Over time it will start to behave better or it will get tossed out of the cluster. Demanding a perfect answer in a hurry is not necessary.</p><p> 将工作发送到带有这些缓存副本的服务器池时，客户端可以超时并重试绑定延迟。它并不真正关心一个单独的服务器的健康状况，因为客户可以通过使用称为对冲的技术重试，从另一个服务器获得一个很好的答案。 3无响应服务器的状态暂时不太重要。让它在不确定状态下生活时是含量的。坦率地说，你没有关于服务器的完美答案和＃39;群体的成员资格。随着时间的推移，它将开始表现得更好，或者它将被扔掉群集。不需要匆忙追究完美的答案。</p><p> There are similar emerging tolerant algorithms for logging. Apache BookKeeper 2 is an open-source logging subsystem in which writes to append new records to the log do not need to get to all log servers containing replicas of the log. Getting to a required subset is enough. Similarly, Amazon Aurora, 8,9 offered through AWS (Amazon Web Services), runs a database in a centralized server but sends its updates to a pool of storage servers. Because not all the storage servers need to respond in a timely fashion, the approach used by BookKeeper and Aurora is dramatically more resilient to delays in servers. An individual replica can live in its own time warp, and the broader distributed algorithm proceeds happily.</p><p> 伐木具有类似的新出现耐受算法。 Apache Bookkeeper 2是一个开源记录子系统，其中写入要将新记录附加到日志，无需到达包含日志副本的所有日志服务器。获取所需子集足够。类似地，通过AWS（亚马逊Web服务）提供的Amazon Aurora，8,9在集中式服务器中运行一个数据库，但将其更新发送到存储服务器池中。因为并非所有存储服务器都需要及时响应，所以簿记员和奥罗拉使用的方法在服务器中大大增加了延迟。个人复制品可以在自己的时间扭曲中生活，更广泛的分布式算法愉快地进行。</p><p> I think of this as water flowing around a rock in a river. Getting  enough work through is dramatically more resilient than insisting  all the work gets through.</p><p> 我认为这是在河里流动的岩石流动的水。通过足够的工作通过急剧更具弹性，而不是坚持所有工作通过。</p><p>   When traditional algorithms depend on perfect knowledge of membership in a cluster, what can you do? Many systems are built expecting perfect knowledge to give perfect answers. For example, HDFS 6 has a NameNode that is responsible for the allocation of data pages. Unless HDFS knows that you have  either zero or one primary NameNode at a time, the file system may be corrupted.</p><p>   当传统算法依赖于集群中的完美知识时，您能做什么？许多系统都建立了期望完美的知识，以提供完美的答案。例如，HDFS 6具有责任数据页的分配的NameNode。除非HDFS知道您一次拥有零或一个主要的NameNode，否则文件系统可能已损坏。 </p><p> When one server fails fast, it is replaced, data sloshes around the cluster, and pretty soon you&#39;re back in business.</p><p>当一个服务器快速失败时，它被替换，群集周围的数据杆，很快，你＆＃39;重新开始。</p><p> HDFS depends on fail-fast as its model for liveness. I worry about the continued ability to use fail-fast and still follow the motto of that old Timex watch commercial:  &#34;It takes a licking but keeps on ticking.&#34;</p><p> HDFS取决于失败作为其性欲的模型。我担心持续使用失败的能力，仍然遵循那个旧时的座右铭观看商业：＆＃34;它需要一个舔但是滴答作响。＆＃34;</p><p>    Well... some algorithms are, indeed, stable when running on top of a surrealistic world. Some, however, are not. Any algorithm dependent on a fixed set of responsive servers conveying strongly consistent linearizable data will increasingly see challenges if the trend toward metastable clusters continues.</p><p>    好吧......在超现实主义世界之上运行时，一些算法确实是稳定的。然而，有些人不是。任何依赖于一组固定的响应服务器的算法都会越来越一致的可直线化数据将越来越多地看到稳定性集群趋势的趋势。</p><p> There are a number of reasons why parts of a cluster may perceive timing differences with other parts:</p><p> 群集部分可能会感知与其他部分的时间差异有多种原因：</p><p> • Servers or VMs not getting the expected amount of the computation for a period of time.</p><p> •服务器或VM不会在一段时间内获得计算的预期金额。</p><p>  • Networks not providing a pair of servers their fair share of the bandwidth, causing delays.</p><p>  •网络不提供一对服务器的公平份额，造成延误。</p><p> • Hardware in the data center behaving unpredictably, especially as the price of these components is driven down. 5</p><p> •数据中心中的硬件表现不可预测，特别是随着这些组件的价格被驱动下来。 5. </p><p> • Increasing dependencies on other services (e.g., ZooKeeper or DNS) that can cause cascading wonkiness because of timeouts.</p><p>•增加可能导致由于超时而导致级联不良的服务的依赖性。</p><p>  I want to emphasize that I see this as a great thing. While, in my dreams, it would be great to have a dedicated freeway lane for my commute home from the office, it&#39;s not really practical. Instead, we share freeway lanes in spite of the inherent risk of delay in an open queuing network that allows lots of incoming traffic without any constraints. Not many of us can build a freeway dedicated to our personal use; hence, we share.  Cloud computing is sharing.</p><p>  我想强调我认为这是一件好事。而在我的梦中，在办公室里，有一个专门的高速公路车道，＆＃39不是真正的实用性，这将是我的通勤家庭。相反，我们尽管允许在没有任何约束的情况下允许许多传入流量的延迟的固有风险，但仍然共享高速公路车道。我们中的许多人都可以建立一个致力于我们个人使用的高速公路;因此，我们分享。云计算正在共享。</p><p> The same is true in real life. If you live in a small town with a walking commute home, you can predictably walk in the front door at 6:23 every evening. As you move to the big city with elevators, parking garages, and freeways to traverse, it&#39;s harder to time your arrival precisely.</p><p> 现实生活中也是如此。如果你住在一个带着散步的上海房子的小镇，你可以在每天6点23分之前预测地走在前门。当你搬到大城市，带电梯，停车车库和高速公路到横穿，它就更加努力地到达您的到来。</p><p>   • How can we compensate for these issues of metastability in cloud environments? Does adding resources help?</p><p>   •我们如何弥补云环境中的这些常规性问题？添加资源有帮助吗？</p><p> • Socially, humans have a tendency to overconsume resources until there&#39;s a problem. Will we always succumb to the tragedy of the commons and suck up all slack until we are metastable?</p><p> •社交方面，人类倾向于在有问题之前过度过度资源。我们会永远屈服于公共场地的悲剧，并吸收所有的松弛，直到我们融化？</p><p> • What algorithms can give us both crisp and clear linearizable updates AND rapid latency 99.9 percent of the time? How about 99.999 percent of the time? How do these respond when the environment is under stress?</p><p> •哪些算法可以为我们提供清晰和明确的线性更新和快速延迟99.9％的时间？ 99.999％的时间有多？当环境受压力下，这些如何应对？</p><p> • How can we evolve away from algorithms that are sensitive to metastability into a world where we tolerate and dampen most metastability?</p><p> •我们如何远离对我们容忍和抑制大多数常规性的世界敏感的算法敏感的算法？ </p><p>     3. Dean, J., Barroso, L. A. 2013. The tail at scale.  Communications of the ACM 56(2), 74-80;  https://cacm.acm.org/magazines/2013/2/160173-the-tail-at-scale/fulltext.</p><p>3. Dean，J.，Barroso，L. A. 2013.尾巴以级别为例。 ACM 56（2），74-80的通信; https://cacm.acm.org/magazines/2013/2/160173-the-tail-at-cale/fulltext。</p><p> 4. Gray, J. 1985. Why Do Computers Stop and What Can Be Done About It?.  Tandem Technical Report TR 85.7;  https://www.hpl.hp.com/techreports/tandem/TR-85.7.pdf</p><p> 4.灰色，J. 1985.为什么电脑停止，可以做些什么？串联技术报告TR 85.7; https://www.hpl.hp.com/techreports/tandem/tr-85.7.pdf.</p><p> 5. Gunawi, H. S., et al. 2018. Fail-slow at scale: evidence of hardware performance faults in large production systems.  Proceedings of the 16th Usenix Conference on File and Storage Technologies;  https://www.usenix.org/system/files/conference/fast18/fast18-gunawi.pdf.</p><p> 5. Gunawi，H. S.等人。 2018年。扩展失败：大型生产系统中硬件性能故障的证据。第16届Usenix档案和储存技术会议的诉讼程序; https://www.usenix.org/system/files/conference/fast18/fast18-gunawi.pdf。</p><p>   8. Verbitski, A., et al. 2017. Amazon Aurora: design considerations for high throughput cloud-native relational databases.  Proceedings of the ACM International Conference on Management of Data, 1041-1052;  https://dl.acm.org/doi/pdf/10.1145/3035918.3056101.</p><p>   8. verbitski，A.等。 2017.亚马逊Aurora：高吞吐量云原生关系数据库的设计考虑因素。 ACM数据管理会议的诉讼程序，1041-1052; https://dl.acm.org/doi/pdf/10.1145/3035918.3056101。</p><p> 9. Verbitski, A., et al. 2018. Amazon Aurora: on avoiding distributed consensus for I/Os, commits, and membership changes.  Proceedings of the ACM International Conference on Management of Data, 789-796;  http://pages.cs.wisc.edu/~yxy/cs839-s20/papers/aurora-sigmod-18.pdf.</p><p> 9. Verbitski，A.等人。 2018.亚马逊奥罗拉：避免为I / O，提交和成员资格更改的分发达成共识。 ACM管理数据管理会议课程，789-796; http://pages.cs.wisc.edu/~yxy/cs839-s20/papers/aurora-sigmod-18.pdf。</p><p>  Pat Helland has been implementing transaction systems, databases, application platforms, distributed systems, fault-tolerant systems, and messaging systems since 1978. For recreation, he occasionally writes technical papers. He works at Salesforce. His blog is at  pathelland.substack.com.</p><p>  Pat Helland自1978年以来一直在实施事务系统，数据库，应用平台，分布式系统，容错系统和消息传递系统。对于娱乐，他偶尔会写下技术文件。他在Salesforce工作。他的博客是pathelland.substack.com。</p><p>  Originally published in Queue vol. 19, no. 1— see this item in the  ACM Digital Library</p><p>  最初在队列卷发布。 19，没有。 1-在ACM数字库中查看此项目 </p><p> Related: Martin Kleppmann, Alastair R. Beresford, Boerge Svingen -   Online Event Processing Support for distributed transactions across heterogeneous storage technologies is either nonexistent or suffers from poor operational and performance characteristics. In contrast, OLEP is increasingly used to provide good performance and strong consistency guarantees in such settings. In data systems it is very common for logs to be used as internal implementation details. The OLEP approach is different: it uses event logs, rather than transactions, as the primary application programming model for data management. Traditional databases are still used, but their writes come from a log rather than directly from the application. The use of OLEP is not simply pragmatism on the part of developers, but rather it offers a number of advantages.</p><p>相关：Martin Kleppmann，Alastair R. Beresford，Boerge Singen  - 在线事件处理支持异构存储技术的分布式交易是不存在的或遭受差的操作和性能特征。相比之下，OLEP越来越多地用于在这种环境中提供良好的性能和强的一致性保证。在数据系统中，将日志作为内部实现详细信息非常常见。 OLEP方法不同：它使用事件日志，而不是事务，作为数据管理的主要应用程序编程模型。仍然使用传统数据库，但其写入来自日志而不是直接从应用程序。 OLEP的使用不仅仅是开发人员的实用主义，而是提供了许多优势。</p><p>  Andrew Leung, Andrew Spyker, Tim Bozarth -   Titus: Introducing Containers to the Netflix Cloud We believe our approach has enabled Netflix to quickly adopt and benefit from containers. Though the details may be Netflix-specific, the approach of providing low-friction container adoption by integrating with existing infrastructure and working with the right early adopters can be a successful strategy for any organization looking to adopt containers.</p><p>  Andrew Leung，Andrew Spyker，Tim Bozarth  -  Titus：将容器引入Netflix Cloud我们认为我们的方法使Netflix能够快速采用和受益于容器。虽然细节可能是Netflix特定的，但通过与现有基础设施集成并与正确的早期采用者合作提供低摩擦集装箱采用的方法可以成为希望采用容器的任何组织的成功策略。</p><p>  Marius Eriksen -   Functional at Scale Modern server software is demanding to develop and operate: it must be available at all times and in all locations; it must reply within milliseconds to user requests; it must respond quickly to capacity demands; it must process a lot of data and even more traffic; it must adapt quickly to changing product needs; and in many cases it must accommodate a large engineering organization, its many engineers the proverbial cooks in a big, messy kitchen.</p><p>  Marius Eriksen  -  Scale现代服务器软件的功能要求开发和操作：它必须在所有时间和所有地点都提供;它必须在毫秒内回复用户请求;它必须迅速响应容量需求;它必须处理大量数据甚至更多的流量;它必须快速调整更改产品需求;在许多情况下，它必须容纳一个大型工程组织，其许多工程师在一个大型凌乱的厨房里烹饪烹饪。</p><p>  Caitie McCaffrey -   The Verification of a Distributed System Leslie Lamport, known for his seminal work in distributed systems, famously said, &#34;A distributed system is one in which the failure of a computer you didn’t even know existed can render your own computer unusable.&#34; Given this bleak outlook and the large set of possible failures, how do you even begin to verify and validate that the distributed systems you build are doing the right thing?</p><p>  Caitie McCaffrey  - 验证分布式系统Leslie Lamport，以其在分布式系统中的开创性工作而闻名，着名，＆＃34;分布式系统是您甚至没有知道存在的计算机的失败可以呈现你的自己的计算机无法使用。＆＃34;鉴于此黯淡的前景和大量可能的故障，您甚至如何开始验证并验证您构建的分布式系统正在进行正确的事情？ </p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://queue.acm.org/detail.cfm?id=3458812">https://queue.acm.org/detail.cfm?id=3458812</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/fast/">#fast</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/服务器/">#服务器</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/分享/">#分享</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy;2012-2021 diglog.com </div></div></body></html>