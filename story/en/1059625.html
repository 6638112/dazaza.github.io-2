<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Facebook在Derek Chauvin的审判之后遏制明尼阿波利斯毒性内容的近期措施提出了为什么公司一直不这样做的问题 Facebook's recent steps to curb toxic content in Minneapolis following Derek Chauvin's trial raises the question of why the company doesn't do so all the time</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">Facebook's recent steps to curb toxic content in Minneapolis following Derek Chauvin's trial raises the question of why the company doesn't do so all the time<br/>Facebook在Derek Chauvin的审判之后遏制明尼阿波利斯毒性内容的近期措施提出了为什么公司一直不这样做的问题 </h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2021-04-22 12:02:32</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2021/4/80f22b845d5c8e94263c959ac2244403.png"><img src="http://img2.diglog.com/img/2021/4/80f22b845d5c8e94263c959ac2244403.png" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>On Monday, Facebook  vowed that its staff was “working around the clock” to identify and restrict posts that could lead to unrest or violence after a verdict was announced in the murder trial of the former Minneapolis police officer Derek Chauvin. In a blog post, the company promised to remove “content that praises, celebrates or mocks” the death of George Floyd. Most of the company’s statement amounted to pinky-swearing to  really, really enforce its existing  community standards, which have long prohibited bullying, hate speech, and incitements to violence.</p><p>周一，Facebook发誓，其员工是“遍布时钟”，以识别和限制可能导致判决在判决前明尼阿波利斯警察德里克·赤道德克·赤道的谋杀审判后发生骚乱或暴力的职位。在博客岗位中，公司承诺删除“赞扬，庆祝或嘲笑”乔治弗洛伊德的死亡。大多数公司的发言都达到了Phighy-Swearing，真的，真正强制执行其现有的社区标准，这些标准长期禁止欺凌，仇恨言论和煽动暴力。</p><p>   Buried in the post was something less humdrum, though: “As we have done in emergency situations in the past,” declared Monika Bickert, the company’s vice president of content policy, “we may also limit the spread of content that our systems predict is likely to violate our Community Standards in the areas of hate speech, graphic violence, and violence and incitement.” Translation: Facebook might turn down the dial on toxic content for a little while. Which raises some questions: Facebook has a toxic-content dial? If so, which level is it set at on a typical day? On a scale of one to 10, is the toxicity level usually a five—or does it go  all the way up to  11?</p><p>   虽然在帖子中埋葬了潮湿的事情，但是：“正如我们在过去的紧急情况下所做的那样，”公司的内容政策副总裁Monika Bickert“宣布，”我们也可能限制了我们的系统预测的内容的传播可能违反仇恨言论，图形暴力和暴力和煽动领域的社区标准。“译文：Facebook可能会在毒性内容上稍微扭转一下。这提出了一些问题：Facebook有一个有毒内容拨号？如果是的话，它在典型的一天设置了哪个级别？在一个到10的范围内，毒性水平通常是五个 - 或者它一直到11？</p><p>  This is not the first time Facebook has talked about reducing the amplification of inflammatory posts to make its platform a better and safer place. In the  run-up to and the  aftermath of the 2020 presidential election, Facebook talked about the “ break glass” measures it was taking to limit the spread of misinformation and incitements to violence in the United States. Such steps had previously been reserved for “ at-risk countries” such as Myanmar, Ethiopia, and Sri Lanka. Now these exceptional measures may be deployed in Minneapolis, which Facebook has “temporarily deemed to be a high-risk location” because of the Chauvin trial.</p><p>  这不是Facebook已经第一次谈到减少炎症柱的扩增，使其平台更好，更安全。在2020年总统选举的过程中，Facebook谈到了“休息玻璃”措施，以限制误导和煽动对美国暴力的传播。此类步骤以前保留为“风险国家”，例如缅甸，埃塞俄比亚和斯里兰卡。现在，由于Chauvin试验，这些特殊措施可以部署在明尼阿波利斯，这是一个Facebook的Facebook“暂时被视为高风险的位置”。</p><p>   When Facebook detects heightened social tension, it puts in place policies to promote authoritative information and add “friction” so that content on the site moves more slowly and more calmly than usual. In short, the company reins in the virality that online platforms otherwise so spectacularly enable. Facebook largely avoided epic failure on Election Day, the  New York Times columnist Kevin Roose  asserted, by “dialing back the very features that have powered the platform’s growth for years.”</p><p>   当Facebook检测到社交紧张时，它建立了推广权威信息的政策，并添加“摩擦”，以便网站上的内容比平常更慢地移动。简而言之，公司缰绳在该景象中，在线平台否则如此壮观。 Facebook在很大程度上避免了选举日的史诗失败，纽约时报专栏作家凯文罗斯声称，“拨回了经过平台增长多年的增长的功能”。</p><p>  These kinds of decisions—about what platforms choose to amplify or add friction to—are the most important in content moderation. Discussion about content moderation tends to focus on binary decisions concerning whether individual pieces of content are left up or taken down. But content moderation is much more about knobs and dials that regulate the overall flow of posts. An individual piece of content is a mere drop in the ocean of Facebook content; the underlying systems that move this content around are the tides. The public discussion about content moderation typically fixates on the drops—what should Facebook have done with  Donald Trump’s posts?—but when you’re weathering a storm, what matters is the tides.</p><p>  这些类型的决定 - 关于什么平台选择放大或增加摩擦 - 是内容适度最重要的。关于内容适度的讨论倾向于关注有关各个内容是否留下或删除的二进制决定。但内容审核更多关于旋钮和调整帖子整体流程的旋钮。个人内容只是在Facebook内容的海洋中下降;移动此内容的底层系统是潮汐。关于内容审核的公众讨论通常会在滴剂上修复 - 应该使用唐纳德特朗普的帖子进行Facebook的措施？ - 当你风化时，事情是潮汐的重要事件。</p><p>  Mark Zuckerberg agrees. In 2018, the Facebook CEO laid out a “ blueprint for content governance” that included what the Harvard law professor Jonathan Zittrain has said should be the “most famous graphs in content moderation.” Stay with me—the graphs are interesting.</p><p>  Mark Zuckerberg同意。 2018年，Facebook首席执行官制定了“内容治理的蓝图”，其中包括哈佛法教授Jonathan Zittrain所说的应该是“内容适度的最着名的图表”。留在我 - 图表很有趣。</p><p>  The graph above shows what usually happens whenever Facebook draws a policy line. Posts that clearly fall beyond that line—overt and credible incitements to violence against police or protesters, to choose a hypothetical example—will be taken down. But posts that don’t cross the line will naturally gain more engagement as they tiptoe closer to it. In this default world, a post that uses hateful language targeted at police might stay up, because police are not a protected class, and attract more likes and shares than a post criticizing law enforcement on policy grounds. The more inflammatory post, in other words, would likely land on the upward curve of user engagement. (These examples are speculative, because Facebook does not provide specific details about what “approaching the line” means.)</p><p>  以上图表显示了通常在Facebook绘制策略行时发生的情况。帖子清楚地落在那条线 - 公开和可靠的煽动暴力对警察或抗议者的暴力行为，选择假设的榜样 - 将被取消。但是帖子不跨越线的帖子将自然地获得更多的参与，因为他们倾斜靠近它。在这个违约世界中，一个使用针对警方的仇恨语言的帖子可能会熬夜，因为警方不是受保护的课程，并且吸引更多的人喜欢和股票而不是批评执法政策基础的职位。换句话说，炎症岗位越多，可能会降落用户参与的向上曲线。 （这些示例是推测性的，因为Facebook没有提供有关“接近线路”方式的具体细节。） </p><p>  But platforms can train their systems to recognize this “borderline content” and make engagement look like the graph below:</p><p>但平台可以培训他们的系统来识别出这个“边界内容”并使订婚看起来像下面的图表：</p><p>  In this scenario, the more inflammatory a post is, the  less distribution it gets. Posts describing police in hateful terms might stay up but be shown to fewer people. According to Zuckerberg, this strategy of reducing the “distribution and virality” of harmful content is the most effective way of dealing with it.</p><p>  在这种情况下，帖子的炎症越多，它得到的分布越少。描述仇恨术语中警方的帖子可能会留下来，但被证明更少。根据扎克伯格的说法，这种减少有害内容的“分布和病毒”的战略是处理它的最有效方法。</p><p> He’s right: The strategy works! Facebook has  recently touted reductions in the amount of hate speech and graphic content that users see on its platform. How did it make these improvements? Not by changing its rules on hate speech. Not by hiring more human content moderators. Not by refining  artificial-intelligence tools that seek out rule-breaking content to take down. The progress was “mainly due to changes we made to reduce problematic content in News Feed.” The company used dials, not on-off switches.</p><p> 他是对的：战略工作！ Facebook最近倾向于用户在其平台上看到的仇恨语音和图形内容的数量。它是如何改进这些改进的？不是改变仇恨言论的规则。不是雇用更多人类内容主持人。不是通过炼制寻求规则破坏内容的人工智能工具来取消。进展是“主要是由于我们在新闻饲料中减少有问题内容的变化。”公司使用拨号，而不是开关。</p><p> Facebook’s critics accuse it of spreading hate and violent content because such material increases users’ time on the site and therefore the company’s profits. That trope is probably  overblown and too simplistic.  Advertisers don’t like their ads running next to  divisive content, and in the long term, users won’t keep coming back to a platform that makes them feel disgusted. Still, some leaks from employees have detailed projects to  tamp down divisive or  harmful content that were killed internally for business reasons. And the  top 10 most-engaged-with posts after the election contained many more mainstream press accounts than before the break-glass measures took effect. The list looked so different from the usual fare of right-wing viral content that Facebook released a blog post  trying to explain  it. (The company conceded that the temporary measures had played a role, but suggested they were not the primary driver for the change.)</p><p> Facebook的批评者指责它传播仇恨和暴力内容，因为这些材料会增加用户在网站上的时间，因此是公司的利润。该牵引可能会覆盖，过于简单。广告商不喜欢他们的广告旁边的分裂内容，并且在长期以来，用户不会继续回到一个让他们感到恶心的平台。尽管如此，员工的一些泄漏有详细的项目，以局限于出于商业原因在内部杀害的分歧或有害内容。在选举后，最多的10个员工最具终端的帖子，而不是在玻璃措施措施生效之前的更多主流新闻账户。该名单看起来与右翼病毒内容的通常票价不同，Facebook发布了一个尝试解释它的博客文章。 （本公司承认，临时措施发挥了作用，但建议他们不是改变的主要司机。）</p><p>   Without any independent access to internal data, outsiders can’t know how much of a difference Facebook’s break-glass measures make, or where its dials usually sit. But Facebook has a reason for announcing these steps. (To the company’s credit, it at least announced measures in anticipation of the Chauvin verdict; other platforms seemed to just keep their head down.) What the company hasn’t explained is why its anti-toxicity measures need to be exceptional at all. If there’s a reason turning down the dials on likely hate speech and incitement to violence all the time is a bad idea, I don’t see it.</p><p>   如果没有对内部数据的任何独立访问，外人都无法知道Facebook的玻璃玻璃措施，或者其拨号通常坐在哪里。但Facebook有一个宣布这些步骤的理由。 （对于公司的信誉，它至少宣布了预期Chauvin判决的措施;其他平台似乎只是让他们的头脑下来。）该公司尚未解释的是为什么它的反毒性措施根本需要特殊。如果有一个原因在可能讨厌言论和煽动暴力的原因，一直都是一个坏主意，我看不到它。</p><p> Facebook’s old internal motto “Move fast and break things” has become an albatross around its neck, symbolizing how the company prioritized growth and scale, leaving chaos behind it. But when confronted with inflammatory content, the platform should move faster and break more glass.</p><p> Facebook的旧内部座右铭“迅速摆脱和突破”已成为围绕其颈部的信天翁，象征公司如何优先考虑增长和规模，留下混乱。但是，当面对炎症内容时，平台应该更快地移动并打破更多的玻璃。</p><p> The Chauvin trial may be a unique event, but racial tension and violence are clearly not. Content on social media leading to offline harm is not confined to Minneapolis or the U.S.; it is a global problem. Toxic online content is not an aberration, but a permanent feature of the internet. Platforms shouldn’t wait until the house is burning down to do something about it.</p><p> Chauvin试验可能是一个独特的事件，但种族紧张和暴力显然不是。社交媒体内容导致离线伤害的内容不仅限于明尼阿波利斯或美国。这是一个全球问题。有毒的在线内容不是像差，而是互联网的永久性。平台不应该等到房子烧毁以做一些事情。 </p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://www.theatlantic.com/ideas/archive/2021/04/facebook-should-dial-down-toxicity-much-more-often/618653/?scrolla=5eb6d68b7fedc32c19ef33b4">https://www.theatlantic.com/ideas/archive/2021/04/facebook-should-dial-down-toxicity-much-more-often/618653/?scrolla=5eb6d68b7fedc32c19ef33b4</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/facebook/">#facebook</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/derek/">#derek</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/steps/">#steps</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/内容/">#内容</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/分享/">#分享</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy;2012-2021 diglog.com </div></div></body></html>