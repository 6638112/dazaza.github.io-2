<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>十个中断的七节课 Seven Lessons from Ten Outages</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">Seven Lessons from Ten Outages<br/>十个中断的七节课 </h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2021-06-23 08:27:15</div><div class="page_narrow text-break page_content"><p>After 10 post-mortems in their first season, Tom and Jamie reflect on the common issues they’ve seen. Click through for details!</p><p>在他们的第一个赛季10次尸体后，汤姆和杰米反映了他们所看到的常见问题。单击详情！</p><p>   We’re just about through our inaugural season of The Downtime Project podcast, and to celebrate, we’re reflecting back on recurring themes we’ve noticed in many of the ten outages we’ve poured over. It’s been remarkable how consistent certain patterns have been–either as risks or as assets–to the engineering teams as they’ve tackled these incidents.</p><p>   我们只是通过我们的停机时间播客的首发赛季，并庆祝，我们反映了我们在我们倾注的十大中断中的许多中断中注意到的经常性主题。由于他们解决了这些事件，这是卓越的某些模式如何成为风险或作为资产 - 工程团队。</p><p> Out of these recurring patterns we’ve extracted lessons that we intend to take into our own engineering teams; and so, we’ve compiled five of those lessons below for the benefit of any interested readers, with the hope that you, too, will find them useful to learn from and to prepare for. As we go, we’ll include links to the outages and episodes where each theme occurred.</p><p> 出于这些经常性模式，我们提取了我们打算进入我们自己的工程团队的课程;因此，我们已经编制了下面的五个课程，以获得任何感兴趣的读者的利益，希望您也发现他们有助于学习和准备。我们走了，我们将包括与每个主题发生的中断和集中的链接。</p><p> If you feel like we’ve missed any major patterns, or have any other feedback for us, please leave a comment. And thank you all for listening to the first season of The Downtime Project.</p><p> 如果您觉得我们错过了任何主要模式，或者对我们有任何其他反馈，请发表评论。谢谢你们所有人听取停机项目的第一个赛季。</p><p>  The instinct to “dogfood” is a great one–after all, how can you reasonably expect your customers to use your products and services if you will not? How can you endorse the workflow they enable if you don’t stake your own company’s productivity on it?</p><p>  “Dogfood”的本能是一个伟大的唯一一个，如果你不会，你如何合理地希望您的客户使用您的产品和服务？如果您不符合自己的公司的生产力，您如何支持他们启用的工作流程？</p><p> However, this healthy instinct backfires when said dogfooding creates a dependency cycle wherein you rely on your own systems… to fix your systems.</p><p> 但是，这种健康的本能返回当所述狗狗食品创建一个依赖周期时，您依靠自己的系统...修复您的系统。</p><p> Other instances of this dependency pattern fall out of the otherwise-virtuous motto:  don’t repeat yourself. Why run another kind of database just for monitoring? You already run a production database very well, thank you very much. So just put the telemetry data in there, too.</p><p> 这种依赖模式的其他实例从其他善良的座右铭中掉出：不要重复自己。为什么跑另一种数据库只是为了监控？你已经很好地运行了生产数据库，非常感谢您。所以只需将遥测数据放在那里。 </p><p> These cycles, too, can hurt badly during outages. Like, authentication needing to be working to access operational systems to fix authentication… or monitoring needing working databases to get to metric data to discover what’s wrong the the databases. Fun stuff like that.</p><p>这些循环也可以在中断时疼得厉害。喜欢，需要努力访问操作系统以修复身份验证的身份验证...或监视需要工作数据库以获得公制数据以发现数据库的错误。有趣的东西。</p><p> Even customer communication systems are sometimes broken because you use your own system to relay system status to your customers.</p><p> 即使是客户通信系统有时被破坏，因为您使用自己的系统将系统状态传递给客户。</p><p>  Ep 1. Slack vs TGWs: Slack couldn’t access dashboards to know what was wrong with their systems because AWS Transit Gateways needed to be healthy in order to get http traffic to their dashboards. Unfortunately, the TGW were what was unhealthy.</p><p>  EP 1. Slack VS TGWS：Slack无法访问仪表板以知道其系统出现了什么问题，因为AWS Transit Gateways需要健康，以便将HTTP流量置于其仪表板。不幸的是，TGW是不健康的。</p><p> Ep 3. Monzo’s 2019 Cassandra Outage: Monzo’s production database was down, which was necessary to authenticate system access and deploy code to fix the issue.</p><p> EP 3. Monzo 2019 Cassandra中断：Monzo的生产数据库已关闭，这是验证系统访问和部署代码以解决问题所必需的。</p><p> Ep 10. Kinesis Hits the Thread Limit: AWS couldn’t update their status page about their Kinesis-related outage because updates to the status page depended on Kinesis.</p><p> EP 10. Kinesis命中线程限制：AWS无法更新其与Kinesis相关的中断的状态页面，因为对状态页面的更新依赖于Kinesis。</p><p> Ep 11. Salesforce Publishes a Controversial Postmortem: Salesforce couldn’t update their status page because they hosted it on a Heroku-based service, and since they owned Heroku and had therefore integrated it into their infrastructure, Heroku’s uptime depended on their system health</p><p> EP 11. Salesforce发布了一个有争议的淘汰的后期：Salesforce无法更新他们的状态页面，因为它们托管了基于Heroku的服务，并且由于他们拥有Heroku并因此将其集成到他们的基础设施中，Heroku的正常运行时间取决于他们的系统健康</p><p>  Everyone is super excited about the modern public cloud and its myriad APIs. The elasticity! The orchestration! Automating away operations so humans don’t have to get woken up!</p><p>  每个人都超级兴奋了解现代公共云及其无数API。弹性！编排！自动化操作，使人类不必被醒来！ </p><p> But this zeal sometimes has us over-automate systems where it is very difficult to test the degenerate cases. And, the downside of those untested degenerate cases may be much more significant than the slight efficiency or economic upside of having this be an automatic decision during healthier system states.</p><p>但是这种热情有时有些人拥有过度自动化的系统，在那里难以测试退化案件。而且，那些未经测试的退化情况下的缺点可能比在更健康的系统状态下是自动决定的略微效率或经济上行的缺点。</p><p> But even if the automation  is sensible because the adjustment needs to happen often and/or the economics involved are substantial, the automation sometimes lacks a necessary “panic mode”, recognizing when parameters have swung way outside their normal range. In these cases the automation should stop automating and page the operators, because it’s about to start making some wildly illogical decisions.</p><p> 但是即使自动化是明智的，因为调整经常和/或涉及的经济学是大量的，但是自动化有时缺乏必要的“恐慌模式”，识别参数在其正常范围之外的参数。在这些情况下，自动化应该停止自动化和页面运营商​​，因为它即将开始制作一些非常不合逻辑的决策。</p><p>  Ep 1. Slack vs TGWs: Slack’s automation threw away a bunch of servers they “didn’t need” (narrator: they did) due to idle CPU during a network issue, then spun up far too many when the surge of traffic returned, causing file descriptor limits to be exceeded on their systems.</p><p>  EP 1. Slack VS TGWS：Slack的自动化扔掉了一堆服务器，他们“不需要”（叙述者：他们所做的）由于空闲的CPU在网络问题期间，当交通返回的流量激增时，太多了。在其系统上导致文件描述符限制。</p><p> Ep 6. GitHub’s 43 Second Network Partition: GitHub’s database automation did a cross-country promotion of a primary with incomplete records during a 43 second network partition.</p><p> EP 6. GitHub的43个网络分区：Github的数据库自动化在43秒的网络分区期间对跨国推广有不完整的记录。</p><p> Ep 8. Auth0’s Seriously Congested Database: Auth0 spun up twice as many frontends when requests slowed down due to the database, just exacerbating issues with even more traffic.</p><p> EP 8. Auth0的严重拥挤数据库：Auth0由于数据库要求减慢时，前端旋转两倍，只需更快地加剧了更多的流量。</p><p>  If only everything were stateless, eh? Those pesky databases are always causing us problems. Even the issues that manifested themselves in frontend layers were often congestion that cascaded upward from databases slowing down deeper in the service stack.</p><p>  如果只有一切都没有状态，呃？这些讨厌的数据库始终导致我们的问题。即使在前端层中表现出自己的问题通常往往拥塞，从数据库中逐渐增加，从数据库减慢服务堆栈中的更深。</p><p> This area was so rife for material that we’ve broken out three sub-lessons:</p><p> 这一领域是因为我们爆发了三个子课程的物质而挣扎： </p><p>  Production systems are happy with flat, uniform loads with low variance. When it comes to database servers, that means lots of very fast queries, probably all index-backed, where the worst-case cost is bound.</p><p>生产系统对具有低方差的平坦，均匀的负载感到满意。涉及数据库服务器时，这意味着许多非常快的查询，可能是所有索引备份，其中最坏情况绑定。</p><p> To ensure this, put your arbitrary batch queries in a dedicated secondary server, or in some OLAP system like BigQuery or Snowflake. Or, heck, dump to CSV and parallel grep. Whatever level of sophistication makes you happy and fits your dataset size and workflow.</p><p> 为了确保这一点，请将任意批量查询放入专用辅助服务器中，或在一些OLAP系统中，如BigQuery或Snowflake。或者，哎呀，转储到CSV和并行Grep。无论复杂程度如何让您快乐，都适合您的数据集大小和工作流程。</p><p> And if you don’t yet know enough about your query time distribution to know whether you have crazy table scans at the end your tails, stop reading this and go add that monitoring right now!</p><p> 如果您尚未了解您的查询时间分发，以了解您是否在最终的尾部扫描了疯狂的表扫描，请停止阅读此操作并立即添加监视！</p><p>  Ep 2. Gitlab’s 2017 Postgres Outage: Very expensive long-running account deletion operations ran live on their production database, leading to congestion and failure.</p><p>  EP 2. Gitlab 2017 Postgres中断：非常昂贵的长期账户删除操作RAN在其生产数据库上实现，导致拥堵和失败。</p><p> Ep 5. Auth0 Silently Loses Some Indexes: Unmonitored failures to create an index caused some queries to suddenly become scans greatly increasing load on database and eventually causing outage.</p><p> EP 5. Auth0默默地失去了一些索引：创建索引的未调解失败导致一些查询突然变得大大增加了数据库的负荷，最终导致中断。</p><p> Ep 8. Auth0’s Seriously Congested Database: Database issues were exacerbated by some ad-hoc expensive scans that were happening on production systems.</p><p> EP 8. Auth0严重拥挤的数据库：通过在生产系统上发生的一些ad-hoc昂贵的扫描来加剧数据库问题。</p><p>   Low magic (good): Use something boring like MySQL and deal with sharding yourself. This will suck because you have to do a lot of extra work in the application layer, but you will probably know how it works when it breaks. This was probably the right idea 10 years ago, but is still fine.</p><p>   低魔法（好）：使用像MySQL这样无聊的东西并处理碎片。这将糟糕，因为您必须在应用程序层中做大量额外的工作，但您可能会知道它在缺失时如何工作。这可能是10年前的正确想法，但仍然很好。 </p><p> Lowest magic (gooder): Just buy a bigger server and use one unsharded MySQL/PostgreSQL server with a replica or two. This good idea is evergreen–ride this as long as you can.</p><p>最低魔法（更好）：只需购买更大的服务器，并使用副本或两台未设置的MySQL / PostgreSQL服务器。只要你可以，这个好主意就是常绿的。</p><p> High magic (admittedly, probably best in 2021+): Pay a cloud provider to run your database for you, including all your backups and failover, etc. You can even use a fancy database if you’d really like, like CloudSpanner, or DynamoDB, or whatever. This used to be unthinkable due the complete, opaque reliance on a 3rd party, but it is likely the best idea in 2021. These big companies have gotten very good at this stuff, and you’re probably already existentially doomed if they don’t do their job well since you’re running your company on one of them anyway. The downside is that it’s gonna cost you, because the markup on these services is high.</p><p> 高魔法（不可否认，可能在2021+中最好）：支付云提供商以为您运行数据库，包括所有备份和故障转移等，如果您真的很喜欢，如CloudSpanner，您甚至可以使用花哨数据库，如CloudSpanner，或者dynamodb，或其他。这曾经是在第三方的完整，不透明的依赖性的不可想象，但它可能是2021年的最好的想法。这些大公司已经很擅长这东西，如果他们没有，你可能已经存在了已经存在注定无论如何你在其中一个人在其中一个人在其中一家运行，他们就好了。缺点是它会花费你，因为这些服务的标记很高。</p><p> Middle Magic (playing with fire): Use something that will claim to automatically solve all your scaling and failover problems, but  you still have to operate, and it has a lot less production miles on it than something boring like MySQL. When it goes wrong, very few people know how to operate or understand its internals well enough to diagnose the sophisticated failure modes of its orchestration flows. The probable suspects we encountered in these outages include MongoDB and Cassandra.</p><p> 中间魔法（用火玩火）：使用一些将声称自动解决所有缩放和故障转移问题的东西，但您仍然必须运行，并且它在它上的生产数量较少，而不是像MySQL这样无聊的东西。出现问题时，很少有人知道如何运行或了解其内部结构，足以诊断其编排流的复杂的失败模式。我们在这些中断遇到的可能嫌疑人包括MongoDB和Cassandra。</p><p>  Ep 3. Monzo’s 2019 Cassandra Outage: Expanding Cassandra cluster had lots of poorly-understood configuration foot guns.</p><p>  EP 3. Monzo 2019 Cassandra停电：扩展Cassandra Cluster有很多不良的配置脚枪。</p><p> Ep 5. Auth0 Silently Loses Some Indexes: The balance of resyncing replicas in mongo without degrading live traffic was very difficult to achieve.</p><p> EP 5. Auth0默默地失去了一些索引：在不降低现场交通的情况下，Mongo中重复复制的余额非常难以实现。</p><p>  Backing up means  nothing if you cannot prove you can restore it, and the restoration produces the correct records, and that restoration will complete before the heat death of the universe.</p><p>  备份意味着如果您无法证明您可以恢复它，并且恢复会产生正确的记录，并且该恢复将在宇宙的热死亡前完成。</p><p>  Backup didn’t run… that would never happen, I’m monitoring that!</p><p>  备份没有运行......永远不会发生，我正在监控！ </p><p> Backup ran and produced a file in S3. This might be as far as your backup validation goes. The file is empty. Or it contains the helpful string:  Error: permission denied on directory /data. Your company is gone, while you scream “but you exited zero!!!” into the night.</p><p>备份ran并在s3中生成文件。就您的备份验证而言，这可能是。该文件是空的。或者它包含有用的字符串：错误：在目录/数据上拒绝权限。你的公司已经走了，而你尖叫着“但你退出零!!!”到深夜。</p><p> Backup ostensibly contains lots of great data, but got corrupted on upload. Your company is gone.</p><p> 备份表面上包含许多大数据，但上传已损坏。你的公司走了。</p><p> Backup contains a valid database! But every shard is shard 0 because of a loop bug in your backup script. 87.5% of your company is gone.</p><p> 备份包含有效数据库！但由于备份脚本中的循环错误，每个碎片都是碎片0。 87.5％的公司消失了。</p><p> Every backup contains the correct, valid database! But downloading it from that cheap storage class over a 85ms link will mean restoring will take 2 weeks. Your company is  still gone.</p><p> 每个备份都包含正确，有效的数据库！但从85毫秒链接下载从那个便宜的存储类将意味着恢复将需要2周。你的公司仍然消失了。</p><p> So, make sure you prove your restores work–automate and monitor this, don’t just do it once in awhile–and make sure they will restore in an acceptable amount of time. Expect it to be a bad day, like 4 hours, but not company ending, like 4 days. Make sure corporate-policy-wise your company is comfortable with this restoration time, and get sign-off from your leadership so they won’t be surprised when the engineering team needs 7 hours to get the databases back during a catastrophe.</p><p> 因此，请确保您证明您的恢复工作 - 自动化和监控此操作，不要一段时间内完成一次 - 并确保他们将在可接受的时间内恢复。期待它是一个糟糕的一天，如4小时，但不是公司结束，就像4天一样。确保公司政策智能公司对此恢复时间感到满意，并从您的领导地位签下，因此当工程团队需要7个小时时，他们不会感到惊讶，以便在灾难期间获得数据库。</p><p>  Ep 2. Gitlab’s 2017 Postgres Outage: Backup script had been running daily, putting things to S3… until a software update broke the backup script. Restorations hadn’t really ever been tested.</p><p>  EP 2. Gitlab的2017年Postgres中断：备份脚本每天运行，将其放入S3 ...直到软件更新打破备份脚本。修复物没有真正过测试过。</p><p> Ep 6. GitHub’s 43 Second Network Partition: Restores took a very long time (10h+), especially during peak traffic, leading to a very long time the site was degraded.</p><p> EP 6. GitHub的43个网络分区：恢复花费了很长时间（10h +），特别是在峰值流量期间，导致网站劣化了很长时间。 </p><p>  Despite our best efforts, mistakes will still happen. We’ll introduce bugs, or misconfigure stuff, or propagate a bad firewall rule, or whatever.</p><p>尽管我们的努力尽力而为，但仍将发生错误。我们将介绍错误，或误解的东西，或传播错误的防火墙规则，或者其他。</p><p> However, staged rollouts localize the issue so you can see the smoke before the fire spreads and burns down your entire site.</p><p> 但是，阶段推出本地化问题，以便您可以在火灾蔓延之前看到烟雾并烧毁整个网站。</p><p> A lot of teams we discussed had a thoughful rollout methodology that made sure their company’s employees were among the first users to be trying out changes to their services, and then only a small fraction of their customers would be exposed before all were.</p><p> 我们讨论的很多团队都有辅助的推出方法，使他们的公司的员工成为第一个努力为其服务进行改变的用户之一，而且只在所有的客户之前都会暴露。</p><p>  Roll out to your  Dogfooding cluster — every hour, or every single change set, the current HEAD version is deployed to your employees. This lets your own team catch issues far before your customers ever see it.</p><p>  向您的Dogfooding集群推出 - 每小时或每一个更改集，目前的头版部署到您的员工。这让您自己的团队在您的客户看到它之前捕获问题。</p><p> Canary cluster — at your release cadence (once a day, perhaps?), the release candidate is pushed out to a small deployment that exposes it to a small percentage of your users. Some companies make this one datacenter among dozens; others make this some percentage of the userbase, based on a modulus of their user_id or similar. A release manager may carefully monitor the metrics on this new release in the canary population, before moving on to…</p><p> 金丝雀群 - 在您的释放节奏（每天一次，也许是？），将释放候选人推出到一个小部署，使其暴露于少量用户。有些公司在几十个中将这一数据中心制作;其他人基于其user_id或类似的模数来提高userbase的一些百分比。发布经理可以仔细监控本金丝雀种群中的新版本的指标，然后继续...</p><p> Production. Now it starts to go out to the wider world. Depending on the criticality of the service and the release cadence, sometimes all at once, or sometimes  further staggered, like a datacenter at a time.</p><p> 生产。现在它开始出去更广泛的世界。根据服务的关键性和释放节奏，有时会一次或有时进一步交错，就像一个时代的数据中心。</p><p> For companies who employed these approaches, certainly there were many occasions when most of us never knew about a small issue because it was caught in dogfooding, or canary, or what-have-you.</p><p> 对于雇用这些方法的公司，当时我们大多数人从未知道一个小问题时，有很多场合，因为它被捕获在狗食，或金丝雀或有关的东西。 </p><p> But in instances in our podcasts where the companies had not utilized a staged rollout, things went markedly less well… and the teams writing the postmortems were the first to call out how much a staged deployment would have made a difference.</p><p>但在我们播客的实例中，公司没有使用阶段的卷展栏，事情越来越不错了......写下后的球队是第一个呼唤阶段部署的差异有多少差异。</p><p>  Ep. 4 One Subtle Regex Takes Down Cloudflare: Cloudflare’s very rapid deployment of a more expensive regular expression-based rule took the entire site down due to CPU exhaustion</p><p>  ep。 4一个微妙的正则表达式缩小了CloudFlare：CloudFlare非常快速地部署了一个更昂贵的正则表达式的规则，由于CPU耗尽而下整个站点下降</p><p> Ep 11. Salesforce Publishes a Controversial Postmortem: Rapid deployment of a DNS configuration change took all their name servers offline</p><p> EP 11. Salesforce发布了一个有争议的后期：迅速部署DNS配置更改将其所有名称服务器脱机</p><p>  Finally, while we’d all love to believe that if we’re very thorough on testing, and if we stage things thoughtfully, we won’t have any more full outages… we all know they’re still going to happen.</p><p>  最后，虽然我们都喜欢相信，如果我们在测试中非常彻底，但如果我们仔细阶段，我们就不会有任何充分的中断......我们都知道他们仍然会发生。</p><p> So, as we learned from many of our outages, if we build in policies and knobs into our systems and playbooks ahead of outages, we’ll have a much easier time recovering from them.</p><p> 因此，正如我们从我们的许多中学到的那样，如果我们在中断之前建立在我们的系统和剧本中的政策和旋钮中，我们将更容易地从中恢复。</p><p> Policies means having thought through and decided things like: if the whole site goes down from excess load, which traffic do we shed first to recover? What types, or what classes of customers? If these decisions are made ahead of time, and signed off by leadership, potentially even validated with lawyers, the engineering teams will have a lot easier time getting things back under duress.</p><p> 政策意味着经过思考和决定的事情：如果整个网站从过量的负载下降，我们首先恢复哪个流量？什么类型，或什么课程？如果这些决定是提前的，并通过领导签署，可能甚至与律师验证，工程团队将在胁迫下让事情变得更加容易。</p><p> Knobs means: do we have something like a “panic mode” we can set, where orchestration stops, load balancers get less clever, and nonessential jobs are automatically paused? Do we have a runtime parameter we can tweak to shed some fractional percentage of our load, so that we don’t have to just turn off and on everything, thereby encouraging the thundering herd?</p><p> 旋钮意味着：我们有类似“恐慌模式”我们可以设置，其中商务流运行，负载均衡器变得更加巧妙，并且自动暂停无数的作业？我们是否有一个运行时参数我们可以调整到我们负荷的一些小数百分比，以便我们不必关闭以及一切，从而鼓励雷鸣群？ </p><p>  Ep 1. Slack vs TGWs: Slack was able to use the envoy proxy’s panic mode to maximize the chance the load balancing algorithm found a healthy host while overloaded.</p><p>EP 1. Slack VS TGWS：Slack能够使用Senvoy Proxy的恐慌模式来最大限度地提高负载平衡算法在超载时发现一个健康主机的机会。</p><p> Ep. 4 One Subtle Regex Takes Down Cloudflare: Cloudflare already had policies and supporting terms-of-use that allowed them to turn off their global Web Application Firewall when that service was failing. Additionally, they had a runtime parameters that allowed them to disable this instantly without deploying code.</p><p> ep。 4一个微妙的正则表达式删除CloudFlare：CloudFlare已经有策略并支持使用条款，允许它们在该服务失败时关闭其全局Web应用程序防火墙。此外，它们具有运行时参数，允许它们立即禁用此而不部署代码。</p><p> Ep 6. GitHub’s 43 Second Network Partition: GitHub turned off web hook invocations and GitHub Pages builds while it was recovering from overload.</p><p> EP 6. GitHub的43个网络分区：GitHub关闭了Web挂钩调用，并且GitHub页面在从过载中恢复时构建。</p><p> Ep 9. How Coinbase Unleashed a Thundering Herd: Coinbase needed to overprovision one of its clusters to deal with thundering herd after flipping all traffic off/on rather than just slowly ramping traffic back up.</p><p> EP 9.冰块如何释放出雷鸣群：乐队需要在翻转所有流量之后过度处理雷鸣群，而不是慢慢地升高交通。</p><p>  After reviewing all these stressful outages, we feel confident in one very encouraging conclusion: a few common practices, many that we’ve enumerated above, will either prevent or dramatically lessen the severity of all manner of resultant site issues.</p><p>  在审查所有这些压力中的中断后，我们对一个非常令人鼓舞的结论感到有信心：一些常见的做法，许多我们上面列举的许多常见做法都将防止或大大地减少所有方式所产生的网站问题的严重程度。</p><p> Thanks again to all Downtime Project listeners out there for your feedback, advocacy, and support! We’re considering these ten outages a wrap on season one, and we’ll regroup, reflect, and be back with more episodes in season two shortly!</p><p> 再次感谢所有停机项目听众，以便您提供反馈，宣传和支持！我们正在考虑这十个中断季节一包，我们将重新组合，反映，并尽快在第二季的剧集中回归！ </p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://downtimeproject.com/podcast/7-lessons-from-10-outages/">https://downtimeproject.com/podcast/7-lessons-from-10-outages/</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/中断/">#中断</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/ten/">#ten</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/数据库/">#数据库</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/谷歌/">#谷歌</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/分享/">#分享</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy;2012-2021 diglog.com </div></div></body></html>