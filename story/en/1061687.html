<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>游戏理论作为大规模数据分析的发动机 Game theory as an engine for large-scale data analysis</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">Game theory as an engine for large-scale data analysis<br/>游戏理论作为大规模数据分析的发动机 </h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2021-05-10 21:27:56</div><div class="page_narrow text-break page_content"><p>Modern AI systems approach tasks like  recognising objects in images and  predicting the 3D structure of proteins as a diligent student would prepare for an exam. By training on many example problems, they minimise their mistakes over time until they achieve success. But this is a solitary endeavour and only one of the known forms of learning. Learning also takes place by interacting and playing with others. It’s rare that a single individual can solve extremely complex problems alone. By allowing problem solving to take on these game-like qualities, previous DeepMind efforts have trained AI agents to play  Capture the Flag and achieve  Grandmaster level at Starcraft. This made us wonder if such a perspective modeled on game theory could help solve other fundamental machine learning problems.</p><p>现代AI系统接近识别图像中的对象等任务，并预测蛋白质的3D结构作为勤奋的学生会准备考试。通过培训许多示例问题，他们随着时间的推移最小化他们的错误，直到他们取得成功。但这是一个孤独的努力，只有一种已知的学习形式。学习也通过与他人进行互动和玩耍来进行。单个个人可以单独解决极其复杂的问题是罕见的。通过允许解决这些游戏的品质来解决这些游戏的品质，之前的深度努力已经训练了AI代理商在捕获旗帜并在星际争霸实现宏大水平。这让我们想知道在游戏理论上建模这样的透视，可以帮助解决其他基本机器的学习问题。</p><p> Today at  ICLR 2021 (the International Conference on Learning Representations), we presented “ EigenGame: PCA as a Nash Equilibrium,” which received an Outstanding Paper Award. Our research explored a new approach to an old problem: we reformulated principal component analysis (PCA), a type of  eigenvalue problem, as a competitive multi-agent game we call EigenGame. PCA is typically formulated as an optimisation problem (or single-agent problem); however, we found that the multi-agent perspective allowed us to develop new insights and algorithms which make use of the latest computational resources. This enabled us to scale to massive data sets that previously would have been too computationally demanding, and offers an alternative approach for future exploration.</p><p> 今天在ICLR 2021（国际学习陈述会议）上，我们介绍了“EIGENGAME：PCA作为纳什均衡”，它获得了优秀的纸张奖。我们的研究探讨了旧问题的新方法：我们重新制定了主要成分分析（PCA），一种特征值问题，作为我们称之为eigengame的竞争多智能经纪人。 PCA通常被制定为优化问题（或单次代理问题）;但是，我们发现多代理商的角度来看，我们允许我们开发使用最新的计算资源的新洞察力和算法。这使我们能够扩展到以前过于计算的大规模数据集，并提供了未来探索的替代方法。</p><p>  First described in the early 1900s,  PCA is a long-standing technique for making sense of the structure of high-dimensional data. This approach is now ubiquitous as a first step in the data-processing pipeline and makes it easy to cluster and visualise data. It can also be a useful tool for learning low-dimensional representations for regression and classification. More than a century later, there are still compelling reasons to study PCA.</p><p>  首先在1900年代初描述，PCA是一种用于了解高维数据结构的长期技术。这种方法现在是普遍存在的数据处理流水线中的第一步，并且可以轻松群集和可视化数据。它也可以是用于学习回归和分类的低维表示的有用工具。超过一个世纪之后，还有令人信服的理由研究PCA。</p><p> Firstly, data was originally recorded by hand in paper notebooks, and now it is stored in data centres the size of warehouses. As a result, this familiar analysis has become a computational bottleneck. Researchers have explored  randomised algorithms and other directions to improve how PCA scales, but we found that these approaches have difficulty scaling to massive datasets because they are unable to fully harness recent deep-learning-centric advances in computation — namely access to many parallel GPUs or TPUs.</p><p> 首先，数据最初用手录制在纸质笔记本上，现在它存储在数据中心的仓库大小。结果，这种熟悉的分析已成为计算瓶颈。研究人员探索了随机算法和其他方向来改进PCA级别的方式，但我们发现这些方法难以扩大到大规模的数据集，因为它们无法完全线束，最近的计算中的深度学习的进步 - 即访问许多平行的GPU或TPU。</p><p> Secondly, PCA shares a common solution with many important ML and engineering problems, namely the  singular value decomposition (SVD). By approaching the PCA problem in the right way, our insights and algorithms apply more broadly across the branches of the ML tree.</p><p> 其次，PCA共享一个具有许多重要ML和工程问题的常见解决方案，即奇异值分解（SVD）。通过以正确的方式接近PCA问题，我们的见解和算法更广泛地跨越ML树的分支。</p><p>      As with any board game, in order to reinvent PCA as a game we need a set of rules and objectives for players to follow. There are many possible ways to design such a game; however, important ideas come from PCA itself: the optimal solution consists of  eigenvectors which capture the important variance in the data and are orthogonal to each other.</p><p>      与任何棋盘游戏一样，为了重新发明PCA作为游戏，我们需要一组规则和目标来遵循球员。有许多方法可以设计这样的游戏;然而，重要的想法来自PCA本身：最佳解决方案由特征向量组成，捕获数据中的重要方差并彼此正交。</p><p>      In EigenGame each player controls an eigenvector. Players increase their score by explaining variance within the data but are penalised if they’re too closely aligned to other players. We also establish a hierarchy: Player 1 only cares about maximising variance, whereas other players also have to worry about minimising their alignment with players above them in the hierarchy. This combination of rewards and penalties defines each player’s utility.</p><p>      在Eigengame中，每个播放器都控制特征向量。玩家通过解释数据内的差异来增加他们的分数，但如果它们与其他玩家保持紧密地对齐，则受到惩罚。我们还建立了一个层次结构：玩家1只关心最大化方差，而其他玩家也必须担心在层次结构中将它们与球员的对齐最小化。这种奖励和惩罚的组合定义了每个玩家的效用。 </p><p>      If all players play optimally, together they achieve the  Nash equilibrium of the game, which is the PCA solution.</p><p>如果所有玩家都在最佳地发挥，它们在一起实现了游戏的纳什均衡，这是PCA解决方案。</p><p> This can be achieved if each player maximises their utility independently and simultaneously using gradient ascent.</p><p> 如果每个玩家独立地和同时使用梯度上升，则可以实现这一点。</p><p>      This independence property of simultaneous ascent is particularly important because it allows for the computation to be distributed across dozens of Google Cloud TPUs, enabling both data- and model-parallelism. This makes it possible for our algorithm to adapt to truly large-scale data. EigenGame finds the principal components in a matter of hours for hundred-terabyte datasets comprising millions of features or billions of rows.</p><p>      同时上升的这种独立性尤为重要，因为它允许计算要分发数十个Google云TPU，从而实现数据和模型并行性。这使我们的算法可以适应真正的大规模数据。 EigEngame在几小时内找到主组件，百分之一的数据集包括数百万个特征或数十亿行。</p><p>      By thinking about PCA from a multi-agent perspective, we were able to propose scalable algorithms and novel analyses. We also uncovered a surprising connection to  Hebbian Learning — or, how neurons adapt when learning. In EigenGame, each player maximising their utilities gives rise to update equations that are similar to  update rules derived from Hebbian models of synaptic plasticity in the brain. Hebbian updates are known to converge to the PCA solution but are not derived as the gradient of any utility function. Game theory gives us a fresh lens to view Hebbian learning, and also suggests a continuum of approaches to machine learning problems.</p><p>      通过从多功能代理商的角度思考PCA，我们能够提出可扩展的算法和新型分析。我们还发现与Hebbian学习的令人惊讶的联系 - 或者神经元在学习时如何适应。在EIGENGAME中，每个玩家最大化其实用程序都会产生类似于更新与大脑中突触塑性模型的更新规则类似的方程式。已知Hebbian更新将收敛到PCA解决方案，但未导出为任何实用程序函数的渐变。博弈论给了我们一个新鲜的镜头，以查看Hebbian学习，并建议机器学习问题的途径连续。</p><p> On one end of the ML continuum is the well-developed path of proposing an objective function that can be optimised: Using the theory of convex and non-convex optimisation, researchers can reason about the global properties of the solution. On the other end, pure  connectionist methods and update rules inspired by neuroscience are specified directly, but analysis of the entire system can be more difficult, often invoking the study of complicated  dynamical systems.</p><p> 在M1连续局的一端是提出可以优化的目标函数的良好开发的路径：使用凸和非凸优化的理论，研究人员可以推理解决方案的全局属性。另一方面，直接指定了由神经科学的启发的纯连接方法和更新规则，但整个系统的分析可能更加困难，往往会调用复杂的动态系统的研究。</p><p> Game theoretic approaches like EigenGame sit somewhere in between. Player updates are not constrained to be the gradient of a function, only a best response to the current strategies of the other players. We’re free to design utilities and updates with desirable properties — for example, specifying updates which are unbiased or accelerated — while ensuring the Nash property still allows us to analyse the system as a whole.</p><p> 游戏理论方法，如Eigengame坐在两者之间。播放器更新并不被限制为函数的梯度，只有对其他玩家的当前策略的最佳响应。我们可以自由设计实用程序和具有可取性的更新 - 例如，指定未偏见或加速的更新 - 确保NASH属性仍然允许我们整个系统分析系统。</p><p>      EigenGame represents a concrete example of designing the solution to a machine learning problem as the output of a large multi-agent system. More generally, designing machine learning problems as multi-agent games is a challenging  mechanism design problem; however, researchers have already used the class of two-player,  zero-sum games to solve machine learning problems. Most notably, the success of  generative adversarial networks (GANs) as an approach to generative modelling has driven interest in the relationship between game theory and machine learning.</p><p>      EIGENGAME代表了将机器学习问题的解决方案设计为大型多功能机系统的输出的具体示例。更一般地说，设计机器学习问题，因为多智能运动游戏是一个具有挑战性的机制设计问题;然而，研究人员已经使用了两位二手零和游戏来解决机器学习问题。最值得注意的是，生成的对抗网络（GANS）的成功作为生成建模的方法引起了对博弈论与机器学习之间关系的兴趣。 </p><p> EigenGame moves beyond this to the more complex many-player, general-sum setting. This enables more obvious parallelism for greater scale and speed. It also presents a quantitative benchmark for the community to test novel multi-agent algorithms alongside richer domains, such as  Diplomacy and  Soccer.</p><p>EIGENGAME将超出此超越此功能，以更复杂的许多播放器，普通和设置。这使得更明显的并行性以获得更大的比例和速度。它还为社区提供了一种定量基准，用于测试新的多助理算法以及较丰富的域名，如外交和足球。</p><p> We hope our blueprint for designing utilities and updates will encourage others to explore this direction for designing new algorithms, agents, and systems. We’re looking forward to seeing what other problems can be formulated as games and whether the insights we glean will further improve our understanding of the multi-agent nature of intelligence.</p><p> 我们希望我们的蓝图设计公用事业和更新将鼓励其他人探索设计新算法，代理和系统的这种方向。我们期待着看到其他问题可以制定为游戏以及我们收集的见解是否会进一步提高我们对智力多智力本质的理解。</p><p>   For more details see our paper  EigenGame: PCA as a Nash Equilibrium and our follow-up work  EigenGame Unloaded: When playing games is better than optimising. This blog post is based on joint work with Thore Graepel, a research group lead at DeepMind and Chair of Machine Learning at University College London.</p><p>   有关详细信息，请参阅我们的论文EIGENGAME：PCA作为纳什均衡和我们的后续工作EIGENGAME卸载：游戏时比优于优化更好。这篇博客文章基于与Greaepel Geemind和Machine学习椅子的研究小组领导的Chore Graepel的联合工作基础。</p><p> We would like to thank Rob Fergus for their technical feedback on this post as well as Sean Carlson, Jon Fildes, Dominic Barlow, Mario Pinto, and Emma Yousif for pulling this all together.</p><p> 我们要感谢Rob Fergus在这篇文章以及肖恩卡尔森，Jon Fildes，Dominic Barlow，Mario Pinto和Emma Yousif中的技术反馈。 </p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://deepmind.com/blog/article/EigenGame">https://deepmind.com/blog/article/EigenGame</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/theory/">#theory</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/学习/">#学习</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/分享/">#分享</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy;2012-2021 diglog.com </div></div></body></html>