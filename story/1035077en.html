<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>个人数据仓库：回收您的数据</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">个人数据仓库：回收您的数据</h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2020-11-14 15:42:47</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2020/11/1586bbb33e3b952ca3046d9d20290415.jpg"><img src="http://img2.diglog.com/img/2020/11/1586bbb33e3b952ca3046d9d20290415.jpg" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>I gave a talk yesterday about personal data warehouses for  GitHub’s OCTO Speaker Series, focusing on my  Datasette and  Dogsheep projects. The video of the talk is now available, and I’m presenting that here along with  an annotated summary of the talk, including links to demos and further information.</p><p>昨天，我为GitHub的Octo扬声器系列做了一个关于个人数据仓库的演讲，重点是我的Datasette和DogSheet项目。演讲的视频现在已经可以观看了，我在这里展示它，并附上演讲的注释摘要，包括到演示和更多信息的链接。</p><p> There’s a short technical glitch with the screen sharing in the first couple of minutes of the talk—I’ve added screenshots to the notes which show what you would have seen if my screen had been correctly shared.</p><p>在演讲的前几分钟，屏幕分享出现了一个短暂的技术故障--我已经在笔记中添加了屏幕截图，这些截图显示了如果我的屏幕被正确分享，你会看到什么。</p><p>    I’m going to be talking about personal data warehouses, what they are, why you want one, how to build them and some of the interesting things you can do once you’ve set one up.</p><p>我将谈论个人数据仓库，它们是什么，你为什么想要一个，如何建立它们，以及一旦你建立了一个你可以做的一些有趣的事情。</p><p>  This is my dog, Cleo—when she won first place in a dog costume competition here, dressed as the Golden Gate Bridge!</p><p>这是我的狗，Cleo--当她在这里的狗狗服装比赛中获得第一名时，她打扮成金门大桥！</p><p>  So the question I want to answer is: How much of a San Francisco hipster is Cleo?</p><p>所以我想回答的问题是：克利奥在多大程度上是旧金山的潮人？</p><p>    I have a database of ten year’s worth of my checkins on Foursquare Swarm—generated using my  swarm-to-sqlite tool. Every time I check in somewhere with Cleo I use the Wolf emoji in the checkin message.</p><p>我在Foursquare Sarm上有一个数据库，里面有我十年的签到记录--这是用我的Sum-to-Sqlite工具生成的。每次我和Cleo在某个地方签到时，我都会在签到消息中使用狼的表情符号。</p><p>    If I facet by venue category, I can see she’s checked in at 57 parks, 32 dog runs, 19 coffee shops and 12 organic groceries.</p><p>如果我按场地类别分类，我可以看到她已经入住了57个公园，32个跑狗场，19家咖啡店和12家有机食品杂货店。</p><p>  Then I can facet by venue category and filter down to just her 19 checkins at coffee shops.</p><p>然后我可以根据场地类别进行分类，然后过滤到她在咖啡店的19个签到。</p><p>    Being able to build a map of the coffee shops that your dog likes is obviously a very valuable reason to build your own personal data warehouse.</p><p>能够建立一张你的狗狗喜欢的咖啡店地图，这显然是建立你自己的个人数据仓库的一个非常有价值的原因。</p><p>  The key to this demo is this web application I’m running called  Datasette. I’ve been working on this project for three years now, and the goal is to make it as easy and cheap as possible to explore data in all sorts of shapes and sizes.</p><p>这个演示的关键是我正在运行的名为Datasette的Web应用程序。我已经在这个项目上工作了三年，目标是让探索各种形状和大小的数据变得尽可能容易和便宜。</p><p>  Ten years ago I was working for the Guardian newspaper in London. One of the things I realized when I joined the organization is that newspapers collect enormous amounts of data. Any time they publish a chart or map in the newspaper someone has to collect the underlying information.</p><p>10年前，我在伦敦为《卫报》(Guardian)工作。当我加入这个组织时，我意识到的一件事是，报纸收集了大量的数据。任何时候，当他们在报纸上发布图表或地图时，总得有人收集背后的信息。</p><p>  There was a journalist there called Simon Rogers who was a wizard at collecting any data you could think to ask for. He knew exactly where to get it from, and had collected a huge number of brilliant spreadsheets on his desktop computer.</p><p>那里有一位名叫西蒙·罗杰斯(Simon Rogers)的记者，他是一位收集任何你能想到的需要的数据的巫师。他清楚地知道从哪里获取它，并在他的台式电脑上收集了大量精美的电子表格。</p><p>  We decided we wanted to publish the data behind the stories. We started something called  the Data Blog, and aimed to accompany our stories with the raw data behind them.</p><p>我们决定要公布故事背后的数据。我们创办了一家名为数据博客的网站，目的是为我们的故事配上背后的原始数据。</p><p>  We ended up using Google Sheets to publish the data. It worked, but I always felt like there should be a better way to publish this kind of structured data in a way that was as useful and flexible as possible for our audience.</p><p>我们最终使用谷歌工作表发布了这些数据。它奏效了，但我一直觉得应该有一种更好的方式来发布这种结构化数据，以一种对我们的受众尽可能有用和灵活的方式。</p><p>  Fast forward to 2017, when I was looking into this new thing called “serverless” hosting—in particular one called Zeit Now, which has since rebranded as  Vercel.</p><p>快进到2017年，当时我正在研究一种名为“无服务器”托管的新事物--特别是一种名为Zeit Now的新事物，它后来更名为Vercel。</p><p>  My favourite aspect of Serverless is “Scale to zero”—the idea that you only pay for hosting when your project is receiving traffic.</p><p>我最喜欢的Serverless的一个特点是“归零”--当你的项目收到流量时，你只需为托管付费。</p><p>  If you’re like me, and you love building side-projects but you don’t like paying $5/month for them for the rest of your life, this is perfect.</p><p>如果你和我一样，喜欢做一些副业，但你不喜欢在以后的生活中每月花5美元去做这些项目，那么这就是完美的选择。</p><p>  The catch is that serverless providers tend to charge you extra for databases, or require you to buy a hosted database from another provider.</p><p>问题是，无服务器提供商往往会向您收取额外的数据库费用，或者要求您从其他提供商那里购买托管数据库。</p><p>  But what if your database doesn’t change? Can you bundle your database in the same container as your code?</p><p>但是，如果您的数据库没有更改，该怎么办呢？你能把你的数据库和你的代码捆绑在同一个容器里吗？</p><p>  Here’s another demo. The  World Resources Institute maintain a CSV file of every power plant in the world.</p><p>这是另一个演示。世界资源研究所(World Resources Institute)保存着世界上每一家发电厂的CSV文件。</p><p>    I have  a script that grabs their most recent data and publishes it using Datasette.</p><p>我有一个脚本，可以获取他们的最新数据并使用Datasette发布。</p><p>    Datasette supports plugins. You’ve already seen this plugin in my demo of Cleo’s coffee shops—it’s called  datasette-cluster-map and it works by looking for tables with a latitude and longitude column and plotting the data on a map.</p><p>Datasette支持插件。你已经在我的Cleo咖啡店演示中看到过这个插件--它被称为Datasette-cluster-map，它的工作方式是查找包含经度和纬度列的表格，并在地图上绘制数据。</p><p>  Straight away looking at this data you notice that there’s a couple of power plants down here in Antarctica. This is McMurdo station, and it has a 6.6MW oil generator.</p><p>一看到这些数据，你就会注意到南极洲下面有几座发电厂。这是麦克默多电站，它有一台6.6兆瓦的石油发电机。</p><p>  And oh look, there’s a wind farm down there too on Ross Island knocking out 1MW of electricity.</p><p>哦，你看，罗斯岛下面也有一个风力发电场，发电能力为1兆瓦。</p><p>  But this is also a demonstration of faceting. I can slice down to just the  nuclear power plants in France and see those on a map.</p><p>但这也是多面性的展示。我可以只看到法国的核电站，并在地图上看到它们。</p><p>  And anything i can see in the interface, I can get out as JSON. Here’s  a JSON file showing all of those nuclear power plants in France.</p><p>而我在界面上看到的任何东西，我都可以作为JSON输出。这是一份JSON文件，显示了法国所有的核电站。</p><p>  And here’s  a CSV export which I can use to pull the data into Excel or other CSV-compatible software.</p><p>这是一个CSV导出，我可以使用它将数据拉入Excel或其他与CSV兼容的软件中。</p><p>  If I click  “view and edit SQL” to get back the SQL query that was used to generate the page—and I can edit and re-execute that query.</p><p>如果我点击“查看和编辑SQL”来返回用于生成页面的SQL查询，我就可以编辑并重新执行该查询。</p><p>  In most web applications this would be seen as a terrifying security hole—it’s a SQL injection attack, as a documented feature!</p><p>在大多数Web应用程序中，这会被视为一个可怕的安全漏洞--这是一个SQL注入攻击，是一个有文档记录的功能！</p><p>    Firstly, this is setup as a read-only database: INSERT and UPDATE statements that would modify it are not allowed. There’s a one second time limit on queries as well.</p><p>首先，它被设置为只读数据库：不允许使用会修改它的INSERT和UPDATE语句。查询也有一秒的时间限制。</p><p>  Secondly, everything in this database is designed to be published. There are no password hashes or private user data that could be exposed here.</p><p>其次，这个数据库中的所有内容都是为发布而设计的。这里没有可能暴露的密码散列或私有用户数据。</p><p>  This also means we have a JSON API that lets JavaScript execute SQL queries against a backend! This turns out to be really useful for rapid prototyping.</p><p>这也意味着我们有一个JSON API，它允许JavaScript对后端执行SQL查询！事实证明，这对快速成型非常有用。</p><p>  This is all built on top of  SQLite. Everyone watching this talk uses SQLite every day, even if you don’t know it.</p><p>这一切都构建在SQLite之上。每个观看这场演讲的人每天都在使用SQLite，即使你不知道它。</p><p>  Most iPhone apps use SQLite, many desktop apps do, it’s even running inside my Apple Watch.</p><p>大多数iPhone应用程序使用SQLite，许多桌面应用程序也使用SQLite，它甚至可以在我的Apple Watch中运行。</p><p>  One of my favourite features is that a SQLite database is a single file on disk. This makes it easy to copy, send around and also means I can bundle data up in that single file, include it in a Docker file and deploy it to serverless hosts to serve it on the internet.</p><p>我最喜欢的特性之一是SQLite数据库是磁盘上的单个文件。这使得复制和发送变得很容易，也意味着我可以将数据捆绑在单个文件中，将其包含在Docker文件中，然后将其部署到无服务器主机上，以便在互联网上提供服务。</p><p>  Here’s another demo that helps show how GitHub fits into all of this.</p><p>这是另一个演示，帮助展示GitHub是如何融入这一切的。</p><p>  Last year PG&amp;E—the power company that covers much of California—turned off the power to large swathes of the state.</p><p>去年，覆盖加州大部分地区的电力公司PG&Amp；E切断了该州大片地区的电力供应。</p><p>  I got lucky: six months earlier I had started scraping  their outage map and recording the history to a GitHub repository.</p><p>我很幸运：六个月前，我开始搜集他们的停机地图，并将历史记录到GitHub存储库。</p><p>  simonw/pge-outages is a git repository with 34,000 commits tracking the history of outages that PG&amp;E had published on their outage map.</p><p>Simonw/PGE-Outages是一个GIT存储库，有34,000条提交记录，跟踪PG&amp；E在其停运地图上发布的停运历史。</p><p>    I’m using this data to publish a Datasette instance with details of their historic outages. Here’s a page  showing their current outages ordered by the most customers affected by the outage.</p><p>我正在使用这些数据发布一个Datasette实例，其中包含其历史停机的详细信息。这是一个页面，显示了受停机影响最多的客户订购的当前停机情况。</p><p>  Read  Tracking PG&amp;E outages by scraping to a git repo for more details on this project.</p><p>有关此项目的更多详细信息，请参阅通过抓取git repo来跟踪PG&amp；E故障。</p><p>  I recently decided to give this technique a name. I’m calling it  Git scraping—the idea is to take any data source on the web that represents a point-in-time and commit it to a git repository that tells the story of the history of that particular thing.</p><p>我最近决定给这项技术起个名字。我称之为Git抓取--这个想法是把网络上代表某个时间点的任何数据源提交到一个Git库中，这个库讲述了这个特定事物的历史故事。</p><p>  Here’s my article describing the pattern in more detail:  Git scraping: track changes over time by scraping to a Git repository.</p><p>下面是我的文章，更详细地描述了这个模式：Git抓取：通过抓取到Git存储库来跟踪随时间的变化。</p><p>  This is the  New York Times election scraper website, built by Alex Gaynor and a growing team of contnributors. It scrapes the New York Times election results and uses the data over time to show how the results are trending.</p><p>这是由亚历克斯·盖纳(Alex Gaynor)和一支日益壮大的发行人团队创建的《纽约时报》(New York Times)选举宣传网站。它收集《纽约时报》的选举结果，并利用一段时间内的数据来显示结果的趋势。</p><p>  It uses a  GitHub Actions script that runs on a schedule, plus a really clever Python script that turns it into a useful web page.</p><p>它使用了一个按计划运行的GitHub操作脚本，再加上一个非常聪明的Python脚本，可以把它变成一个有用的网页。</p><p>  I’m going to do a bit of live coding to show you how this stuff works.</p><p>我将进行一些实时编码，向您展示这些东西是如何工作的。</p><p>    Any time I see a map like this, my first instinct is to open up the browser developer tools and try to figure out how it works.</p><p>每当我看到这样的地图，我的第一反应就是打开浏览器开发工具，试着弄清楚它是如何工作的。</p><p>  If I open the network tab, refresh the page and then filter to just XHR requests.</p><p>如果我打开网络选项卡，刷新页面，然后只过滤XHR请求。</p><p>  A neat trick is to order by size—because inevitably the thing at the top of the list is the most interesting data on the page.</p><p>一个巧妙的窍门是按大小排序--因为不可避免的是，列表顶部的内容是页面上最有趣的数据。</p><p>  This appears to be  a JSON file telling me about all of the current fires in the state of California!</p><p>这似乎是一个JSON文件，告诉我加利福尼亚州目前发生的所有火灾！</p><p>    Now I’m going to take this a step further and turn it into a Datasette instance.</p><p>现在，我将进一步将其转换为Datasette实例。</p><p>    I’m going to use  curl to fetch that data, then pipe it through  jq to filter for just that  AllYearIncidents array.</p><p>我将使用cURL来获取该数据，然后通过JQ管道将其传递给只过滤AllYearIntents数组的人。</p><p>    Next I’m going to pipe it into a tool I’ve been building called  sqlite-utils—it’s a suite of tools for manipulating SQLite databases.</p><p>接下来，我将把它输送到我一直在构建的名为sqlite-utils的工具中--这是一套用于操作SQLite数据库的工具。</p><p>  I’m going to use the “insert” command and insert the data into a  ca-fires.db in an  incidents table.</p><p>我将使用“INSERT”命令并将数据插入到事件表的ca-fires.db中。</p><p>  You can straight away see that one of the rows has a bad location, hence it appears in Antarctica.</p><p>你可以直接看到其中一排的位置不好，因此它出现在南极洲。</p><p>  I can also facet by county, to see which county had the most fires in 2020—Riverside had 21.</p><p>我还可以从各个县的角度来分析，看看2020年哪个县的火灾最多--河滨有21个。</p><p>  I’m going to take this a step further and put it on the internet, using a command called  datasette publish.</p><p>我将更进一步，使用一个名为Datasette Publish的命令将其放到互联网上。</p><p>  Datasette publish supports a number of different hosting providers. I’m going to use  Vercel.</p><p>Datasette Publish支持多种不同的宿主提供程序。我要用维塞尔。</p><p>  I’m going to tell it to publish that database to a project called “ca-fires”—and tell it to install the  datasette-cluster-map plugin.</p><p>我将告诉它将该数据库发布到一个名为“ca-fires”的项目中，并告诉它安装Datasette-cluster-map插件。</p><p>    This then takes that database file, bundles it up with the Datasette application and deploys it to Vercel.</p><p>然后，这将获取该数据库文件，将其与Datasette应用程序捆绑在一起，并将其部署到Vercel。</p><p>  The goal here is to have as few steps as possible between finding some interesting data, turning it into a SQLite database you can use with Datasette and then publishing it online.</p><p>这里的目标是尽可能少地查找一些有趣的数据，将其转换为可与Datasette一起使用的SQLite数据库，然后将其在线发布。</p><p>  And this here is that database I just created—available for anyone on the internet to visit and build against.</p><p>这就是我刚刚创建的数据库--互联网上的任何人都可以访问和建立数据库。</p><p>  I’ve given you a whistle-stop tour of Datasette for the purposes of publishing data, and hopefully doing some serious data journalism.</p><p>为了发布数据，我带您参观了一下Datasette，希望能做一些严肃的数据新闻工作。</p><p>    Last year, I read this essay by Stephen Wolfram:  Seeking the Productive Life: Some Details of My Personal Infrastructure. It’s an incredible exploration of fourty years of productivity hacks that Stephen Wolfram has applied to become the CEO of a 1,000 person company that works remotely. He’s optimized every aspect of his professional and personal life.</p><p>去年，我读到了斯蒂芬·沃尔弗拉姆(Stephen Wolfram)的这篇文章：寻求生产性生活：我个人基础设施的一些细节。斯蒂芬·沃尔夫勒姆申请成为一家1000人远程工作公司的首席执行官，这是对长达40年的生产率黑客的一次令人难以置信的探索。他优化了职业和个人生活的方方面面。</p><p>  But there was one part of this that really caught my eye. He talks about a thing he calls a “metasearcher”—a search engine on his personal homepage that searches every email, journals, files, everything he’s ever done—all in one place.</p><p>但其中有一部分真的吸引了我的眼球。他谈到了一种他称之为“元搜索器”的东西--他个人主页上的一个搜索引擎，可以搜索他曾经做过的每一封电子邮件、日记、文件，所有这些都在一个地方。</p><p>  And I thought to myself, I really want THAT. I love this idea of a personal portal to my own stuff.</p><p>我对自己说，我真的想要这样。我喜欢这个我自己的东西的个人门户的想法。</p><p>  And because it was inspired by Stephen Wolfram, but I was planning on building a much less impressive version, I decided to call it Dogsheep.</p><p>因为它的灵感来自斯蒂芬·沃尔夫拉姆，但我计划打造一个不那么令人印象深刻的版本，所以我决定把它命名为DogSheet。</p><p>  So essentially this is my personal data warehouse. It pulls in my personal data from as many sources as I can find and gives me an interface to browse that data and run queries against it.</p><p>所以从本质上说，这就是我的个人数据仓库。它从我能找到的尽可能多的来源提取我的个人数据，并为我提供一个浏览这些数据并对其运行查询的界面。</p><p>  I’ve got data from Twitter, Apple HealthKit, GitHub, Swarm, Hacker News, Photos, a copy of my genome... all sorts of things.</p><p>我从Twitter，Apple HealthKit，GitHub，Sarm，Hacker News，Photos，一份我的基因组中获得了数据……。各种各样的事情。</p><p>  Here’s another one about Cleo. Cleo has  a Twitter account, and every time she goes to the vet she posts a selfie and says how much she weighs.</p><p>这是另一个关于克利奥的故事。Cleo有一个推特账号，每次她去看兽医时，她都会上传一张自拍，并说她有多重。</p><p>  Here’s a SQL query that finds every tweet that mentions her weight, pulls out her weight in pounds using a regular expression, then uses the  datasette-vega charting plugin to show a self-reported chart of her weight over time.</p><p>下面是一个SQL查询，它查找每条提到她体重的推文，使用正则表达式提取她的体重(以磅为单位)，然后使用Datasette-Vega图表插件显示一段时间内她的自我报告体重图表。</p><p>  select created_at, regexp_match(&#39;.*?(\d+(\.\d+))lb.*&#39;, full_text, 1) as lbs, full_text, case when (media_url_https is not null) then json_object(&#39;img_src&#39;, media_url_https, &#39;width&#39;, 300) end as photo from tweets left join media_tweets on tweets.id = media_tweets.tweets_id left join media on media.id = media_tweets.media_id where full_text like &#39;%lb%&#39; and user = 3166449535 and lbs is not null group by tweets.id order by created_at desc limit 101</p><p>选择Created_at，regexp_Match(&#39；.*？(\d+(\.\d+))lb.*&#39；，Full_text，1)作为lbs，Full_Text，Case When(media_url_https不为空)，然后选择json_Object(&#39；img_src&39；，media_url_https，&#39；width&#39；)，然后选择json_object(&#39；img_src&39；，media_url_https，&#39；width&#39；，300)结束为左侧推文中的照片加入tweets.id=media_tweets.twets_id左侧加入media.id=media_tweets.media_id，其中Full_Text Like%lb%&#39；User=3166449535且lbs不是NULL GROUP BY Tweets.id ORDER BY CREATED_AT Desc Limit 101</p><p>  I did  23AndMe a few years ago, so I have a copy of my genome in Dogsheep. This SQL query tells me what colour my eyes are.</p><p>几年前我做了23andMe，所以我有一份狗羊的基因组。这个SQL查询告诉我我的眼睛是什么颜色。</p><p>    select rsid, genotype, case genotype when &#39;AA&#39; then &#39;brown eye color, 80% of the time&#39; when &#39;AG&#39; then &#39;brown eye color&#39; when &#39;GG&#39; then &#39;blue eye color, 99% of the time&#39; end as interpretation from genome where rsid = &#39;rs12913832&#39;</p><p>选择rsid、基因型、病例基因型，当rsid；aa；然后；aa；然后；rsid；rs12913832和#39；rsid=#39；rsid=#39；rs12913832&39；的基因组解释结束时，80%的情况下选择rsid、基因型、病例基因型；当rsid=；rs12913832&39；时，选择rsid、基因型、病例基因型的几率为99%；当rsid=；rsid=；rs12913832&39；时，选择rsid、基因型、病例基因型的几率为99%；当rsid=；rs12913832&39；</p><p>  Something I really like about Apple’s approach to this stuff is that they don’t just upload all of your data to the cloud.</p><p>我真的很喜欢苹果在这方面的做法，那就是他们不只是把你所有的数据上传到云端。</p><p>  This data lives on your watch and on your phone, and there’s an option in the Health app on your phone to export it—as a zip file full of XML.</p><p>这些数据存储在您的手表和手机上，手机上的Health应用程序中有一个选项可以将其导出--作为一个充满XML的压缩文件。</p><p>  I wrote a script called  healthkit-to-sqlite that converts that zip file into a SQLite database, and now I have tables for things like my basal energy burned, my body fat percentage, flights of stairs I’ve climbed.</p><p>我编写了一个名为HealthKit-to-sqlite的脚本，将该压缩文件转换为SQLite数据库，现在我有了一些表格，比如我的基础能量消耗、我的体脂百分比、我爬过的楼梯。</p><p>  But the really fun part is that it turns out any time you track an outdoor workout on your Apple Watch it records your exact location every few seconds, and you can get that data back out again!</p><p>但真正有趣的是，每当你在苹果手表上追踪户外锻炼时，它每隔几秒钟就会记录下你的确切位置，然后你就可以重新获得这些数据了！</p><p>  This is a map of my exact route for the San Francisco Half Marathon three years ago.</p><p>这是我三年前参加旧金山半程马拉松的确切路线地图。</p><p>  I’ve started tracking an “outdoor walk” every time I go on a walk now, just so I can get the GPS data out again later.</p><p>现在，我开始跟踪每次散步时的“户外行走”，这样以后我就可以再次获取GPS数据。</p><p>  I have a lot of data from GitHub about my projects—all of my commits, issues, issue comments and releases—everything I can get out of the GitHub API using my  github-to-sqlite tool.</p><p>我从GitHub获得了大量关于我的项目的数据--我所有的提交、问题、问题评论和发布--所有我可以使用GitHub-to-Sqlite工具从GitHub API中获得的信息。</p><p>  So I can do things like see all of my commits across all of my projects, search and facet them.</p><p>所以我可以做一些事情，比如查看我在所有项目中的所有承诺，搜索它们并对它们进行切面。</p><p>    I have  all of my releases, which is useful for when I write  my weeknotes and want to figure out what I’ve been working on.</p><p>我有我所有的版本，当我写我的周记，并想弄清楚我一直在做什么的时候，这是很有用的。</p><p>  It turns out the Apple Photos app uses a SQLite database, and if you know what you’re doing you can extract photo metadata from it.</p><p>事实证明，Apple Photos应用程序使用的是SQLite数据库，如果你知道自己在做什么，就可以从其中提取照片元数据。</p><p>  They actually run machine learning models on your own device to figure out what your photos are of!</p><p>他们实际上在你自己的设备上运行机器学习模型，以找出你的照片是什么！</p><p>  You can use the machine learning labels to see all of the photos you have taken of pelicans. Here are all of the photos I have taken that Apple Photos have identified as pelicans.</p><p>你可以使用机器学习标签来查看你拍摄的鹈鹕的所有照片。以下是我拍摄的所有照片，Apple Photos已经确认它们是鹈鹕。</p><p>  It also turns out they have columns called things like ZOVERALLAESTHETICSCORE, ZHARMONIOUSCOLORSCORE, ZPLEASANTCAMERATILTSCORE and more.</p><p>原来他们还有ZOVERALLAESTHETICSCORE、ZHARMONIOUSCOLORSCORE、ZPLEASANTCAMERATILTSCORE等栏目。</p><p>    And a few weeks ago I finally got around to building the thing I’d always wanted: the search engine.</p><p>几周前，我终于开始着手打造我一直想要的东西：搜索引擎。</p><p>  I called it  Dogsheep Beta, because Stephen Wolfram has a search engine called  Wolfram Alpha.</p><p>我叫它狗羊Beta，因为Stephen Wolfram有一个叫Wolfram Alpha的搜索引擎。</p><p>  This is pun-driven development: I came up with this pun a while ago and liked it so much I committed to building the software.</p><p>这是双关语驱动的开发：我不久前想出了这个双关语，我非常喜欢它，所以我致力于构建软件。</p><p>  I wanted to know when the last time I had eaten a waffle-fish ice cream was. I knew it was in Cupertino, so I searched Dogsheep Beta for Cupertino and found this photo.</p><p>我想知道我最后一次吃华夫饼是什么时候。我知道它在库比蒂诺，所以我在狗羊Beta上搜索库比蒂诺，找到了这张照片。</p><p>  I hope this illustrates how much you can do if you pull all of your personal data into one place!</p><p>我希望这能说明，如果你把所有的个人数据放在一个地方，你能做多少！</p><p>  The GDPR law that passed in Europe a few years ago really helps with this stuff.</p><p>几年前在欧洲通过的GDPR法律对解决这一问题真的很有帮助。</p><p>  Companies have to provide you with access to the data that they store about you.</p><p>公司必须向您提供访问它们存储的有关您的数据的权限。</p><p>  Many big internet companies have responded to this by providing a self-service export feature, usually buried somewhere in the settings.</p><p>许多大型互联网公司对此做出了回应，提供了自助式出口功能，通常隐藏在设置中的某个地方。</p><p>  You can also request data directly from companies, but the self-service option helps them keep their customer support costs down.</p><p>您也可以直接从公司请求数据，但自助服务选项可帮助他们降低客户支持成本。</p><p>  Everything I’ve shown you today is open source: you can install this software and use it yourself, for free.</p><p>我今天向你展示的一切都是开源的：你可以免费安装这个软件并自己使用。</p><p>  But there’s a lot of assembly required. You need to figure out authentication tokens, find somewhere to host it, set up cron jobs and authentication.</p><p>但需要进行大量的组装。您需要找出身份验证令牌，找到托管它的地方，设置cron作业和身份验证。</p><p>  Expecting regular humans to run a secure web server somewhere is pretty terrifying. I’ve been looking at  WireGuard and  Tailscale to help make secure access between devices easier, but that’s still very much for super-users only.</p><p>指望普通人在某个地方运行安全的网络服务器是相当可怕的。我一直在研究WireGuard和TailScale，以帮助简化设备之间的安全访问，但这在很大程度上仍然只针对超级用户。</p><p>  Running this as a hosted service doesn’t appeal: taking responsibility for people’s personal data is scary, and it’s probably not a great business.</p><p>将其作为托管服务运行并不吸引人：对人们的个人数据负责是可怕的，而且这可能不是一项伟大的业务。</p><p>  I think the best options are to run on people’s own personal devices—their mobile phones and their laptops. I think it’s feasible to get Datasette running in those environments, and I really like the idea of users being able to import their personal data onto a device that they control and analyzing it there.</p><p>我认为最好的选择是在人们自己的个人设备上运行-他们的手机和笔记本电脑。我认为让Datasette在这些环境中运行是可行的，我真的很喜欢用户能够将他们的个人数据导入到他们控制的设备上并在那里进行分析的想法。</p><p>    The  Dogsheep GitHub organization has most of the tools that I’ve used to build out my personal Dogsheep warehouse—many of them using the naming convention of something-to-sqlite.</p><p>我在构建我的个人DogSheet仓库时使用过的大部分工具都在DogSheet GitHub组织中--其中很多都使用了Sqlite的命名约定。</p><p>    Q: Is there/will there be a Datasette hosted service that I can pay $ for? I would like to pay $5/month to get access to the latest version of Dogsheep with all the latest plugins!</p><p>问：是否有/是否有我可以支付$的Datasette托管服务？我想支付每月5美元，以获得最新版本的狗羊与所有最新的插件！</p><p>  I don’t want to build a hosting site for personal private data because I think people should stay in control of that themselves, plus I don’t think there’s a particularly good business model for that.</p><p>我不想为个人隐私数据建立一个托管网站，因为我认为人们应该自己控制这些数据，而且我也不认为有一个特别好的商业模式。</p><p>  Instead, I’m building a hosted service for Datasette (called Datasette Cloud) which is aimed at companies and organizations. I want to be able to provide newsrooms and other groups with a private, secure, hosted environment where they can share data with each other and run analysis.</p><p>相反，我正在为Datasette(称为Datasette Cloud)构建一个面向公司和组织的托管服务。我希望能够为新闻编辑室和其他小组提供一个私人的、安全的、托管的环境，在那里他们可以彼此共享数据并运行分析。</p><p>  Q: How do you sync your data from your phone/watch to the data warehouse? Is it a manual process?</p><p>问：如何将手机/手表中的数据同步到数据仓库？这是人工操作吗？</p><p>  The health data is manual: the iOS Health app has an export button which generates a zip file of XML which you can then AirDrop to a laptop. I then run my  healthkit-to-sqlite script against it to generate the DB file and SCP that to my Dogsheep server.</p><p>健康数据是手动的：iOS Health应用程序有一个导出按钮，可以生成一个XML压缩文件，然后您可以将其AirDrop到笔记本电脑上。然后，我针对它运行HealthKit-to-Sqlite脚本，以生成DB文件和SCP，并将其发送到我的DogSheet服务器。</p><p>  Many of my other Dogsheep tools use APIs and can run on cron, to fetch the most recent data from Swarm and Twitter and GitHub and so on.</p><p>我的许多其他DogSheet工具都使用API，可以在cron上运行，从Sarm、Twitter和GitHub等获取最新数据。</p><p>  Q: When accessing Github/Twitter etc do you run queries against their API or you periodically sync (retrieve mostly I guess) the data to the warehouse first and then query locally?</p><p>问：在访问Github/Twitter等网站时，您是针对它们的API运行查询，还是定期将数据先同步(我猜主要是检索)到仓库，然后在本地查询？</p><p>  I always try to get ALL the data so I can query it locally. The problem with APIs that let you run queries is that inevitably there’s something I want to do that can’t be done of the API—so I’d much rather suck everything down into my own database so I can write my own SQL queries.</p><p>我总是尝试获取所有数据，以便在本地进行查询。让您运行查询的API的问题是，不可避免地有一些我想做的事情是API无法完成的-所以我更愿意将所有内容都吸收到我自己的数据库中，这样我就可以编写我自己的SQL查询。</p><p>  Here’s an example of my  swarm-to-sqlite script, pulling in just checkins from the past two weeks (using authentication credentials from an environment variable).</p><p>下面是我的群集到SQLite脚本的一个示例，它只获取过去两周的签入(使用来自环境变量的身份验证凭据)。</p><p>  Q: Have you explored doing this as a single page app so that it is possible to deploy this as a static site? What are the constraints there?</p><p>问：你有没有尝试过把它作为一个单页面应用程序来做，这样就有可能把它作为一个静态站点来部署？那里的制约因素是什么？</p><p>  It’s actually possible to query SQLite databases entirely within client-side JavaScript using  SQL.js (SQLite compiled to WebAssembly)</p><p>实际上，使用SQL.js(SQLite编译为WebAssembly)完全可以在客户端JavaScript中查询SQLite数据库。</p><p>  This Observable notebook is an example that uses this to run SQL queries against a SQLite database file loaded from a URL.</p><p>这个可观察到的笔记本是一个使用它对从URL加载的SQLite数据库文件运行SQL查询的示例。</p><p>  Datasette’s JSON and GraphQL APIs mean it can easily act as an API backend to SPAs</p><p>Datasette的JSON和GraphQL API意味着它可以很容易地充当SPA的API后端。</p><p>  I built this site to offer a search engine for trees in San Francisco. View source to see how it hits a Datasette API in the background:  https://sf-trees.com/?q=palm</p><p>我建这个网站是为了给旧金山的树木提供一个搜索引擎。查看源代码，查看它如何在后台命中Datasette API：https://sf-trees.com/?q=palm。</p><p>  You can use the network pane to see that it’s running queries against a Datasette backend.</p><p>您可以使用网络窗格查看它是否正在针对Datasette后端运行查询。</p><p>      Writable canned queries are a relatively recent Datasette feature that allow administrators to configure a UPDATE/INSERT/DELETE query that can be called by users filling in forms or accessed via a JSON API.</p><p>可写的预录查询是一个相对较新的Datasette特性，它允许管理员配置一个更新/插入/删除查询，填写表单的用户可以调用该查询，或者通过JSON API访问该查询。</p><p>  The idea is to make it easy to build backends that handle simple data entry in addition to serving read-only queries. It’s a feature with a lot of potential but so far I’ve not used it for anything significant.</p><p>这个想法是为了使构建后端变得容易，除了提供只读查询之外，这些后端还可以处理简单的数据输入。这是一个很有潜力的功能，但到目前为止，我还没有把它用于任何有意义的事情。</p><p>  Currently it can generate a VERY basic form (with single-line input values, similar to  this search example) but I hope to expand it in the future to support  custom form widgets via plugins for things like dates, map locations or autocomplete against other tables.</p><p>目前它可以生成一个非常基本的表单(带有单行输入值，类似于这个搜索示例)，但我希望在未来扩展它，通过插件支持自定义表单小部件，比如日期、地图位置或针对其他表格的自动完成。</p><p>  Q: For the local version where you had a 1-line push to deploy a new datasette: how do you handle updates? Is there a similar 1-line update to update an existing deployed datasette?</p><p>问：在本地版本中，您需要通过1行操作来部署新的数据板：您是如何处理更新的？是否有类似的单行更新来更新现有的已部署数据集？</p><p>  I deploy a brand new installation every time the data changes! This works great for data that only changes a few times a day. If I have a project that changes multiple times an hour I’ll run it as a regular VPS instead rather than use a serverless hosting provider.</p><p>每次数据更改时，我都会部署全新的安装！这对于一天只更改几次的数据非常有效。如果我有一个每小时更改多次的项目，我会将其作为常规VPS运行，而不是使用无服务器主机提供商。</p><p> Posted  14th November 2020 at 3:53 am · Tagged  github,  presentations,  speaking,  talks,  datasette,  dogsheep,  weeknotes,  sqliteutils · Follow  @simonw on Twitter</p><p>2020年11月14日凌晨3：53发布·带标签的GitHub、演示文稿、演讲、演讲、数据集、狗羊、Weeknote、sqliteutils·在Twitter上关注@simonw</p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://simonwillison.net/2020/Nov/14/personal-data-warehouses/">https://simonwillison.net/2020/Nov/14/personal-data-warehouses/</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/数据仓库/">#数据仓库</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/data/">#data</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/数据/">#数据</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/美国/">#美国</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/谷歌/">#谷歌</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/linux/">#linux</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/程序/">#程序</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy; 2020 diglog.com </div></div></body></html>