<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>获取使用Web Audio API的音频可视化效果</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">获取使用Web Audio API的音频可视化效果</h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2020-10-30 12:08:36</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2020/10/172082a0ec3f8f658c2c5fa0dcd39969.png"><img src="http://img2.diglog.com/img/2020/10/172082a0ec3f8f658c2c5fa0dcd39969.png" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>I’ve been working on getting WebRTC video chat working here on the website for a few weeks now. I finally got to the point where both text, video chat, and screen sharing all work really well, but somewhere in the back of my mind I kept thinking about complaints about “ Zoom fatigue” during the pandemic:</p><p>几个星期以来，我一直致力于让WebRTC视频聊天在网站上运行。我终于达到了文本、视频聊天和屏幕分享都工作得很好的地步，但在我脑海中的某个地方，我一直在想着在大流行期间对“缩放疲劳”的抱怨：</p><p> Zoom fatigue, Hall argues now, is real. “Zoom is exhausting and lonely because you have to be so much more attentive and so much more aware of what’s going on than you do on phone calls.” If you haven’t turned off your own camera, you are also watching yourself speak, which can be arousing and disconcerting. The blips, delays and cut off sentences also create confusion. Much more exploration needs to be done, but he says, “maybe this isn’t the solution to our problems that we thought it might have been.” Phone calls, by comparison, are less demanding. “You can be in your own space. You can take a walk, make dinner,” Hall says.</p><p>霍尔现在认为，变焦疲劳是真实存在的。“Zoom让人精疲力尽，也很孤独，因为你必须比打电话时更用心、更清楚地知道发生了什么。”如果你没有关掉自己的相机，你也在看着自己说话，这可能会让人兴奋和不安。时断时续、延误和断句也造成了混乱。还需要做更多的探索，但他说，“也许这不是我们认为的问题的解决方案。”相比之下，电话要求较低。“你可以呆在你自己的空间里。你可以散步，做饭，“霍尔说。</p><p>  It’s kind of an interesting thing to have on your mind while spending weeks writing/debugging/testing video chat code.</p><p>当您花费数周时间编写/调试/测试视频聊天代码时，脑海中浮现出这样的想法是一件很有趣的事情。</p><p> So I decided to add an audio-only mode. And if I was gonna do that, I had to show something cool in place of the video. So I figured I would try to add audio visualizations when one or both of the users didn’t have video on. Using the relatively recent  1  Web Audio API seemed like the right way to go.</p><p>所以我决定添加一个纯音频模式。如果我要这么做，我必须展示一些很酷的东西来代替视频。因此，我想当其中一个用户或两个用户都没有打开视频时，我会尝试添加音频可视化效果。使用相对较新的1Web Audio API似乎是正确的选择。</p><p>         To create audio visualizations, the first thing you’ll need is an  AnalyserNode, which you can get from the  createAnalyser method of a  BaseAudioContext. You can get both of these things pretty easily  2 like this:</p><p>要创建音频可视化，首先需要一个AnalyserNode，您可以从BaseAudioContext的createAnalyser方法中获得它。你可以很容易地得到这两样东西，就像这样：</p><p>  Next, create a  MediaStreamAudioSourceNode from an existing data stream (I use either the local or remote data streams from either  getUserMedia or from the ‘track’ event of  RTCPeerConnection respectively) using  AudioContext.createMediaStreamSource. Then you can connect that audio source to the analyser object like this:</p><p>接下来，使用AudioContext.createMediaStreamSource从现有数据流(我分别使用来自getUserMedia或RTCPeerConnection的‘Track’事件的本地或远程数据流)创建一个MediaStreamAudioSourceNode。然后，您可以将该音频源连接到分析器对象，如下所示：</p><p>    window.requestAnimationFrame is nice. Call it, passing in your drawing function, and then inside that function call  requestAnimationFrame again. Get yourself a nice little recursive loop going that’s automatically timed properly by the browser.</p><p>Window.requestAnimationFrame很不错。调用它，传入绘图函数，然后在该函数内部再次调用requestAnimationFrame。让您自己进行一个漂亮的小递归循环，浏览器会自动对其进行正确的计时。</p><p> In my situation, there will either be 0, 1, or 2 visualizations running, since either side can choose either video chat, audio-only (…except during screen sharing), or just text chat. So I have one loop that draws both. It looks like this:</p><p>在我的情况下，将运行0、1或2个可视化效果，因为任何一方都可以选择视频聊天、纯音频(…。除了在屏幕共享期间)，或者仅仅是文本聊天。所以我有一个循环来画这两个。它看起来是这样的：</p><p>  I created the class for those visualization objects, and they handle whether or not to draw. They each contain the analyser, source, and context objects for their visualization.</p><p>我为这些可视化对象创建了类，它们处理是否绘制。它们每个都包含用于可视化的分析器、源和上下文对象。</p><p> Then when I detect that loop doesn’t have to run anymore, I can cancel it using that  audioCancel value:</p><p>然后，当我检测到该循环不再需要运行时，我可以使用该audioCancel值取消它：</p><p>    Like in the  example you’ll see a lot if you look at the MDN documentation for this stuff, I provide options for two audio visualizations: frequency bars and a sine wave. Here’s how I configure the analyser for each type:</p><p>就像在这个例子中一样，如果您查看MDN文档，您会看到很多东西，我提供了两种音频可视化的选项：频率条和正弦波。下面是我如何为每种类型配置分析器：</p><p> 1 switch ( this.type) {  2  case  &#39;frequencybars&#39; :  3  this.analyser.minDecibels  =  - 90;  4  this.analyser.maxDecibels  =  - 10;  5  this.analyser.smoothingTimeConstant  =  0.85;  6  this.analyser.fftSize  =  256;  7  this.bufferLength  =  this.analyser.frequencyBinCount;  8  this.dataArray  =  new Uint8Array( this.bufferLength);  9  break; 10  default : 11  this.analyser.minDecibels  =  - 90; 12  this.analyser.maxDecibels  =  - 10; 13  this.analyser.smoothingTimeConstant  =  0.9; 14  this.analyser.fftSize  =  1024; 15  this.bufferLength  =  this.analyser.fftSize; 16  this.dataArray  =  new Uint8Array( this.bufferLength); 17  break; 18}</p><p>1开关(this.type){2个案例#39；：3个this.analyser.minDecibels=-90；4个this.analyser.maxDecibels=-10；5个this.analyser.平滑TimeConstant=0.85；6个this.analyser.fftSize=256；7个this.BufferLength=this.analyser.requencyBinCount；8个this.dataArray=new Uint8Array(this.BufferLength)；9个中断；10个默认值：11个this.analyser.minDecibels=-90；12个this.analyser.maxDecibels=-10；13 this.analyser.mooth ingTimeConstant=0.9；14 this.analyser.fftSize=1024；15 this.BufferLength=this.analyser.fftSize；16 this.dataArray=new Uint8Array(this.BufferLength)；17 Break；18}。</p><p> I’ve adjusted these numbers a lot, and I’m gonna keep doing it. A note about  fftSize and  frequencyBinCount:  frequencyBinCount is set right after you set  fftSize and it’s usually just half the  fftSize value. These values are about the amount of data you want to receive from the main analyser functions I’m about to talk about next. As you can see, they directly control the size of the data array that you’ll use to store the audio data on each draw call.</p><p>我已经对这些数字做了很多调整，而且我还会继续这样做。关于fftSize和requencyBinCount：requencyBinCount的注释是在设置fftSize之后立即设置的，它通常只是fftSize值的一半。这些值是关于您想要从我接下来要讨论的主要分析器函数接收的数据量。如您所见，它们直接控制数据数组的大小，您将使用该数组在每次绘制调用时存储音频数据。</p><p>  On each draw call, depending on the type of visualization, call either  getByteFrequencyData or  getByteTimeDomainData with the array that was created above, and it’ll be filled with data. Then you run a simple loop over each element and start drawing. Here’s my sine wave code:</p><p>在每次绘制调用时，根据可视化的类型，使用上面创建的数组调用getByteFrequencyData或getByteTimeDomainData，它将用数据填充。然后在每个元素上运行一个简单的循环并开始绘图。这是我的正弦波代码：</p><p> 1 this.analyser.getByteTimeDomainData( this.dataArray);  2 this.ctx.lineWidth  =  2;  3 this.ctx.strokeStyle  = audioSecondaryStroke;  4  5 this.ctx.beginPath();  6  7 let v, y;  8 for ( let i  =  0; i  &lt;  this.bufferLength; i ++) {  9 v  =  this.dataArray[i]  /  128.0; 10 y  = v  * height  /  2; 11 12  if (i  ===  0) { 13  this.ctx.moveTo(x, y); 14 }  else { 15  this.ctx.lineTo(x, y); 16 } 17 18 x  += width  *  1.0  /  this.bufferLength; 19} 20 21 this.ctx.lineTo(width, height  /  2); 22 this.ctx.stroke();</p><p>1this.analyser.getByteTimeDomainData(this.dataArray)；2this.ctx.lineWidth=2；3this.ctx.strokeStyle=AudioSecond daryStroke；4 5this.ctx.eginPath()；6 7个字母v，y；8 for(设i=0；i&lt；this.BufferLength；i++){9v=this.dataArray[i]/128.0；10y=v*高度/2；11 12 if(i==0){13 this.ctx.moveTo(x，y)；14}Else{15 this.ctx.lineTo(x，y)；16}17 18 x+=width*1.0/this.BufferLength；19}20 21 this.ctx.lineTo(width，Height/2)；22 this.ctx.strok()；</p><p>   So I did all of this stuff I just talked about, but for  days I could  not get this to work in Safari. Not because of errors or anything, but because both  getByteFrequencyData and  getByteTimeDomainData just filled the array with 0s every time. No matter what I did. I was able to get the audio data in Firefox just fine.</p><p>所以我做了所有我刚才谈到的事情，但是有几天我无法在Safari中使用这些东西。不是因为错误或其他原因，而是因为getByteFrequencyData和getByteTimeDomainData每次都用0填充数组。不管我做了什么。我可以很好地获取Firefox中的音频数据。</p><p> So at first, I figured it just didn’t work at all in Safari and I would just have to wait until Apple fixed it. But then I came across  this sample audio project and noticed it worked just fine in Safari.</p><p>所以一开始，我想它在Safari中根本不起作用，我只能等到苹果修复它。但是后来我发现了这个示例音频项目，并注意到它在Safari中工作得很好。</p><p> So I studied the code for an hour trying to understand what was different about my code and theirs. I made a lot of changes to my code to make it more like what they were doing. One of the big differences is that they’re connecting the audio source to different audio distortion nodes to actually change the audio. I just want to create a visualization so I wasn’t using any of those objects.</p><p>所以我花了一个小时研究代码，试图理解我的代码和他们的代码有什么不同。我对我的代码做了很多修改，使其更像他们正在做的事情。最大的区别之一是，它们将音频源连接到不同的音频失真节点，以实际更改音频。我只想创建一个可视化效果，所以我没有使用这些对象中的任何一个。</p><p>   WaveShaperNode: Use  BaseAudioContext.createWaveShaper to create a non-linear distortion. You can use a custom function to change the audio data.</p><p>WaveShaperNode：使用BaseAudioContext.createWaveShaper创建非线性失真。您可以使用自定义函数更改音频数据。</p><p> Each one of these objects has a  connect function where you pass another context, output, or filter. Each one has a certain number of inputs and outputs. Here’s an example from that sample project of connecting all of them:</p><p>这些对象中的每一个都有一个连接函数，您可以在其中传递另一个上下文、输出或过滤器。每一个都有一定数量的输入和输出。以下是示例项目中将它们全部连接起来示例：</p><p>  Note: Don’t connect to your audio context  destination if you’re just trying to create a visualization for a call. The user will hear themselves talking.</p><p>注意：如果您只是尝试为呼叫创建可视化效果，请不要连接到音频上下文目标。用户将听到自己的谈话。</p><p> Anyway, I tried adding these things to my code to see if that would get it working in Safari, but I had no luck.</p><p>不管怎样，我试着将这些东西添加到我的代码中，看看这是否能让它在Safari中工作，但我没有运气。</p><p>  I was starting to get  real frustrated trying to figure this out. I was gonna let it go when I thought Safari was just broken (because it usually is), but since I knew it  could work in Safari, I couldn’t leave it alone.</p><p>我开始对试图弄清楚这件事感到非常沮丧。当我认为Safari只是坏了(因为它通常是坏的)时，我想让它过去，但因为我知道它可以在Safari中工作，所以我不能让它一个人呆着。</p><p> Eventually I downloaded the actual HTML and Javascript files from that sample and started removing shit from their code, running it locally and seeing if it worked. Which it did. So now I’m editing my own code, and  their code, to get them to be pretty much the same. Which I did. And  still theirs worked and mine didn’t.</p><p>最后，我从该示例下载了实际的HTML和Javascript文件，并开始从他们的代码中清除垃圾，在本地运行，看看它是否正常工作。它确实做到了。所以现在我在编辑我自己的代码，和他们的代码，让它们几乎是一样的。我确实做到了。尽管如此，他们的还是起作用了，而我的不起作用。</p><p> Next I just started desperately logging every single object at different points in my code to figure out what the fuck was going on. Then I noticed something.</p><p>接下来，我开始拼命地在代码中的不同位置记录每个对象，以找出他妈的是怎么回事。然后我注意到一些东西。</p><p>   The  state is “suspended”? Why? I don’t know. I did the same log in the sample code (that I had downloaded and was running on my machine) and it was “running”.</p><p>国家被“停职”了吗？为什么？我不知道。我在示例代码(我已经下载并在我的机器上运行)中执行了相同的日志，它正在“运行”。</p><p>   Calling  resume changes the state and then everything works. To this day I still don’t know why the sample code didn’t need that line.</p><p>调用Resume会更改状态，然后一切都会正常工作。直到今天，我仍然不知道为什么示例代码不需要该行。</p><p>  Like everything else on my site, all of this must support different color schemes (and screen sizes, and mobile devices). That was surprisingly difficult when trying to draw an SVG on the canvas.</p><p>就像我网站上的其他东西一样，所有这些都必须支持不同的配色方案(以及屏幕大小和移动设备)。当试图在画布上绘制SVG时，这是出人意料的困难。</p><p> I’m using  FontAwesome for all my icons on the site. I wanted to use one of them for these visualizations. The FontAwesome files are all SVGs (which is great), but I didn’t know how to draw the image in different colors in Javascript. The way I decided to do this was to load the SVG file into a Javascript  Image object, then draw that onto the canvas each draw call.</p><p>我正在使用FontAwesom作为我在网站上的所有图标。我想用它们中的一个来实现这些可视化。FontAwese文件都是SVG(这很棒)，但是我不知道如何在Javascript中用不同的颜色绘制图像。我决定这样做的方法是将SVG文件加载到一个Javascript Image对象中，然后在每次绘制调用时将其绘制到画布上。</p><p> That worked, but it only drew it black even after changing the fill and stroke colors. So after some web searching I read about someone deciding to draw out an image on an offscreen canvas, reading all the image data, and manually rewriting the image data for each pixel if the alpha channel is greater than 0. Then the actual visualization code can just copy the image from the offscreen canvas onto the real one.</p><p>这很管用，但即使在更改了填充和笔触颜色之后，它也只将其绘制为黑色。因此，在一些网络搜索之后，我读到有人决定在屏幕外画布上画出一幅图像，读取所有图像数据，如果alpha通道大于0，则手动重写每个像素的图像数据。然后，实际的可视化代码就可以将图像从屏幕外的画布复制到真实的画布上。</p><p> So that’s what I did. But of course there was a browser specific issue. But  not from Safari!!!!!</p><p>所以我就是这么做的。但当然也有一个特定于浏览器的问题。但不是从萨法里来的！</p><p> It turns out that loading a SVG file into an  Image object (offscreen) doesn’t actually populate the width and height attributes of that object in Firefox. It does in Safari, which is what I tested this with  3. I actually need the width and height to do the canvas drawing operations.</p><p>事实证明，将SVG文件加载到Image对象(屏幕外)实际上并不填充Firefox中该对象的宽度和高度属性。在Safari中是这样的，这也是我用3测试过的。我实际上需要宽度和高度来做画布绘制操作。</p><p> So as a workaround, I try to load the SVG, and if the object has no width, I load a png file I made from the SVG using Pixelmator. Here’s the code for loading the image and drawing it to a canvas:</p><p>因此，作为一种解决办法，我尝试加载SVG，如果对象没有宽度，则使用Pixelmator加载从SVG生成的PNG文件。以下是加载图像并将其绘制到画布的代码：</p><p> 1audioImage.onload  = () =&gt; {  2  if ( !audioImage.width) {  3 audioImage.src  =  &#39;/static/images/microphone.png&#39;;  4  return;  5 }  6  7 audioCanvas.width  = audioImage.width;  8 audioCanvas.height  = audioImage.height;  9 10  const ctx  = audioCanvas.getContext( &#39;2d&#39;); 11 ctx.drawImage(audioImage,  0,  0); 12 13  const svgData  = ctx.getImageData( 0,  0, audioImage.width, audioImage.height); 14  const data  = svgData.data; 15  for ( let i  =  0; i  &lt; data.length; i  +=  4) { 16  if (data[i  +  3]  !==  0) { 17 data[i]  =  parseInt(audioStroke.substring( 1,  3),  16); 18 data[i  +  1]  =  parseInt(audioStroke.substring( 3,  5),  16); 19 data[i  +  2]  =  parseInt(audioStroke.substring( 5,  7),  16); 20 } 21 } 22 23 ctx.putImageData(svgData,  0,  0); 24}; 25 26audioImage.src  =  &#39;/static/images/microphone.svg&#39;;</p><p>1audioImage.onload=()=&gt；{2 if(！audioImage.width){3 audioImage.src=&#39；/static/image/microphone e.png&#39；；4 return；5}6 7 audioCanvas.width=audioImage.width；8 audioCanvas.high=audioImage.high；9 10 const ctx=audioCanvas.getContext(&#39；2d&#39；)；11 ctx.drawImage(audioImage，0，0)；12 13 const svgData=ctx.getImageData(0，0，audioImage.width，audioImage.high)；14 const data=svgData.data；15 for(设i=0；i&lt；data.length；i+=4){16if(data[i+3]！==0){17data[i]=parseInt(audioStroke.substring(1，3)，16)；18 data[i+1]=parseInt(audioStroke.substring(3，5)，16)；19data[i+2]=parseInt(audioStroke.substring(5，7)，16)；20}21}22 23ctx.putImageData(svgData，0，0)；24}；25 26audioImage.src=&#39；/static/image/microhone.svg&#39；；</p><p> In this case, I know the  audioStroke value is always in the format  #000000, so I just parse the colors and write them to the array.</p><p>在本例中，我知道AudioStrok值始终采用#000000的格式，所以我只是解析颜色并将它们写入数组。</p><p>  If you’ve done any canvas element drawing (especially when you have both high and low DPI monitors) you know by default it looks pretty low resolution. Any canvas drawing I do takes  window.devicePixelRatio into account.</p><p>如果您已经绘制过任何画布元素(特别是当您同时具有高和低DPI监视器时)，您就知道在默认情况下它看起来分辨率相当低。我绘制的任何画布都会考虑window.devicePixelRatio。</p><p> The idea is to adjust the canvas “real” width to factor in the screen pixel ratio, then CSS resize it back down to the original size. So on a high resolution screen (like in any Macbook),  window.devicePixelRatio will be 2, so you’ll resize the canvas to be twice the width and height, and then CSS size it down to what you wanted.</p><p>其想法是调整画布的“实际”宽度以考虑屏幕像素比率，然后CSS将其调整回原始大小。因此，在高分辨率屏幕上(就像在任何Macbook中一样)，window.devicePixelRatio将为2，因此您需要将画布的大小调整为宽度和高度的两倍，然后CSS将其大小缩小到您想要的大小。</p><p> This is the same concept as creating 2x images when Retina screens first came out so they can be sized down and look sharp af.</p><p>这与在Retina屏幕首次面世时创建2倍图像的概念相同，这样它们就可以缩小尺寸，看起来更清晰。</p><p>  1 const dpr  =  window.devicePixelRatio  ||  1;  2 this.canvasRect  =  this.canvas.getBoundingClientRect();  3  4 this.canvas.width  =  this.canvasRect.width  * dpr;  5 this.canvas.height  =  this.canvasRect.height  * dpr;  6 this.ctx  =  this.canvas.getContext( &#39;2d&#39;);  7 this.ctx.scale(dpr, dpr);  8  9 this.canvas.style.width  =  this.canvasRect.width  +  &#39;px&#39;; 10 this.canvas.style.height  =  this.canvasRect.height  +  &#39;px&#39;;</p><p>1 const dpr=window.devicePixelRatio||1；2this.canvasRect=this.canvas.get边界ClientRect()；3 4this.canvas.width=this.canvasRect.width*dpr；5this.canvas.high=this.canRect.high*dpr；6this.ctx=this.canvas.getContext(&#39；2d&#39；)；7this.ctx.scale(DPR，DPR)；8 9this.canvas.style.width=this.canvasRect.width+&#39；PX&#39；；10 this.canvas.style.high=this.canvasRect.high+&#39；px&#39；；</p><p> I store the canvasRect so I can use the width and height for all the other drawing calculations.</p><p>我存储canvasRect，以便可以将宽度和高度用于所有其他绘图计算。</p><p>  I really like the way this eventually turned out. There were a few times where I figured it would just be completely broken in some browsers, and a brief moment where I thought I would have to give up on my goal to have everything on the site react to color scheme switches, but I actually did everything I wanted to.</p><p>我真的很喜欢这件事最终的结果。有几次我认为它在一些浏览器中会完全崩溃，有那么一瞬间我认为我必须放弃我的目标，让网站上的所有东西都能对颜色方案切换做出反应，但实际上我做了我想做的一切。</p><p> Now I just have to keep messing around with those  AnalyserNode values until I get something that looks perfect.  4</p><p>现在，我只需要不断地处理这些AnalyserNode值，直到得到看起来完美的东西。4.。</p><p> It looks like the early Mozilla version of this API has been around since 2010, but Apple’s been working on this official Web Audio API standard a lot recently. See release 115 (current as of the date I’m writing this article) of their  Safari Technology Preview release notes.  ↩︎</p><p>看起来这个API的早期Mozilla版本从2010年就已经出现了，但是苹果公司最近一直在努力制定这个官方的Web Audio API标准。请参阅他们的Safari技术预览版发行说明的版本115(截至我撰写本文之日的当前版本)。↩︎。</p><p> I’ve been using  this “adapter.js” shim from Google to smooth over browser differences with WebRTC objects, and it’s also helpful with Web Audio API. Some browsers still have  AudioContext prefixed as  webkitAudioContext so if you’re not using something like adapter.js you’ll have to do  new (window.AudioContext || window.webkitAudioContext)().  ↩︎</p><p>我一直在使用Google的这个“Adapter.js”填充程序来消除WebRTC对象与浏览器之间的差异，它对Web Audio API也很有帮助。一些浏览器仍然将AudioContext作为webkitAudioContext的前缀，所以如果您没有使用Adapter.js之类的内容，则必须执行new(window.AudioContext||window.webkitAudioContext)()。↩︎。</p><p> It’s funny how after all this time fighting with and complaining about Safari issues (of which there are  many) I still develop with Safari. In this case, a lot of the reason is because Firefox runs my fans when I do WebRTC testing.  ↩︎</p><p>有趣的是，经过这么长时间的斗争和抱怨，我仍然在使用Safari开发Safari问题(其中有很多)。在这种情况下，很大程度上是因为Firefox在我进行WebRTC测试时运行我的粉丝。↩︎。</p><p> lol. There is no “perfect” with computers. The work never ends. I’ll be messing with all of this code until it’s completely replaced.  ↩︎</p><p>LOL。电脑是没有“完美”的。这项工作永远不会结束。在完全替换之前，我会处理所有这些代码。↩︎。</p><p>      Was this post useful to you? Want to support this website?  Learn more. Thanks for reading!</p><p>这篇文章对你有用吗？想要支持此网站吗？了解更多。谢谢你的阅读！</p><p>      Code    Add a Code so you can edit or delete this comment later. Using the same Name and Code for multiple comments will link them together.  Learn more.</p><p>代码添加代码，以便您以后可以编辑或删除此注释。对多个注释使用相同的名称和代码会将它们链接在一起。了解更多。</p><p>          ·    By posting a comment, you are agreeing to the  Terms of Use.</p><p>{##**$$}通过发布评论，即表示您同意使用条款。</p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://dwayne.xyz/post/audio-visualizations-web-audio-api">https://dwayne.xyz/post/audio-visualizations-web-audio-api</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/可视化/">#可视化</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/audio/">#audio</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/美国/">#美国</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/谷歌/">#谷歌</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/linux/">#linux</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/程序/">#程序</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy; 2020 diglog.com </div></div></body></html>