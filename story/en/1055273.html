<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>没有动物园的Kafka. Kafka without ZooKeeper</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">Kafka without ZooKeeper<br/>没有动物园的Kafka. </h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2021-04-01 19:35:52</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2021/4/5957214543e61b2009e2522cc6045172.png"><img src="http://img2.diglog.com/img/2021/4/5957214543e61b2009e2522cc6045172.png" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>At the heart of Apache Kafka ® sits the log—a simple data structure that uses sequential operations that work symbiotically with the underlying hardware. Efficient disk buffering and CPU cache usage, prefetch, zero-copy data transfers, and  many other benefits arise from the log-centric design, leading to the high efficiency and throughput that it is known for. For those new to Kafka, the topic—and its underlying implementation as a commit log—is often the first thing they learn about.</p><p>在ApacheKafka®的核心侧坐在日志 - 一个简单的数据结构，它使用顺序操作与底层硬件合作。高效的磁盘缓冲和CPU高速缓存使用，预取，零复制数据传输以及许多其他益处从以日志为中心的设计出现，导致它所以的高效率和吞吐量。对于那些新的Kafka，主题 - 以及其作为提交日志的底层实施 - 通常是他们了解的第一件事。</p><p> But the code for the log itself makes up a comparatively small part of the system as a whole. A far larger proportion of Kafka’s codebase is responsible for arranging partitions (i.e., logs) across the many brokers in a cluster, allocating leadership, handling failures, etc. This is the code that makes Kafka a reliable and trusted distributed system.</p><p> 但是日志本身的代码构成了整个系统的相对小部分。 kafka的codebase比例远远负责在群集中的许多经纪商中排列分区（即，日志），分配领导，处理失败等。这是使Kafka成为可靠和可信的分布式系统的代码。</p><p> Historically, Apache ZooKeeper was a critical part of how this distributed code worked. ZooKeeper provided the authoritative store of metadata holding the system’s most important facts: where partitions live, which replica is the leader, and so forth. The use of ZooKeeper made sense early on—it is a powerful and proven tool. But ultimately, ZooKeeper is a somewhat idiosyncratic filesystem/trigger API on top of a consistent log. Kafka is a pub/sub API on top of a consistent log. This led those operating the system to tune, configure, monitor, secure, and reason about communication and performance across two log implementations, two network layers, and two security implementations, each with distinct tools and monitoring hooks. It became unnecessarily complex. This inherent and unavoidable complexity spurred a recent initiative to replace ZooKeeper with an internal quorum service that runs entirely inside Kafka itself.</p><p> 从历史上看，Apache Zookeeper是这种分布式代码如何工作的关键部分。 Zookeeper提供了持有该系统最重要的事实的Metadata的权威商店：在划分的地方，哪个副本是领导者等等。使用ZooKeeper的使用早期就是一种强大而经过验证的工具。但最终，Zookeeper是一个一致的日志顶部有点特殊文件系统/触发API。 Kafka是一个一致的日志顶部的PUB / sub API。这导致了操作系统调整，配置，监视，安全性以及两个日志实现，两个网络层和两个安全实现的通信和性能的原因，每个都具有不同的工具和监视钩子。它变得不必要地复杂。这种固有和不可避免的复杂性促使最近的举措取代了ZooKeeper，其中内部法定人服务完全在Kafka本身内运行。</p><p> Of course, replacing ZooKeeper is a sizable piece of work and last April we started a community initiative to accelerate the schedule and deliver a working system by the end of the year.</p><p> 当然，取代Zookeeper是一款相当大的工作岗位，去年4月我们开始了一个社区倡议，以加速日程安排并在年底之前提供工作系统。</p><p> I just sat with Jason, Colin and the KIP-500 team and went through a full Kafka server lifecycle, produce, consume and all Zookeeper-free. Pretty darn sweet!</p><p> 我刚坐在杰森，科林和kip-500团队中，经历了完整的Kafka Server生命周期，生产，消费和所有自动统一。漂亮的甜蜜！</p><p>  So we’re very pleased to say that the early access of the KIP-500 code has been committed to trunk and is expected to be included in the upcoming 2.8 release. For the first time, you can run Kafka without ZooKeeper. We call this the Kafka Raft Metadata mode, typically shortened to KRaft (pronounced like  craft) mode.</p><p>  因此，我们非常高兴地说，KIP-500代码的早期访问已致力于中继，预计将包含在即将到来的2.8释放中。首次，您可以在没有Zookeeper的情况下运行Kafka。我们称之为Kafka Raft元数据模式，通常缩短到克拉特（发音等工艺）模式。</p><p> Beware, there are some features that are not available in this early-access release. We do not yet support the use of ACLs and other security features or transactions. Also, both partition reassignment and JBOD are unsupported in KRaft mode (these are anticipated to be available in an Apache Kafka release later in the year). Hence, consider the quorum controller  experimental software—we don’t advise subjecting it to production workloads. If you do try out the software, however, you’ll find a host of new advantages: It’s simpler to deploy and operate, you can run Kafka in its entirety as a single process, and it can accommodate significantly more partitions per cluster (see measurements below).</p><p> 请注意，此早期访问版本中有一些功能不可用。我们还不支持使用ACL和其他安全功能或交易。此外，分区重新分配和JBOD在克拉特模式下不受支持（这些预计将在Apache Kafka在年后发布中提供）。因此，考虑到仲裁控制器实验软件 - 我们不建议将其进行生产工作负载。但是，如果您尝试了该软件，您将找到一系列新的优点：部署和操作更简单，您可以整体运行Kafka作为单一进程，它可以适应每个群集的更多分区（参见测量以下）。 </p><p>  If you opt to run Kafka using the new quorum controller, all metadata responsibilities previously undertaken by the Kafka controller and ZooKeeper are merged into this one new service, running inside the Kafka cluster itself. The quorum controller can also run on dedicated hardware should you have a use case that demands it.</p><p>如果您选择使用新的仲裁控制器运行Kafka，则Kafka Controller和Zookeeper先前所承诺的所有元数据职责都将合并为此新服务，在Kafka集群本身内运行。仲裁控制器也可以在专用硬件上运行，如果您有一个要求它的用例。</p><p>  Internally, though, it gets interesting. The quorum controllers use the new KRaft protocol to ensure that metadata is accurately replicated across the quorum. This protocol is similar in many ways to ZooKeeper’s ZAB protocol, and to Raft, but has some important differences, one notable and befitting one being its use of an event-driven architecture.</p><p>  但内部，它变得有趣。仲裁控制器使用新的KRAFT协议来确保在仲裁中准确地复制元数据。此协议以许多方式与Zookeeper的Zab协议相似，并且对RAFT，但具有一些重要的差异，一个值得注意的差异，并且一个值得支持的差异是它使用事件驱动的架构。</p><p> The quorum controller stores its state using an event-sourced storage model, which ensures that the internal state machines can always be accurately recreated. The event log used to store this state (also known as the metadata topic) is periodically abridged by snapshots to guarantee that the log cannot grow indefinitely. The other controllers within the quorum follow the active controller by responding to the events that it creates and stores in its log. Thus, should one node pause due to a partitioning event, for example, it can quickly catch up on any events it missed by accessing the log when it rejoins. This significantly decreases the unavailability window, improving the worst-case recovery time of the system.</p><p> 仲裁控制器使用事件源存储模型存储其状态，这确保了内部状态机可以始终准确地重新创建。用于存储此状态的事件日志（也称为元数据主题）通过快照定期删除，以保证日志不能无限期地生长。仲裁中的其他控制器通过响应其在其日志中创建和存储的事件来遵循活动的控制器。因此，例如，如果由于分区事件引起的一个节点暂停，例如，它可以快速追赶它在重新加入时访问日志的任何事件。这显着降低了不可用窗口，从而提高了系统的最坏情况恢复时间。</p><p>  The event-driven nature of the KRaft protocol means that, unlike the ZooKeeper-based controller, the quorum controller does not need to load state from ZooKeeper before it becomes active. When leadership changes, the new active controller already has all of the committed metadata records in memory. What’s more, the same event-driven mechanism used in the KRaft protocol is used to track metadata across the cluster. A task that was previously handled with RPCs now benefits from being event-driven as well as using an actual log for communication. A pleasant consequence of these changes—and ones that were very much baked into the original design—is that Kafka can now support many more partitions than it previously could. Let’s discuss that in more detail.</p><p>  克拉夫协议的事件驱动性质意味着，与基于ZooKeEper的控制器不同，仲裁控制器不需要在变为活动之前从zookeeper加载状态。当领导层发生变化时，新的活动控制器已包含内存中的所有已提交的元数据记录。更重要的是，克拉夫协议中使用的相同事件驱动机制用于跟踪群集中的元数据。以前用RPC处理的任务现在是福利事件驱动以及使用实际日志进行通信。这些变化的令人愉快的结果 - 以及非常烘焙到原始设计的变化 - 是Kafka现在可以支持比以前的更多分区。让我们更详细地讨论这一点。</p><p>  The number of partitions that a Kafka cluster can support is determined by two properties: the per-node partition count limit and the cluster-wide partition limit. Both are interesting, but to date, metadata management has been the main bottleneck for the cluster-wide limitation. Previous Kafka Improvement Proposals (KIPs) have improved the per-node limit, although there is always more that can be done. But Kafka’s scalability depends primarily on adding nodes to get more capacity. This is where the cluster-wide limit becomes important as it defines the upper bounds of scalability within the system.</p><p>  Kafka群集可以支持的分区数由两个属性确定：每个节点分区计数限制和群集范围的分区限制。两者都很有趣，但到目前为止，元数据管理是集群范围限制的主要瓶颈。以前的Kafka改进提案（KIPS）已经改进了每个节点限制，尽管总是可以完成更多。但Kafka的可扩展性主要取决于添加节点以获得更多容量。这是群集范围限制变得重要的位置，因为它定义了系统内的可扩展性的上限。</p><p> The new quorum controller is designed to handle a much larger number of partitions per cluster. To evaluate this, we ran tests similar to those run previously in 2018 to publicise  Kafka’s inherent partition limits. These tests measure the time taken by shutdown and recovery, which is an O(#partitions) operation for the old controller. It is this operation that places an upper bound on the number of partitions that Kafka can support in a single cluster today.</p><p> 新的仲裁控制器旨在处理每群集数量大的分区。为了评估这一点，我们在2018年之前运行了类似于先前运行的测试，以宣传Kafka的固有分区限制。这些测试测量关闭和恢复所花费的时间，这是旧控制器的O（#Partitions）操作。这是此操作，将kafka在今天在单个集群中支持的分区数上的上限置于上限。</p><p> The previous implementation, as Jun Rao explained in the post referenced above, could achieve 200K partitions, with the limiting factor being the time taken to move critical metadata between the external consensus (ZooKeeper) and internal leader management (the Kafka controller). With the new quorum controller, both of these roles are served by the same component. The event-driven approach means that controller failover is now near-instantaneous. Below are the summary numbers for a cluster running 2 million partitions (10x the previous upper bound) executed in our lab:</p><p> 作为上述帖子中的jun Rao在上面引用的帖子中解释的以前的实施，可以实现200k分区，限制因素是在外部共识（Zookeeper）和内部领导者管理（Kafka Controller）之间移动关键元数据所花费的时间。使用新的仲裁控制器，这两个角色都由相同的组件提供。事件驱动方法意味着控制器故障转移现在近乎瞬时。以下是在我们的实验室中执行的群集运行200万分区（10x上一个上限）的摘要编号： </p><p>  Both measures for controlled and uncontrolled shutdown are important. Controlled shutdowns impact common operational scenarios, such as a rolling restart: the standard procedure for deploying software changes while maintaining availability throughout. Recovery from uncontrolled shutdowns is arguably more important as it sets the recovery time objective (RTO) of the system, say, after an unexpected failure, such as a VM or pod crashing or a data centre becoming unavailable. While these measures are only indicators of broader system performance, they directly measure the well-known bottleneck that ZooKeeper’s use imposes.</p><p>对受控和不受控制的关机的措施都很重要。受控关闭影响常用操作场景，例如滚动重启：部署软件更改的标准过程，同时保持始终保持可用性。从不受控制的停机中恢复可以说是更重要的是，它设置系统的恢复时间目标（RTO），例如在意外的失败之后，例如VM或POD崩溃或数据中心变得不可用。虽然这些措施只是更广泛的系统性能的指标，但他们直接测量Zookeeper使用施加的众所周知的瓶颈。</p><p> Note that the controlled and uncontrolled measurements are not directly comparable. The uncontrolled shutdown case includes the time taken for new leaders to be elected, while the controlled case does not. This disparity is deliberate to keep the controlled case in line with Jun Rao’s original measurements.</p><p> 请注意，受控和不受控制的测量不直接可比较。不受控制的关机案件包括新领导人所采取的时间，而受控案例没有。这种差异是刻意保持受控案例与Jun Rao的原始测量一致。</p><p>  Kafka has often been perceived as heavyweight infrastructure and the complexity of managing ZooKeeper—a second, separate distributed system—is a big part of why this perception exists. This often leads projects to opt for a lighter-weight message queue when they are starting out—say a traditional queue like ActiveMQ or RabbitMQ—and moving to Kafka when their scale demands it.</p><p>  Kafka经常被视为重量级基础设施以及管理Zookeeper-A第二个单独分布式系统的复杂性 - 是为什么这种感知存在的重要组成部分。这通常会导致项目以选择更轻量的消息队列，当他们开始时出示一个传统的队列，如ActiveMQ或Rabbitmq  - 并在其比例要求时转向Kafka。</p><p> This is unfortunate because the abstraction that Kafka provides, formed around a commit log, is just as applicable to the small-scale workloads you might see at a startup as it is to the high-throughput ones at Netflix or Instagram. What is more, if you want to add stream processing, you need Kafka and its commit log abstraction, whether it’s using Kafka Streams, ksqlDB, or another stream processing framework. But because of the complexity of managing two separate systems—Kafka and Zookeeper—users often felt they had to choose between scale or ease of getting started.</p><p> 这是不幸的，因为Kafka提供的抽象在提交日志中形成，同样适用于您可能在启动时看到的小规模工作负载，因为它是Netflix或Instagram的高吞吐量。更重要的是，如果要添加流处理，则需要Kafka及其提交日志抽象，无论是使用Kafka Streams，KSQLDB还是其他流处理框架。但由于管理两个单独的系统的复杂性 -  Kafka和Zookeeper-user常认为他们必须在比例之间选择或易于入门。</p><p> This is no longer the case. KIP-500 and the KRaft mode provide a great, lightweight way to get started with Kafka or use it as an alternative to monolithic brokers like ActiveMQ or RabbitMQ. The lightweight, single-process deployment is also better suited to edge scenarios and those that use lightweight hardware. Cloud adds an interesting, tangential angle to the same problem. Managed services like  Confluent Cloud remove the operational burden entirely. So, whether you’re looking to run your own cluster, or have it run for you, you can start small and grow to (potentially) massive scale as your underlying use case expands—all with the same infrastructure. Let’s see what that looks like for a single-process deployment.</p><p> 这已不再是这种情况。 KIP-500和KRAFT模式提供了一种伟大的轻量级方式来开始Kafka，或者将其用作替代品如Actimemq或Rabbitmq等单片经纪人。轻量级，单流程部署也更适合边缘方案和使用轻质硬件的人。云增加了同样的问题的有趣，切向角度。汇率云等托管服务完全消除了运营负担。因此，您是否正在寻求运行自己的群集，或者为您运行，您可以从中开始且增长（潜在地）大规模比例，因为您的基础用例展开 - 所有具有相同的基础架构。让我们看看单程部署的样子。</p><p>  The new quorum controller is available in trunk today in experimental mode and is expected to be included in the upcoming Apache Kafka 2.8 release. So what can you do with it? As mentioned, one simple but very cool new feature is the ability to create a single process Kafka cluster as the short demo below shows.</p><p>  新的仲裁控制器今天在实验模式下在后备箱中提供，预计将包含在即将到来的Apache Kafka 2.8版本中。那么你能做什么呢？如上所述，一个简单但非常酷的新功能是能够在下面的简短演示中创建一个过程Kafka群集。</p><p>   Of course, if you want to scale that out to support higher throughputs and add replication for fault tolerance, you just need to add new broker processes. As you know, this is an early access release of the KRaft-based quorum controller. Please don’t use it for critical workloads. Over the next few months, we’ll be adding the final missing pieces, performing TLA+ modeling of the protocol, and hardening the quorum controller in Confluent Cloud.</p><p>   当然，如果要扩展到支持更高的吞吐量并添加容错的复制，只需添加新的代理流程。如您所知，这是基于Kraft的仲裁控制器的早期访问释放。请不要为关键工作负载使用它。在接下来的几个月里，我们将添加最终缺失的碎片，执行协议的TLA +建模，并在Confluent Cloud中强化仲裁控制器。 </p><p> You can try the new quorum controller out for yourself right now.  See the full README on GitHub.</p><p>您可以立即尝试新的仲裁控制器。在github上看到完整的自述文件。</p><p>   This has been (and continues to be) a huge effort that would not have been possible without the Apache Kafka community and a group of distributed systems engineers who worked tirelessly during a pandemic to go from zero to a working system in about nine months. We want to extend a special thank you to Colin McCabe, Jason Gustafson, Ron Dagostino, Boyang Chen, David Arthur, Jose Garcia Sancio, Guozhang Wang, Alok Nikhil, Deng Zi Ming, Sagar Rao, Feyman, Chia-Ping Tsai, Jun Rao, Heidi Howard, and all members of the Apache Kafka community who have helped make this happen.</p><p>   如果没有Apache Kafka社区，并且一组分布式系统工程师在大流行期间，这是一个巨大的努力，这一直是（并继续是）巨大的努力。我们想简要介绍一个特别感谢Colin Mccabe，Jason Gustafson，Ron Dagostino，Boyang Chen，David Arthur，Jose Garcia Sancio，Guozang Wancio，Guokhang Wang，Alokhiol，邓自明，Sagar Rao，Feyman，Chia-Ping Tsai，Jun Rao ，Heidi Howard，以及帮助实现这一目标的Apache Kafka社区的所有成员。</p><p> Ben Stopford is lead technologist in the Office of the CTO at Confluent. He is a data technology specialist who has worked on a range of systems at Confluent, Thoughtworks, and enterprise organizations. His contributions to Apache Kafka include work on Kafka’s replication protocol and other associated projects. He is also the author of the O’Reilly book:  Designing Event-Driven Systems.</p><p> 本斯托斯福德是CTO办公室的领导技术专家。他是一个数据技术专家，他们在汇合，思考和企业组织的一系列系统上工作。他对Apache Kafka的贡献包括Kafka的复制协议和其他相关项目的工作。他也是O'Reilly Book：设计事件驱动系统的作者。</p><p> Ismael Juma is an engineering leader at Confluent focusing on Apache Kafka and Confluent Cloud. Ismael worked on initiatives such as Infinite Storage in Confluent Cloud and replacing ZooKeeper with a Kafka Raft (KRaft) metadata quorum. Ismael is also an Apache Kafka Committer and Project Management Committee (PMC) member.</p><p> Ismael Juma是融合在Apache Kafka和Confluent Cloud的汇合的工程领导者。 Ismael在汇合云中的无限存储等举措上工作，用Kafka Raft（牛皮纸）元数据法定值替换Zookeeper。 Ismael还是Apache Kafka提名和项目管理委员会（PMC）成员。 </p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://www.confluent.io/blog/kafka-without-zookeeper-a-sneak-peek/">https://www.confluent.io/blog/kafka-without-zookeeper-a-sneak-peek/</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/动物园/">#动物园</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/kafka/">#kafka</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/分享/">#分享</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy;2012-2021 diglog.com </div></div></body></html>