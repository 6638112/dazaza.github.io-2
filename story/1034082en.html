<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>使用Python将Utzoo-Wiseman Usenet磁带转换为PostgreSQL后端</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">使用Python将Utzoo-Wiseman Usenet磁带转换为PostgreSQL后端</h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2020-11-10 01:04:30</div><div class="page_narrow text-break page_content"><p>Recently, I came across a resource that allowed me to download the entire collection of UTZOO NetNews Archive of the earliest USENET posts. These were essentially the earliest available discussions posted to the Internet by people working at various Universities who were already connected to the Internet. There were approximately 2.1 million posts in these archives created between Feb 1981 and June of 1991. This article describes the journey of converting those tapes into fully searchable PostgreSQL database and later also into the  usenetarchives.com website.</p><p>最近，我偶然看到一个资源，它允许我下载UTZOO网络新闻档案中最早的Usenet帖子的全部集合。这些基本上是已经连接到互联网的各个大学的工作人员在互联网上发布的最早的可用讨论。这些档案馆在1981年2月至1991年6月期间设立了大约210万个职位。本文描述了如何将这些磁带转换成完全可搜索的PostgreSQL数据库，然后再转换到usenetArchives.com网站。</p><p>   Until 2001, these early Usenet discussions were considered being lost, but miraculously  Henry Spencer from the University of Toronto, Department of Zoology was backing it up onto magnetic tapes and kept them stored for all these years (apparently at a great cost).</p><p>直到2001年，这些早期的Usenet讨论都被认为是丢失的，但神奇的是，多伦多大学动物系的亨利·斯宾塞(Henry Spencer)奇迹般地将其备份到磁带上，并将其保存了这么多年(显然花费了很大的代价)。</p><p> H. Spencer had altogether 141 of these magnetic tapes, but there were of no use, so eventually, him and a couple of motivated people such as David Wiseman (who dragged 141 tapes back and forth in his a pickup truck), Lance Bailey, Bruce Jones, Bob Webber, Brewster Kahle, and Sue Thielen; embarked on a process of converting all of these tapes into the regular format, accessible to everyone.</p><p>H·斯宾塞一共有141盘这样的磁带，但都没有用，所以最终，他和大卫·怀斯曼(他用一辆皮卡来回拖着141盘磁带)、兰斯·贝利、布鲁斯·琼斯、鲍勃·韦伯、布鲁斯特·卡勒和苏·蒂伦等几个积极进取的人开始了一个将所有这些磁带转换成常规格式的过程，每个人都可以接触到这些磁带。</p><p>  Well, not so fast, once I unzipped the data, I realized that the TGZ format contains literally millions of small text files (each post in its own file). While it was certainly nice to have, it wasn’t something that I or anyone else could read. Certainly not in a forum like discussion format. It wasn’t obvious which post is the one that starts the discussion or which ones are the replies to the thread. And forget about searching through these files, that was utterly not possible. Just to put things into perspective, it took me over 5 hours to un-tar the archives.</p><p>好吧，没那么快，在我解压数据之后，我意识到TGZ格式实际上包含数百万个小文本文件(每个帖子都在它自己的文件中)。虽然这本书很棒，但它不是我或任何人都能读懂的。当然不是在讨论形式的论坛上。目前还不清楚哪个帖子是引发讨论的帖子，也不清楚哪些帖子是对该帖子的回复。忘了搜索这些文件吧，那是完全不可能的。简单地说，我花了5个多小时才解开档案。</p><p> That said, it didn’t take long for me to decide to develop a Python-based converter that would allow me to convert the entire collection from millions of flat files into a fully searchable PostgreSQL database. The following post talks about the process and also includes the Python code of the solution released as open source.</p><p>也就是说，没过多久，我就决定开发一个基于Python的转换器，使我能够将整个集合从数百万个平面文件转换成一个完全可搜索的PostgreSQL数据库。下面的帖子将讨论这一过程，并包括作为开源发布的解决方案的Python代码。</p><p>     Once downloaded you’ll see that archive contains 161 x TAR Archive files. It looks like this:</p><p>下载后，您将看到归档文件包含161x个tar归档文件。它看起来是这样的：</p><p>  So, I grabbed a copy of the 7-Zip archiver from  https://www.7-zip.org and started decompressing the files.</p><p>于是，我从https://www.7-zip.org那里拿了一份7-Zip压缩包，开始解压缩文件。</p><p> I ended up with over  2,104,828 flat text files in  56,988 folders, which was the entire copy of Henry Spencer’s Usenet archive.</p><p>我最终在56,988个文件夹中得到了超过2104,828个纯文本文件，这是亨利·斯宾塞的Usenet档案的完整副本。</p><p> For those who like numbers, here is each Utzoo tape along with its size, number of files and folders:</p><p>对于那些喜欢数字的人，这里有每个Utzoo磁带及其大小、文件和文件夹的数量：</p><p>   While examining the extract, I realized that Magnetic Tape 118 is uncompressed in \utzoo-wiseman-usenet-archive\news118f1 folder, named tape118, so I had rename it to tape118.tar and extracted it manually, only to realize it’s a copy of files which I already have. Someone creating the original archive forgotten to remove that file. There are 3 files in these folders that need to have.tar extension added and decompressed as well:</p><p>在检查解压文件时，我意识到磁带118解压在\utzoo-Wiseman-Usenet-ARCHIVE\news 118f1文件夹中，名为tape118，所以我将其重命名为Tape118.tar并手动解压，结果才意识到它是我已经拥有的文件的副本。创建原始存档的人忘记删除该文件。这些文件夹中有3个文件需要添加并解压缩.tar扩展名：</p><p>  If you opened one of the folders and navigated down to one of the many subfolders, you’d find a file that contained the message. For example, going into \utzoo-wiseman-usenet-archive\news006f1\b15\net\aviation folder, I was now apparently in the  net.aviation Usenet group. But the only way to find out was to open one of the files and look at the content. Here I highlighted what it looked like. As you can see, each file seems to consist of a header, then a single empty line and the body of the message:</p><p>如果您打开其中一个文件夹并向下导航到众多子文件夹中的一个，您会发现包含该邮件的文件。例如，进入\utzoo-wiseman-usenet-archive\news006f1\b15\net\aviation文件夹，我现在显然是在net.Aviation Usenet组中。但唯一能找到答案的方法就是打开其中一个文件，看看里面的内容。我在这里强调了它看起来是什么样子。正如您所看到的，每个文件似乎都包含一个标题，然后是一个空行和消息正文：</p><p>    So, I decided to build a Python parser, that went through all these files reading the header portion of each message and grouping all unique results together, giving me all the possible headers such as (From, Subject, Newsgroup, etc.). I found that there were about 79 x different types of headers. So it appeared that not all messages adhered to the same basic structure. Going through the headers, all had the standard set that was common across all posts.</p><p>因此，我决定构建一个Python解析器，它遍历所有这些文件，读取每条消息的头部分，并将所有唯一的结果组合在一起，给出所有可能的头信息，例如(From、Subject、Newsgroup等)。我发现大约有79种不同类型的标题。因此，似乎并不是所有的信息都遵循相同的基本结构。通过查看标题，所有帖子都采用了所有帖子通用的标准设置。</p><p> Once I had the common field, I’ve created a Postgres database called ‘utzoo’</p><p>一旦我有了公共字段，我就创建了一个名为‘utzoo’的Postgres数据库。</p><p>    The above database and schema were the pre-requisites. Everything else, like table creation, inserting the posts, etc. is part of the Python script and fully automated.</p><p>上述数据库和架构是先决条件。其他所有事情，如创建表、插入帖子等，都是Python脚本的一部分，并且是完全自动化的。</p><p> In terms of table creation, the script automatically creates 5 tables for each detected newsgroup:</p><p>在创建表方面，该脚本自动为每个检测到的新闻组创建5个表：</p><p>   create table all_messages. GroupName_headers( id bigserial not null constraint GroupName_headers_pk primary key, dateparsed timestamp, subj_id bigint, ref smallint, msg_id text, msg_from bigint, enc text, contype text, processed timestamp default CURRENT_TIMESTAMP);alter table all_messages.GroupName_headers owner to postgres;create table all_messages. GroupName_refs( id bigint, ref_msg text default null);alter table all_messages.GroupName_refs owner to postgres;create table all_messages. GroupName_body( id bigint primary key, data text default null);alter table all_messages.GroupName_body owner to postgres;create table all_messages. GroupName_from( id serial not null constraint GroupName_from_pk primary key, data text);alter table all_messages.GroupName_from owner to postgres;create table all_messages. GroupName_subjects( id serial not null constraint GroupName_subjects_pk primary key, subject text);alter table all_messages.GroupName_subjects owner to postgres;</p><p>创建表ALL_MESSAGES。GroupName_Headers(id bigSerial NOT NULL约束GroupName_Headers_pk主键，日期解析时间戳，subj_id bigint，ref mall int，msg_id text，msg_from bigint，enc text，contype text，Proceded Timestamp Default Current_Timestamp)；将表all_Messages.GroupName_Headers Owner更改为Postgres；创建表all_Messages。GroupName_refs(id bigint，ref_msg text Default NULL)；将表all_Messages.GroupName_refs Owner更改为Postgres；创建表all_Messages。GroupName_Body(id bigint主键，数据文本默认为NULL)；将表ALL_Messages.GroupName_Body Owner改为Postgres；创建表ALL_MESSAGES。GroupName_from(id序列非空约束GroupName_from_pk主键，数据文本)；将表ALL_Messages.GroupName_from Owner更改为Postgres；创建表ALL_MESSAGES。GroupName_Subjects(id序列非空约束GroupName_Subjects_PK主键，主题文本)；将表ALL_Messages.GroupName_Subjects Owner改为Postgres；</p><p> Those will be the tables where the Python parser will dump all the data and make sure posts are properly lined up between tables.</p><p>这些表将是Python解析器将转储所有数据的表，并确保表之间的POST排列正确。</p><p> The python script also creates indexes to make the inserting and later reading of the posts faster:</p><p>Python脚本还创建了索引，以便更快地插入和稍后阅读帖子：</p><p> create unique index GroupName_headers_uiidx on all_messages.GroupName_headers(id);create unique index GroupName_headers_umidx on all_messages.GroupName_headers(msg_id);create unique index GroupName_body_idx on all_messages.GroupName_body(id);; create unique index GroupName_from_idx on all_messages.GroupName_from(data);create unique index GroupName_subjects_idx on all_messages.GroupName_subjects(subject);</p><p>在all_Messages.GroupName_Headers(Id)上创建唯一索引GroupName_Headers_uiidx；在all_Messages.GroupName_Headers(Msg_Id)上创建唯一索引GroupName_Headers_umidx；在all_Messages.GroupName_Body(Id)上创建唯一索引GroupName_body_idx；在all_Messages.GroupName_from_idx上创建唯一索引GroupName_from_idx。</p><p>   The following screenshot explains how it’s all wired up. I didn’t do any hardcoded relationships, but you can change the script if you want that.</p><p>下面的屏幕截图解释了它是如何连接在一起的。我没有做任何硬编码的关系，但是如果你愿意，你可以改变脚本。</p><p>    The date is an integral part of each message and I had to do some data conversion massaging in Python to get the proper date, as dates were coming in a variety of formats. I’ve tried various libraries but dateutil.parser.parse standard date and time library for Python did the best job.</p><p>日期是每条消息不可或缺的一部分，我必须在Python中进行一些数据转换处理才能获得正确的日期，因为日期的格式多种多样。我尝试过各种库，但针对Python的dateutil.parser.parse标准日期和时间库做得最好。</p><p> However, I still needed to account for various labelling of data fields in the headers, so if data wasn’t found in the ‘date’ header, I had to look into other header parts such as ‘NNTP-Posting-Date’, ‘X-Article-Creation-Date’, ‘Posted’, or ‘Received’ fields.</p><p>然而，我仍然需要考虑标题中数据字段的各种标签，所以如果在“Date”标题中找不到数据，我就不得不查找其他标题部分，如“nntp-Posting-Date”、“X-文章-Creation-Date”、“Pasted”、“”或“Receive”字段。</p><p>   Well and then it was all about creating a Python parser, start the PostgreSQL, point it to an archive directory, and wait :)</p><p>然后创建一个Python解析器，启动PostgreSQL，将其指向存档目录，然后等待：)。</p><p> At the bottom of this article is the code of the Python solution. It’s about 1,000 lines, and it took altogether about 1 day to create and test it. The script is smart enough to keep the track of where it started, so if it needs to be interrupted, it’ll know where to continue from to get the job done.</p><p>本文的底部是Python解决方案的代码。它大约有1000行，总共花了大约1天的时间来创建和测试它。该脚本足够智能，可以跟踪它从哪里开始，因此如果需要中断，它将知道从哪里继续完成工作。</p><p>      The final solution artifact is called ‘ utzoo2postgres.py‘ , and it was tested on Python 3.8.</p><p>最终的解决方案构件名为‘utzoo2postgres.py’，并在Python3.8上进行了测试。</p><p>          Note: In case you need to stop the program and run it later, the script is smart to resume from the last spot it was processing.</p><p>注意：如果您需要停止程序并稍后运行它，脚本最好从它正在处理的最后一个位置继续运行。</p><p>   The script will process all Utzoo Archive messages in about 6 hours (depending on the speed of your machine).</p><p>该脚本将在大约6小时内处理所有Utzoo存档消息(取决于您机器的速度)。</p><p>   Here is a screenshot of the database after only a couple of minutes of conversion:</p><p>以下是仅转换几分钟后的数据库屏幕截图：</p><p>  As you can see, the conversion utility produces a database with 5 tables per group where messages are linked to each other through auto-created indexes.</p><p>如您所见，转换实用程序为每个组生成一个包含5个表的数据库，其中消息通过自动创建的索引相互链接。</p><p> Let’s say we want to look up all discussions in the  net.physics discussions; and sort them out by the number of replies.</p><p>比方说，我们想要在网上查找所有讨论。物理讨论；并根据回复的数量对它们进行排序。</p><p>   Now, we can look up a particular discussion by the ID. For example, we want the ID: 1648 from the screenshot above, the discussion with the subject: “ Question on FTL and quantum mechanics“. That’s not so hard either:</p><p>现在，我们可以通过ID来查找特定的讨论。例如，我们想要上面屏幕截图中的ID：1648，主题是“关于FTL和量子力学的问题”。这也不是很难：</p><p>    It’s nice to have a database full of posts, but it’s hardly usable that way. I needed something that would allow me to easily access these posts.</p><p>拥有一个满是帖子的数据库固然不错，但以这种方式很难使用。我需要一些能让我轻松访问这些帖子的东西。</p><p> So, once everything was done, I built a PHP script around this code and registered  https://usenetarchives.com to make all these archives available online, in an easy to read and search (forum-like) web site.</p><p>所以，当一切都完成后，我围绕这段代码构建了一个php脚本，并注册了https://usenetarchives.com，以便在一个易于阅读和搜索(类似论坛)的网站上提供所有这些档案。</p><p> The PHP code is not part of this article, but you can head over to   https://usenetarchives.com/groups.php?c=utzoo to see how it all works:</p><p>PHP代码不是本文的一部分，但是您可以转到https://usenetarchives.com/groups.php?c=utzoo查看它是如何工作的：</p><p>    So now that it’s all done, I have to say, it was a great journey.</p><p>所以现在一切都完成了，我不得不说，这是一次伟大的旅程。</p><p> For those who want to play with the code, you can grab it from  Github and adjust it to your liking. Please don’t judge the code, it’s not pretty, nor formatted or commented out (for the most part) as I wasn’t exactly planning to release it. I did so primarily for posterity reasons. But now that it’s out there you’re more than welcome to fork the repo, clean it up though and commit your changes, so others can benefit from your work too.</p><p>对于那些想要玩代码的人，你可以从Github那里拿到它，然后根据自己的喜好进行调整。请不要评判代码，它不美观，也不格式化或注释掉(在很大程度上)，因为我并不完全打算发布它。我这么做主要是出于子孙后代的原因。但是现在它已经发布了，我们非常欢迎您分叉repo，清理它并提交您的更改，这样其他人也可以从您的工作中受益。</p><p>  To conclude this article, this is the illustrated process of getting information from each of the files into the PostgreSQL database.</p><p>作为本文的总结，下面展示了从每个文件获取信息到PostgreSQL数据库的过程。</p><p>  7. The result: PostgreSQL fully searchable database of all lost Usenet posts Feb 1981 and June of 1991</p><p>7.结果：PostgreSQL完全可搜索到1981年2月和1991年6月丢失的所有Usenet帖子的数据库</p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://www.joe0.com/2020/10/07/converting-utzoo-wiseman-netnews-archive-to-postgresql-using-python-3-8/">https://www.joe0.com/2020/10/07/converting-utzoo-wiseman-netnews-archive-to-postgresql-using-python-3-8/</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/python/">#python</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/utzoo/">#utzoo</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/文件/">#文件</a></button></div></div><div class="shadow p-3 mb-5 bg-white rounded clearfix"><div class="container"><div class="row"><div class="col-sm"><div><a target="_blank" href="/story/1034012.html"><img src="http://img2.diglog.com/img/2020/11/thumb_a270829c58d97b90ea892ae979fa861b.jpg" class="img-fluid" onerror="this.style.display='none'"></a></div><div class="item_title"><a target="_blank" href="/story/1034012.html">重头开始的Python并发性(2015)[视频]</a></div><span class="my_story_list_date">2020-11-9 20:56</span></div><div class="col-sm"><div><a target="_blank" href="/story/1033930.html"><img src="http://img2.diglog.com/img/2020/11/thumb_3a1be40609f8294f8c760a1e36d336a5.png" class="img-fluid" onerror="this.style.display='none'"></a></div><div class="item_title"><a target="_blank" href="/story/1033930.html">避免Bash受挫-将Python用于Shell脚本</a></div><span class="my_story_list_date">2020-11-9 4:51</span></div><div class="col-sm"><div><a target="_blank" href="/story/1033316.html"><img src="http://img2.diglog.com/img/2020/11/thumb_21f8be35cef4397449ea9dd55e0aa657.jpg" class="img-fluid" onerror="this.style.display='none'"></a></div><div class="item_title"><a target="_blank" href="/story/1033316.html">Python取代Java成为第二大最受欢迎的编程语言</a></div><span class="my_story_list_date">2020-11-5 20:25</span></div><div class="col-sm"><div><a target="_blank" href="/story/1032893.html"><img src="http://img2.diglog.com/img/2020/11/thumb_64d2ec6863c7815afccdaaa0cf416c51.png" class="img-fluid" onerror="this.style.display='none'"></a></div><div class="item_title"><a target="_blank" href="/story/1032893.html">使用VizTracer可视化Python代码执行</a></div><span class="my_story_list_date">2020-11-3 10:14</span></div></div></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/美国/">#美国</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/谷歌/">#谷歌</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/linux/">#linux</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/程序/">#程序</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy; 2020 diglog.com </div></div></body></html>