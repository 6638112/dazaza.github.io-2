<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>取消删除被Mv覆盖的文件Undeleting a File Overwritten with Mv</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">Undeleting a File Overwritten with Mv<br/>取消删除被Mv覆盖的文件</h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2020-11-29 14:31:05</div><div class="page_narrow text-break page_content"><p>It’s been a while since we shared the story of an incident with you, and that’s probably a good thing –most operational incidents we had in the past year were “boring” enough in nature to fix them easily.This time, we’ve got a story of a data loss, caused by pure and simple human error – and the story ofhow we recovered the data.</p><p>自从我们与您分享一个事件的故事以来已经有一段时间了，这可能是一件好事–过去一年中，我们所遇到的大多数运营事件本质上都“无聊”到可以轻松修复。这一次，我们已经一个纯粹的人为错误导致的数据丢失的故事，以及我们如何恢复数据的故事。</p><p> Even though it is quite embarrassing how the data loss happened, we think it’s worth sharing the storyof its recovery, as it might allow you to learn a few useful things in case you ever end up in asimilar situation.</p><p> 尽管这很令人尴尬，但我们仍然值得分享恢复的故事，因为它可能使您学到一些有用的信息，以防万一您遇到类似的情况。</p><p> As you might have seen, over the last 7 months, we’ve extended our offerings beyond ticketing to allowour customers to transform their events into the digital space as long as the global pandemic makestraditional event formats impossible. The result of our effort is a joint venture called  Venueless that you should absolutely check out if you haven’t yet.</p><p> 如您所见，在过去的7个月中，我们已经将服务范围扩展到票务之外，只要全球大流行使传统活动的格式无法实现，我们的客户就可以将其活动转换为数字空间。我们努力的结果是建立了一家名为Venueless的合资企业，您应该绝对检查是否还没有。</p><p> One component of the virtual events we run on venueless is  live video streaming. In this process,our customers use a tool like  OBS or  StreamYardto create a live video stream. The stream is then sent to an  encoding server of ours via RTMP.On the encoding server, we re-encode the stream into different quality levels and then distributeit to our very own tiny streaming CDN.</p><p> 我们在无场所上运行的虚拟事件的一个组成部分是实时视频流。在此过程中，我们的客户使用OBS或StreamYard之类的工具来创建实时视频流。然后通过RTMP将流发送到我们的编码服务器。在编码服务器上，我们将流重新编码为不同的质量级别，然后将其分发到我们自己的小型流CDN。</p><p> Venueless currently does  not yet include a video-on-demand component and usually, our customers recordtheir content at the source, e.g. with OBS or StreamYard, and process or publish them on their own.However, just to be safe, we keep a recording of the incoming stream as well. This isn’t currentlypart of our promoted service offering, we rather see it as a free backup service to our clients in case theylose their recording. Given that we already consider it to just be a backup, we currently don’t make anyfurther backups of this data.</p><p> Venueless目前尚不包含视频点播组件，通常，我们的客户会在源头（例如使用OBS或StreamYard，并自行处理或发布。但是，为了安全起见，我们还会记录传入的流。目前，这不是我们促销服务的一部分，我们宁愿将其视为对客户的免费备份服务，以防客户录音。鉴于我们已经将其视为备份，因此我们目前不会对此数据进行任何进一步的备份。</p><p>  Usually, we delete these recordings after a while, but in some cases, our customers ask us to get them, e.g.because their own recording failed, or because StreamYard only records the first 8 hours of everystream. Since this doesn’t happen a lot, it’s not yet an automated process in our system. Whenever a customerrequests a recording, we SSH into the respective encoding server and move the recording file to adirectory that’s accessible through HTTP, like this:</p><p>  通常，我们会在一段时间后删除这些录像，但是在某些情况下，我们的客户会要求我们获取这些录像，例如，因为他们自己的录像失败，或者是因为StreamYard仅记录了每个流的前8个小时。由于这种情况很少发生，因此在我们的系统中还不是自动化的过程。每当客户请求录制文件时，我们都会通过SSH进入相应的编码服务器，并将录制文件移至可通过HTTP访问的目录，如下所示：</p><p>  That’s it, we share the link with the customer, and the process is done. One of the simplest steps possiblein all this. Yesterday, a customer asked us for the recordings of the two last streams of their event. Justbefore finishing up for the week, I wanted to supply them with the required file, SSH’d into the server,looked for the correct files and typed…</p><p>  就是这样，我们与客户共享链接，然后过程就完成了。这可能是最简单的步骤之一。昨天，一位客户要求我们提供他们活动的最后两个流的记录。就在本周结束之前，我想向他们提供所需的文件，并通过SSH进入服务器，寻找正确的文件并键入...</p><p>  Oops. I hit return before typing out  public/, and therefore replaced the last stream with thesecond-last, losing one of the videos.</p><p>哎呀。我在键入public /之前先按回车键，然后用倒数第二个替换了最后一个流，丢失了其中一个视频。</p><p>  Having a very naive understanding of how file systems work, I knew that the  mv command has onlychanged the directory listing of the file system, but hasn’t actually wiped the file from the disk,so I knew there is likely still a chance to recover the file, if it’s not overwritten by somethingelse in the meantime.</p><p>  我对文件系统的工作原理非常幼稚，因此我知道mv命令仅更改了文件系统的目录列表，但实际上并未从磁盘上擦除文件，因此我知道仍然有可能恢复文件，如果同时没有被其他文件覆盖。</p><p> Since I didn’t manage to re-mount the root partition as read-only to avoid further damage softly,I used the  big hammer to remounteverything read-only immediately:</p><p> 由于我没有设法将根分区重新安装为只读以避免软损坏，因此我用大铁锤立即将所有只读分区重新安装：</p><p>  Uhm, okay, this worked, but how do I install any data recovery tools now? After some experiments,I decided it would be easiest to reboot into the recovery system provided by our server provider Hetzner. So I configured the boot loader to boot their recovery systemfrom the network and forcefully rebooted the server.</p><p>  嗯，好的，这行得通，但是现在如何安装任何数据恢复工具？经过一些实验，我认为最简单的方法是重新启动由我们的服务器提供商Hetzner提供的恢复系统。因此，我将引导加载程序配置为从网络引导其恢复系统，并强制重新引导服务器。</p><p> To be able to perform disk dumps and have some operational flexibility without downloading a 2 TBdisk image to my local machine (which would take rougly a week), I also quickly purchaseda  Hetzner Storage Box with 5 TB space.</p><p> 为了能够执行磁盘转储并具有一些操作灵活性，而无需将2 TB磁盘映像下载到我的本地计算机上（这可能需要一周的时间），我还快速购买了一个5 TB空间的Hetzner存储盒。</p><p>  Just before I executed my fatal  mv command, I executed  ls -lisah to get a directory listingof the files:</p><p>  在执行致命的mv命令之前，我执行了ls -lisah以获取文件目录列表：</p><p> 3146449 1.1G -rw-r--r-- 1 www-data www-data 1.1G Nov XX XX:XX recording-16678.flv3146113 1.6G -rw-r--r-- 1 www-data www-data 1.6G Nov XX XX:XX recording-16679.flv</p><p> 3146449 1.1G -rw-r--r-- 1 www-data www-data 1.1G 11月XX月XX：XX记录16678.flv3146113 1.6G -rw-r--r-- 1 www-data www-data 1.6 G 11月XX月XX：XX记录16679.flv</p><p> This meant I  knew the inode number of the deleted file! As I mentioned before, my understandingof file systems was (and is) rather naive, and I was pretty optimistic to be able to recover thefile using that information. Isn’t that sort of what a journaling file system is for?</p><p>这意味着我知道已删除文件的索引节点号！如前所述，我对文件系统的理解是（而且现在）很幼稚，并且我非常乐观能够使用这些信息来恢复文件。这不是日记文件系统的用途吗？</p><p> Recovering the file this way hover appeared to be impossible.  ext4magicand  extundelete are powerful tools that did find some deleted files on my disk – but not the one I was looking for, even after trying different optionsfor over two hours.</p><p> 以这种方式恢复文件似乎是不可能的。 ext4magicand extundelete是功能强大的工具，即使在尝试了两个小时以上的其他选项后，它们也确实在磁盘上找到了一些已删除的文件，但不是我一直在寻找的文件。</p><p> I did not spend the time to really understand how ext4 works, but from I gathered from variousblogs, I was pretty much out of luck since the inode did no longer contain the relevant informationand ext4magic also wasn’t able to  recover the neccessary information from the journaleither.</p><p> 我没有花时间真正地了解ext4的工作原理，但是从我的各种博客中了解到，我的运气很差，因为inode不再包含相关信息，而ext4magic也无法从ext4中恢复必要的信息。日记。</p><p> debugfs: inode_dump &lt;3146113&gt;0000 a081 0000 8503 0000 e83a c15f e83a c15f .........:._.:._0020 e83a c15f 0000 0000 7200 0100 0800 0000 .:._....r.......0040 0000 0800 0100 0000 0af3 0100 0400 0000 ................0060 0000 0000 0000 0000 0100 0000 e6eb c000 ................0100 0000 0000 0000 0000 0000 0000 0000 0000 ................*0140 0000 0000 92d0 2cf5 0000 0000 0000 0000 ......,.........0160 0000 0000 0000 0000 0000 0000 6fb2 0000 ............o...0200 2000 e3fb 208a 515b 7c65 5d5a 7c65 5d5a ... .Q[|e]Z|e]Z0220 e83a c15f 7c65 5d5a 0000 0000 0000 0000 .:._|e]Z........0240 0000 0000 0000 0000 0000 0000 0000 0000 ................*</p><p> debugfs：inode_dump  0000 a081 0000 8503 0000 e83a c15f e83a c15f .........：._。：._ 0020 e83a c15f 0000 0000 7200 0100 0800 0000。：._.... r .. ..... 0040 0000 0800 0100 0000 0af3 0100 0400 0000 ................ 0060 0000 0000 0000 0000 0100 0000 e6eb c000 ...... ..... 0100 0000 0000 0000 0000 0000 0000 0000 0000 ................ * 0140 0000 0000 92d0 2cf5 0000 0000 0000 0000 ......，... ............ 0160 0000 0000 0000 0000 0000 0000 6fb2 0000 ............ o ... 0200 2000 e3fb 208a 515b 7c65 5d5a 7c65 5d5a ... .Q [| e] Z | e] Z0220 e83a c15f 7c65 5d5a 0000 0000 0000 0000。：._ | e] Z ........ 0240 0000 0000 0000 0000 0000 0000 0000 0000 ............. ... *</p><p> However, if you’re in a similar situation – the ext4magic how-tos are really helpful and worth a try.</p><p> 但是，如果您遇到类似情况，则ext4magic操作方法确实很有帮助，值得一试。</p><p>  There is this one other approach to file recovery that is often recommended on the internet, usuallyfor “small text files”: Just  grep your whole disk for known parts of its contents! So why wouldn’tthis work on larger non-text files as well?</p><p>  互联网上通常建议使用另一种文件恢复方法，通常用于“小文本文件”：只需将整个磁盘复制到其中的已知部分即可！那么，为什么这也不适用于较大的非文本文件呢？</p><p> The first problem is obviously what to grep for. The only thing I know about the missing file, apartfrom its rough size, is that it’s a FLV video file. Luckily,  all FLV filesthat contain video start with the byte sequence  FLV\x01\x05. So let’s search our 2 TB disk forthat byte sequence and print out the byte offset of all occurences!</p><p> 第一个问题显然是grep的目的。除了丢失的文件大小，我对丢失的文件唯一了解的是它是FLV视频文件。幸运的是，所有包含视频的FLV文件都以字节序列FLV \ x01 \ x05开始。因此，让我们在2 TB磁盘中搜索该字节序列，并打印出所有出现的字节偏移！</p><p> cat /dev/md2 \	| pv -s 1888127576000 \	| grep -P --byte-offset --text &#39;FLV\x01\x05&#39; \	| tee -a /mnt/storagebox/grep-log.txt</p><p>猫/ dev / md2 pv -s 1888127576000 \ | grep -P --byte-offset --text'FLV \ x01 \ x05' tee -a /mnt/storagebox/grep-log.txt</p><p> This took roughly 7 hours. The  pv command with the (rough) total size of the disk is optional, but gives youa nice progress bar. Overall, this took a little over 6 hours on our server.</p><p> 这大约花费了7个小时。带有（大约）磁盘总大小的pv命令是可选的，但它为您提供了一个不错的进度条。总体而言，这在我们的服务器上花费了6个多小时。</p><p> grep works line-based, which in a binary file menas “any byte sequence between two ASCII line breaks”. Thelog file therefore contained lots of lines like this:</p><p> grep基于行工作，在二进制文件中表示“两个ASCII换行符之间的任何字节序列”。因此，日志文件包含许多这样的行：</p><p>  In total, the search found 126 FLV file headers on our disk. This was pretty reassuring, since we had 122 FLV filesstill known to the file system – so there are at least four FLV byte sequences without a filename!</p><p>  搜索总共在我们的磁盘上找到126个FLV文件头。令人放心的是，由于文件系统仍然知道122个FLV文件，因此至少有四个没有文件名的FLV字节序列！</p><p>  Now, I needed to find out which of the 126 byte sequences did not have a filename. Since I really didn’t wantto spend all weekend with a deep-dive into the ext4 disk layout, I went for an easier solution: For every filestill known in the file system, I computed a hash of the first 500 kilobytes of the file:</p><p>  现在，我需要找出126个字节序列中的哪个没有文件名。由于我真的不想花整个周末来深入研究ext4磁盘布局，因此我寻求了一个更简单的解决方案：对于文件系统中仍然已知的每个文件，我都会计算文件前500 KB的哈希值：</p><p> #!/usr/bin/python3 import  glob import  hashlib import  os hashsize  =  500  *  1024 known_hashes  =  {} not_deleted_files  =  sorted (  glob . glob ( &#39;/mnt/disk/var/recordings/*.flv&#39; )  +  glob . glob ( &#39;/mnt/disk/var/recordings/public/*.flv&#39; ) ) # Ignore files shorter than our hash size not_deleted_files  =  [  f  for  f  in  not_deleted_files  if  os . stat ( f ). st_size  &gt;  hashsize ] for  fname  in  not_deleted_files :  with  open ( fname ,  &#39;rb&#39; )  as  f :  h  =  hashlib . md5 ( f . read ( hashsize )). hexdigest ()  if  h  in  known_hashes :  print ( &#34;duplicate hash found:&#34; )  known_hashes [ h ]  =  fname  print ( h ,  fname ) print (  len ( not_deleted_files ),  &#34;files with&#34; ,  len ( known_hashes ),  &#34;hashes&#34; )</p><p> ＃！/ usr / bin / python3 import glob import hashlib import os hashsize = 500 * 1024known_hashes = {} not_deleted_files = sorted（glob。glob（'/mnt/disk/var/recordings/*.flv'）+ glob。glob （'/mnt/disk/var/recordings/public/*.flv'））＃忽略小于我们的哈希值的文件not_deleted_files = [如果在os中，则not_deleted_files中的f为f。统计（f）。 not_deleted_files中fname的st_size> hashsize]：打开（fname，'rb'）为f：h = hashlib。 md5（f。read（hashsize））。 hexdigest（）如果h在known_hashes中：print（“发现重复的哈希值：”）known_hashes [h] = fname print（h，fname）print（len（not_deleted_files），“带有”的文件，len（known_hashes），“哈希”）</p><p> Interestingly, two files from the completely different customers shared the same hash of the first 500 kilobytes.I haven’t tested it yet, but my theory is that those were streams that just did not contain any audio or videoin their first minutes, but only empty frames. However, since I knew this isn’t the case for my missing file,I felt confident in proceeding with this approach.</p><p> 有趣的是，来自完全不同的客户的两个文件共享前500 KB的相同哈希值，但我尚未对其进行测试，但我的理论是，这些文件流在刚开始的第一分钟内不包含任何音频或视频，而仅空框架。但是，由于我知道丢失的文件并非如此，因此我对继续使用此方法充满信心。</p><p> Next, I computed the same hash for every byte offest found by grep and compared it to the hashes found in theprevious step:</p><p>接下来，我为grep找到的每个字节计算了相同的哈希值，并将其与上一步中找到的哈希值进行了比较：</p><p> grep_log  =  &#39;/mnt/storagebox/grep-log.txt&#39; disk  =  &#39;/dev/md2&#39; print ( &#34;Parsing grep log…&#34; ) positions  =  [] with  open ( grep_log ,  &#39;rb&#39; )  as  f :  for  line  in  f . read (). split ( b&#39; \n &#39; ):  if  not  line :  # ignore empty line e.g. at end of file  continue  pos ,  data  =  line . split ( b&#39;:&#39; ,  1 )  pos  =  int ( pos . decode ())  # add offset of FLV within line  binoffset  =  data . index ( b&#34;FLV \x01 &#34; )  pos  +=  binoffset  positions . append ( pos ) print ( &#34;Computing hashes of files on disk…&#34; ) found_hashes  =  {} with  open ( disk ,  &#39;rb&#39; )  as  f :  for  p  in  positions :  f . seek ( p )  d  =  f . read ( hashsize )  h  =  hashlib . md5 ( d ). hexdigest ()  if  h  in  known_hashes :  print ( &#34;At offset&#34; ,  p ,  &#34;found known hash&#34; ,  h ,  &#34;corresponding to&#34; ,  known_hashes [ h ])  else :  print ( &#34;At offset&#34; ,  p ,  &#34;found unknown hash&#34; ,  h )  found_hashes [ h ]  =  p unknown_hashes  =  {  h :  p  for  h ,  p  in  found_hashes . items ()  if  h  not  in  known_hashes } files_not_found  =  [  fname  for  h ,  fname  in  known_hashes . items ()  if  h  not  in  found_hashes ] print ( len ( found_hashes ),  &#34;found hashes,&#34; ,  len ( unknown_hashes ),  &#34;of them unknown&#34; ) print ( len ( files_not_found ),  &#34;files not found:&#34; ,  files_not_found )</p><p> grep_log ='/mnt/storagebox/grep-log.txt'磁盘='/ dev / md2'打印（“ parsing grep log…”）position = []打开（grep_log，'rb'）为f：用于输入行F 。阅读（）。 split（b'\ n'）：如果不是line：＃忽略空行，例如在文件末尾继续pos，数据=行。 split（b'：'，1）pos = int（pos.decode（））＃在行binoffset = data中添加FLV的偏移量。索引（b“ FLV \ x01”）pos + = binoffset位置。 append（pos）print（“正在计算磁盘上的文件哈希...”）found_hashes = {}，其中open（disk，'rb'）为f：对于位置f中的p。求（p）d = f。读取（hashsize）h = hashlib。 md5（d）。 hexdigest（）如果h在known_hashes中：print（“ At offset”，p，“找到已知哈希”，h，“对应”，known_hashes [h]）else：print（“ At offset”，p，“发现未知哈希“，h）found_hashes [h] = p unknown_hashes = {h：p代表h，p在found_hashhes中。 items（）如果h在known_hashes中不}} files_not_found = [f代表h，fname则在known_hashes中。 items（）如果h不在found_hashes中，请打印（len（found_hashes），“ found散列”，len（unknown_hashes，“其中未知”））print（len（files_not_found），“找不到文件：”，files_not_found</p><p> This produced 5 byte offsets with a checksum – exactly what I expected. Four that really did not correspond to a file, one corresponding to a file smaller than 500 kilobytes and thereforewith a different hash.</p><p> 这产生了带有校验和的5字节偏移量-正是我所期望的。四个确实不对应于文件的文件，一个对应于小于500 KB的文件，因此具有不同的哈希。</p><p> Now, all that was left to do was writing out the byte sequences of (at least) 1.6 GB startingat the five possible byte offsets. Just to be safe, I exported 1.8 GB of each:</p><p> 现在，剩下要做的就是从五个可能的字节偏移量开始写出（至少）1.6 GB的字节序列。为了安全起见，我分别导出了1.8 GB：</p><p> from  math  import  floor from  tqdm  import  tqdm from  tqdm.auto  import  trange size_missing_file  =  1.8  *  1024  *  1024  *  1024 print ( &#34;Exporting files with unknown hashes:&#34; ) for  h ,  p  in  tqdm ( unknown_hashes . items ()):  with  open ( disk ,  &#39;rb&#39; )  as  fr :  fr . seek ( p )  with  open ( f&#39;out_ { h } .flv&#39; ,  &#39;wb&#39; )  as  fw :  for  i  in  trange ( floor ( size_missing_file  //  1024 )):  fw . write ( fr . read ( 1024 ))</p><p> 从数学导入层从tqdm从tqdm.auto导入tqdm （disk，'rb'）as fr：fr。在open（f'out_ {h ..flv'，'wb'）中以fw查找（p）作为fw：对于trange中的i（floor（size_missing_file // 1024））：fw。写（读（1024））</p><p>  I then downloaded the five files, and indeed, the one with the highest position on disk containedthe video file I accidentally deleted. Except some very minor corruption of less than a secondsomewhere in the video, the video was fully recovered. Phew.</p><p>  然后，我下载了五个文件，实际上，磁盘上位置最高的那个文件包含我不小心删除的视频文件。除了视频中不到一秒的轻微损坏之外，视频已完全恢复。 ew</p><p> In the long term, we’ll of course work on preventing this from possibly happening again. Leavingvery specific solutions like  alias mv=&#39;mv -i&#39; aside, we’ll obviously re-evaluate whether we needto create separate backups of this data if our customers begin to rely on it more than we intended to,and looking at possible video-on-demand features coming to Venueless, we’ll at some point createa fully automated video processing pipeline that removes the manual and error-prone steps from thisprocess.</p><p> 从长远来看，我们当然会努力防止这种情况再次发生。除了别名mv ='mv -i'之外，还有很多特定的解决方案，如果客户开始比我们预期更多地依赖它，我们显然会重新评估是否需要为此数据创建单独的备份，并查看可能的视频-随着Venueless的点播功能的到来，我们将在某个时候创建​​一个全自动的视频处理管道，从而从该过程中删除手动和易于出错的步骤。</p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://behind.pretix.eu/2020/11/28/undelete-flv-file/">https://behind.pretix.eu/2020/11/28/undelete-flv-file/</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/删除/">#删除</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/file/">#file</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/文件/">#文件</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/分享/">#分享</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy; 2020 diglog.com </div></div></body></html>