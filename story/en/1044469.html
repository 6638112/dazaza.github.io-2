<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>计算表明不可能控制超智能AI Calculations Show It'll Be Impossible To Control a Super-Intelligent AI</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">Calculations Show It'll Be Impossible To Control a Super-Intelligent AI<br/>计算表明不可能控制超智能AI </h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2021-01-16 07:26:21</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2021/1/ce48826f57808d3433d9b19e6db8fcc6.jpg"><img src="http://img2.diglog.com/img/2021/1/ce48826f57808d3433d9b19e6db8fcc6.jpg" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>The idea of  artificial intelligence overthrowing humankind has been talked about for  many decades, and scientists have just delivered their verdict on whether we&#39;d be able to control a high-level computer super-intelligence. The answer? Almost definitely not.</p><p>人工智能推翻人类的想法已经讨论了几十年了，科学家们刚刚就我们是否能够控制高级计算机超级智能做出了判断。答案？几乎肯定不是。</p><p>   The catch is that controlling a super-intelligence far beyond human comprehension would require a simulation of that super-intelligence which we can analyse. But if we&#39;re unable to comprehend it, it&#39;s impossible to create such a simulation.</p><p>   要注意的是，要控制一个超出人类理解能力的超级智能，就需要对这种超级智能进行模拟，我们可以对其进行分析。但是，如果我们无法理解它，就不可能创建这样的模拟。</p><p> Rules such as &#39;cause no harm to humans&#39; can&#39;t be set if we don&#39;t understand the kind of scenarios that an AI is going to come up with, suggest the authors of the new paper. Once a computer system is working on a level above the scope of our programmers, we can no longer set limits.</p><p> 诸如此类的规则不会对人类造成伤害新论文的作者建议，如果我们不了解人工智能将要提出的那种情况，就无法设置。一旦计算机系统的工作水平超出了程序员的范围，我们将无法再设置限制。</p><p> &#34;A super-intelligence poses a fundamentally different problem than those typically studied under the banner of &#39;robot ethics&#39;,&#34;  write the researchers.</p><p> ＆＃34;超级智能提出的问题与通常以“机器人伦理”，“＃34;写研究人员。</p><p> &#34;This is because a superintelligence is multi-faceted, and therefore potentially capable of mobilising a diversity of resources in order to achieve objectives that are potentially incomprehensible to humans, let alone controllable.&#34;</p><p> ＆＃34;因为超级智能是多方面的，因此潜在地有能力动员多种资源来实现人类可能无法理解的目标，更不用说可控了。</p><p> Part of the team&#39;s reasoning comes from the  halting problem put forward by Alan Turing in 1936. The problem centres on knowing whether or not a computer program will reach a conclusion and answer (so it halts), or simply loop forever trying to find one.</p><p> 团队的部分推理来自于艾伦·图灵（Alan Turing）在1936年提出的暂停问题。问题的中心在于知道计算机程序是否会得出结论并回答（因此会暂停），或者只是循环循环进行永久尝试找一个。</p><p>   As Turing proved through some  smart math, while we can know that for some specific programs, it&#39;s logically impossible to find a way that will allow us to know that for every potential program that could ever be written. That brings us back to AI, which in a super-intelligent state could feasibly hold every possible computer program in its memory at once.</p><p>   正如Turing通过一些聪明的数学证明的那样，虽然我们可以知道对于某些特定程序，但从逻辑上讲，不可能找到一种方法让我们知道每个可能编写的程序。这使我们回到了AI领域，在超级智能状态下，它可以一次将所有可能的计算机程序保存在其内存中。 </p><p> Any program written to stop AI harming humans and destroying the world, for example, may reach a conclusion (and halt) or not – it&#39;s mathematically impossible for us to be absolutely sure either way, which means it&#39;s not containable.</p><p>例如，为阻止AI伤害人类并破坏世界而编写的任何程序都可能会得出结论（或停止）-从数学上讲，我们绝对无法确定哪种方法，这意味着它确实是对的。无法遏制。</p><p> &#34;In effect, this makes the containment algorithm unusable,&#34;  says computer scientist Iyad Rahwan, from the Max-Planck Institute for Human Development in Germany.</p><p> ＆＃34;实际上，这使包含算法无法使用，＆＃34;德国马克斯-普朗克人类发展研究所的计算机科学家Iyad Rahwan说。</p><p> The alternative to teaching AI some ethics and telling it not to destroy the world – something which no algorithm can be absolutely certain of doing, the researchers say – is to limit the capabilities of the super-intelligence. It could be cut off from parts of the internet or from certain networks, for example.</p><p> 研究人员说，向AI讲道德并告诉其不要破坏世界的另一种方法是限制超级智能的能力，这是算法绝对不能确定的。例如，它可以与部分互联网或某些网络隔离。</p><p> The new study rejects this idea too, suggesting that it would limit the reach of the  artificial intelligence – the argument goes that if we&#39;re not going to use it to solve problems beyond the scope of humans, then why create it at all?</p><p> 这项新研究也拒绝了这个想法，暗示它将限制人工智能的应用范围。论点是，如果我们不打算使用人工智能来解决人类无法解决的问题，那为什么还要创造它呢？ ？</p><p> If we are going to push ahead with artificial intelligence, we might not even know when a super-intelligence beyond our control arrives, such is its incomprehensibility. That means we need to start asking some  serious questions about the directions we&#39;re going in.</p><p> 如果我们要推进人工智能，我们甚至可能不知道何时会出现我们无法控制的超级智能，这就是它的不可理解性。这意味着我们需要开始对我们前进的方向提出一些严肃的问题。</p><p> &#34;A super-intelligent machine that controls the world sounds like science fiction,&#34;  says computer scientist Manuel Cebrian, from the Max-Planck Institute for Human Development. &#34;But there are already machines that perform certain important tasks independently without programmers fully understanding how they learned it.&#34;</p><p> ＆＃34;控制世界的超级智能机器听起来像科幻小说，＆＃34; Max-Planck人类发展研究所的计算机科学家Manuel Cebrian说。 ＆＃34;但是已经有机器能够独立执行某些重要任务，而程序员却没有完全了解他们的学习方式。</p><p> &#34;The question therefore arises whether this could at some point become uncontrollable and dangerous for humanity.&#34;</p><p> ＆＃34;因此，出现了一个问题，在某些时候这是否可能变得不可控制并且对人类构成危险。 </p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://www.sciencealert.com/calculations-show-it-d-be-impossible-to-control-a-rogue-super-smart-ai">https://www.sciencealert.com/calculations-show-it-d-be-impossible-to-control-a-rogue-super-smart-ai</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/控制/">#控制</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/show/">#show</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/人类/">#人类</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/分享/">#分享</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy; 2020 diglog.com </div></div></body></html>