<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Nvidia研究人员创建了一种增强方法来训练生成对抗性网络，他们说可以将结果减少10到20倍的数据 Nvidia researchers have created an augmentation method for training generative adversarial networks that they say enables results with 10 to 20 times less data</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">Nvidia researchers have created an augmentation method for training generative adversarial networks that they say enables results with 10 to 20 times less data<br/>Nvidia研究人员创建了一种增强方法来训练生成对抗性网络，他们说可以将结果减少10到20倍的数据 </h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2020-12-08 19:02:09</div><div class="page_narrow text-break page_content"><p>Nvidia researchers have created an augmentation method for training generative adversarial networks ( GANs) that requires less data. Nvidia has made GANs for creating  works of art like landscape paintings and recently one for  video conferencing. (A GAN is a form of AI that pits a generator network against a discriminator network to create images or videos.) Training GANs can require upwards of 100,000 images, but an approach called adaptive discriminator augmentation (ADA) detailed in the paper “Training Generative Adversarial Networks with Limited Data,” enables results with 10 to 20 times less data.</p><p>Nvidia研究人员已经创建了一种增强方法，用于训练需要较少数据的生成对抗网络（GAN）。 Nvidia制作了GAN，用于创作山水画之类的艺术品，最近又制作了用于视频会议的GAN。 （GAN是AI的一种形式，它使生成器网络与鉴别器网络对接以创建图像或视频。）训练GAN可能需要多达100,000张图像，但在论文“训练生成器”中详细介绍了一种称为自适应鉴别器增强（ADA）的方法数据有限的对抗性网络”，结果数据量减少10到20倍。</p><p> “The key problem with small datasets is that the discriminator overfits to the training examples; its feedback to the generator becomes meaningless and training starts to diverge,”  the paper reads. “We demonstrate, on several datasets, that good results are now possible using only a few thousand images, often matching StyleGAN2 results with an order of magnitude fewer images.”</p><p> “使用小型数据集的关键问题在于，判别器过度适合训练示例；它对发电机的反馈变得毫无意义，培训开始出现分歧。 “我们证明，在几个数据集上，仅使用几千个图像就可以实现良好的结果，并且通常将StyleGAN2结果与数量少的图像相匹配。”</p><p>  Earlier this year, researchers from Adobe Research, MIT, and Tsinghua University  detailed DiffAugment, another approach to augmentation for GANs.</p><p>  今年早些时候，来自Adobe Research，麻省理工学院和清华大学的研究人员详细介绍了DiffAugment，这是GAN增强的另一种方法。</p><p> Nvidia VP of graphics research David Luebke told VentureBeat that anybody who has done pragmatic data science in the wild knows the vast majority of time is spent collecting and curating data. This is sometimes referred to as the ETL pipeline: to extract, transform, and load.</p><p> Nvidia图形研究副总裁David Luebke告诉VentureBeat，任何在野外进行过实用数据科学的人都知道，绝大多数时间都花在了收集和整理数据上。有时将其称为ETL管道：提取，转换和加载。</p><p> “That alone takes a huge chunk of pragmatic boots-on-the-ground data science, and we think this [approach] is super helpful because you don’t need nearly as much of that [data] to get useful results,” he said.</p><p> 他说：“仅这一项就需要大量实用的地面数据科学，我们认为这种方法非常有用，因为您不需要那么多的数据就可以得到有用的结果。”说过。</p><p> This can be even more important when working with annotators who have little time to spare, he said.</p><p> 他说，当与没有时间的注释者一起工作时，这一点甚至更为重要。</p><p> Authors of the paper believe reducing data constraints can empower researchers to inspect new use cases for GANs. Beyond creating fake photos of people or animals, researchers believe GANs may have applications in medical imaging data.</p><p> 该论文的作者认为，减少数据约束可以使研究人员能够检查GAN的新用例。除了创建人或动物的伪造照片外，研究人员还认为GAN可能会在医学成像数据中得到应用。 </p><p> “If you have a radiologist who specializes in a particular condition … to have him or her sit down and label 50,000 images for you probably isn’t going to happen … but to have them label 1,000 images seems quite possible. It really changes the amount of effort that a practical data scientist needs to put into curation of the data, and as a result it makes it a lot easier to do exploration,” Luebke said.</p><p>“如果您有一名放射科医生专门研究特定的疾病……让他或她坐下来为您贴上50,000张图像可能不会发生……但是让他们贴上1,000张图像似乎很有可能。这确实改变了实际的数据科学家在整理数据时需要付出的努力，结果使进行探索变得容易得多。” Luebke说。</p><p> A  paper detailing the approach was published this week as part of the NeurIPS conference for neural information processing networks, the largest annual AI research conference in the world.</p><p> 本周，作为神经信息处理网络的NeurIPS会议的一部分，发表了一篇详细介绍该方法的论文，这是世界上最大的年度AI研究会议。</p><p> “Training Generative Adversarial Networks with Limited Data” wasn’t the only GAN-related paper.  Another research paper introduces Discriminator Driven Latent Sampling (DDLS), which achieves improved performance for off-the-shelf GANs when assessed using the CIFAR-10 dataset. That paper was written by MILA Quebec Artificial Intelligence Institute and Google Brain researchers, including Yoshua Bengio and Hugo Larochelle, leader of the Google Brain group in Montreal and general chair of the NeurIPS conference.</p><p> 并非仅有的与GAN相关的论文“用有限的数据训练生成对抗网络”。另一篇研究论文介绍了鉴别器驱动的潜在采样（DDLS），当使用CIFAR-10数据集进行评估时，它可以提高现成GAN的性能。该论文是由MILA魁北克人工智能研究所和Google Brain研究人员撰写的，其中包括蒙特利尔Google Brain小组组长兼NeurIPS会议主席Yoshua Bengio和Hugo Larochelle。 </p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/nvidia/">#nvidia</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/研究/">#研究</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/数据/">#数据</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/分享/">#分享</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy; 2020 diglog.com </div></div></body></html>