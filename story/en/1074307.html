<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>静态B-树：一种用于快速二进制搜索的数据结构Static B-Trees: A data structure for faster binary search</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">Static B-Trees: A data structure for faster binary search<br/>静态B-树：一种用于快速二进制搜索的数据结构</h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2022-02-20 22:23:57</div><div class="page_narrow text-break page_content"><p>This article is a follow-up to the  previous one, where we optimized binary search by the means of removing branching and improving the memory layout. Here, we will also be searching over sorted arrays, but this time we are not limited to fetching and comparing only one element at a time.</p><p>本文是前一篇文章的后续，我们通过删除分支和改进内存布局来优化二进制搜索。在这里，我们还将搜索已排序的数组，但这次我们不仅限于一次只获取和比较一个元素。</p><p> In this article, we generalize the techniques we developed for binary search to  static B-trees and accelerate them further using  SIMD instructions. In particular, we develop two new implicit data structures:</p><p>在本文中，我们将我们开发的二进制搜索技术推广到静态B树，并使用SIMD指令进一步加速它们。特别是，我们开发了两种新的隐式数据结构：</p><p> The  first is based on the memory layout of a B-tree, and, depending on the array size, it is up to 8x faster than  std::lower_bound while using the same space as the array and only requiring a permutation of its elements.</p><p>第一种是基于B树的内存布局，根据阵列大小，它比std:：lower_bound快8倍，同时使用与阵列相同的空间，只需要对其元素进行排列。</p><p> The  second is based on the memory layout of a B+ tree, and it is up to 15x faster than  std::lower_bound while using just 6-7% more memory — or 6-7%  of the memory if we can keep the original sorted array.</p><p>第二种是基于B+树的内存布局，它比std:：lower_bound快15倍，同时只使用了6-7%的内存，或者如果我们可以保留原始排序数组，则使用6-7%的内存。</p><p> To distinguish them from B-trees — the structures with pointers, hundreds to thousands of keys per node, and empty spaces in them — we will use the names  S-tree and  S+ tree respectively to refer to these particular memory layouts  1.</p><p>为了将它们与B-树区分开来，B-树的结构中有指针，每个节点上有数百到数千个键，其中有空格，我们将分别使用S-树和S+树的名称来表示这些特定的内存布局1。</p><p> To the best of my knowledge, this is a significant improvement over the existing  approaches. As before, we are using Clang 10 targeting a Zen 2 CPU, but the performance improvements should approximately transfer to most other platforms, including Arm-based chips. Use  this single-source benchmark of the final implementation if you want to test it on your machine.</p><p>据我所知，这是对现有方法的重大改进。与之前一样，我们使用的是针对Zen 2 CPU的Clang 10，但性能改进应该大致转移到大多数其他平台，包括基于Arm的芯片。如果您想在您的机器上测试它，请使用最终实现的这个单一源基准测试。</p><p> This is a long article, and since it also serves as a  textbook case study, we will improve the algorithm incrementally for pedagogical goals. If you are already an expert and feel comfortable reading  intrinsic-heavy code with little to no context, you can jump straight to the  final implementation.</p><p>这是一篇很长的文章，因为它也是教科书上的案例研究，我们将为教学目标逐步改进算法。如果您已经是一名专家，并且在几乎没有或几乎没有上下文的情况下轻松地阅读内在的繁重代码，那么您可以直接跳到最终实现。</p><p>   B-trees generalize the concept of binary search trees by allowing nodes to have more than two children. Instead of a single key, a node of a B-tree of order $k$ can contain up to $B = (k - 1)$ keys that are stored in sorted order and up to $k$ pointers to child nodes, each satisfying the property that all keys in the subtrees of the first $i$ children are not greater than the $i$-th key in the parent node.</p><p>B-树通过允许节点有两个以上的子节点，推广了二叉搜索树的概念。顺序为$k$的B-树的节点可以包含最多按排序顺序存储的$B=（k-1）$键，以及最多指向子节点的$k$指针，每个节点都满足以下属性：第一个$i$子节点的子树中的所有键不大于父节点中的$i$-th键。</p><p>  The main advantage of this approach is that it reduces the tree height by $\frac{\log_2 n}{\log_k n} = \frac{\log k}{\log 2} = \log_2 k$ times while fetching each node still takes roughly the same time — as long it fits into a single  memory block.</p><p>这种方法的主要优点是，它将树的高度减少了$\frac{\log_2 n}{\log_k n}=\frac{\log k}{\log 2}=\log_2 k$次，而获取每个节点所需的时间仍然大致相同——只要它适合单个内存块。</p><p> B-trees were primarily developed for the purpose of managing on-disk databases, where the latency of randomly fetching a single byte is comparable with the time it takes to read the next 1MB of data sequentially. For our use case, we will be using the block size of $B = 16$ elements — or $64$ bytes, the size of the cache line — which makes the tree height and the total number of cache line fetches per query $\log_2 17 \approx 4$ times smaller compared to the binary search.</p><p>B树主要是为了管理磁盘数据库而开发的，在磁盘数据库中，随机获取单个字节的延迟与顺序读取下一个1MB数据所需的时间相当。在我们的用例中，我们将使用块大小$B=16$元素，或$64$字节，即缓存线的大小，这使得树的高度和每个查询的缓存线获取总数$\log_2 17\大约比二进制搜索小4$。</p><p>   Storing and fetching pointers in a B-tree node wastes precious cache space and decreases performance, but they are essential for changing the tree structure on inserts and deletions. But when there are no updates and the structure of a tree is  static, we can get rid of the pointers, which makes the structure  implicit.</p><p>在B树节点中存储和获取指针会浪费宝贵的缓存空间并降低性能，但它们对于在插入和删除时更改树结构至关重要。但是，当没有更新且树的结构是静态的时，我们可以去掉指针，这使得结构是隐式的。</p><p> One of the ways to achieve this is by generalizing the  Eytzinger numeration to $(B + 1)$-ary trees:</p><p>实现这一点的方法之一是将Eytzinger计数推广到$（B+1）$元树：</p><p> Node $k$ has $(B + 1)$ child nodes numbered $\{k \cdot (B+1) + i + 1\}$ for $i \in [0, B]$.</p><p>节点$k$有$（B+1）$子节点，编号为$\{k\cdot（B+1）+i+1\}$，用于[0，B]$中的$i\。</p><p> This way, we can only use $O(1)$ additional memory by allocating one large two-dimensional array of keys and relying on index arithmetic to locate children nodes in the tree:</p><p>这样，通过分配一个大的二维键数组并依靠索引算法在树中定位子节点，我们只能使用$O（1）$额外内存：</p><p> const  int  B  =  16 ; int  nblocks  =  ( n  +  B  -  1 )  /  B ; int  btree [ nblocks ][ B ]; int  go ( int  k ,  int  i )  {  return  k  *  ( B  +  1 )  +  i  +  1 ;  }</p><p>常数int B=16；int nblocks=（n+B-1）/B；int btree[nblocks][B]；int go（int k，int i）{return k*（B+1）+i+1；}</p><p> This numeration automatically makes the B-tree complete or almost complete with the height of $\Theta(\log_{B + 1} n)$. If the length of the initial array is not a multiple of $B$, the last block is padded with the largest value of its data type.</p><p>这种计算会自动使B树以$\Theta（\log_{B+1}n）$的高度完成或几乎完成。如果初始数组的长度不是$B$的倍数，则最后一个块用其数据类型的最大值填充。</p><p>   We can construct the B-tree similar to how we constructed the Eytzinger array — by traversing the search tree:</p><p>我们可以像构造Eytzinger数组一样构造B树——通过遍历搜索树：</p><p> void  build ( int  k  =  0 )  {  static  int  t  =  0 ;  if  ( k  &lt;  nblocks )  {  for  ( int  i  =  0 ;  i  &lt;  B ;  i ++ )  {  build ( go ( k ,  i ));  btree [ k ][ i ]  =  ( t  &lt;  n  ?  a [ t ++ ]  :  INT_MAX );  }  build ( go ( k ,  B ));  } }</p><p>无效构建（intk=0）{static intt=0；if（k&lt；nblocks）{for（inti=0；i&lt；B；i++）{build（go（k，i））；btree[k][i]=（t&lt；n？a[t++]：int_MAX）}构建（go（k，B））；}</p><p> It is correct because each value of the initial array will be copied to a unique position in the resulting array, and the tree height is $\Theta(\log_{B+1} n)$ because $k$ is multiplied by $(B + 1)$ each time we descend into a child node.</p><p>这是正确的，因为初始数组的每个值都将被复制到结果数组中的唯一位置，树的高度是$\Theta（\log_{B+1}n）$，因为每次我们下降到子节点时，$k$乘以$（B+1）$。</p><p> Note that this numeration causes a slight imbalance: left-er children may have larger subtrees, although this is only true for $O(\log_{B+1} n)$ parent nodes.</p><p>请注意，这种计算会导致轻微的不平衡：左er子节点可能有更大的子树，尽管这仅适用于$O（\log_{B+1}n）$父节点。</p><p>   To find the lower bound, we need to fetch the $B$ keys in a node, find the first key $a_i$ not less than $x$, descend to the $i$-th child — and continue until we reach a leaf node. There is some variability in how to find that first key. For example, we could do a tiny internal binary search that makes $O(\log B)$ iterations, or maybe just compare each key sequentially in $O(B)$ time until we find the local lower bound, hopefully exiting from the loop a bit early.</p><p>为了找到下限，我们需要在一个节点中获取$B$键，找到第一个不小于$x$的$a_i$，下降到第$i$子节点，然后继续，直到到达一个叶节点。在如何找到第一把钥匙方面存在一些差异。例如，我们可以进行一个小型的内部二进制搜索，进行$O（\log B）$迭代，或者只需在$O（B）$时间内按顺序比较每个键，直到找到局部下限，希望尽早退出循环。</p><p> But we are not going to do that — because we can use  SIMD. It doesn’t work well with branching, so essentially what we want to do is to compare against all $B$ elements regardless, compute a bitmask out of these comparisons, and then use the  ffs instruction to find the bit corresponding to the first non-lesser element:</p><p>但我们不会这么做，因为我们可以使用SIMD。它不能很好地用于分支，因此我们要做的基本上是与所有$B$元素进行比较，从这些比较中计算位掩码，然后使用ffs指令找到与第一个非较小元素对应的位：</p><p> int  mask  =  ( 1  &lt;&lt;  B ); for  ( int  i  =  0 ;  i  &lt;  B ;  i ++ )  mask  |=  ( btree [ k ][ i ]  &gt;=  x )  &lt;&lt;  i ; int  i  =  __builtin_ffs ( mask )  -  1 ; // now i is the number of the correct child node</p><p>整数掩码=（1&lt；&lt；B）；对于（inti=0；i&lt；B；i++）掩码|=（B树[k][i]&gt；=x）&lt&书信电报；我int i=__内置ffs（掩码）-1；//现在我是正确的子节点的编号</p><p> Unfortunately, the compilers are not smart enough yet to auto-vectorize this code, so we need to manually vectorize it with intrinsics:</p><p>不幸的是，编译器还不够智能，无法自动矢量化此代码，因此我们需要使用intrinsic手动矢量化它：</p><p> typedef  __m256i  reg ; int  cmp ( reg  x_vec ,  int *  y_ptr )  {  reg  y_vec  =  _mm256_load_si256 (( reg * )  y_ptr );  // load 8 sorted elements   reg  mask  =  _mm256_cmpgt_epi32 ( x_vec ,  y_vec );  // compare against the key   return  _mm256_movemask_ps (( __m256 )  mask );  // extract the 8-bit mask  }</p><p>typedef__M256ireg；int cmp（reg x_vec，int*y_ptr）{reg y_vec=_mm256_load_si256（（reg*）y_ptr）；//加载8个已排序元素reg mask=_mm256_cmpgt_epi32（x_vec，y_vec）；//与返回键比较_mm256_movemask_ps（u m256）mask）；//提取8位mask}</p><p> This function works for 8-element vectors, which is half our block / cache line size. To process the entire block, we need to call it twice and then combine the masks:</p><p>该函数适用于8元素向量，这是块/缓存线大小的一半。要处理整个块，我们需要调用它两次，然后组合遮罩：</p><p>  Now, to descend down the tree, we use  ffs on that mask to get the correct child number and just call the  go function we defined earlier:</p><p>现在，要从树上下来，我们使用该掩码上的ffs来获得正确的子编号，只需调用前面定义的go函数：</p><p>  To actually return the result in the end, we’d want to just fetch  btree[k][i] in the last node we visited, but the problem is that sometimes the local lower bound doesn’t exist ($i \ge B$) because $x$ happens to be greater than all the keys in the node. We could, in theory, do the same thing we did for the  Eytzinger binary search and restore the correct element  after we calculate the last index, but we don’t have a nice bit trick this time and have to do a lot of  divisions by 17 to compute it, which will be slow and almost certainly not worth it.</p><p>为了最终实际返回结果，我们只需要在我们访问的最后一个节点中获取btree[k][i]，但问题是，有时本地下限不存在（$i\ge B$），因为$x$恰好大于节点中的所有键。理论上，我们可以做与Eytzinger二进制搜索相同的事情，并在计算最后一个索引后恢复正确的元素，但这次我们没有什么好技巧，需要做很多除以17的运算，这会很慢，几乎肯定不值得。</p><p> Instead, we can just remember and return the last local lower bound we encountered when we descended the tree:</p><p>相反，我们只需记住并返回我们下山时遇到的最后一个局部下限：</p><p> int  lower_bound ( int  _x )  {  int  k  =  0 ,  res  =  INT_MAX ;  reg  x  =  _mm256_set1_epi32 ( _x );  while  ( k  &lt;  nblocks )  {  int  mask  =  ~ (  cmp ( x ,  &amp; btree [ k ][ 0 ])  +  ( cmp ( x ,  &amp; btree [ k ][ 8 ])  &lt;&lt;  8 )  );  int  i  =  __builtin_ffs ( mask )  -  1 ;  if  ( i  &lt;  B )  res  =  btree [ k ][ i ];  k  =  go ( k ,  i );  }  return  res ; }</p><p>int下限（int_x）{int k=0，res=int_MAX；reg x=_mm256_set1_epi32（_x）；而（k&lt；nblocks）{int mask=~（cmp（x，&amp；btree[k][0]）+（cmp（x，&amp；btree[k][8]）；int i=_内置ffs（mask）-1；if（i&lt；B）res btree k[i];  k=go（k，i）；}返回res；}</p><p>      Before everything else, let’s allocate the memory for the array on a  hugepage:</p><p>首先，让我们为hugepage上的阵列分配内存：</p><p> const  int  P  =  1  &lt;&lt;  21 ;  // page size in bytes (2MB)  const  int  T  =  ( 64  *  nblocks  +  P  -  1 )  /  P  *  P ;  // can only allocate whole number of pages  btree  =  ( int ( * )[ 16 ])  std :: aligned_alloc ( P ,  T ); madvise ( btree ,  T ,  MADV_HUGEPAGE );</p><p>常数int P=1&lt&书信电报；21 ;  // 页面大小（以字节为单位）（2MB）常量int T=（64*nblocks+P-1）/P*P；//只能分配整页数btree=（int（*）[16]）std:：aligned_alloc（P，T）；madvise（b树，T，MADV_HUGEPAGE）；</p><p>   Ideally, we’d also need to enable hugepages for all  previous implementations to make the comparison fair, but it doesn’t matter that much because they all have some form of prefetching that alleviates this problem.</p><p>理想情况下，我们还需要为所有以前的实现启用hugepages，以使比较公平，但这并不重要，因为它们都有某种形式的预取来缓解这个问题。</p><p> With that settled, let’s begin real optimization. First of all, we’d want to use compile-time constants instead of variables as much as possible because it lets the compiler embed them in the machine code, unroll loops, optimize arithmetic, and do all sorts of other nice stuff for us for free. Specifically, we want to know the tree height in advance:</p><p>解决了这个问题，让我们开始真正的优化。首先，我们希望尽可能多地使用编译时常量，而不是变量，因为它可以让编译器将它们嵌入机器代码中，展开循环，优化算法，并免费为我们做各种各样的事情。具体来说，我们想提前知道树的高度：</p><p> constexpr  int  height ( int  n )  {  // grow the tree until its size exceeds n elements   int  s  =  0 ,  // total size so far   l  =  B ,  // size of the next layer   h  =  0 ;  // height so far   while  ( s  +  l  -  B  &lt;  n )  {  s  +=  l ;  l  *=  ( B  +  1 );  h ++ ;  }  return  h ; } const  int  H  =  height ( N );</p><p>constexpr int height（int n）{//生长树，直到其大小超过n个元素int s=0，//到目前为止的总大小l=B，//下一层的大小h=0；//到目前为止的高度（s+l-B&lt；n）{s+=l；l*=（B+1）；h++；}返回h；}常数int H=高度（N）；</p><p> Next, we can find the local lower bound in nodes faster. Instead of calculating it separately for two 8-element blocks and merging two 8-bit masks, we combine the vector masks using the  packs instruction and readily extract it using  movemask just once:</p><p>接下来，我们可以更快地在节点中找到局部下界。我们没有为两个8元素块分别计算它并合并两个8位掩码，而是使用packs指令组合向量掩码，并使用movemask轻松提取一次：</p><p> unsigned  rank ( reg  x ,  int *  y )  {  reg  a  =  _mm256_load_si256 (( reg * )  y );  reg  b  =  _mm256_load_si256 (( reg * )  ( y  +  8 ));  reg  ca  =  _mm256_cmpgt_epi32 ( a ,  x );  reg  cb  =  _mm256_cmpgt_epi32 ( b ,  x );  reg  c  =  _mm256_packs_epi32 ( ca ,  cb );  int  mask  =  _mm256_movemask_epi8 ( c );  // we need to divide the result by two because we call movemask_epi8 on 16-bit masks:   return  __tzcnt_u32 ( mask )  &gt;&gt;  1 ; }</p><p>无符号秩（reg x，int*y）{reg a=_mm256_load_si256（（reg*）y）；reg b=_mm256_load_si256（（reg*）（y+8））；reg ca=_mm256_cmpgt_epi32（a，x）；reg cb=_mm256_cmpgt_epi32（b，x）；reg c=_mm256_packs_epi32（ca，cb）；int=_mm256_movemask_epi8（c）;  // 我们需要将结果除以2，因为我们在16位掩码上调用movemask_epi8:return u tzcnt_u32（mask）&gt&gt；1 ; }</p><p> This instruction converts 32-bit integers stored in two registers to 16-bit integers stored in one register — in our case, effectively joining the vector masks into one. Note that we’ve swapped the order of comparison — this lets us not invert the mask in the end, but we have to subtract one from the search key once in the beginning to make it correct (otherwise, it works as  upper_bound).</p><p>该指令将存储在两个寄存器中的32位整数转换为存储在一个寄存器中的16位整数——在我们的例子中，有效地将向量掩码合并为一个。请注意，我们已经交换了比较顺序——这让我们最终不会反转掩码，但我们必须在开始时从搜索键中减去一次以使其正确（否则，它将作为上限）。</p><p> The problem is, it does this weird interleaving where the result is written in the  a1 b1 a2 b2 order instead of  a1 a2 b1 b2 that we want — many AVX2 instructions tend to do that. To correct this, we need to  permute the resulting vector, but instead of doing it during the query time, we can just permute every node during preprocessing:</p><p>问题是，它会进行这种奇怪的交错，结果以a1 b1 a2 b2顺序写入，而不是我们想要的a1 a2 b1 b2顺序写入——许多AVX2指令都倾向于这样做。要纠正这一点，我们需要对结果向量进行排列，但我们可以在预处理期间对每个节点进行排列，而不是在查询期间进行排列：</p><p> void  permute ( int  * node )  {  const  reg  perm  =  _mm256_setr_epi32 ( 4 ,  5 ,  6 ,  7 ,  0 ,  1 ,  2 ,  3 );  reg *  middle  =  ( reg * )  ( node  +  4 );  reg  x  =  _mm256_loadu_si256 ( middle );  x  =  _mm256_permutevar8x32_epi32 ( x ,  perm );  _mm256_storeu_si256 ( middle ,  x ); }</p><p>void permute（int*node）{const reg perm=_mm256_setr_epi32（4,5,6,7,0,1,2,3）；reg*middle=（reg*）（node+4）；reg x=_mm256_loadu_si256（middle）；x=_mm256_permutevar8x32_epi32（x，perm）；_mm256_storeu_si256（middle，x）}</p><p> Now we just call  permute(&amp;btree[k]) right after we are done building the node. There are probably faster ways to swap the middle elements, but we will leave it here as the preprocessing time is not that important for now.</p><p>现在，我们只需在构建完节点后立即调用permute（&amp；btree[k]）。可能有更快的方法来交换中间元素，但我们将把它留在这里，因为预处理时间目前并不那么重要。</p><p> This new SIMD routine is significantly faster because the extra  movemask is slow, and also blending the two masks takes quite a few instructions. Unfortunately, we now can’t just do the  res = btree[k][i] update anymore because the elements are permuted. We can solve this problem with some bit-level trickery in terms of  i, but indexing a small lookup table turns out to be faster and also doesn’t require a new branch:</p><p>这个新的SIMD例程的速度明显更快，因为额外的movemask速度很慢，而且混合这两个掩码需要相当多的指令。不幸的是，我们现在不能再进行res=btree[k][i]更新了，因为元素已经被置换了。我们可以用一些位级别的技巧来解决这个问题，但是索引一个小的查找表会更快，也不需要新的分支：</p><p> const  int  translate [ 17 ]  =  {  0 ,  1 ,  2 ,  3 ,  8 ,  9 ,  10 ,  11 ,  4 ,  5 ,  6 ,  7 ,  12 ,  13 ,  14 ,  15 ,  0 }; void  update ( int  &amp; res ,  int *  node ,  unsigned  i )  {  int  val  =  node [ translate [ i ]];  res  =  ( i  &lt;  B  ?  val  :  res ); }</p><p>const int translate[17]={0,1,2,3,8,9,10,11,4,5,6,7,12,13,14,15,0}；无效更新（int&amp；res，int*node，unsigned i）{int val=node[translate[i]]；res=（i&lt；B？val:res）；}</p><p> This  update procedure takes some time, but it’s not on the critical path between the iterations, so it doesn’t affect the actual performance that much.</p><p>这个更新过程需要一些时间，但它不在迭代之间的关键路径上，所以它对实际性能影响不大。</p><p>  int  lower_bound ( int  _x )  {  int  k  =  0 ,  res  =  INT_MAX ;  reg  x  =  _mm256_set1_epi32 ( _x  -  1 );  for  ( int  h  =  0 ;  h  &lt;  H  -  1 ;  h ++ )  {  unsigned  i  =  rank ( x ,  &amp; btree [ k ]);  update ( res ,  &amp; btree [ k ],  i );  k  =  go ( k ,  i );  }  // the last branch:   if  ( k  &lt;  nblocks )  {  unsigned  i  =  rank ( x ,  btree [ k ]);  update ( res ,  &amp; btree [ k ],  i );  }  return  res ; }</p><p>int下限（int_x）{int k=0，res=int_MAX；reg x=_mm256_set1_epi32（_x-1）；for（int h=0；h&lt；h-1；h++）{unsigned i=rank（x，&amp；btree[k]）；update（res和btree[k]，i）；k=go（k，i）}//最后一个分支：if（k&lt；nblocks）{unsigned i=rank（x，btree[k]）；update（res，&amp；btree[k]，i）；}返回res；}</p><p>   It doesn’t feel very satisfying so far, but we will reuse these optimization ideas later.</p><p>到目前为止，感觉不是很满意，但我们稍后将重用这些优化想法。</p><p>  The  update procedure is quite costly, especially considering that it is very likely going to be useless: 16 out of 17 times, we can just fetch the result from the last block.</p><p>更新过程的成本相当高，尤其是考虑到它很可能是无用的：17次中有16次，我们只能从最后一个块中获取结果。</p><p> We do a non-constant number of iterations, causing branch prediction problems similar to how it did for the  Eytzinger binary search; you can also see it on the graph this time, but the latency bumps have a period of $2^4$.</p><p>我们进行了非恒定次数的迭代，导致分支预测问题，类似于Eytzinger二进制搜索；这一次你也可以在图表上看到，但是延迟突增的周期是$2^4$。</p><p>    Most of the time, when people talk about B-trees, they really mean  B+ trees, which is a modification that distinguishes between the two types of nodes:</p><p>大多数时候，当人们谈论B-树时，他们实际上指的是B+树，这是一种区分两种节点类型的修改：</p><p> Internal nodes store up to $B$ keys and $(B + 1)$ pointers to child nodes. The key number $i$ is always equal to the smallest key in the subtree of the $(i + 1)$-th child node.</p><p>内部节点最多存储$B$键和指向子节点的$（B+1）$指针。密钥编号$i$始终等于第$（i+1）$个子节点子树中的最小密钥。</p><p> Data nodes or  leaves store up to $B$ keys, the pointer to the next leaf node, and, optionally, an associated value for each key — if the structure is used as a key-value map.</p><p>数据节点或叶最多可存储$B$键、指向下一个叶节点的指针，以及每个键的可选关联值（如果该结构用作键值映射）。</p><p> The advantages of this approach include faster search time (as the internal nodes only store keys) and the ability to quickly iterate over a range of entries (by following next leaf node pointers), but this comes at the cost of some memory overhead: we have to store copies of keys in the internal nodes.</p><p>这种方法的优点包括更快的搜索时间（因为内部节点只存储密钥）和快速迭代一系列条目的能力（通过遵循下一个叶节点指针），但这是以一些内存开销为代价的：我们必须在内部节点中存储密钥的副本。</p><p>   Either the last node we descend into has the local lower bound, or it is the first key of the next leaf node, so we don’t need to call  update on each iteration.</p><p>要么我们下降到的最后一个节点具有局部下界，要么它是下一个叶节点的第一个键，因此我们不需要在每次迭代时调用update。</p><p> The depth of all leaves is constant because B+ trees grow at the root and not at the leaves, which removes the need for branching.</p><p>所有叶子的深度都是恒定的，因为B+树生长在根部，而不是叶子，这就不需要分枝。</p><p> The disadvantage is that this layout is not  succinct: we need some additional memory to store the internal nodes — about $\frac{1}{16}$-th of the original array size, to be exact — but the performance improvement will be more than worth it.</p><p>缺点是这种布局并不简洁：我们需要一些额外的内存来存储内部节点——确切地说，大约是原始数组大小的$\frac{1}{16}$——但性能改进将是非常值得的。</p><p>   To be more explicit with pointer arithmetic, we will store the entire tree in a single one-dimensional array. To minimize index computations during run-time, we will store each layer sequentially in this array and use compile-time computed offsets to address them: the keys of the node number  k on layer  h start with  btree[offset(h) + k * B], and its  i-th child will at  btree[offset(h - 1) + (k * (B + 1) + i) * B].</p><p>为了更明确地使用指针算法，我们将把整个树存储在一个一维数组中。为了在运行时最小化索引计算，我们将在该数组中顺序存储每一层，并使用编译时计算的偏移量来解决它们：层h上节点号k的键以btree[offset（h）+k*B]开始，其第i个子节点将位于btree[offset（h-1）+（k*（B+1）+i）*B]。</p><p>  // number of B-element blocks in a layer with n keys  constexpr  int  blocks ( int  n )  {  return  ( n  +  B  -  1 )  /  B ; } // number of keys on the layer pervious to one with n element  constexpr  int  prev_keys ( int  n )  {  return  ( blocks ( n )  +  B )  /  ( B  +  1 )  *  B ; } // height of a balanced n-key B+ tree  constexpr  int  height ( int  n )  {  return  ( n  &lt;=  B  ?  1  :  height ( prev_keys ( n ))  +  1 ); } // where the layer h starts (0 is the largest)  constexpr  int  offset ( int  h )  {  int  k  =  0 ,  n  =  N ;  while  ( h -- )  {  k  +=  blocks ( n )  *  B ;  n  =  prev_keys ( n );  }  return  k ; } const  int  H  =  height ( N ); const  int  S  =  offset ( H );  // the tree size is the offset of the (non-existent) layer H  int  * btree ;  // the tree itself is stored in a single hugepage-aligned array of size S</p><p>//具有n个键的层中的B元素块的数量constepr int blocks（int n）{return（n+B-1）/B；}//层上的键数，与n个元素constexpr int prev_keys（int n）{return（blocks（n）+B）/（B+1）*B；}//平衡n-键B+树constepr int height（int n）{return（n&lt；=B？1:height（prev_-keys（n））+1）；}/其中层h开始（0是最大的）constepr int offset（int h）{int k=0，n=n；而（h--）{k+=blocks（n）*B；n=prev_keys（n）；}返回k；}常数int H=高度（N）；常数int S=偏移量（H）；//树的大小是（不存在的）层H int*b树的偏移量；//树本身存储在一个大小为S的hugepage对齐数组中</p><p> Note that we store the layers in reverse order, but the nodes within a layer and data in them are still left-to-right, and also the layers are numbered bottom-up: the leaves form the zeroth layer, and the root is the layer  H - 1. These are just arbitrary decisions — it is just slightly easier to implement in code.</p><p>请注意，我们以相反的顺序存储层，但层内的节点和其中的数据仍然是从左到右的，而且层是自下而上编号的：叶子形成第零层，根是层H-1。这些都是随意的决定——只是在代码中实现起来稍微容易一些。</p><p>   To construct the tree from a sorted array  a, we first need to copy it into the zeroth layer and pad it with infinities:</p><p>要从排序数组a构建树，我们首先需要将其复制到第0层，并用无穷大填充它：</p><p> memcpy ( btree ,  a ,  4  *  N ); for  ( int  i  =  N ;  i  &lt;  S ;  i ++ )  btree [ i ]  =  INT_MAX ;</p><p>memcpy（b树，a，4*N）；对于（int i=N；i&lt；S；i++）btree[i]=int_MAX；</p><p> Now we build the internal nodes, layer by layer. For each key, we need to descend to the right of it in, always go left until we reach a leaf node, and then take its first key — it will be the smallest on the subtree:</p><p>现在我们逐层构建内部节点。对于每一个关键点，我们需要下降到它的右边，总是向左走，直到我们到达一个叶节点，然后取它的第一个关键点——它将是子树上最小的关键点：</p><p> for  ( int  h  =  1 ;  h  &lt;  H ;  h ++ )  {  for  ( int  i  =  0 ;  i  &lt;  offset ( h  +  1 )  -  offset ( h );  i ++ )  {  // i = k * B + j   int  k  =  i  /  B ,  j  =  i  -  k  *  B ;  k  =  k  *  ( B  +  1 )  +  j  +  1 ;  // compare to the right of the key   // and then always to the left   for  ( int  l  =  0 ;  l  &lt;  h  -  1 ;  l ++ )  k  *=  ( B  +  1 );  // pad the rest with infinities if the key doesn&#39;t exist    btree [ offset ( h )  +  i ]  =  ( k  *  B  &lt;  N  ?  btree [ k  *  B ]  :  INT_MAX );  } }</p><p>for（inth=1；h&lt；h；h++）{for（inti=0；i&lt；offset（h+1）-offset（h）；i++）{//i=k*B+j intk=i/B，j=i-k*B；k=k*（B+1）+j+1；//比较键的右侧//然后始终比较键的左侧（int l=0；l&lt；h-1；l++）k*=（B+1）；//如果键没有&#39，则在剩余的部分填充无穷大；t exist btree[offset（h）+i]=（k*B&lt；N？btree[k*B]：INT_MAX）；}</p><p> And just the finishing touch — we need to permute keys in internal nodes to search them faster:</p><p>最后，我们需要在内部节点中排列键，以便更快地搜索它们：</p><p>  We start from  offset(1), and we specifically don’t permute leaf nodes and leave the array in the original sorted order. The motivation is that we’d need to do this complex index translation we do in  update if the keys were permuted, and it is on the critical path when this is the last operation. So, just for this layer, we switch to the original mask-blending local lower bound procedure.</p><p>我们从偏移量（1）开始，明确地说，我们不排列叶节点，而是让数组保持原来的排序顺序。这样做的动机是，如果密钥被置换，我们需要进行复杂的索引转换，而这是最后一次操作时，它处于关键路径上。所以，对于这一层，我们切换到原始的掩模混合局部下限程序。</p><p>   The search procedure becomes simpler than for the B-tree layout: we don’t need to do  update and only execute a fixed number of iterations — although the last one with some special treatment:</p><p>搜索过程比B-树布局更简单：我们不需要进行更新，只需要执行固定数量的迭代——尽管最后一个迭代经过了一些特殊处理：</p><p> int  lower_bound ( int  _x )  {  unsigned  k  =  0 ;  // we assume k already multiplied by B to optimize pointer arithmetic   reg  x  =  _mm256_set1_epi32 ( _x  -  1 );  for  ( int  h  =  H  -  1 ;  h  &gt;  0 ;  h -- )  {  unsigned  i  =  permuted_rank ( x ,  btree  +  offset ( h )  +  k );  k  =  k  *  ( B  +  1 )  +  i  *  B ;  }  unsigned  i  =  direct_rank ( x ,  btree  +  k );  return  btree [ k  +  i ]; }</p><p>int lower_bound（int_x）{unsigned k=0；//我们假设k已经乘以B来优化指针算术reg x=_mm256_set1_epi32（_x-1）；for（int h=h-1；h&gt；0；h-）{unsigned i=permuted_秩（x，btree+offset（h）+k）；k=k*（B+1）+i*B；}无符号i=直接秩（x，b树+k）；返回b树[k+i]；}</p><p> Switching to the B+ layout more than paid off: the S+ tree is 1.5-3x faster compared to the optimized S-tree:</p><p>切换到B+布局的速度比优化的S-树快1.5-3倍：</p><p>  The spikes at the high end of the graph are caused by the L1 TLB not being large enough: it has 64 entries, so it can handle at most 64 × 2 = 128MB of data, which is exactly what is required for storing  2^25 integers. The S+ tree hits this limit slightly sooner because of the ~7% memory overhead.</p><p>图中高端的峰值是由L1 TLB不够大造成的：它有64个条目，因此最多可以处理64×2=128MB的数据，这正是存储2^25个整数所需的数据。由于大约7%的内存开销，S+树更快地达到这个限制。</p><p>       The cliffs at the beginning of the graph are because the running time of  std::lower_bound grows smoothly with the array size, while for an S+ tree, it is locally flat and increases in discrete steps when a new layer needs to be added.</p><p>图开头的悬崖峭壁是因为std:：lower_bound的运行时间随数组大小平滑增长，而对于S+树，它是局部平坦的，当需要添加新层时，它会以离散的步骤增加。</p><p> One important asterisk we haven’t discussed is that what we are measuring is not real latency, but the  reciprocal throughput — the total time it takes to execute a lot of queries divided by the number of queries:</p><p>我们没有讨论的一个重要星号是，我们测量的不是实际延迟，而是交互吞吐量——执行大量查询所需的总时间除以查询数量：</p><p> clock_t  start  =  clock (); for  ( int  i  =  0 ;  i  &lt;  m ;  i ++ )  checksum  ^=  lower_bound ( q [ i ]); float  seconds  =  float ( clock ()  -  start )  /  CLOCKS_PER_SEC ; printf ( &#34;%.2f ns per query \n &#34; ,  1e9  *  seconds  /  m );</p><p>clock_t start=clock（）；对于（int i=0；i&lt；m；i++）校验和^=下界（q[i]）；浮动秒数=浮动（时钟（）-开始）/每秒时钟数；printf（&#34；%.2f ns/次查询\n&#34；，1e9*秒/m）；</p><p> To measure  actual latency, we need to introduce a dependency between the loop iterations so that the next query can’t start before the previous one finishes:</p><p>为了测量实际延迟，我们需要在循环迭代之间引入一个依赖项，以便在前一个查询完成之前无法启动下一个查询：</p><p> int  last  =  0 ; for  ( int  i  =  0 ;  i  &lt;  m ;  i ++ )  {  last  =  lower_bound ( q [ i ]  ^  last );  checksum  ^=  last ; }</p><p>int last=0；对于（int i=0；i&lt；m；i++）{last=下限（q[i]^last）；校验和^=last；}</p><p>   A lot of the performance boost of the S+ tree comes from removing branching and minimizing memory requests, which allows overlapping the execution of more adjacent queries — apparently, around three on average.</p><p>S+树的许多性能提升来自于移除分支和最小化内存请求，这允许重叠执行更多相邻的查询——显然，平均大约三个。</p><p> Although nobody except maybe the HFT people cares about real latency, and everybody actually measures throughput even when using the word “latency”, this nuance is still something to take into account when predicting the possible speedup in user applications.</p><p>虽然除了HFT用户之外，没有人关心真正的延迟，而且每个人甚至在使用“延迟”这个词时都会测量吞吐量，但在预测用户应用程序中可能的加速时，这种细微差别仍然需要考虑。</p><p>   To minimize the number of memory accesses during a query, we can increase the block size. To find the local lower bound in a 32-element node (spanning two cache lines and four AVX2 registers), we can use a  similar trick that uses two  packs_epi32 and one  packs_epi16 to combine masks.</p><p>为了最小化查询期间的内存访问次数，我们可以增加块大小。为了在32个元素节点（跨越两条缓存线和四个AVX2寄存器）中找到局部下界，我们可以使用类似的技巧，使用两个packs_epi32和一个packs_epi16组合掩码。</p><p> We can also try to use the cache more effi</p><p>我们还可以尝试更有效地使用缓存</p><p>......</p><p>......</p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/搜索/">#搜索</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/trees/">#trees</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/int/">#int</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/谷歌/">#谷歌</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy;2012-2021 diglog.com </div></div></body></html>