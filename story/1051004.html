<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>语言模型是否知道大象有多重？ </title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">语言模型是否知道大象有多重？ </h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2021-03-07 11:01:34</div><div class="page_narrow text-break page_content"><p>人类具有相当良好的规模感，或这些数字属性的合理范围，不同的对象，但做预先训练的慵懒言列属性？虽然预先接受了训练的语言模型（LMS），如BERT HAVESHOWN，但能够了解各种知识，包括事实知识，仍然不清楚他们的表示是否可以在没有显式训练数据的情况下从文本中捕获这些类型的数字属性。</p><p>  在我们的最近来看，我们测量在预训练的文本表示中捕获的比例信息量，并且表明，尽管捕获了大量的这样的信息，但它们的当前性能和理论界之间的差距很大。我们确定了这些文本代表性，在数值推理捕获败斑液时是上下文和良好的。我们还提出了一个新版本的BERT，称为Numbert，通过他们的科学符号替换PretRimingText语料库中的数字以其进行科学符号，对模型更加容易曝光，并证明Numbert表示表明比以前的所有这些都能显着更好textrepresentations。</p><p>  为了理解预先训练的文本表示的程度，诸如捕获量表信息，我们提出了一个TaskCalled标量探测：探测能够预测对象的标量属性的值的分布。在这方面，我们专注于三种标量属性：重量，长度和价格。</p><p>   在这个例子中，我们正试图了解由预先训练的编码器提取的“狗”的表示是否可用于通过线性模型来预测/恢复狗的重量的分布。我们probethree基线语言表示：Word2vec，elmo和bert.since后两个是操作unentences而不是单词的上下文表示，我们在使用textittemplates构造的句子中源。例如，对于重量，我们使用模板“x ishevy”，其中x是兴趣的对象。</p><p> 我们探讨了预测预测完全分布的估值点估计的探测器。为了预测观察点，我们使用标准的线性重新攻击（我们表示为“RGR”）训练，以预测用于所考虑的尺度属性的每个对象的所有值的所有值的中位数的日志。我们预测了日志，因为再次，我们关心一般规模而不是确切的价值。使用预测和地图实话分布中位数的日志来计算Theloss。为了预测完全分配，我们USEA线性软MAX多级分类器（我们表示为“MCC”）在12个数量级上产生acatication分布。使用NumberT（我们的伯特的改良率）预测的分类分布;在上面的例子中显示了橙色直方图的表示表示表示表示。</p><p> 我们使用的地面实际分布来自分布式过度级（Doq）数据集，由标量属性的实证计数为标量值，它超过10种不同的标记，形容词和动词，自动从大型Web文本语料库中提取。在数据集的构造过程中注意到，鉴定的所有单位都是统一统一的（例如centimeter /米/公里 - 仪表），并且数值是缩放的。我们将每个对象attributepair的收集的计数转换为doq的每个对象attributepair到一个超过12次级的分类分布。在上面的狗重量的示例中，地面真实分布式被显示为灰色直方图，它是集中的10-100kg 。</p><p> 预测性能越好，我们正在处理的所有对象attributepairs，培训的预先训练的代表性越好相应的比例信息。 </p><p>在查看这些不同的语言的标量探测结果之前，我们还考虑擅长捕获尺度信息以及如何更好地提高现有LMSTO捕获量表的良好的陈述。所有这些模型都使用Wikipedia，新闻等训练使用大型线文本语料库。他们如何从所有这些文本中汲取比例信息？</p><p> 这是我在搜索opegle“大象重量”时获得的第一件文档的一篇文章：</p><p> “......非洲大象可以从5000磅到14,000英镑（6,350公斤）......”</p><p> 因此，缩放的学习很可能是部分地通过从数字（这里“5,000”，“14,000”等）转移到名词（这里的“大象”）和数值，即戏剧性的原因数字，对代表性来说可能很重要！</p><p> 然而，曾经是现有的训练有素的文本表示，包括BERT，ELMO和WORD2VEC的曾经是HASSHOWN，并不擅长推理数量。例如，超出〜500的幅度，甚至无法解码来自其字嵌入的数字，例如，嵌入（“710”）710.因此，我们建议通过将LM培训数据中的数量替换为具有其科学的CNotation，重新预先预订伯特（我们称之为号码）来提高这些表示的数值推理能力。这个eNableSthe模型将直接在句子中更轻松地将对象与指数中表达的幅度相关联，忽略了相对的脚步。</p><p>     上表显示了DOQ数据上标量探测的结果。 Woouse三个评估度量：准确性，均值平方误差（MSE）和地球移动器距离（EMD），我们在四个域进行了实验：长度，群众，价格和动物群众（群众的一部分）。对于MSEAND EMD，最好的分数是0，而我们通过从地面真实的分布和反对模式采样来计算宽松的准确性。这个上限实现了0.570的精度，为群众0.537，价格为0.476。</p><p> 对于每个属性的聚合基线，我们将在训练集中的所有对象中计算eMpiricalDistribute，并使用它作为测试Set中所有对象的预测分布..我们可以看到MCC探测器结束BestText表示捕获大约一半（按准确度测量）到与上限的距离的Athird（通过MSE和EMD），这表明在标准信息的数量可用时，还有很长的路要支持强大争议。 </p><p>具体而言，NumberT表示始终比地球移动器距离（EMD）上的其他人更好，这是磁性测量度量，因为它更好地融合了分解的对抗扰动和鲁棒性。 Word2VECPERFORMS SIGNIS比上下文表示更糟糕 - 事件任务是非组成（因为我们没有在我们的不同上下文中发生的对象的不同地图真相）。此外，尽管在下游的NLP任务上的BERT较弱，但ELMO在标量探测中表现得更好，与它更好的Atnumeracy Dueto它的性格级标记。</p><p>  我们注意到Doq从Web文本和包含的内容衍生出来。因此，我们还评估ON SCALAR属性的2个数据集通知地面真理标签的DOQ培训的探针：VERMPHYSICS和Amazon Pricedataset。这是一个相对比较的人类标记数据集，例如，人，狐狸，重量，更大）。对此任务的预测是通过对MCC的RGR和最高评分桶的点估计进行。第二个是亚马逊上的产品经验分布的数据集。我们使用12个电源-4buckets来支持DoQ价格的探讨，以支持隐藏的预测。</p><p>  结果显示在上表中。在Valomphysics（顶部的表格）上，RGR + Numbert表现最佳，将Doq的性能接近作为Oracle，虽然短暂的专业典范。用MCC培训的标量探针表现不佳，可能已经减少了预测分布的FINER-GRIME模型，这不是3级比较任务。在亚马逊价格数据集（底部的表）上，这是一个完整的分发预测任务，MCC + NumberT在分布度量标准上都没有。在零拍摄转移任务中，NumberT表示是跨越/目标的所有配置，这表明在培训前的语料库中的文本中的数字表示可以在规模预测上显着。</p><p>  在上面的工作中，我们介绍了一个名为scalar探测的新任务，它使用了对象培训的文本表示的数字属性的数字属性的数量有多少信息捕获并找出了objectrepresentations中的大量规模信息（半到三分之一）理论上限），TheSemodels远非实现常识规模的理解。我们拥有一个改进的BERT版本，称为Numbert，Whoserezentations捕获比例信息比以前的方式更好。</p><p> 标量探测开辟了探索的新令人兴奋的研究方向。 forexample，很多工作都有预先接受过大型视觉＆amp; langagemodels，如vilbert和clip.probing他们的表示，看看众规则信息是否有多少，并在仅通过语言模型学习的andrepresentations之间进行系统的比较可能是非常有趣的。</p><p> 此外，模型学习文本表示预测比例更好可以获得巨大的真实影响。考虑类似的网页查询：</p><p>  常识了解对“建筑物”的合理高度范围是什么，我们可以在错误时检测当前Web QA系统中的错误，例如，如前所述或解析。当一个维基百科句子关于建筑物被解释为19英里的而不是米。 </p><p>查看纸张Do语言嵌入式捕获量吗？ Byxikun Zhang，Deepak Ramachandran，Ian Tenney，Yanai Elazar和Danroth。  通过通过电子邮件或电子邮件保持最新的帆博客帖子之上： </p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://ai.stanford.edu/blog/scalar-probing/">https://ai.stanford.edu/blog/scalar-probing/</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/模型/">#模型</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/models/">#models</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/表示/">#表示</a></button></div></div><div class="shadow p-3 mb-5 bg-white rounded clearfix"><div class="container"><div class="row"><div class="col-sm"><div><a target="_blank" href="/story/1050743.html"><img src="http://img2.diglog.com/img/2021/3/thumb_8b2942b416a0d64ff317adeea26f4b5c.png" class="img-fluid" onerror="this.style.display='none'"></a></div><div class="item_title"><a target="_blank" href="/story/1050743.html">联想宣布推出具有Tiger Lake CPU的ThinkEdge无风扇，坚固耐用的微型PC </a></div><span class="my_story_list_date">2021-3-4 2:54</span></div><div class="col-sm"><div><a target="_blank" href="/story/1050314.html"><img src="http://img2.diglog.com/img/2021/3/thumb_a5ce30a4fc139d6af806d6c39d35a906.jpg" class="img-fluid" onerror="this.style.display='none'"></a></div><div class="item_title"><a target="_blank" href="/story/1050314.html">随机效果和受罚样条线是一回事 </a></div><span class="my_story_list_date">2021-3-2 10:32</span></div><div class="col-sm"><div><a target="_blank" href="/story/1049934.html"><img src="http://img2.diglog.com/img/2021/2/thumb_5044256b725008005984363ab6f5a67b.png" class="img-fluid" onerror="this.style.display='none'"></a></div><div class="item_title"><a target="_blank" href="/story/1049934.html">FACET是用于人类可解释AI的开源库 </a></div><span class="my_story_list_date">2021-2-28 22:23</span></div><div class="col-sm"><div><a target="_blank" href="/story/1049111.html"><img src="http://img2.diglog.com/img/2021/2/thumb_21c491ca96512441a5accd414725c248.jpg" class="img-fluid" onerror="this.style.display='none'"></a></div><div class="item_title"><a target="_blank" href="/story/1049111.html">Aquarium获得260万美元种子资金以完善机器学习模型数据 </a></div><span class="my_story_list_date">2021-2-25 1:1</span></div></div></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/谷歌/">#谷歌</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy;2012-2021 diglog.com </div></div></body></html>