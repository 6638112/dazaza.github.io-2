<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>#强化</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1>#强化</h1><div class="row"><div class="col-lg-8 col-12"><div id="list"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded clearfix"><div class="item_title"><a target="_blank" href="/story/1060160.html">不断变化的强化学习算法 </a></div><div class="item_title_en"><a target="_blank" href="https://ai.googleblog.com/2021/04/evolving-reinforcement-learning.html">Evolving Reinforcement Learning Algorithms</a><span>(ai.googleblog.com)</span></div><span class="my_story_list_date">2021-4-26 10:40</span><div class="float-md-right my_story_img_thumb"><a target="_blank" href="/story/1060160.html"><img src="http://img2.diglog.com/img/2021/4/thumb_52b03383f830f67c707d01d620371549.png" class="img-fluid my_story_img_thumb" onerror="this.style.display='none'"></a></div><div class="my_story_list_item_desc">2021年4月22日星期四 </div><div class="my_item_tag_container"><button type="button" class="btn btn-light my_tag"><a href="/tag/算法/">#算法</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/强化/">#强化</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/星期四/">#星期四</a></button></div></div><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded clearfix"><div class="item_title"><a target="_blank" href="/story/1044957.html">不断发展的强化学习算法 </a></div><div class="item_title_en"><a target="_blank" href="https://arxiv.org/abs/2101.03958">Evolving Reinforcement Learning Algorithms</a><span>(arxiv.org)</span></div><span class="my_story_list_date">2021-1-19 4:5</span><div class="my_story_list_item_desc">下载PDF摘要：我们通过搜索计算图的空间，提出一种元学习强化学习算法的方法，该计算图可计算损失函数，以基于值的无模型RL代理进行优化。 学习算法与领域无关，可以推广到培训期间未看到的新环境。 我们的方法可以从头开始学习，也可以从已知的现有算法（例如DQN）中引导，从而实现可解释的改进，从而提高性能。 我们的方法从零开......</div><div class="my_item_tag_container"><button type="button" class="btn btn-light my_tag"><a href="/tag/算法/">#算法</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/强化/">#强化</a></button></div></div><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded clearfix"><div class="item_title"><a target="_blank" href="/story/1042764.html">Linux强化指南 </a></div><div class="item_title_en"><a target="_blank" href="https://madaidans-insecurities.github.io/guides/linux-hardening.html">Linux Hardening Guide</a><span>(madaidans-insecurities.github.io)</span></div><span class="my_story_list_date">2021-1-1 8:57</span><div class="my_story_list_item_desc">Linux不是安全的操作系统。但是，您可以采取一些步骤对其进行改进。本指南旨在说明如何尽可能地加强Linux的安全性和隐私性。本指南试图与发行版无关，并且不限于任何特定的指南。免责声明：如果您不确定自己在做什么，请不要尝试在本文中应用任何内容。本指南仅关注安全性和隐私性，而不关注性能，可用性或其他任何内容。本指南中列......</div><div class="my_item_tag_container"><button type="button" class="btn btn-light my_tag"><a href="/tag/linux/">#linux</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/强化/">#强化</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/hardening/">#hardening</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/内核/">#内核</a></button></div></div><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded clearfix"><div class="item_title"><a target="_blank" href="/story/1038361.html">Microsoft的强化学习 </a></div><div class="item_title_en"><a target="_blank" href="https://www.microsoft.com/en-us/research/blog/research-collection-reinforcement-learning-at-microsoft/">Reinforcement Learning at Microsoft</a><span>(www.microsoft.com)</span></div><span class="my_story_list_date">2020-12-8 12:7</span><div class="float-md-right my_story_img_thumb"><a target="_blank" href="/story/1038361.html"><img src="http://img2.diglog.com/img/2020/12/thumb_b2b3fbe290c7048b0cb78139a52ec85c.png" class="img-fluid my_story_img_thumb" onerror="this.style.display='none'"></a></div><div class="my_story_list_item_desc">强化学习是关于代理商从世界上获取信息并学习与之互动的策略，以使他们表现更好。因此，您可以想象一个未来，每次您在键盘上打字时，键盘都会学会更好地了解您。或每次您与某个网站进行交互时，它都会更好地了解您的喜好，因此世界在与人交互方面的工作越来越好。
 MSR纽约市合伙人研究经理John Langford
 从根本上讲，强......</div><div class="my_item_tag_container"><button type="button" class="btn btn-light my_tag"><a href="/tag/microsoft/">#microsoft</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/强化/">#强化</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/learning/">#learning</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/学习/">#学习</a></button></div></div><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded clearfix"><div class="item_title"><a target="_blank" href="/story/1029508.html">(浅？)。强化学习</a></div><div class="item_title_en"><a target="_blank" href="https://medium.com/swlh/shallow-reinforcement-learning-3e8b59ff66c7">(Shallow?) Reinforcement Learning</a><span>(medium.com)</span></div><span class="my_story_list_date">2020-10-18 7:11</span><div class="float-md-right my_story_img_thumb"><a target="_blank" href="/story/1029508.html"><img src="http://img2.diglog.com/img/2020/10/thumb_8901794480b4f9b070c96b46b7180981.jpeg" class="img-fluid my_story_img_thumb" onerror="this.style.display='none'"></a></div><div class="my_story_list_item_desc">最近的壮举，比如AlphaGo战胜了世界上最好的围棋选手，把强化学习(RL)带到了聚光灯下。然而，什么是RL，它是如何取得如此显著的效果的呢？
在第一篇文章中，我们将探讨蒙特卡罗控制方法(不是深度控制方法)，尽管该方法非常简单，但它是构建一些最先进的RL的基础。
RL问题包括(至少)两个实体：代理和环境，如下图所示。......</div><div class="my_item_tag_container"><button type="button" class="btn btn-light my_tag"><a href="/tag/强化/">#强化</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/状态/">#状态</a></button></div></div><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded clearfix"><div class="item_title"><a target="_blank" href="/story/1029184.html">当你有基础物理的时候，你不需要强化学习</a></div><div class="item_title_en"><a target="_blank" href="https://npdeep.github.io/cartpole-without-reinforcement-learning.html">You don't need reinforcement learning when you have basic physics</a><span>(npdeep.github.io)</span></div><span class="my_story_list_date">2020-10-16 11:25</span><div class="my_story_list_item_desc">车-杆平衡问题是强化学习的一个典型问题。一根杆子系在带有旋转接头的手推车上。代理人必须通过向左或向右移动手推车来平衡杆子。
互联网上的大多数解决方案似乎都采用强化学习结合复杂的Kera模型来解决这一问题。
在这篇文章中，我将向您展示，如果您足够了解您的系统，您不需要任何深度学习方案。在手摇平衡的情况下，你所需要的只是......</div><div class="my_item_tag_container"><button type="button" class="btn btn-light my_tag"><a href="/tag/强化/">#强化</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/手推车/">#手推车</a></button></div></div><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded clearfix"><div class="item_title"><a target="_blank" href="/story/1025103.html">基于Nash强化学习的鲁棒垃圾邮件检测</a></div><div class="item_title_en"><a target="_blank" href="https://github.com/YingtongDou/Nash-Detect">Robust Spammer Detection by Nash Reinforcement Learning</a><span>(github.com)</span></div><span class="my_story_list_date">2020-9-20 6:40</span><div class="float-md-right my_story_img_thumb"><a target="_blank" href="/story/1025103.html"><img src="http://img2.diglog.com/img/2020/9/thumb_056d9e14f65471a63bab1cec7cf9928a.jpeg" class="img-fluid my_story_img_thumb" onerror="this.style.display='none'"></a></div><div class="my_story_list_item_desc">代码的KDD 2020论文稳健垃圾邮件检测纳什强化学习。窦颖彤，马桂祥，余承东，谢思红。[论文][幻灯片][视频][工具箱][中文博客]。
Nash-Detect是本文提出的一种利用强化学习训练鲁棒垃圾评论检测器的算法。鲁棒检测器由五个基本检测器组成，通过垃圾邮件发送者和防御者之间的极小极大博弈进行训练。垃圾邮件发送......</div><div class="my_item_tag_container"><button type="button" class="btn btn-light my_tag"><a href="/tag/强化/">#强化</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/spammer/">#spammer</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/垃圾邮件/">#垃圾邮件</a></button></div></div><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded clearfix"><div class="item_title"><a target="_blank" href="/story/1017142.html">智能手机强化版非根指南2.0(适用于普通人)</a></div><div class="item_title_en"><a target="_blank" href="https://dev.lemmy.ml/post/38770">Smartphone Hardening non-root Guide 2.0 (for normal people)</a><span>(dev.lemmy.ml)</span></div><span class="my_story_list_date">2020-8-9 12:20</span><div class="my_story_list_item_desc">莱米</div><div class="my_item_tag_container"><button type="button" class="btn btn-light my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/强化/">#强化</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/hardening/">#hardening</a></button></div></div><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded clearfix"><div class="item_title"><a target="_blank" href="/story/1011231.html">分散强化学习</a></div><div class="item_title_en"><a target="_blank" href="https://bair.berkeley.edu/blog/2020/07/11/auction/">Decentralized Reinforcement Learning</a><span>(bair.berkeley.edu)</span></div><span class="my_story_list_date">2020-7-12 1:9</span><div class="float-md-right my_story_img_thumb"><a target="_blank" href="/story/1011231.html"><img src="http://img.diglog.com/img/2020/7/thumb_37420c51b752bf097e69ae9247f60fa6.png" class="img-fluid my_story_img_thumb" onerror="this.style.display='none'"></a></div><div class="my_story_list_item_desc">今天各种人工智能系统背后的许多神经网络结构与一个世纪前的早期计算机有着有趣的相似之处。就像早期的计算机是专门用于特定目的的电路，如解线性系统或密码分析一样，训练有素的神经网络通常也作为执行特定任务的专门电路发挥作用，所有参数在同一全局范围内耦合在一起。
人们可能自然会想，学习系统可能需要什么才能以与编程系统相同的方式......</div><div class="my_item_tag_container"><button type="button" class="btn btn-light my_tag"><a href="/tag/强化/">#强化</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/社会/">#社会</a></button></div></div><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded clearfix"><div class="item_title"><a target="_blank" href="/story/1004834.html">ACME-一种分布式强化学习框架</a></div><div class="item_title_en"><a target="_blank" href="https://github.com/deepmind/acme">Acme – A framework for distributed reinforcement learning</a><span>(github.com)</span></div><span class="my_story_list_date">2020-6-2 22:34</span><div class="float-md-right my_story_img_thumb"><a target="_blank" href="/story/1004834.html"><img src="http://img.diglog.com/img/2020/6/thumb_c4a4fb78c34a5cc2f4211ed9a028fc9d.png" class="img-fluid my_story_img_thumb" onerror="this.style.display='none'"></a></div><div class="my_story_list_item_desc">ACME是一个强化学习(RL)代理和代理构建块的库。Acme努力公开简单、高效和可读的代理，这些代理既可以作为流行算法的参考实现，也可以作为强基线，同时仍然提供足够的灵活性来进行新的研究。Acme的设计还试图在不同的复杂程度上为RR问题提供多个入口点。
在最高级别，Acme公开了许多可以简单使用的代理，如下所示：
i......</div><div class="my_item_tag_container"><button type="button" class="btn btn-light my_tag"><a href="/tag/强化/">#强化</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/framework/">#framework</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/代理/">#代理</a></button></div></div><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded clearfix"><div class="item_title"><a target="_blank" href="/story/1000721.html">网格世界中的表格强化学习算法</a></div><div class="item_title_en"><a target="_blank" href="https://github.com/laxatives/rl/blob/master/gridworld_mdp.ipynb">Tabular Reinforcement Learning Algorithms in Gridworld</a><span>(github.com)</span></div><span class="my_story_list_date">2020-5-5 18:40</span><div class="my_story_list_item_desc">PermalLink GitHub是5000多万开发人员的家园，他们一起工作，共同托管和审查代码、管理项目和构建软件。
报名</div><div class="my_item_tag_container"><button type="button" class="btn btn-light my_tag"><a href="/tag/算法/">#算法</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/强化/">#强化</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/审查/">#审查</a></button></div></div></div></div><div class="col-lg-4 col-0"><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/美国/">#美国</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/谷歌/">#谷歌</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/程序/">#程序</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/rust/">#rust</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/数据/">#数据</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/warning/">#warning</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/代码/">#代码</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/ai/">#ai</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/linux/">#linux</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/学习/">#学习</a></button></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/谷歌/">#谷歌</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button></div></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy;2012-2021 diglog.com </div></div></body></html>