<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>利用机器学习泡菜文件 Exploiting machine learning Pickle files</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">Exploiting machine learning Pickle files<br/>利用机器学习泡菜文件 </h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2021-03-18 22:21:10</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2021/3/9d9595427ddabcd048e5ef10c26c355d.png"><img src="http://img2.diglog.com/img/2021/3/9d9595427ddabcd048e5ef10c26c355d.png" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>Many machine learning (ML) models are  Python pickle files under the hood, and it makes sense. The use of pickling conserves memory, enables start-and-stop model training, and makes trained models portable (and, thereby, shareable). Pickling is easy to implement, is built into Python without requiring additional dependencies, and supports serialization of custom objects. There’s little doubt about why choosing pickling for persistence is a popular practice among Python programmers and ML practitioners.</p><p>许多机器学习（ML）模型是引擎盖下的Python泡菜文件，它有意义。使用酸洗保存记忆，启动启动模型培训，并使培训的型号便携式（以及由此，可共享）。酸洗易于实现，内置于Python，而无需其他依赖项，并支持自定义对象的序列化。对为什么选择康复的人有点疑问是Python程序员和ML从业者之间的流行练习。</p><p> Pre-trained models are typically treated as “free” byproducts of ML since they allow the valuable intellectual property like algorithms and corpora that produced the model to remain private. This gives many people the confidence to share their models over the internet, particularly for reusable computer vision and natural language processing classifiers. Websites like  PyTorch Hub facilitate model sharing, and some libraries even provide APIs to download models from GitHub repositories automatically.</p><p> 预先训练的模型通常被视为ML的“免费”副产品，因为它们允许生产模型的算法和Corpora等算法，以保持私密的算法。这使许多人可以通过互联网分享模型的信心，特别是对于可重用的计算机视觉和自然语言处理分类器。像Pytorch Hub这样的网站促进了模型共享，并且某些库甚至为API提供自动从GitHub存储库下载模型。</p><p> Here, we discuss the underhanded antics that can occur simply from loading an untrusted pickle file or ML model. In the process, we introduce a new tool,  Fickling, that can help you reverse engineer, test, and even create malicious pickle files. If you are an ML practitioner, you’ll learn about the security risks inherent in standard ML practices. If you are a security engineer, you’ll learn about a new tool that can help you construct and forensically examine pickle files. Either way, by the end of this article, pickling will hopefully leave a sour taste in your mouth.</p><p> 在这里，我们讨论无法加载不受信任的泡菜文件或ML模型时发生的被削弱的滑轨。在此过程中，我们介绍了一个新的工具，即可以帮助您撤消工程师，测试，甚至创建恶意泡沫文件。如果您是ML从业者，您将了解标准ML实践中固有的安全风险。如果您是一个安全工程师，您将了解一个可以帮助您构建和取证泡沫文件的新工具。无论哪种方式，到本文结束时，酸洗将希望在嘴里留下酸味。</p><p>   Python pickles are compiled programs run in a unique virtual machine called a  Pickle Machine (PM). The PM interprets the pickle file’s sequence of opcodes to construct an arbitrarily complex Python object. Python pickle is also a streaming format, allowing the PM to incrementally build the resulting object as portions of the pickle are downloaded over the network or read from a file.</p><p>   Python Pickles是编译的程序在一个名为泡菜机（PM）的唯一虚拟机中运行。 PM解释泡沫文件的操作码序列以构造任意复杂的Python对象。 Python Pickle也是一种流式格式，允许PM递增地构建生成的对象，因为通过网络下载泡块的部分或从文件读取。</p><p> The PM uses a Harvard architecture, segregating the program opcodes from writable data memory, thus preventing self-modifying code and memory corruption attacks. It also lacks support for conditionals, looping, or even arithmetic. During unpickling, the PM reads in a pickle program and performs a sequence of instructions. It stops as soon as it reaches the  STOP opcode and whatever object is on top of the stack at that point is the final result of unpickling.</p><p> PM使用哈佛架构，从可写数据存储器中分离程序操作码，从而防止自修改代码和内存损坏攻击。它还缺乏对条件，循环甚至算术的支持。在未划分期间，PM在泡菜程序中读取并执行一系列指令。它一旦到达停止OPODE，它就会停止，并且在该点处的堆栈顶部是一个对象是未划分的最终结果。</p><p> From this description, one might reasonably conclude that the PM is not Turing-complete. How could this format possibly be unsafe? To corrode the words of  Mishima’s famous  aphorism:</p><p> 从本说明书来看，人们可能会合理地得出结论，PM不是图灵完整的。这种格式怎么可能不安全？腐蚀Mishima着名流行主义的话：</p><p> Computer programs are a medium that reduces reality to abstraction for transmission to our reason, and in their power to corrode reality inevitably lurks the danger of the   weird machines.</p><p> 计算机程序是一种媒介，减少了对我们的原因进行传播的现实，并且在他们的权力中，腐蚀现实不可避免地潜伏了奇怪的机器的危险。 </p><p> The PM contains two opcodes that can execute arbitrary Python code  outside of the PM, pushing the result onto the PM’s stack:  GLOBAL and  REDUCE.  GLOBAL is used to import a Python module or class, and  REDUCE is used to apply a set of arguments to a callable, typically previously imported through  GLOBAL. Even if a pickle file does not use the  REDUCE opcode, the act of importing a module alone can and will execute arbitrary code in that module, so  GLOBAL alone is dangerous.</p><p>PM包含两个可以在PM之外执行任意Python代码的操作码，将结果推入PM的堆栈：Global并减少。 Global用于导入Python模块或类，并且减少用于将一组参数应用于可调用的，通常先前通过全局导入。即使泡菜文件不使用yey reduce操作码，单独导入模块的动作也可以在该模块中执行任意代码，因此单独的全局是危险的。</p><p> For example, one can use a  GLOBAL to import the exec function from  __builtins__ and then  REDUCE to call  exec with an arbitrary string containing Python code to run. Likewise for other sensitive functions like  os.system and  subprocess.call. Python programs can optionally limit this behavior by defining a custom unpickler; however, none of the ML libraries we inspected do so. Even if they did, these protections can almost always be circumvented; there is no guaranteed way to safely load untrusted pickle files, as is highlighted in  this admonition from the official Python 3.9 Pickle documentation:</p><p> 例如，人们可以使用全局从__builtins__导入exec函数，然后用包含python代码的任意字符串缩小到调用exec。同样，对于像OS.System和subprocess.call等其他敏感函数。 Python程序可以选择通过定义自定义unpickler来限制此行为;但是，我们检查的ML库都不是这样做。即使他们这样做，这些保护几乎总是被规避;没有保证安全的方法可以安全地加载不受信任的泡沫文件，从官方Python 3.9泡菜文档中突出显示，如此突出显示：</p><p> It is possible to construct malicious pickle data which will  execute arbitrary code during unpickling. Never unpickle data that could have come from an untrusted source, or that could have been tampered with.</p><p> 可以构建恶意泡菜数据，该数据将在未划分期间执行任意代码。从来没有解开可能来自不受信任的来源的数据，或者这可能被篡改。</p><p> Consider signing data with  hmac if you need to ensure that it has not been tampered with.</p><p> 如果需要确保它没有被篡改，请使用HMAC签名数据。</p><p> Safer serialization formats such as  JSON may be more appropriate if you are processing untrusted data.</p><p> 如果您正在处理不受信任的数据，更安全的序列化格式（如JSON）可能更合适。</p><p> We are not aware of any ML file formats that include a checksum of the model, either   † Some libraries like Tensorflow  do have the capability to verify download checksums, however,  verification is disabled by default and based upon a checksum embedded in the filename, which can be easily forged..</p><p> 我们不知道包含模型的校验和的任何ML文件格式，无论是Tensorflow等一些库都有能力验证下载校验和，默认情况下是否禁用验证，并基于嵌入文件名中的校验和可以轻松伪造..</p><p> The dangers of Python pickling have been known to the computer security community for  quite some  time.</p><p> 电脑安全社区已知Python酸洗的危险是一段时间。 </p><p>  Fickling has its own implementation of a Pickle Virtual Machine (PM), and it is safe to run on potentially malicious files, because it symbolically executes code rather than overtly executing it.</p><p>Fickling拥有自己的泡菜虚拟机（PM）的实现，并且在可能的恶意文件上运行是安全的，因为它象征性地执行代码而不是公开执行它。</p><p> Let’s see how Fickling can be used to reverse engineer a pickle file by creating an innocuous pickle containing a serialized list of basic Python types:</p><p> 让我们看，通过创建一个无数的泡菜，通过创建包含序列化的基本Python类型列表的无序泡菜来逆转工程师：</p><p> $ python3 -c &#34;import sys, pickle; \ sys.stdout.buffer.write(pickle.dumps([1, ‘2’, {3: 4}]))&#34; \ &gt; simple_list.pickle$ python3 -m pickle simple_list.pickle[1, ‘2’, {3: 4}]</p><p> $ python3 -c＆＃34;进口系统，泡菜; \ sys.stdout.buffer.write（pickle.dumps（[1，'2'，{3：4}]）））＆＃34; \＆gt; simple_list.pickle $ python3 -m pickle simple_list.pickle [1，'2'，{3：4}]</p><p> Running  fickling on the pickle file will decompile it and produce a human-readable Python program equivalent to what code would be run by the real PM during deserialization:</p><p> 在泡沫文件上运行Fickling将对它进行反编译，并生成相当于在反序列化期间由真实PM运行的代码的人类可读的Python程序：</p><p>  In this case, since it’s a simple serialized list, the code is neither surprising nor very interesting. By passing the  --trace option to Fickling, we can trace the execution of the PM:</p><p>  在这种情况下，由于它是一个简单的序列化列表，代码既不令人惊讶也不是非常有趣的。通过将--trace选项传递到Fickling，我们可以追踪PM的执行：</p><p> $ fickling --trace simple_list.picklePROTOFRAMEEMPTY_LIST Pushed []MEMOIZE Memoized 0 -&gt; []MARK Pushed MARKBININT1 Pushed 1SHORT_BINUNICODE Pushed &#39;2&#39;MEMOIZE Memoized 1 -&gt; &#39;2&#39;EMPTY_DICT Pushed {}MEMOIZE Memoized 2 -&gt; {}BININT1 Pushed 3BININT1 Pushed 4SETITEM Popped 4 Popped 3 Popped {} Pushed {3: 4}APPENDS Popped {3: 4} Popped &#39;2&#39; Popped 1 Popped MARKSTOP result = [1, &#39;2&#39;, {3: 4}] Popped [1, &#39;2&#39;, {3: 4}]</p><p> $ fickling --trace simple_list.pickleprotoframempty_list推送[]备忘录Memoized 0  - ＆gt; []标记推动的MarkBinInt1推动1short_binunicode推动＆＃39; 2＆＃39; Memoize Memoized 1  - ＆gt; ＆＃39; 2＆＃39; empty_dict按{} Memoize Memoized 2  - ＆gt; {} BinInt1按3binint1按下4触发4个POPPED 3 POPPED {}按{3：4}追加{3：4} POPPED＆＃39; 2＆＃39;弹出1个popped markstop结果= [1，＆＃39; 2＆＃39;，{3：4}]弹出[1，＆＃39; 2＆＃39;，{3：4}]</p><p> You can run Fickling’s static analyses to detect certain classes of malicious pickles by passing the  --check-safety option:</p><p> 您可以通过传递--Check-Safety选项来运行Fickling的静态分析来检测某些类别的恶意泡菜： </p><p> $ fickling --check-safety simple_list.pickleWarning: Fickling failed to detect any overtly unsafe code,but the pickle file may still be unsafe.Do not unpickle this file if it is from an untrusted source!</p><p>$ fickling  - 检查 - 安全simple_list.picklewarning：fickling无法检测到任何明显的不安全的代码，但泡沫文件可能仍然是不安全的。如果它来自不受信任的来源，则不会解开此文件！</p><p> What would it look like if the pickle file  were malicious? Well, why not make one! We can do that by injecting arbitrary Python code into the pickle file:</p><p> 如果泡菜文件是恶意的，它会看起来像什么？好吧，为什么不制作一个！我们可以通过将任意Python代码注入泡沫文件来实现：</p><p> $ fickling --inject &#39;print(&#34;Hello World!&#34;)&#39; testpickle &gt; testpickle.pwn3d$ python3 -m pickle testpickle.pwn3dHello World![1, &#39;2&#39;, {3: 4}]</p><p> $ fickling  - ＆＃39;打印（＆＃34;你好世界！＆＃34;）＆＃39; testpickle＆gt; testpickle.pwn3d $ python3-m pickle testpickle.pwn3dhello world！[1，＃39; 2＆＃39;，{3：4}]</p><p>    $ fickling --check-safety testpickle.pwn3dCall to `eval(&#39;print(&#34;Hello World!&#34;)&#39;)` is almost certainlyevidence of a malicious pickle file</p><p>    $ fickling  - 检查 - 安全testpickle.pwn3dcall到`eval（＆＃39;打印（＆＃34; hello world！＆＃34;）`几乎肯定是一个恶意泡菜文件</p><p> Fickling can also be used as a Python library, and has a programmatic interface to decompile, analyze, modify, and synthesize Pickle files. It is  open source, and you can install it by running:</p><p> Fickling也可以用作Python库，并具有分解，分析，修改和综合泡沫文件的程序化接口。它是开源，您可以通过运行安装它：</p><p>    Since the majority of ML models use pickling extensively, there is a potential attack surface for weight/neuron perturbations on models, including fault injections, live trojans, and weight poisoning attacks among others. For example, during deserialization, code injected into the pickle could programmatically make changes to the model depending on the local environment, such as time of day, timezone, hostname, system locale/language, or IP address. These changes could be subtle, like a bitflip attack, or more overt, like injecting arbitrary delays in the deserialization to deny service.</p><p>    由于ML模型的大多数ML模型广泛使用酸洗，因此有一个潜在的攻击表面，用于对模型的重量/神经元扰动，包括故障注射，活的特洛伊木马和体重中毒攻击等。例如，在反序列化期间，注入到泡菜中的代码可以根据本地环境以编程方式进行编程更改，例如日常环境，时区，主机名，系统语言环境/语言或IP地址。这些变化可能是微妙的，如比特闪光攻击，或者更明显，如在反序列化中注入任意延迟到拒绝服务。</p><p> Fickling has  a proof-of-concept based on the official PyTorch tutorial that injects arbitrary code into an existing PyTorch model. This example shows how loading the generated model into PyTorch will automatically list all of the files in the current directory (presumably containing proprietary models and code) and exfiltrate them to a remote server.</p><p> Fickling基于官方Pytorch教程的概念证明，该教程将任意代码注入现有的Pytorch模型。此示例显示如何将生成的模型加载到Pytorch中，将自动列出当前目录中的所有文件（可能包含专有模型和代码），并将其删除到远程服务器。 </p><p> This is concerning for services like Microsoft’s  Azure ML, which supports running user-supplied models in their cloud instances. A malicious, “Fickled” model could cause a denial of service, and/or achieve remote code execution in an environment that Microsoft likely assumed would be proprietary. If multiple users’ jobs are not adequately compartmentalized, there is also the potential of exfiltrating other users’ proprietary models.</p><p>这有关Microsoft的Azure ML等服务，它支持在云实例中运行用户提供的模型。恶意的“Fickled”模型可能导致拒绝服务，和/或在微软可能假定的环境中实现远程代码执行。如果多个用户的作业没有充分划分，则还有潜在的抵抗其他用户的专有模型。</p><p>   The ideal solution is to avoid pickling altogether. There are several different encodings—JSON, CBOR, ProtoBuf—that are much safer than pickling and are sufficient for encoding these models. In fact, PyTorch already includes  state_dict and  load_state_dict functions that save and load model weights into a dictionary, which can be easily serialized into a JSON format. In order to fully load the model, the model structure (how many layers, layer types,  etc.) is also required. If PyTorch implements serialization/deserialization methods for the model structure, the entire model can be much more safely encoded into JSON files.</p><p>   理想的解决方案是避免完全酸洗。有几种不同的编码-JSON，CBOR，PROTOBUF  - 比酸洗更安全，并且足以编码这些模型。实际上，Pytorch已经包括state_dict和load_state_dict函数，将和加载模型权重放入字典中，这可以很容易地序列化为JSON格式。为了完全加载模型，模型结构（也需要多层，层类型等）。如果Pytorch实现了模型结构的序列化/反序列化方法，则整个模型可以更安全地编码到JSON文件中。</p><p> Outside of PyTorch, there are other frameworks that avoid using pickle for serialization. For example, the  Open Neural Network Exchange (ONNX) aims to provide a universal standard for encoding AI models to improve interoperability. The ONNX specification uses ProtoBuf to encode their model representations.</p><p> 在Pytorch之外，还有其他框架避免使用泡菜进行序列化。例如，开放式神经网络交换（ONNX）旨在为编码AI模型提供通用标准以改善互操作性。 ONNX规范使用protobuf来编码其模型表示。</p><p>  We reported our concerns about sharing ML models to the PyTorch and PyTorch Hub maintainers on January 25th and received a reply two days later. The maintainers said that they will consider adding additional warnings to PyTorch and PyTorch Hub. They also explained that models submitted to PyTorch Hub are vetted for quality and utility, but the maintainers do not perform any background checks on the people publishing the model or carefully audit the code for security before adding a link to the GitHub repository on the PyTorch Hub indexing page. The maintainers do not appear to be following our recommendation to switch to a safer form of serialization; they say that the onus is on the user to ensure the provenance and trustworthiness of third party models.</p><p>  我们向1月25日向Pytorch和Pytorch Hub维护者分享了ML模型并在两天后收到了回复。维护者认为他们会考虑向Pytorch和Pytorch集线器添加其他警告。他们还解释说，提交给Pytorch集线器的模型是用于质量和实用程序的审查，但维护者不对发布模型的人员或仔细审核用于安全性的人的人员进行任何背景检查，请在添加到Pytorch集线器上的Github存储库中的链接之前索引页面。维护者似乎遵循我们的建议，以切换到更安全的序列化形式;他们说，ONU是在用户身上，以确保第三方模型的出处和可靠性。</p><p> We do not believe this is sufficient, particularly in the face of increasingly prevalent typosquatting attacks (see those of  pip and  npm). Moreover, a supply chain attack could very easily inject malicious code into a legitimate model, even though the associated source code appears benign. The only way to detect such an attack would be to manually inspect the model using a tool like Fickling.</p><p> 我们不相信这是足够的，特别是在面对越来越普遍的粉碎攻击（见PIP和NPM）。此外，即使关联的源代码出现良性，供应链攻击可能会将恶意代码很容易地注入合法模型。检测此类攻击的唯一方法是使用像Fickling这样的工具手动检查模型。</p><p>  As ML continues to grow in popularity and the majority of practitioners rely on generalized frameworks, we must ensure the frameworks are secure. Many users do not have a background in computer science, let alone computer security, and may not understand the dangers of trusting model files of unknown provenance. Moving away from pickling as a form of data serialization is relatively straightforward for most frameworks and is an easy win for security. We relish the thought of a day when pickling will no longer be used to deserialize untrusted files. In the meantime, try out Fickling and let us know how you use it!</p><p>  由于ML继续普及，大多数从业者依赖于广义框架，我们必须确保框架是安全的。许多用户在计算机科学中没有背景，更不用说计算机安全，并且可能无法理解信任模型文件的未知出处的危险。随着大多数框架的数据序列化形式而远离酸洗，对于大多数框架来说是相对简单的，并且可以轻松获胜。我们在酸洗将不再用于将不受信任的文件进行反级化时享受一天的想法。与此同时，尝试耗尽，让我们知道如何使用它！</p><p>  Many thanks goes out to our team for their hard work on this effort: Sonya Schriner, Sina Pilehchiha, Jim Miller, Suha S. Hussain, Carson Harmon, Josselin Feist, and Trent Brunson</p><p>  非常感谢我们的团队努力解决这项工作：Sonya Schriner，Sina Pulchiha，Jim Miller，Suha S. Hussain，Carson Harmon，Josselin Feist和Trent Brunson </p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://blog.trailofbits.com/2021/03/15/never-a-dill-moment-exploiting-machine-learning-pickle-files/">https://blog.trailofbits.com/2021/03/15/never-a-dill-moment-exploiting-machine-learning-pickle-files/</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/机器/">#机器</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/machine/">#machine</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/模型/">#模型</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/分享/">#分享</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy;2012-2021 diglog.com </div></div></body></html>