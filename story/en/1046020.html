<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>缓存管理经验教训 Cache Management Lessons Learned</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">Cache Management Lessons Learned<br/>缓存管理经验教训 </h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2021-01-24 03:34:23</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2021/1/3d33075e736db3cc8886c279e2b6e559.png"><img src="http://img2.diglog.com/img/2021/1/3d33075e736db3cc8886c279e2b6e559.png" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>We’re coming up on the tenth anniversary of LMDB, and I’ve been thinking back to the bad old days of cache tuning that we struggled with, before LMDB’s advent. As noted in the  LMDB design doc tuning caches used to be a major pain point in administering OpenLDAP. It was a constant juggling act due to the presence of at least 3 different layers of caching being in effect, each with different space and time characteristics. While we’ve been free of this burden for nearly 10 years now, we gained a lot of hard-won knowledge about caching in the years before that. Most of that knowledge is no longer necessary for operating OpenLDAP, but there’s still a lot of software in use today that tries to manage their own caches, and the lessons we learned are still valuable in those other contexts.</p><p>我们即将迎来LMDB十周年纪念日，而我一直在回想起LMDB出现之前我们一直在努力的缓存调整的糟糕年代。如LMDB设计中所述，文档调整缓存曾经是管理OpenLDAP的主要难题。由于存在至少3个不同的缓存层（每个缓存层具有不同的时空特性），因此这是一种持续的变戏法行为。尽管我们已经摆脱了近十年的负担，但在此之前的几年中，我们获得了很多来之不易的缓存知识。大部分知识不再是操作OpenLDAP所必需的，但是当今仍在使用许多试图管理自己的缓存的软件，并且我们在其他情况下所汲取的教训仍然很有价值。</p><p> The  slapd-ldbm,  slapd-bdb, and slapd-hdb backends all used their own application-level entry caches to optimize read performance. These caches were essential because the underlying DB libraries (gdbm, bdb, ndbm, etc.) performed quite slowly on their own. The same cache management policy was used on each,  LRU: Least Recently Used. This is one of the simplest to understand and simplest to implement, and it’s widely documented.</p><p> slapd-ldbm，slapd-bdb和slapd-hdb后端都使用它们自己的应用程序级条目缓存来优化读取性能。这些缓存非常重要，因为基础数据库库（gdbm，bdb，ndbm等）本身执行得很慢。每个LRU：最近最少使用了相同的缓存管理策略。这是最容易理解和最容易实现的方法之一，并且已被广泛记录。</p><p> The typical implementation in C uses a doubly-linked list. Cached elements are added at one end of the list when they’re used, and dropped from the other end of the list when the cache size limit is reached. Any cached elements that are referenced again are pulled out of their spot in the middle of the list and added back onto the end.</p><p> C语言中的典型实现使用双链表。使用缓存元素时，它们会在列表的一端添加，而在达到缓存大小限制时会从列表的另一端删除。再次引用的所有缓存元素将从列表中间的位置拉出，然后添加回末尾。</p><p> It turns out that this data structure performs very poorly with higher levels of concurrency; the head and tail pointers of the list must be mutex protected, as well as the pointers within each cache element. And every read operation in the server actually expands to a write operation in the cache, pulling an entry out of its old position and tacking it on to its new position.</p><p> 事实证明，这种数据结构在较高的并发级别下表现非常差。列表的头和尾指针以及每个缓存元素中的指针必须是互斥保护的。服务器中的每个读取操作实际上都会扩展为缓存中的写入操作，从而将条目从其旧位置拉出并固定到新位置。</p><p> One of the major improvements we made to slapd-bdb/hdb caching was to replace this LRU mechanism with  CLOCK in   2006.</p><p> 我们对slapd-bdb / hdb缓存进行的一项重大改进是在2006年用CLOCK取代了这种LRU机制。</p><p> Logically it is the same strategy as LRU, but the implementation uses a circularly linked list. Instead of popping pages out of their position and tacking them onto the end, there is a clock-hand pointer that points to the current head/tail, and a Referenced flag for each entry. When an entry is referenced, the hand is just advanced to the next entry in the circle. This approach drastically reduces the locking overhead in reading and updating the cache, removing a major bottleneck in multi-threaded operation.</p><p> 从逻辑上讲，它与LRU是相同的策略，但是实现使用循环链接列表。不是将页面弹出其位置并将其固定到末尾，而是有一个指向当前头/尾的时针指针，以及每个条目的“已引用”标志。当引用一个条目时，手将前进到圆圈中的下一个条目。这种方法极大地减少了读取和更新缓存时的锁定开销，从而消除了多线程操作中的主要瓶颈。</p><p> Important Lesson #1: If you’re using plain LRU in your code, stop. Use CLOCK instead.</p><p> 重要第一课：如果您在代码中使用普通LRU，请停止。请改用CLOCK。 </p><p> Aside from classical LRU being terrible for multi-threaded performance, it has some pathological cases where it cannot offer any performance benefit at all. In particular, if the cache has a maximum size of N entries, and a sequence of operations arrive that touch M &gt; N entries, the cache effectiveness goes to zero.</p><p>除了经典的LRU难以实现多线程性能外，它在某些病理情况下根本无法提供任何性能优势。特别地，如果高速缓存具有N个条目的最大大小，并且到达操作序列，则触摸M＞ M。 N个条目，缓存效率变为零。</p><p> For example, given a cache with max size 4, and a request that accesses 5 entries A, B, C, D, and E, the cache will grow as:</p><p> 例如，给定一个最大大小为4的缓存，以及访问5个条目A，B，C，D和E的请求，该缓存将增长为：</p><p>  At every step an entry is added to the cache. Since there are no repeats in the sequence, none of the cached entries are reused while executing the sequence. At the last step, because the cache is full, entry A is evicted to make room for entry E to be added.</p><p>  在每个步骤，条目都会添加到缓存中。由于序列中没有重复，因此在执行序列时不会重用任何缓存的条目。在最后一步，由于缓存已满，因此驱逐了条目A，以便为要添加的条目E腾出空间。</p><p> If the operation accessing this sequence of 5 entries is repeated, the cache contents will become</p><p> 如果重复访问此5个条目的序列的操作，则缓存内容将变为</p><p> C D E A D E A B E A B C A B C D B C D E</p><p> C D E A D E A B E A B C A B C D B C D E</p><p> None of the cache’s contents will ever be reused to service the request, because the next entry being requested is always the one that was just evicted a moment before. In these situations the cache is just a waste of time and memory.</p><p> 缓存的任何内容都不会再用于服务请求，因为被请求的下一个条目始终是刚才被逐出的条目。在这些情况下，缓存只是浪费时间和内存。</p><p> This is a major weakness in LRU and its related cache management schemes. One of the solutions proposed to this problem is the  Clock-Pro algorithm.</p><p> 这是LRU及其相关的缓存管理方案的主要弱点。针对此问题提出的解决方案之一是Clock-Pro算法。 </p><p>  One of the difficulties in working with these experimental algorithms is that they tend to be developed in the context of managing virtual memory pages in a demand-paged operating system kernel. A kernel has many low level high performance facilities at its disposal that have no equivalent in user-level application space, or whose usage is more expensive in user-land. In the case of Clock-Pro, it may have worked in kernel space but adapting it to user level was a very poor fit.</p><p>使用这些实验算法的困难之一是它们往往是在管理按需分页的操作系统内核中的虚拟内存页的上下文中开发的。内核拥有许多低级的高性能设施，这些设施在用户级应用程序空间中不具有等效功能，或者在用户领域的使用成本较高。在Clock-Pro的情况下，它可能已经在内核空间中工作，但是使其适应用户级别非常不适合。</p><p> Eventually a simpler solution was arrived at: just stop adding entries to the cache if the number of entries accessed in the request exceeds the maximum size of the cache. This allowed the cache effectiveness to approach 100% (every entry in the cache gets reused) and was a huge performance boost for these pathological operations. To illustrate with the same cache and operations as in the previous example, the cache grows almost the same as before:</p><p> 最终找到了一个更简单的解决方案：如果在请求中访问的条目数超过了缓存的最大大小，则停止将条目添加到缓存中。这使得缓存效率接近100％（缓存中的每个条目都被重用），并且极大地提高了这些病理操作的性能。为了说明与上一示例相同的缓存和操作，缓存的增长与之前几乎相同：</p><p>  But when we process entry E, we discard it instead of caching it. Then when the sequence is repeated, entries A, B, C, and D are already in the cache and are processed at basically zero cost. We simply pay the cost of fetching entry E again. In this example, the repeated operation runs 5x faster than the uncached operation.</p><p>  但是，当我们处理条目E时，我们将其丢弃而不是进行缓存。然后，当重复序列时，条目A，B，C和D已经在高速缓存中，并且以基本上为零的成本进行处理。我们只需支付再次获取条目E的费用。在此示例中，重复操作的运行速度比未缓存的操作快5倍。</p><p> This simple optimization is one that works because we have higher level knowledge about the request being performed. It’s an advantage that we gave up, in adopting LMDB and leaving all cache management to the OS. (Advantages like these are reasons why most DB engineers claim that DBs can manage caches better than OSs can.) In practice, memory management in systems like  Linux has advanced beyond simple LRU, with features adopted from Clock-Pro and other designs.</p><p> 这种简单的优化之所以可行，是因为我们对正在执行的请求有更高的了解。在采用LMDB并将所有缓存管理留给操作系统方面，我们放弃了这一优势。 （像这样的优势是大多数数据库工程师声称数据库可以比操作系统更好地管理缓存的原因。）实际上，Linux等系统中的内存管理已经超越了简单的LRU，并具有Clock-Pro和其他设计所采用的功能。</p><p> So at least on Linux, cache performance hasn’t been an issue with LMDB. It’s noticeably worse on Windows, as is memory management in general on Windows, but obviously Windows is not a high performance platform to begin with.</p><p> 因此，至少在Linux上，LMDB并不是缓存性能问题。 Windows上的情况明显更糟，Windows上的内存管理也是如此，但是显然Windows并不是一开始的高性能平台。</p><p> Important Lesson #2: Exotic solutions aren’t always all they’re cracked up to be; take a step back and you may see a simpler option.</p><p> 重要的第二课：异国情调的解决方案并不总是全部被破解。退后一步，您可能会看到一个更简单的选择。</p><p> Despite the weaknesses of LRU in some rare corner cases, it still performs well in general. This is especially true for hierarchically structured data, due to the nature of these structures. For example, given a directory tree like this:</p><p> 尽管LRU在某些罕见的极端情况下具有弱点，但总体上仍然表现良好。由于这些结构的性质，对于分层结构的数据尤其如此。例如，给定这样的目录树： </p><p>    Assuming the cache size limit is 4, then a lookup for cn=Bob,ou=people,dc=example,dc=com will touch these entries and cache them:</p><p>假设缓存大小限制为4，则对cn = Bob，ou = people，dc = example，dc = com的查找将触摸以下条目并将其缓存：</p><p>  The LRU policy will naturally evict the cn=Carol entry, while preserving the other entries. So with tree structured data you will always get the maximum possible effectiveness from an LRU-based cache. This same principle applies to the B+trees used internally in LMDB. Because tree traversals always start at a tree root, the tree root will always be hot in the cache, and frequently used branches will also stay hot in the cache, with only the leaves being cold. So the natural access pattern of tree-oriented data structures inherently maximizes the effectiveness of system caches, without any additional effort required. This is one reason why OpenLDAP is still the world’s fastest, most efficient distributed database today, while requiring no cache tuning.</p><p>  LRU策略自然会退出cn = Carol条目，同时保留其他条目。因此，使用树状结构的数据，您将始终从基于LRU的缓存中获得最大的效率。相同的原理适用于LMDB内部使用的B +树。因为树遍历始终从树的根开始，所以树的根在缓存中将始终是热的，而经常使用的分支在缓存中也将保持热，只有叶子是冷的。因此，面向树的数据结构的自然访问模式本质上可以最大程度地提高系统缓存的效率，而无需任何额外的工作。这就是为什么OpenLDAP仍然是当今世界上最快，最高效的分布式数据库而无需进行缓存调整的原因之一。</p><p>  A lot of intensive work is still ongoing in designing optimal caching algorithms. Even if you have a great design, realizing it in a good implementation can still be a difficult challenge. (Looking at the commit history of the old caching code in OpenLDAP gives a hint of just how much effort it takes to get it right.) For locally stored data the best cache management strategy these days is “let the OS do it for you.”</p><p>  在设计最佳缓存算法方面，大量的工作仍在进行中。即使您拥有出色的设计，但要在良好的实现中实现它仍然是一个艰巨的挑战。 （通过查看OpenLDAP中旧缓存代码的提交历史，可以看出需要花多少精力才能正确处理。）对于本地存储的数据，如今最好的缓存管理策略是“让操作系统为您完成。 ” </p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://symas.com/cache-management-lessons-learned/">https://symas.com/cache-management-lessons-learned/</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/缓存/">#缓存</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/管理/">#管理</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/分享/">#分享</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy; 2020 diglog.com </div></div></body></html>