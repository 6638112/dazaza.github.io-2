<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>GPT-3。它学会了编码（以及博客和争论）GPT-3. It Has Learned to Code (and Blog and Argue)</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">GPT-3. It Has Learned to Code (and Blog and Argue)<br/>GPT-3。它学会了编码（以及博客和争论）</h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2020-11-24 23:54:56</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2020/11/d57da4f1c547a67db59eafa6628cbf0f.jpg"><img src="http://img2.diglog.com/img/2020/11/d57da4f1c547a67db59eafa6628cbf0f.jpg" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>This summer, an artificial intelligence lab in San Francisco called OpenAI unveiled a technology several months in the making. This new system, GPT-3, had spent those months learning the ins and outs of natural language by analyzing thousands of digital books, the length and breadth of Wikipedia, and nearly a trillion words posted to blogs, social media and the rest of the internet.</p><p>今年夏天，位于旧金山的一家名为OpenAI的人工智能实验室在数月之内推出了一项技术。这个新系统GPT-3花费了几个月的时间来分析自然语言的来龙去脉，方法是分析数千本数字书籍，Wikipedia的长度和广度以及将近一万亿个单词发布到博客，社交媒体和其他互联网。</p><p> Mckay Wrigley, a 23-year-old computer programmer from Salt Lake City, was one of the few invited to tinker with the system, which uses everything it has learned from that vast sea of digital text to generate new language on its own. Mr. Wrigley wondered if it could imitate public figures — write like them, perhaps even chat like them.</p><p> 来自盐湖城的23岁的计算机程序员Mckay Wrigley是受邀参加该系统修补工作的少数人之一，该系统利用从浩瀚的数字文本中学到的一切知识自行产生新的语言。箭牌先生想知道它是否可以模仿公众人物-像他们一样写作，甚至像他们一样聊天。</p><p> One of his experiments involved a pop psychologist, Scott Barry Kaufman. The system took in Mr. Kaufman’s name and a topic for discussion: creativity. Then, when asked “How do we become more creative?” GPT-3 responded instantly:</p><p> 他的一项实验涉及一名流行心理学家斯科特·巴里·考夫曼（Scott Barry Kaufman）。该系统采用了考夫曼先生的名字和一个讨论话题：创造力。然后，当被问到“我们如何变得更有创造力？” GPT-3立即做出了回应：</p><p> I think creative expression is a natural byproduct of growing up in a diverse world. The more diverse the world is, the more you get exposed to different people, to different opportunities, to different places and to different challenges. And the more diverse that is, the more likely you’ll be to be able to put the dots together to form something new. And in many ways, I think if you want to be creative, you have to go for it. If you want to be a writer, you have to write, if you want to be a musician, you have to create music, if you want to be a comedian, you have to create comedy, and the more you create, the more likely it is that you’ll stumble onto some interesting stuff.</p><p> 我认为创意表达是在多元化世界中成长的自然产物。世界越多样化，您越会暴露给不同的人，不同的机会，不同的地方和不同的挑战。而且，多样性越多，您越有可能将各个点放在一起形成新的事物。从很多方面来说，我认为如果您想发挥创造力，就必须努力。如果要成为作家，就必须写作；如果要成为音乐家，就必须创作音乐；如果要成为喜剧演员，就必须创作喜剧片；创作的次数越多，可能性就越大。就是您会偶然发现一些有趣的东西。</p><p> Later, when Mr. Wrigley  posted the paragraph on Twitter, somebody looped in the real Scott Barry Kaufman. He was stunned. “ It definitely sounds like something I would say,” the real Mr. Kaufman tweeted, later adding, “ Crazy accurate A.I.”</p><p> 后来，当瑞格利先生在Twitter上发布该段落时，有人在真正的斯科特·巴里·考夫曼中循环。他被惊呆了。真正的考夫曼在推特上写道：“这听起来确实像我会说的。”后来又补充道，“疯狂准确的人工智能。”</p><p> In the weeks since its arrival, GPT-3 has spawned dozens of other experiments that raise the eyebrows in much the same way. It  generates tweets,  pens poetry,  summarizes emails,  answers trivia questions,  translates languages and  even writes its own computer programs, all with very little prompting. Some of these skills caught even the experts off guard.</p><p> 在GPT-3抵达后的几周内，它产生了数十项其他实验，这些实验几乎以相同的方式引起了人们的注意。它生成推文，写诗，总结电子邮件，回答琐事问题，翻译语言甚至编写自己的计算机程序，而几乎没有提示。其中一些技能甚至使专家措手不及。</p><p>  For many artificial intelligence researchers, it is an unexpected step toward machines that can understand the vagaries of human language — and perhaps even tackle other human skills.</p><p>  对于许多人工智能研究人员而言，这是朝着能够理解人类语言变幻莫测的机器迈出的出乎意料的一步，甚至可能解决其他人类技能。</p><p> “It is surprising to me, and to a lot of people,” said Melanie Mitchell, an A.I. researcher at the Santa Fe Institute, an independent lab in New Mexico, who is among those experimenting with the system. “It is hard to figure out exactly what this thing is doing.”</p><p>人工智能的梅兰妮·米切尔（Melanie Mitchell）说：“这令我和很多人感到惊讶。新墨西哥州的一个独立实验室圣塔菲研究所的研究员，正在尝试使用该系统。 “很难确切地知道这件事在做什么。”</p><p> GPT-3 is far from flawless. It often spews biased and toxic language. And if you ask for 10 paragraphs in the style of Scott Barry Kaufman, it might give you five that are convincing — and five others that are not. When Mr. Kaufman actually chatted with his A.I. doppelgänger, he was not nearly as impressed as he was at first:</p><p> GPT-3并非完美无缺。它经常会产生偏见和有毒的语言。而且，如果您要求使用Scott Barry Kaufman风格的10个段落，则可能会给您五个令人信服的内容，而其他五个则不具有说服力。当考夫曼先生实际上与他的人工智能聊天时doppelgänger，他没有起初的印象深刻：</p><p> “Scott Barry Kaufman”: Nope, you should know. You are the one who knows what imagination is. What do you think it is?</p><p> “斯科特·巴里·考夫曼”：不，你应该知道。您是知道想象力的人。你认为那是什么？</p><p> But even this looked like real conversation. And notably, it showed what the system could do entirely on its own, without extra coding or fine-tuning.</p><p> 但是，即使这看起来像是真实的对话。尤其值得注意的是，它显示了系统可以完全自己完成的工作，而无需进行额外的编码或微调。</p><p> GPT-3 is the culmination of several years of work inside the world’s leading artificial intelligence labs, including OpenAI, an independent organization backed by  $1 billion dollars in funding from Microsoft, as well as labs at Google and Facebook. At Google, a similar system  helps answer queries on the company’s search engine.</p><p> GPT-3是在全球领先的人工智能实验室中进行数年工作的结晶，其中包括OpenAI，这是一个独立组织，得到了Microsoft的10亿美元资金的支持，以及Google和Facebook的实验室。在Google，类似的系统可帮助回答公司搜索引擎上的查询。</p><p> These systems — known as  universal language models — can help power a wide range of tools, like services that automatically summarize news articles and “chatbots” designed for  online conversation. So far, their impact on real-world technology has been small. But GPT-3 — which learned from a far larger collection of online text than previous systems — opens the door to a wide range of new possibilities, such as software that can speed the development of new smartphone apps, or chatbots that can converse in far more human ways than past technologies.</p><p> 这些系统（称为通用语言模型）可以帮助提供各种工具，例如自动汇总新闻文章的服务以及为在线对话设计的“聊天机器人”。到目前为止，它们对实际技术的影响很小。但是GPT-3（它从比以前的系统更大的在线文本集合中学习）为许多新的可能性打开了大门，例如可以加速新智能手机应用程序开发的软件，或者可以在很长时间内进行交流的聊天机器人。比过去的技术更人性化。</p><p> As software designers, entrepreneurs, pundits and artists explore this system, each new experiment stokes an already heated debate over how powerful this breed of technology will ultimately be. While some say it may be a path toward truly intelligent machines, others argue that these experiments, while endlessly fascinating, are also misleading.</p><p> 当软件设计师，企业家，专家和艺术家探索该系统时，每个新实验都引发了关于该技术最终将具有多强大的激烈辩论。尽管有些人说这可能是通往真正智能机器的道路，但另一些人则认为，尽管这些实验令人着迷，但它们也具有误导性。</p><p> “It is very fluent,” said Mark Riedl, a professor and researcher at the Georgia Institute of Technology. “It is very articulate. It is very good at producing reasonable-sounding text. What it does not do, however, is think in advance. It does not plan out what it is going to say. It does not really have a goal.”</p><p>乔治亚理工学院的教授兼研究员马克·里德尔说：“这非常流利。” “它非常清晰。它非常擅长产生听起来合理的文本。但是，它没有做的事就是事先考虑。它没有计划要说什么。它确实没有目标。”</p><p>  Jordan Singer is a product designer at Square, the Silicon Valley mobile-payments company. He helps design the company’s smartphone apps, building the graphics, menus, buttons and other widgets that define an app’s look and feel. When he heard about GPT-3, he wondered if this automated system could do his job.</p><p>  Jordan Singer是硅谷移动支付公司Square的产品设计师。他帮助设计公司的智能手机应用程序，构建图形，菜单，按钮和其他定义应用程序外观的小部件。当他听说GPT-3时，他想知道这种自动化系统是否能胜任其工作。</p><p> He fed the system a simple description of a smartphone app, and the computer code needed to create the app. The description was in plain English. The code was built inside Figma, a specialized design tool used by professionals like Mr. Singer.</p><p> 他向系统提供了一个智能手机应用程序的简单描述，以及创建该应用程序所需的计算机代码。描述用简单的英语。该代码内置在Figma内，Figma是Singer等专业人员使用的专用设计工具。</p><p> He did this a few more times, feeding the system several more English-language descriptions alongside the matching Figma code. And when he was done, GPT-3 could write such code on its own.</p><p> 他做了几次，向系统提供了更多的英语描述以及匹配的Figma代码。完成后，GPT-3可以自己编写此类代码。</p><p> If he described a simple app for posting and viewing photos as a user would on Instagram, the system generated the code needed to build it. This code was sometimes flawed. But typically, if Mr. Singer made just a tweak or two, it worked as he wanted. “It’s not absolutely perfect,” he said. “But it is very, very close.”</p><p> 如果他描述了一个简单的应用程序，就像用户在Instagram上发布和查看照片一样，那么系统会生成构建该应用程序所需的代码。该代码有时存在缺陷。但通常来说，如果辛格先生只做了一两次调整，就可以按他的意愿进行。他说：“这并非绝对完美。” “但是它非常非常接近。”</p><p> This behavior was entirely new, and it surprised even the designers of GPT-3. They had not built GPT-3 to generate computer code, just as they had not built it to write like Mr. Kaufman or generate tweets or translate languages. They had built it to do just one thing: predict the next word in a sequence of words.</p><p> 这种行为是全新的，甚至让GPT-3的设计人员都感到惊讶。他们没有构建GPT-3来生成计算机代码，就像没有构建它那样像Kaufman先生那样编写或生成推文或翻译语言一样。他们建立它只是为了做一件事：预测单词序列中的下一个单词。</p><p>  GPT-3 is what artificial intelligence researchers call a neural network,  a mathematical system loosely modeled on the web of neurons in the brain. This is the same technology that identifies faces in the photos you post to Facebook and recognizes the commands you bark into your iPhone.</p><p>  GPT-3被人工智能研究人员称为神经网络，神经网络是一个松散地建模在大脑神经元网上的数学系统。这与识别发布到Facebook的照片中的面孔并识别输入到iPhone的命令的技术相同。</p><p> A neural network learns such skills by pinpointing patterns in vast amounts of digital data. By analyzing thousands of cat photos, for instance, it can learn to recognize a cat.</p><p>神经网络通过查明大量数字数据中的模式来学习这些技能。例如，通过分析数千张猫的照片，它可以学习识别猫。</p><p> About three years ago, researchers at Google and top labs like OpenAI started designing neural networks that learned from enormous amounts of prose, including unpublished books and Wikipedia articles by the thousands. These universal language models  could be applied not just to one task, like translation, but to many.</p><p> 大约三年前，谷歌和OpenAI等顶级实验室的研究人员开始设计神经网络，该网络从大量散文中学习，包括成千上万的未出版书籍和维基百科文章。这些通用语言模型不仅可以应用于一项任务（例如翻译），而且可以应用于许多任务。</p><p> GPT-3 analyzed digital prose on an unprecedented scale, spending months looking for patterns in huge amounts of text posted to the internet. In this way, it learned to predict the next word in a sequence. If you type a few words into GPT-3, it will keep going, completing your thought with entire paragraphs of text.</p><p> GPT-3以前所未有的规模分析了数字散文，花了几个月的时间寻找发布到互联网上的大量文本的模式。通过这种方式，它学会了预测序列中的下一个单词。如果您在GPT-3中输入几个单词，它将继续进行，并用整段文字完善您的想法。</p><p> But in acquiring this specific skill, it learned much more. During its months of training, GPT-3 identified more than 175 billion parameters — mathematical representations of patterns — in that sea of books, Wikipedia articles and other online texts. These patterns amount to a map of human language: a mathematical description of the way we piece characters together, whether we are writing blogs or coding software programs. Using this map, GPT-3 can perform all sorts of tasks it was not built to do.</p><p> 但是，在掌握这项特定技能时，它学到了很多。在为期几个月的培训中，GPT-3在书海，维基百科文章和其他在线文本中识别出超过1,750亿个参数（模式的数学表示形式）。这些模式相当于一幅人类语言图：无论是编写博客还是编写软件程序，都是对字符进行组合的方式的数学描述。使用此映射，GPT-3可以执行其并非旨在执行的所有任务。</p><p> Before asking GPT-3 to generate new text, you can focus it on particular patterns it may have learned during its training, priming the system for certain tasks. You can feed it descriptions of smartphone apps and the matching Figma code. Or you can show it reams of human dialogue. Then, when you start typing, it will complete the sequence in a more specific way. If you prime it with dialogue, for instance, it will start chatting with you.</p><p> 在要求GPT-3生成新文本之前，您可以将其重点放在其在培训过程中可能学到的特定模式上，为系统完成某些任务做好准备。您可以向其提供智能手机应用程序的描述以及匹配的Figma代码。或者，您可以向其展示大量人类对话。然后，当您开始键入时，它将以更特定的方式完成序列。例如，如果您通过对话来启动它，它将开始与您聊天。</p><p> “It has this emergent quality,” said Dario Amodei, vice president for research at OpenAI. “It has some ability to recognize the pattern that you gave it and complete the story, give another example.”</p><p> OpenAI研究副总裁Dario Amodei说：“它具有这种出众的品质。” “它具有识别您给出的模式并完成故事的能力，再举一个例子。”</p><p> Previous language models worked in similar ways. But GPT-3 can do things that previous models could not, like write its own computer code. And, perhaps more important, you can prime it for specific tasks using just a few examples, as opposed to the thousands of examples and several hours of additional training required by its predecessors. Researchers call this “few-shot learning,” and they believe GPT-3 is the first real example of what could be a powerful phenomenon.</p><p> 以前的语言模型以类似的方式工作。但是GPT-3可以完成以前的模型无法完成的工作，例如编写自己的计算机代码。而且，也许更重要的是，您可以仅使用几个示例就可以将其准备用于特定任务，而之前的示例则需要数千个示例和数小时的额外培训。研究人员将其称为“少量学习”，他们认为GPT-3是第一个可能成为一种强大现象的真实例子。</p><p> “It exhibits a capability that no one thought possible,” said Ilya Sutskever, OpenAI’s chief scientist and a key figure in the rise of artificial intelligence technologies over the past decade. “Any layperson can take this model and provide these examples in about five minutes and get useful behavior out of it.”</p><p>OpenAI的首席科学家，过去十年来人工智能技术兴起的关键人物Ilya Sutskever说：“它展现了前所未有的能力。” “任何外行人都可以采用此模型，并在大约五分钟内提供这些示例，并从中获得有用的行为。”</p><p>   OpenAI plans to sell access to GPT-3 via the internet, turning it into a widely used commercial product, and this year it made the system available to a limited number of beta testers through their web browsers. Not long after, Jerome Pesenti, who leads the Facebook A.I. lab,  called GPT-3 “unsafe,” pointing to sexist, racist and otherwise toxic language the system generated when asked to discuss women, Black people, Jews and the Holocaust.</p><p>   OpenAI计划通过互联网出售对GPT-3的访问权，将其转变为一种广泛使用的商业产品，今年，该公司通过其Web浏览器将该系统提供给有限的beta测试人员。不久之后，领导Facebook AI的Jerome Pesenti被称为GPT-3“不安全”的实验室，指出了系统被要求讨论女性，黑人，犹太人和大屠杀时所产生的性别歧视，种族主义和其他有毒语言。</p><p> With systems like GPT-3, the problem is endemic. Everyday language is inherently biased and often hateful, particularly on the internet. Because GPT-3 learns from such language, it, too, can show  bias and hate. And because it learns from internet text that associates atheism with the words “cool” and “correct” and that pairs Islam with “terrorism,”  GPT-3 does the same thing.</p><p> 对于像GPT-3这样的系统，这个问题很普遍。日常语言天生就有偏见，并且常常令人讨厌，尤其是在互联网上。因为GPT-3从这种语言中学习，所以它也会表现出偏见和仇恨。而且由于GPT-3从互联网文本中学习，该文本将无神论与“酷”和“正确”这两个词联系在一起，并将伊斯兰与“恐怖主义”结合在一起，因此GPT-3的作用相同。</p><p> This may be one reason that OpenAI has shared GPT-3 with only a small number of testers. The lab has built filters that warn that toxic language might be coming, but they are merely Band-Aids placed over a problem that no one quite knows how to solve.</p><p> 这可能是OpenAI仅与少量测试人员共享GPT-3的原因之一。实验室建立了过滤器，警告可能会出现有害的语言，但它们只是解决了一个没人知道如何解决的问题的创可贴。</p><p> “They are doing the right thing by not just publicly releasing GPT-3,” said Allison Koenecke, a Stanford researcher who explores unwanted bias in A.I. systems. “A lot is still up in the air.”</p><p> 斯坦福大学研究人员艾里森·科内克（Allison Koenecke）说：“他们不仅通过公开发布GPT-3，而且在做正确的事。”系统。 “还有很多事情要做。”</p><p> The onus is ultimately on OpenAI to ensure that this behavior remains in check, said Liz O’Sullivan, a vice president with Arthur, a company that helps businesses manage the behavior of artificial intelligence technologies. As it stands, she said, OpenAI is “passing along legal and reputation risk to anyone who might want to use the model in consumer-facing applications.”</p><p> 帮助企业管理人工智能技术行为的Arthur公司副总裁Liz O’Sullivan说，确保这种行为最终受到控制是OpenAI的责任。她说，就目前情况而言，OpenAI正在“将法律和声誉风险传递给任何可能要在面向消费者的应用程序中使用该模型的人。”</p><p> Other experts worry that these language models could help spread disinformation across the internet,  amping up the kind of online campaigns that may have helped sway the 2016 presidential election. GPT-3 points to a future in which we are even less sure if what we are reading is real or fake. That goes for tweets, online conversations, even long-form prose.</p><p> 其他专家担心，这些语言模型可能有助于在互联网上传播虚假信息，从而加剧可能助长2016年总统大选的在线竞选活动。 GPT-3指出了一个未来，在这个未来中，我们甚至不确定所阅读的内容是真实的还是假的。这适用于推文，在线对话，甚至是长篇散文。</p><p> At the end of July, Liam Porr, a student at the University of California, Berkeley, generated several blog posts with GPT-3 and  posted them on the internet, where they were read by 26,000 people. Sixty viewers were inspired to subscribe to the blog, and only a few suspected that the posts were written by a machine.</p><p>7月底，加州大学伯克利分校的学生利亚姆·波尔（Liam Porr）用GPT-3撰写了几篇博客文章，并将其发布到互联网上，有26,000人阅读。启发了60位观众订阅该博客，只有少数几个怀疑帖子是由机器撰写的。</p><p> They were not necessarily gullible people.  One of the blog posts — which argued that you can increase your productivity if you avoid thinking too much about everything you do — rose to the top of the leader board on Hacker News, a site where seasoned Silicon Valley programmers, engineers and entrepreneurs rate news articles and other online content. (“In order to get something done, maybe we need to think less,” the post begins. “Seems counterintuitive, but I believe sometimes our thoughts can get in the way of the creative process.”)</p><p> 他们不一定是易受骗的人。其中一篇博客文章声称，如果您避免对自己所做的事情过多考虑，就可以提高工作效率。该博客文章升至Hacker News排行榜的首位，在此网站上，经验丰富的硅谷程序员，工程师和企业家为新闻评分文章和其他在线内容。 （“开始做某事，也许我们需要减少思考。”这篇文章似乎违反直觉，但我相信有时候我们的想法会阻碍创作过程。）</p><p> But as with most experiments involving GPT-3, Mr. Porr’s is not as powerful as it might seem.</p><p> 但是，与大多数涉及GPT-3的实验一样，波尔先生的力量并不像看起来那样强大。</p><p>  In the mid-1960s, Joseph Weizenbaum, a researcher at the Massachusetts Institute of Technology, built an automated psychotherapist he called ELIZA. Judged from our vantage point in 2020, this chatbot was exceedingly simple.</p><p>  在1960年代中期，麻省理工学院的研究员约瑟夫·魏岑鲍姆（Joseph Weizenbaum）建造了一个自动心理治疗师，他称其为ELIZA。从2020年的优势出发，这个聊天机器人非常简单。</p><p> Unlike GPT-3, ELIZA did not learn from prose. It operated according to a few basic rules defined by its designer. It pretty much repeated whatever you said to it, only in the form of a question. But much to Dr. Weizenbaum’s surprise, many people treated the bot as if it were human, unloading their problems without reservation and taking comfort in the responses.</p><p> 与GPT-3不同，ELIZA没有从散文中学习。它根据其设计师定义的一些基本规则进行操作。无论您说什么，它几乎都以问题的形式重复了。但是令维岑鲍姆博士感到惊讶的是，很多人都把机器人看成是一种机器人，它毫不犹豫地抛弃了他们的问题，并对回应感到满意。</p><p> When dogs and other animals exhibit even small amounts of humanlike behavior, we tend to assume they are more like us than they really are. The same goes for machines, said Colin Allen, a professor at the University of Pittsburgh who explores cognitive skills in both animals and machines. “People get sucked in,” he said, “even if they know they are being sucked in.”</p><p> 当狗和其他动物表现出很少的类人行为时，我们倾向于认为它们比我们更像我们。匹兹堡大学的教授科林·艾伦说，机器也一样。他说：“人们被吸了，即使他们知道自己被吸了。”</p><p> That is part of what is happening with GPT-3. Because it can generate convincing tweets, blog posts and computer code, we read humanity into this digital system — and pay less attention to its limits.</p><p> 这就是GPT-3所发生的事情的一部分。由于它可以产生令人信服的推文，博客文章和计算机代码，因此我们将人性读入了该数字系统-并较少关注其局限性。</p><p> In practice, the system fails about as often as it succeeds. We overlook that the computer code it writes requires some fine-tuning from human programmers — a line removed here or added there. We do not notice that its talent for conversation breaks down after a few exchanges, when it cannot “remember” what it said just a few seconds before. We do not quite realize that although the system generated a convincing blog post for Mr. Porr, he provided the headline and the photo and the first few sentences, and he removed some sentences that were less convincing.</p><p>在实践中，系统失败与成功一样多。我们忽略了它编写的计算机代码需要人类程序员进行一些微调-在此处删除或添加一行。我们没有注意到它的对话才能在几次交流之后就消失了，因为它无法“记住”它在几秒钟前所说的话。我们还不太清楚，尽管系统为Porr先生撰写了令人信服的博客文章，但他提供了标题，照片和前几句话，并删除了一些不太令人信服的句子。</p><p> Mr. Porr does not believe GPT-3 is an enormous threat to the battle against disinformation in the short term, because it still requires so much help from humans. A tool like this becomes truly dangerous only if it can generate enormous amounts of convincing disinformation entirely on its own, exceeding what a team of hired hands can do with relative ease today.</p><p> 波尔先生认为GPT-3短期内不会对打击虚假信息构成巨大威胁，因为它仍然需要人类的大力帮助。这样的工具只有完全能够自己产生大量令人信服的虚假信息，才真正具有危险性，而这超出了如今一支雇佣团队可以相对轻松地完成的工作。</p><p> Similarly, when app designers ask Mr. Singer of Square if GPT-3 is a threat to their careers, he assures them it is not — at least not yet. He sees it as a way of making their jobs easier. “If it can get 70 percent of the way there, that is a lot of tedious work taken out of the equation,” he said.</p><p> 同样，当应用程序设计师问Square的Singer先生时，GPT-3是否对他们的职业构成威胁，他向他们保证，这不是-至少现在还不是。他认为这是使他们的工作更轻松的一种方式。他说：“如果它能达到目标的70％，那将是很多乏味的工作。”</p><p> What we do not know is how much this technology will continue to improve in the months and years to come.</p><p> 我们不知道的是，在未来的几个月和几年中，这项技术将继续改进多少。</p><p>  While the researchers at OpenAI were training GPT-3 on more than a trillion words posted to the internet, they ran a second experiment, training a similar system on tens of thousands of digital photos. That system could analyze all of those photos and learn to build images in much the same way that GPT-3 builds paragraphs. Given half of a cat photo, it could generate the rest of the cat.</p><p>  当OpenAI的研究人员正在训练GPT-3上超过一万亿个发布到互联网上的单词时，他们进行了第二项实验，在成千上万张数码照片上训练了一个类似的系统。该系统可以分析所有这些照片，并学习以与GPT-3构建段落相同的方式构建图像。给定一半的猫照片，它可以生成其余的猫。</p><p> For some researchers, the experiment indicates that such a system could ultimately handle tasks across multiple dimensions — language, sight, sound — much like humans do. Even when trained solely on language, they say, the system could already reach into other areas, whether computer programming,  playing chess or  generating guitar tabs.</p><p> 对于一些研究人员而言，实验表明，这样的系统最终可以像人类一样，在多个维度（语言，视觉，声音）上处理任务。他们说，即使仅接受语言培训，该系统也可能已经涉足其他领域，无论是计算机编程，下棋还是生成吉他谱。</p><p> But continuing to improve this technology is far from trivial. Processing all of that internet data requires a  specialized supercomputer running for months on end, an undertaking that is enormously expensive. When asked if such a project ran into the millions of dollars, Sam Altman, OpenAI’s chief executive, said the costs were actually “higher,” running into the tens of millions.</p><p> 但是，继续改进这项技术绝非易事。处理所有这些互联网数据需要一台连续运行数月的专用超级计算机，这项工作非常昂贵。当被问及这样一个项目是否耗资数百万美元时，OpenAI首席执行官萨姆·奥特曼（Sam Altman）说，费用实际上“更高”，达到数千万美元。</p><p> Mr. Amodei, OpenAI’s vice president for research, said there was still room to improve the technique, using more processing power to analyze more data. But he also said the approach might be close to running out of “juice.”</p><p>OpenAI研究副总裁Amodei先生说，仍然存在改进技术的空间，可以使用更多的处理能力来分析更多的数据。但他还表示，这种方法可能接近用完“果汁”。</p><p> At the very least, GPT-3 is a new tool for a world of A.I. researchers and entrepreneurs, a way of building all sorts of new technologies and new products. Mr. Wrigley, the computer programmer, recently quit his day job to start a company called LearnFromAnyone, which aims to build a kind of automated tutor using GPT-3 that can assume  the guise of everyone from scientist Douglas Hofstadter to venture capitalist Peter Thiel. Others are building companies that aim to automatically generate code for computer programmers and automatically write promotional emails and tweets for marketing professionals.</p><p> 至少，GPT-3是人工智能世界的新工具。研究人员和企业家，这是构建各种新技术和新产品的一种方式。计算机程序员Wrigley先生最近辞去了日常工作，创办了一家名为LearnFromAnyone的公司，该公司的目标是使用GPT-3构建一种自动导师，可以承担从科学家Douglas Hofstadter到风险投资家Peter Thiel的各种伪装。其他公司正在建立公司，这些公司旨在自动为计算机程序员生成代码，并自动为市场营销专业人员编写促销电子邮件和推文。</p><p> But it is unclear how effective these services will ultimately be. If GPT-3 generates the right text only half of the time, can it satisfy professionals? And it is unclear whether this technique is a path to truly conversational machines, let alone truly intelligent systems. Additional progress on the long road to machines that can mimic the human brain, Mr. Amodei said, will require entirely new ideas.</p><p> 但是尚不清楚这些服务最终将如何有效。如果GPT-3仅在一半的时间内生成正确的文本，它能使专业人员满意吗？尚不清楚该技术是否是通向真正对话机器的途径，更不用说真正的智能系统了。阿德莫迪说，在可以模仿人脑的机器的漫长道路上要取得进一步的进展，将需要全新的想法。</p><p> “It is kind of like a chemistry reaction,” he said. “We have this one ingredient. But other ingredients are required as well.”</p><p> 他说：“这有点像化学反应。” “我们有这一成分。但是其他成分也是必需的。”</p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://www.nytimes.com/2020/11/24/science/artificial-intelligence-ai-gpt3.html">https://www.nytimes.com/2020/11/24/science/artificial-intelligence-ai-gpt3.html</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/编码/">#编码</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/code/">#code</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/系统/">#系统</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/分享/">#分享</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy; 2020 diglog.com </div></div></body></html>