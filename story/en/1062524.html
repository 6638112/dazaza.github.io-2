<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>五角大楼朝着让AI控制武器 The Pentagon Inches Toward Letting AI Control Weapons</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">The Pentagon Inches Toward Letting AI Control Weapons<br/>五角大楼朝着让AI控制武器 </h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2021-05-14 03:10:59</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2021/5/1ed9767525457735cfcb5b952ccdd7d6.jpg"><img src="http://img2.diglog.com/img/2021/5/1ed9767525457735cfcb5b952ccdd7d6.jpg" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>Last August, several dozen military  drones and tanklike  robots took to the skies and roads 40 miles south of Seattle. Their mission: Find terrorists suspected of hiding among several buildings.</p><p>去年8月，几十名军事无人机和坦克的机器人到了西雅图南部40英里40英里的天空和道路。他们的使命：发现恐怖分子涉嫌躲藏在几座建筑物中。</p><p> So many robots were involved in the operation that no human operator could keep a close eye on all of them. So they were given instructions to find—and eliminate—enemy combatants when necessary.</p><p> 这么多机器人参与了操作员可以保持密切关注的操作。因此，在必要时，他们被指示了解 - 并消除 - 敌人的战斗人员。</p><p> The mission was just an exercise, organized by the  Defense Advanced Research Projects Agency, a blue-sky research division of the Pentagon; the robots were armed with nothing more lethal than radio transmitters designed to simulate interactions with both friendly and enemy robots.</p><p> 特派团只是一项锻炼，由国防高级研究项目机构，五角大楼的蓝天研究部门组织;机器人被武装，而不是旨在模拟与友好和敌人机器人的相互作用的无线电发射机更致命。</p><p> The drill was one of several conducted last summer to test how  artificial intelligence could help expand the use of automation in military systems, including in scenarios that are too complex and fast-moving for humans to make every critical decision. The demonstrations also reflect a subtle shift in the Pentagon’s thinking about autonomous weapons, as it becomes clearer that machines can outperform humans at parsing complex situations or operating at high speed.</p><p> 钻探是去年夏天进行的几个进行的，以测试人工智能如何帮助扩大军事系统中自动化的使用，包括在太复杂和太快的情景中，为人类做出一切批判性决定。示威活动也反映了五角大楼对自主武器的思考的微妙转变，因为它变得更加清晰，机器可以超越分析复杂情况或以高速运行的人。</p><p>  General  John Murray of the US Army Futures Command told an audience at the US Military Academy last month that swarms of robots will force military planners, policymakers, and society to think about whether a person should make every decision about using lethal force in new autonomous systems. Murray asked: “Is it within a human&#39;s ability to pick out which ones have to be engaged” and then make 100 individual decisions? “Is it even necessary to have a human in the loop?” he added.</p><p>  美国陆军期货委员会的约翰·默里上个月在美国军方学院讲述了一位受众，即机器人的大群将迫使军队规划者，政策制定者和社会思考一个人是否应该在新的自治系统中使用致命力量的决定。 。默里问：“它在人类中＆＃39;能够挑选哪些必须订婚的能力”然后制作100个个人决定？ “甚至是有必要在循环中有一个人吗？”他加了。</p><p>  Other comments from military commanders suggest interest in giving autonomous weapons systems more agency. At a conference on AI in the Air Force last week, Michael Kanaan, director of operations for the Air Force Artificial Intelligence Accelerator at MIT and a leading voice on AI within the US military, said thinking is evolving. He says AI should perform more identifying and distinguishing potential targets while humans make high-level decisions. “I think that&#39;s where we&#39;re going,” Kanaan says.</p><p>  军事指挥官的其他评论建议兴趣给予自主武器系统更多机构。在上周在空军的AI会议上，MIC MIT人工智能加速器的业务总监Michael Kanaan和美国军队内部的领先声音，说思路正在不断发展。他说，当人类做出高级别的决定时，他应该表现更多的识别和区分潜在目标。 “我认为那个＆＃39;我们在哪里＆＃39;重新进入，”Kanaan说。</p><p>  At the same event, Lieutenant General  Clinton Hinote, deputy chief of staff for strategy, integration, and requirements at the Pentagon, says that whether a person can be removed from the loop of a lethal autonomous system is “one of the most interesting debates that is coming, [and] has not been settled yet.”</p><p>  在同一赛季，战略，集成以及五角大楼的副职员副主任克林顿文化委员会中尉表示，如果一个人可以从致命的自治系统的循环中删除是“最有趣的辩论之一即将到来，[和]尚未解决。“ </p><p> A report this month from the National Security Commission on Artificial Intelligence (NSCAI), an advisory group created by Congress, recommended, among other things, that the US resist calls for an international ban on the development of autonomous weapons.</p><p>本月从国家安全情报（NSCAI）的报告，由国会创作的咨询小组，其中包括美国抵制呼吁国际禁止自主武器的发展。</p><p>  Timothy Chung, the Darpa program manager in charge of the swarming project, says last summer’s exercises were designed to explore when a human drone operator should, and should not, make decisions for the autonomous systems. For example, when faced with attacks on several fronts, human control can sometimes get in the way of a mission, because people are unable to react quickly enough. “Actually, the systems can do better from not having someone intervene,” Chung says.</p><p>  Timothy Chung负责蜂拥项目的DARPA计划经理，表示，上夏天的练习旨在探索人类无人机运营商应该，不应该为自治系统做出决定。例如，当面对几个前面的攻击时，人类的控制有时会妨碍使命的方式，因为人们无法快速地反应。 “实际上，系统可以从没有有人干预方面做得更好，”钟说。</p><p> The drones and the wheeled robots, each about the size of a large backpack, were given an overall objective, then tapped AI algorithms to devise a plan to achieve it. Some of them surrounded buildings while others carried out surveillance sweeps. A few were destroyed by simulated explosives; some identified beacons representing enemy combatants and chose to attack.</p><p> 无人驾驶和轮式机器人，每个大小的大背包的大小都被赋予了整体目标，然后点击AI算法设计了实现它的计划。其中一些包围了建筑物，而其他人则进行监控扫描。一些被模拟炸药摧毁了一些;一些识别的信标代表敌人的战斗人员并选择攻击。</p><p> The US and other nations have used autonomy in weapons systems for decades. Some missiles can, for instance, autonomously identify and attack enemies within a given area. But rapid advances in AI algorithms will change how the military uses such systems. Off-the-shelf AI code capable of controlling robots and identifying landmarks and targets, often with high reliability, will make it possible to deploy more systems in a wider range of situations.</p><p> 几十年来，美国和其他国家在武器系统中使用了自主权。例如，某些导弹可以在给定区域内自主识别和攻击敌人。但是AI算法的快速进步将改变军队如何使用此类系统。能够控制机器人和识别地标和目标的空置AI代码，通常具有高可靠性，将使可以在更广泛的情况下部署更多系统。</p><p>  But as the drone demonstrations highlight, more widespread use of AI will sometimes make it more difficult to keep a human in the loop. This might prove problematic, because AI technology  can harbor biases or behave unpredictably. A vision algorithm trained to recognize a particular uniform might mistakenly target someone wearing similar clothing. Chung says the swarm project presumes that AI algorithms will improve to a point where they can identify enemies with enough reliability to be trusted.</p><p>  但随着寄生虫示范突出，更广泛使用AI有时会使人类留在循环中更加困难。这可能证明是有问题的，因为AI技术可以覆盖偏见或表现不可预测地。培训的视觉算法旨在识别特定制服可能会误认为是戴着类似衣物的人。 Chung表示，群体项目假定AI算法将改进到他们可以识别有足够可靠性的敌人的点。</p><p>  Use of AI in weapons systems has become controversial in recent years. Google faced employee protest and public outcry in 2018 after  supplying AI technology to the Air Force through a project known as  Maven.</p><p>  近年来，在武器系统中使用AI在武器系统中变得争议。谷歌面临员工抗议和2018年通过称为Maven的项目向空军提供AI技术后，2018年。</p><p>  To some degree, the project is part of a long history of autonomy in weapons systems, with some missiles already capable of carrying out limited missions independent of human control. But it also shows how recent advances in AI will make autonomy more attractive and inevitable in certain situations. What&#39;s more, it highlights the trust that will be placed in technology that can still behave unpredictably.</p><p>  在某种程度上，该项目是武器系统中悠久的自主权历史的一部分，一些导弹已经能够独立于人类对照进行有限的任务。但它还展示了AI最近的近期进步将使某些情况下的自主权更具吸引力和不可避免。什么＆＃39;较多，它强调了将仍然可以不可预测的技术的信任。 </p><p> Paul Scharre, an expert at the Center for New American Security and author of   Army of None: Autonomous Weapons and the Future of War, says it is time to have a more sophisticated discussion about autonomous weapons technology. “The discussion surrounding ‘humans in the loop’ ought to be more sophisticated than simply a binary ‘are they or aren&#39;t they?’” Scharre says. “If a human makes a decision to engage a swarm of enemy drones, does the human need to individually select each target?”</p><p>保罗Scharre是新美国安全中心和军队作者的专家：自治武器和战争的未来，说现在是有关于自治武器技术更复杂的讨论。 “围绕”循环中的人类的讨论“应该更复杂，而不是简单的二进制'他们还是aren＆＃39; t他们？'”scharre说。 “如果一个人决定从事敌人无人机的群体，人类需要单独选择每个目标吗？”</p><p> The Defense Department issued a  policy on autonomous weapons in November 2012, stating that autonomous weapons systems need to have human oversight—but this need not mean soldiers making every decision.</p><p> 国防部于二零一二年十一月发布了一项关于自治武器的政策，指出自主武器系统需要具有人类监督的人 - 但这不需要士兵做出所有决定。</p><p> Those who believe that militaries could use AI to cross a Rubicon when it comes to human responsibility for lethal force see things differently.</p><p> 那些相信军队可以使用AI在人类对致命力量的责任方面越过Rubicon看到事情的不同之处。</p><p> “Lethal autonomous weapons cheap enough that every terrorist can afford them are not in America&#39;s national security interest,” says  Max Tegmark, a professor at MIT and cofounder of the  Future of Life Institute, a nonprofit that opposes autonomous weapons.</p><p> “致命的自主武器便宜，每个恐怖分子都能负担得起他们不在美国，而且国家安全利益的国家安全利益最多，”生命研究所未来的未来教授，是一个反对自治武器的非营利组织。</p><p> Tegmark says AI weapons should be “stigmatized and banned like biological weapons.” The NSCAI report&#39;s opposition a global ban is a strategic mistake, he says: “I think we&#39;ll one day regret it even more than we regret having armed the Taliban.”</p><p> Tegmark说，AI武器应该是“耻辱和禁止的生物武器”。 NSCAI报告＆＃39;相反的全球禁令是一个战略错误，他说：“我认为我们有一天甚至更遗憾地抱歉，我们遗憾地武装塔利班。”</p><p>   🎧 Things not sounding right? Check out our favorite  wireless headphones,  soundbars, and  Bluetooth speakers</p><p>   🎧声音不对的东西？查看我们最喜欢的无线耳机，声栏和蓝牙音箱 </p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://www.wired.com/story/pentagon-inches-toward-letting-ai-control-weapons/">https://www.wired.com/story/pentagon-inches-toward-letting-ai-control-weapons/</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/ai/">#ai</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/inches/">#inches</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/人类/">#人类</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/分享/">#分享</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy;2012-2021 diglog.com </div></div></body></html>