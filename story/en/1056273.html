<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>预测编码已经用BackProjagation统一 Predictive Coding has been Unified with Backpropagation</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">Predictive Coding has been Unified with Backpropagation<br/>预测编码已经用BackProjagation统一 </h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2021-04-05 22:29:42</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2021/4/541d566aeaddc767983584423388ecdf.png"><img src="http://img2.diglog.com/img/2021/4/541d566aeaddc767983584423388ecdf.png" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>Artificial Neural Networks (ANNs) are based around the backpropagation algorithm. The backpropagation algorithm allows you to perform gradient descent on a network of neurons. When we feed training data through an ANNs, we use the backpropagation algorithm to tell us how the weights should change.</p><p>人工神经网络（ANNS）基于BackProjagation算法。 BackProjagation算法允许您在神经元网络上执行梯度下降。当我们通过ANNS提供培训数据时，我们使用BackProjagation算法告诉我们权重应该如何改变。</p><p> ANNs are good at inference problems. Biological Neural Networks (BNNs) are good at inference too. ANNs are built out of neurons. BNNs are built out of neurons too. It makes intuitive sense that ANNs and BNNs might be running similar algorithms.</p><p> Anns擅长推理问题。生物神经网络（BNNS）也擅长推动。 Anns是由神经元构成的。 BNN也是由神经元构成的。它使ANNS和BNNS可能正在运行类似的算法，这是直观的。</p><p>  We do not know quite enough about biology to say it is impossible for BNNs to run the backpropagation algorithm. However, &#34;a consensus has emerged that the brain cannot directly implement backprop, since to do so would require biologically implausible connection rules&#34;  [1].</p><p>  我们对生物学不太了解，可以说BNN不可能运行BackPropagation算法。然而，＆＃34;一项共识已经出现，大脑不能直接实施背部，因为这样做就需要生物学难以置信的连接规则＆＃34; [1]。</p><p>   The backpropagation algorithm requires information to flow forward and backward along the network. But biological neurons are one-directional. An action potential goes from the cell body down the axon to the axon terminals to another cell&#39;s dendrites. An axon potential never travels backward from a cell&#39;s terminals to its body.</p><p>   BackProjagation算法需要沿网络向前和向后流动的信息。但生物神经元是单方面的。动作电位从轴身向下到轴突到轴线端子到另一个细胞＆＃39; s树枝状体。轴突势永远不会从电池和＃39; S端子向后行驶到其身体。</p><p>   Predictive coding is the idea that BNNs generate a mental model of their environment and then transmit only the information that deviates from this model. Predictive coding considers error and surprise to be the same thing. Hebbian theory is specific mathematical formulation of predictive coding.</p><p>   预测编码是BNN生成其环境的心理模型的想法，然后仅发送偏离该模型的信息。预测编码考虑错误并惊喜是相同的。 Hebbian理论是预测编码的特定数学制定。</p><p> Predictive coding is biologically plausible. It operates locally. There are no separate prediction and training phases which must be synchronized. Most importantly, it lets you train a neural network without sending axon potentials backwards.</p><p> 预测编码是生物学可言论的。它在本地运营。没有单独的预测和训练阶段必须同步。最重要的是，它可以让您训练神经网络，而不会向后发送Axon电位。</p><p>  Predictive coding is easier to implement in hardware. It is locally-defined; it parallelizes better than backpropagation; it continues to function when you cut its substrate in half. (Corpus callosotomy is used to treat epilepsy.) Digital computers break when you cut them in half. Predictive coding is something evolution could plausibly invent.</p><p>  在硬件中更容易实现预测编码。它是本地定义的;它比背部经历更好地顺序化;当您将基板缩小为一半时，它继续运行。 （胼callootomy用于治疗癫痫症。）当你将它们切成两半时，数字电脑打破。预测编码是一种易于发明的东西。 </p><p>  The paper  Predictive Coding Approximates Backprop Along Arbitrary Computation Graphs  [1:1] &#34;demonstrate[s] that predictive coding converges asymptotically (and in practice rapidly) to exact backprop gradients on arbitrary computation graphs using only local learning rules.&#34; The authors have unified predictive coding and backpropagation into a single theory of neural networks. Predictive coding and backpropagation are separate hardware implementations of what is ultimately the same algorithm.</p><p>纸张预测编码沿任意计算图[1：1]＆＃34沿着任意计算图近似于倒波;演示预测编码会收敛于使用本地学习规则的任意计算图中的渐近渐变（并且在实践中迅速地）。＆＃ 34;作者对一个神经网络的单一理论进行了统一的预测编码和反向化。预测编码和BackProjagation是最终相同算法的单独硬件实现。</p><p>  If they set         η   v to 1 they converge in a single backward pass           1, since they then calculate precisely backprop. Setting         η   v to less than that and perhaps mixing up the pass order merely obfuscates and delays this process, but converges because any neuron without incorrect children has nowhere to go but towards correctness. And the entire convergence is for a single input! After which they manually do a gradient step on the weights as usual.</p><p>  如果它们将ηv到1设置为它们，则在单个后向通行证1中会聚，因为它们然后计算精确反击。将ηv设置为小于那个，也许混合通过顺序仅仅会使此过程延迟并延迟此过程，但收敛，因为任何没有错误儿童的神经元都无处可行，而是朝着正确的情况。整个收敛是单一输入！之后，它们可以像往常一样手动对重量进行梯度步骤。</p><p> I mean, it&#39;s neat that you can treat activations and parameters by the same update rule, but then you should actually do it. Every &#34;tick&#34;, replace the input and label and have every neuron update its parameters and data in lockstep, where every neuron can only look at its neighbors. Of course, this only has a chance of working if the inputs and labels come from a continuous stream, as they would if the input were the output of another network. They also notice the possibility of continuous data. And then one could see how its performance degrades as one speeds up the poor brain&#39;s environment :).</p><p> 我的意思是，它的整洁，你可以通过相同的更新规则治疗激活和参数，但是你应该实际做到这一点。每个＆＃34;勾选＆＃34;，替换输入和标签，并让每个神经元更新其参数和数据，其中每个神经元只能看其邻居。当然，如果输入和标签来自连续流，则只有工作的机会，因为如果输入是另一个网络的输出，则会有机会。他们还注意到连续数据的可能性。然后一个人可以看到它的性能如何降低，因为一种速度达到糟糕的大脑和环境:)。</p><p> 1: Which has to be in backward order and         ϵ   i  ←    v   i  −         ^   v   i has to be done once more after the v update line. Epistemic status:  Everyone else is hyping so maybe I&#39;m being silly?</p><p> 1：必须处于向后顺序和εi←v i  -  ^ v我必须在v更新行之后再次完成。认知状态：其他人都在振荡所以也许我是愚蠢的？</p><p> Of course, this only has a chance of working if the inputs and labels come from a continuous stream, as they would if the input were the output of another network.</p><p> 当然，如果输入和标签来自连续流，则只有工作的机会，因为如果输入是另一个网络的输出，则会有机会。</p><p> Predictive processing is thus well-suited for BNNs because the real-time sensory data of a living organism, including sensory data preprocessed by another network, is a continuous stream.</p><p> 因此，预测处理非常适合于BNN，因为生物体的实时感官数据，包括被另一网络预处理的感官数据，是连续流。</p><p> Current neural nets seem to require more data (e.g. games of Starcraft) to reach the same level of performance as a human adult. There are different hypotheses as to why this is:</p><p> 目前的神经网络似乎需要更多的数据（例如星际争霸游戏），以达到与人类成年人相同的表现。有不同的假设，为什么这是： </p><p>  --Human brains have a ton of pre-training from which they can acquire good habits and models which generalize to new tasks/situations (we call this &#34;childhood&#34; and &#34;education&#34;). GPT-3 etc. show that something similar works for neural nets, maybe we just need to do more of this with bigger brains.</p><p>- 乌鸦大脑有很多预先培训，他们可以获得良好的习惯和模型，它概括为新的任务/情况（我们称之为＆＃34;童年＆＃34;和＃34;教育＆＃34;）。 GPT-3等显示了神经网的类似作品，也许我们只需要用更大的大脑做更多的事情。</p><p>    I&#39;ve heard all of these hypotheses seriously maintained by various people. If this is true it rules out the last one.</p><p>    我听到了各种人严重维护的所有这些假设。如果这是真的，它会排除最后一个。</p><p> There is no question that human brains have tons of instincts built-in. But there is a hard limit on how much information a single species&#39; instincts can contain. It is implausible that human beings&#39; cognitive instincts contain significantly more information than the human genome (750 megabytes). I expect our instincts contain much less.</p><p> 毫无疑问，人性大脑有很多本能内置的本能。但是有多少信息单一物种和＃39;本能可以包含。人类＆＃39是难以置信的;认知本能含有比人类基因组更大的信息（750兆字节）。我期待我们的本能较少。</p><p> Human brains definitely have special architectures too, like the hippocampus. The critical question is how important these special architectures are. Are our special architectures critical to general intelligence or are they just speed hacks? If they are speed hacks then we can outrace them by building a bigger computer or writing more efficient algorithms.</p><p> 人类大脑肯定有特殊的建筑，就像海马一样。关键问题是这些特殊架构的重要性。我们的特殊架构是否对一般情报至关重要，也是他们只是速度的黑客攻击？如果它们是速度黑客，那么我们可以通过构建更大的计算机或编写更高效的算法来超越它们。</p><p> There is no doubt that humans transmit more cultural knowledge than other animals. This has to do with language. (More specifically, I think our biology underpinning language hit a critical point around 50,000 years ago.) Complex grammar is not present in any non-human animal. Wernicke&#39;s area is involved. Wernicke&#39;s area could be a special architecture.</p><p> 毫无疑问，人类比其他动物传播更多的文化知识。这与语言有关。 （更具体地说，我认为我们的生物学笔触语言在50,000年前袭击了一个关键点。）复杂的语法不存在于任何非人类动物中。 Wernicke＆＃39;涉及区域。 Wernicke＆＃39; S区域可能是一个特殊的架构。</p><p> How important are the above human advantages? I believe that taking a popular ANN architecture and merely scaling it up will not enable a neural network to compete with humans at  StarCraft with equal quantities of training data. If, in addition, the ANN is not allowed to utilize transfer learning then I am willing to publicly bet money on this prediction. (The ANN must be restricted to a human rate of actions-per-second. The ANN does not get to play via an API or similar hand-coded preprocessor. If the ANN watches videos of other players then that counts towards its training data.)</p><p> 上述人类优势有多重要？我相信采取受欢迎的ANN架构并仅仅缩放它不会使神经网络能够在星际争霸中与人类竞争等量的培训数据。如果另外，ANN不允许使用转移学习，那么我愿意在这一预测上公开赌注。 （ANN必须限于每秒人为行动率。安娜没有通过API或类似的手工编码预处理器进行播放。如果ANN观看其他玩家的视频，那么这对它的培训数据有所依赖。 ）</p><p> If the ANN can&#39;t use transfer learning, that&#39;s pretty unfair, since the human can. (It&#39;s not like a baby can play Starcraft straight out of the womb; humans can learn Starcraft but only after  years of pre-training on diverse data in diverse environments)</p><p> 如果Ann可以＆＃39; it使用转移学习，＆＃39; s漂亮的不公平，因为人类可以。 （＆＃39;不像婴儿直接从子宫中播放星际争霸;人类可以学习星际争霸，但只有多年的多年在各种环境中的不同数据进行预训练） </p><p> Good point. Transfer learning is allowed but it still counts towards the total training data where &#34;training data&#34; is now everything a human can process over a lifetime.</p><p>好点子。允许转移学习，但它仍然符合培训数据的总培训数据;培训数据＆＃34;现在是人类可以在一生中处理的一切。</p><p> Due to the need to iterate the vs until convergence, the predictive coding network had roughly a 100x greater computational cost than the backprop network.</p><p> 由于需要迭代VS直到收敛，预测编码网络的计算成本大致100倍，而不是背部网络。</p><p> This seems to imply that artificial NNs are 100x more computationally efficient (at the cost of not being able to grow and probably lower fault tolerance etc.). Still, I&#39;m updating to simulating a brain requiring much less CPU than the neurons in the brain would indicate.</p><p> 这似乎暗示，人造NNS是100倍的计算效率（以不能增长并且可能降低容错等的成本）。仍然，i＆＃39; m更新以模拟需要比大脑中的神经元更小的CPU需要表明的大脑。</p><p> That&#39;s assuming that the brain is using predictive coding to implement backprop, whereas it might instead be doing something that is more computationally efficient given its hardware limitations. (Indeed, the fact that it&#39;s so inefficient should make you update that it&#39;s not likely for the brain to be doing it)</p><p> 假设大脑使用预测编码来实现BackProp，而它可能改为在其硬件限制的情况下做出更多计算效率的事情。 （实际上，它的事实＆＃39; s如此效率低效，让您更新它＆＃39;不太可能为大脑做到这一点）</p><p> Partly, yes. But partly the computation could be the cheap part compared to the thing it&#39;s trading off against (ability to grow, fault tolerance, ...). It is also possible that the brains architecture allows it to include a wider range of inputs that might not be able to model with back-prod (or not efficiently so).</p><p> 部分，是的。但部分计算可能是与它的交易交易（成长，容错，......）的交易相比廉价的部分。大脑架构也可能允许它包括更广泛的输入，这些输入可能无法使用背部产品（或没有有效地）。</p><p> I think that&#39;s premature. This is just one (digital, synchronous) implementation of one model of BNN that can be shown to converge on the same result as backprop. In a neuromorphic implementation of this circuit, the convergence would occur on the same time scale as the forward propagation.</p><p> 我认为那个早产权。这只是一个BNN型号的一个（数字，同步）实现，可以显示在与BackProp相同的结果上会聚。在该电路的神经形态实现中，收敛将在与前向传播相同的时间尺度上发生。</p><p> Scott summarizes the Predictive Processing theory, explains it in a very accessible way (no math required), and uses it to explain a whole bunch of mental phenomena (attention, imagination, motor behavior, autism, schizophrenia, etc.)</p><p> 斯科特总结了预测性处理理论，以非常便宜的方式解释（无需数学），并使用它来解释一大堆心理现象（注意，想象力，运动行为，自闭症，精神分裂症等） </p><p> Can someone ELI5/TLDR this paper for me, explain in a way more accessible to a non-technical person?</p><p>有人可以为我提供ELI5 / TLDR本文，以非技术人员更容易获得的方式解释？</p><p> - How does backprop work if the information can&#39;t flow backwards? - In Scotts post, he says that when lower-level sense data contradicts high-level predictions, high-level layers can override lower-level predictions without you noticing it. But if low-level sensed data has high confidence/precision - the higher levels notice it and you experience &#34;surprise&#34;. Which one of those is equivalent to the backdrop error? Is it low-level predictions being overridden, or high-level layers noticing the surprise, or something else, like changing the connections between neurons to train the network and learn from the error somehow?</p><p>  - 如果信息可以＆＃39向后流动，背部工作如何？ - 在Scotts Post中，他说，当较低级别的感测数据违反高级别预测时，在没有注意到它的情况下，高级层可以覆盖较低级别的预测。但是，如果低级感测数据具有高置信度/精度 - 较高的级别会通知它，您的体验＆＃34;惊喜＆＃34;哪一个相当于背景错误？它是低级别的预测被覆盖，或者高级别的层注意到惊喜，或者其他东西，如改变神经元之间的连接来训练网络并以某种方式从错误中学习？</p><p> Is it known whether predictive coding is easier to train than backprop? Local learning rules seem like they would be more parallelizable.</p><p> 它已知预测编码是否比返回更容易训练？本地学习规则似乎它们将更加平行化。</p><p>  We show, however, that deep networks learned by the standard gradient descent algorithm are in fact mathematically approximately equivalent to kernel machines, a learning method that simply memorizes the data and uses it directly for prediction via a similarity function (the kernel). This greatly enhances the interpretability of deep network weights, by elucidating that they are effectively a superposition of the training examples. The network architecture incorporates knowledge of the target function into the kernel.</p><p>  然而，我们示出了由标准梯度下降算法学习的深网络实际上大致相当于内核机器，这是一种简单地存储数据的学习方法，并通过相似函数（内核直接用于预测。这极大地提高了深网络权重的可解释性，通过阐明它们是有效的训练示例的叠加。网络架构将目标函数的知识包含在内核中。</p><p> A first drawback of this paper is that its conclusion assumes that the NN underneath trains with gradient  flow (GF), which is the continuous-time version of gradient descent (GD). This is a good assumption if the learning rate is very small, and the resulting GD dynamics closely track the GF differential equation.</p><p> 本文的第一个缺点是其结论假设具有梯度流动（GF）的列车下的NN，这是梯度下降（GD）的连续时间版本。如果学习速率非常小，并且由此产生的GD动力学紧密地跟踪GF微分方程，则这是一个很好的假设。</p><p> This does not seem to be the case in practice. Larger initial learning rates help get better performance ( https://arxiv.org/abs/1907.04595), so people use them in practice. If what people use in practice was well-approximated by GF, then smaller learning rates would give the same result. You can use another differential equation that does seem to approximate GD fairly well ( http://ai.stanford.edu/blog/neural-mechanics/), but I don&#39;t know if the math from the paper still works out.</p><p> 似乎在实践中似乎并不是这种情况。更大的初始学习率有助于获得更好的性能（https://arxiv.org/abs/1907.04595），人们在实践中使用它们。如果人们在实践中使用的是由GF近似地近似，那么较小的学习率会给出相同的结果。您可以使用另一个似乎似乎对GD相当好的另一种差分方程（http://ai.stanford.edu/blog / whebecharics/），但我不知道纸上的数学是否仍然效果。</p><p> Second, as the paper points out, the kernel machine learned by GD is a bit strange in that the coefficients $a_i$ for weighing different $K(x, x_i)$ depend on $x$. Thus, the resulting output function is not in the reproducing kernel Hilbert space of the kernel that is purported to describe the NN. As a result, as kernel machines go, it&#39;s pretty weird. I expect that a lot of the analysis about the output of the learning process (learning theory etc) assumes that the $a_i$ do not depend on the test input $x$.</p><p> 其次，正如论文所指出的那样，GD学习的内核机器有点奇怪的是，系数$ A_I $用于称重不同$ k（x，x_i）$依赖于$ x $。因此，所得到的输出函数不在封入内核的再现内核HILBERT空间中，该空间被声称描述NN。结果，作为内核机器，它＆＃39;非常奇怪。我希望大量分析学习过程的输出（学习理论等）假设$ A_I $不依赖于测试输入$ x $。 </p><p> Do you know of any work that applies similar methods to study the equivalent kernel machine learned by predictive coding?</p><p>您是否知道使用类似方法来研究通过预测编码学习的等效内核机器的任何工作？</p><p> I don&#39;t, and my best guess is that nobody has done it :) The paper you linked is extremely recent.</p><p> 我不，我最好的猜测是没有人这样做:)你所谓的纸张是最近的。</p><p> You&#39;d have to start by finding an ODE model of predictive coding, which I suppose is possible taking limit of the learning rate to 0.</p><p> 您＆＃39; D必须首先找到预测编码的ode模型，我认为可能将学习率限制为0。</p><p> Due to the need to iterate the  vs until convergence, the predictive coding network had roughly a 100x greater computational cost than the backprop network.</p><p> 由于需要迭代VS直到收敛，预测编码网络的计算成本大致100倍，而不是背部网络。</p><p> The paper claims that predictive coding takes more compute. I agree that predictive coding ought to be more parallelizable. If you are using a GPU then backpropagation is already sufficiently parallelizable. However, it may be that neuromorphic hardware could parallelize better than a GPU, this producing an increase in compute power that outstrips the 100x greater computational cost of the algorithm itself.</p><p> 本文要求预测编码需要更多计算。我同意预测编码应该更平行化。如果您使用的是GPU，则BackPropagation已经充分并行化。然而，可能是神经形态硬件可以比GPU更好地平行化，这产生了计算功率的增加，该计算能力超过了算法本身的100倍的计算成本。</p><p> There seem to be a couple of sign errors in the manuscript. (Probably worth reaching out to the authors directly)</p><p> 稿件似乎有几个符号错误。 （可能值得直接向作者伸出援手）</p><p> Their predictive coding algorithm holds the vhat values fixed during convergence, which actually implies a somewhat different network topology than the more traditional one shown in your figure.</p><p> 它们的预测编码算法在收敛过程中固定的VHAT值，其实际上意味着多个不同的网络拓扑，而不是图中所示的更传统的网络拓扑。 </p><p> Right side of equation 2. Also the v update step in algorithm 1 should have a negative sign (the text version earlier on the same page has it right).</p><p>等式2的右侧。此外，算法1中的V更新步骤应该具有否定标志（同一页面上的文本版本具有正确的文本版本）。</p><p> The black       v circles represent neurons. The red       ϵ triangles represent activations (action potentials). Action potentials&#39; information content is shared between presynaptic neurons and postsynaptic neurons because activations are transmitted from the presynaptic neuron to the postsynaptic neuron.</p><p> 黑色V圈代表神经元。红色ε三角形表示激活（动作电位）。行动潜力＆＃39;在突触前神经元和后腹膜神经元之间共享信息含量，因为激活从突触前神经元传播到后腹膜神经元。</p><p> The black arrows in the bottom diagram denote the physical creation of action potentials. The red arrows denote intra-neuron calculation of the gradient. Keep in mind that each neuron knows both the action potential it generates itself and the action potentials sent to it.</p><p> 底部图中的黑色箭头表示动作电位的物理创建。红色箭头表示梯度的神经元内计算。请记住，每个神经元都知道它产生它自己的动作潜力以及发送给它的动作电位。</p><p> Oh that makes a lot more sense. Is delta v1 hat the change of v1 rather than a infintesimal? (Asking because if it was then it&#39;d be easier to understand how it is calculated).</p><p> 哦，这更有意义。 Delta v1帽子的变化V1而不是一个infintesimal？ （询问，因为它是它＆＃39; d更容易理解它是如何计算的）。</p><p> There is no relationship between neurons and the &#34;neurons&#34; of an ANN. It&#39;s just a naming mishap at this point.</p><p> 神经元和＆＃34之间没有关系;神经元＆＃34;一个安。这一点＆＃39;＆＃39;此时只是一个命名的事故。 </p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://www.lesswrong.com/posts/JZZENevaLzLLeC3zn/predictive-coding-has-been-unified-with-backpropagation">https://www.lesswrong.com/posts/JZZENevaLzLLeC3zn/predictive-coding-has-been-unified-with-backpropagation</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/预测/">#预测</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/coding/">#coding</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/学习/">#学习</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/谷歌/">#谷歌</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy;2012-2021 diglog.com </div></div></body></html>