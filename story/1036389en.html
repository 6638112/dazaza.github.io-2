<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>使用FFmpeg和WebAssembly在浏览器中对视频文件进行转码In-browser transcoding of video files with FFmpeg and WebAssembly</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">In-browser transcoding of video files with FFmpeg and WebAssembly<br/>使用FFmpeg和WebAssembly在浏览器中对视频文件进行转码</h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2020-11-25 03:47:37</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2020/11/99f25566e98b7e102165a0e26795d28e.png"><img src="http://img2.diglog.com/img/2020/11/99f25566e98b7e102165a0e26795d28e.png" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>The WebAssembly build of FFmpeg allows you to run this powerful video processing tool directly within the browser. In this blog post I explore  FFmpeg.wasm and create a simple client-side transcoder that streams data into a video element, with a bit of RxJS thrown in for good measure.</p><p>FFmpeg的WebAssembly构建允许您直接在浏览器中运行此功能强大的视频处理工具。在此博客文章中，我将探索FFmpeg.wasm并创建一个简单的客户端代码转换器，将数据流传输到视频元素中，并加入一些RxJS以作很好的衡量。</p><p>   FFmpeg is most often used via its command-line interface. For example, you can transcode an AVI file to an equivalent video file in MP4 as follows:</p><p>   FFmpeg最常通过其命令行界面使用。例如，您可以按如下方式将AVI文件转码为MP4中的等效视频文件：</p><p>  Let’s look at how you perform the same task within the browser …</p><p>  让我们看看您如何在浏览器中执行相同的任务……</p><p> FFmpeg.wasm is a WebAssembly port of FFmpeg, which you can install via npm and use within Node or the browser just like any other JavaScript module:</p><p> FFmpeg.wasm是FFmpeg的WebAssembly端口，您可以通过npm安装该端口，并在Node或浏览器中使用它，就像其他任何JavaScript模块一样：</p><p>  With FFmpeg.wasm installed, you can perform an equivalent transcoding entirely within the browser as follows:</p><p>  安装FFmpeg.wasm后，您可以完全在浏览器中执行等效的代码转换，如下所示：</p><p> // fetch the AVI file const  sourceBuffer  =  await  fetch ( &#34; input.avi &#34; ). then ( r  =&gt;  r . arrayBuffer ()); // create the FFmpeg instance and load it const  ffmpeg  =  createFFmpeg ({  log :  true  }); await  ffmpeg . load (); // write the AVI to the FFmpeg file system ffmpeg . FS (  &#34; writeFile &#34; ,  &#34; input.avi &#34; ,  new  Uint8Array ( sourceBuffer ,  0 ,  sourceBuffer . byteLength ) ); // run the FFmpeg command-line tool, converting the AVI into an MP4 await  ffmpeg . run ( &#34; -i &#34; ,  &#34; input.avi &#34; ,  &#34; output.mp4 &#34; ); // read the MP4 file back from the FFmpeg file system const  output  =  ffmpeg . FS ( &#34; readFile &#34; ,  &#34; output.mp4 &#34; ); // ... and now do something with the file const  video  =  document . getElementById ( &#34; video &#34; ); video . src  =  URL . createObjectURL (  new  Blob ([ output . buffer ],  {  type :  &#34; video/mp4 &#34;  }) );</p><p> //获取AVI文件const sourceBuffer = await fetch（“ input.avi”）。然后（r => r。arrayBuffer（））; //创建FFmpeg实例并加载它const ffmpeg = createFFmpeg（{log：true}）;等待ffmpeg。加载（）; //将AVI写入FFmpeg文件系统ffmpeg。 FS（“ writeFile”，“ input.avi”，新的Uint8Array（sourceBuffer，0，sourceBuffer。byteLength））; //运行FFmpeg命令行工具，将AVI转换为MP4等待ffmpeg。运行（“ -i”，“ input.avi”，“ output.mp4”）; //从FFmpeg文件系统const output = ffmpeg读回MP4文件。 FS（“ readFile”，“ output.mp4”）; // ...现在对文件const video = document进行处理。 getElementById（“ video”）;视频 。 src = URL。 createObjectURL（新的Blob（[output.buffer]，{type：“ video / mp4”}））;</p><p> There’s a lot of interesting stuff going on here, so let’s dive into the details.</p><p> 这里有很多有趣的事情，所以让我们深入研究细节。</p><p> After using the  fetch API to load the AVI file, the following steps initialise FFmpeg itself:</p><p>使用获取API加载AVI文件后，以下步骤将初始化FFmpeg本身：</p><p>  FFmpeg.wasm is composed of a thin JavaScript API layer and a more substantial (20MByte!) WebAssembly binary. The above code loads and initialises the WebAssembly file ready for use.</p><p>  FFmpeg.wasm由一个薄JavaScript API层和一个更大量的（20MByte！）WebAssembly二进制文件组成。上面的代码加载并初始化了可供使用的WebAssembly文件。</p><p> WebAssembly is a new performance-optimised low-level bytecode that runs within the browser. It was specifically designed as a compilation target for a wide range of languages, and a convenient vehicle from allowing existing non-browser applications to target the web.</p><p> WebAssembly是在浏览器中运行的，经过性能优化的新低级字节码。它被专门设计为多种语言的编译目标，并且是允许现有的非浏览器应用程序定位到Web的便捷工具。</p><p> In this case, FFmpeg is a 20 year old project, with &gt; 1,000 contributors and almost 100k commits. Prior to WebAssembly, it would be almost inconceivable to create a JavaScript port of this library, the effort involved would be collosal! Furthermore, the performance characteristics of JavaScript might limit the effectiveness of this approach.</p><p> 在这种情况下，FFmpeg是一个已有20年历史的项目，拥有超过1,000名贡献者和近10万次提交。在进行WebAssembly之前，几乎无法想象要创建此库的JavaScript端口，所涉及的工作可能很繁琐！此外，JavaScript的性能特征可能会限制这种方法的有效性。</p><p> In the long-term we’ll likely see WebAssembly used more widely, but for now, it has found most success as a mechanism for bringing mature and substantial C/C++ codebases to the web, e.g.  Google Earth,  AutoCAD, and  TensorFlow</p><p> 从长远来看，我们可能会看到WebAssembly的使用更为广泛，但就目前而言，WebAssembly作为将成熟的大量C / C ++代码库引入网络的一种机制最为成功。 Google Earth，AutoCAD和TensorFlow</p><p> After initialisation, the next step is to write the AVI file to the file system:</p><p> 初始化之后，下一步是将AVI文件写入文件系统：</p><p>  OK, so that’s a bit odd isn’t it? To understand what’s going on here, we need to dig a little deeper into how FFmpeg.wasm is compiled.</p><p>  好吧，这有点奇怪不是吗？要了解这里发生的情况，我们需要更深入地研究FFmpeg.wasm的编译方式。</p><p> FFmpeg.wasm is compiled into WebAssembly using  Emscripten, a C/C++ to WebAssembly toolchain that was developed alongside the WebAssembly specification. Emscripten is more than just a C++ compiler - in order to ease migration of existing codebases, it provides support for a number of C/C++ APIs via web-based equivalents. For example OpenGL is supported by mapping calls to WebGL. It also supports SDL, POSIX and pthreads.</p><p>FFmpeg.wasm使用Emscripten编译成WebAssembly，Emscripten是与WebAssembly规范一起开发的C / C ++到WebAssembly工具链。 Emscripten不仅仅是一个C ++编译器-为了简化现有代码库的迁移，它通过基于Web的等效项提供对许多C / C ++ API的支持。例如，通过将调用映射到WebGL来支持OpenGL。它还支持SDL，POSIX和pthread。</p><p> Emscripten provides a  file-system API which is mapped to in-memory storage. With FFmpeg.wasm, the underlying Emscripten file-system API is exposed directly via the  ffmpeg.FS function - you can use this interface to navigate folders, create files and various other file system operations.</p><p> Emscripten提供了映射到内存中存储的文件系统API。使用FFmpeg.wasm，可以直接通过ffmpeg.FS函数公开基础的Emscripten文件系统API-您可以使用此界面导航文件夹，创建文件和其他各种文件系统操作。</p><p>   If you step over the above line in the Chrome Dev Tools, you’ll notice that it creates a number of Web Workers, with each one loading ffmpeg.wasm:</p><p>   如果您在Chrome开发工具中跨过以上一行，则会注意到它创建了许多Web Worker，每个Web Worker都加载ffmpeg.wasm：</p><p>  This makes use of  Emscripten’s Pthread support. As we’ve enabled logging, you can see the progress within console;</p><p>  这利用了Emscripten的Pthread支持。启用日志记录后，您可以在控制台中查看进度；</p><p> Output #0, mp4, to &#39;output.mp4&#39;: Metadata: encoder : Lavf58.45.100 Stream #0:0: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 256x240, q=-1--1, 35 fps, 17920 tbn, 35 tbc Metadata: encoder : Lavc58.91.100 libx264 Side data: cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/Aframe= 47 fps=0.0 q=0.0 size= 0kB time=00:00:00.00 bitrate=N/A speed= 0xframe= 76 fps= 68 q=30.0 size= 0kB time=00:00:00.65 bitrate= 0.6kbits/s speed=0.589xframe= 102 fps= 62 q=30.0 size= 0kB time=00:00:01.40 bitrate= 0.3kbits/s speed=0.846x</p><p> 输出＃0，mp4，到'output.mp4'：元数据：编码器：Lavf58.45.100流＃0：0：视频：h264（libx264）（avc1 / 0x31637661），yuv420p，256x240，q = -1--1， 35 fps，17920 tbn，35 tbc元数据：编码器：Lavc58.91.100 libx264辅助数据：cpb：最大比特率/最小/平均：0/0/0缓冲区大小：0 vbv_delay：N / Aframe = 47 fps = 0.0 q = 0.0大小= 0kB时间= 00：00：00.00比特率= N / A速度= 0xframe = 76 fps = 68 q = 30.0大小= 0kB时间= 00：00：00.65比特率= 0.6kbits / s速度= 0.589xframe = 102 fps = 62 q = 30.0大小= 0kB时间= 00：00：01.40比特率= 0.3kbits / s速度= 0.846x</p><p> The final step is to read the output file and supply it to a video element:</p><p> 最后一步是读取输出文件并将其提供给video元素：</p><p> const  output  =  ffmpeg . FS ( &#34; readFile &#34; ,  &#34; output.mp4 &#34; ); const  video  =  document . getElementById ( &#34; video &#34; ); video . src  =  URL . createObjectURL (  new  Blob ([ output . buffer ],  {  type :  &#34; video/mp4 &#34;  }) );</p><p> const output = ffmpeg。 FS（“ readFile”，“ output.mp4”）; const video = document。 getElementById（“ video”）;视频 。 src = URL。 createObjectURL（新的Blob（[output.buffer]，{type：“ video / mp4”}））;</p><p>  Interestingly, the experience of using FFmpeg.wasm, a command-line tool with a virtual file system, feels a bit like using a docker!</p><p>有趣的是，使用带有虚拟文件系统的命令行工具FFmpeg.wasm的经验有点像使用docker！</p><p>  Transcoding large files can take a little while. For a bit of fun, let’s take a look at how you can transcode the file into segments, incrementally adding them to the video buffer.</p><p>  对大文件进行代码转换可能需要一些时间。有趣的是，让我们看一下如何将文件转码为片段，并将其逐步添加到视频缓冲区中。</p><p> You can build a streaming media play by using the  Media Source Extension APIs, which includes the  MediaSource and  SourceBuffer objects. Creating and loading buffers can be quite tricky, with both of these objects providing lifecycle events which you must handle in order to append new buffers at the correct time. In order to manage the coordination of these various events, I opted to use  RxJS.</p><p> 您可以使用Media Source Extension API（包括MediaSource和SourceBuffer对象）来构建流媒体播放。创建和加载缓冲区可能非常棘手，因为这两个对象都提供了生命周期事件，您必须处理这些事件才能在正确的时间添加新的缓冲区。为了管理这些事件的协调，我选择使用RxJS。</p><p>  const  bufferStream  =  filename  =&gt;  new  Observable ( async  subscriber  =&gt;  {  const  ffmpeg  =  FFmpeg . createFFmpeg ({  corePath :  &#34; thirdparty/ffmpeg-core.js &#34; ,  log :  false  });  const  fileExists  =  file  =&gt;  ffmpeg . FS ( &#34; readdir &#34; ,  &#34; / &#34; ). includes ( file );  const  readFile  =  file  =&gt;  ffmpeg . FS ( &#34; readFile &#34; ,  file );  await  ffmpeg . load ();  const  sourceBuffer  =  await  fetch ( filename ). then ( r  =&gt;  r . arrayBuffer ());  ffmpeg . FS (  &#34; writeFile &#34; ,  &#34; input.mp4 &#34; ,  new  Uint8Array ( sourceBuffer ,  0 ,  sourceBuffer . byteLength )  );  let  index  =  0 ;  ffmpeg  . run (  &#34; -i &#34; ,  &#34; input.mp4 &#34; ,  // Encode for MediaStream  &#34; -segment_format_options &#34; ,  &#34; movflags=frag_keyframe+empty_moov+default_base_moof &#34; ,  // encode 5 second segments  &#34; -segment_time &#34; ,  &#34; 5 &#34; ,  // write to files by index  &#34; -f &#34; ,  &#34; segment &#34; ,  &#34; %d.mp4 &#34;  )  . then (()  =&gt;  {  // send out the remaining files  while  ( fileExists ( ` ${ index } .mp4` ))  {  subscriber . next ( readFile ( ` ${ index } .mp4` ));  index ++ ;  }  subscriber . complete ();  });  setInterval (()  =&gt;  {  // periodically check for files that have been written  if  ( fileExists ( ` ${ index  +  1 } .mp4` ))  {  subscriber . next ( readFile ( ` ${ index } .mp4` ));  index ++ ;  }  },  200 );  });</p><p>  const bufferStream = filename => new Observable（异步订阅者=> {const ffmpeg = FFmpeg。createFFmpeg（{corePath：“ thirdparty / ffmpeg-core.js”，log：false}）； const fileExists =文件=> ffmpeg。FS（ “（readdir”，“ /”）。包括（文件）; const readFile =文件=> ffmpeg。FS（“ readFile”，file）;等待ffmpeg。load（）; const sourceBuffer =等待fetch（文件名）。然后（r => r。arrayBuffer（））; ffmpeg。FS（“ writeFile”，“ input.mp4”，新的Uint8Array（sourceBuffer，0，sourceBuffer。byteLength））; let index = 0; ffmpeg。run（“ -i”， “ input.mp4”，//编码媒体流“ -segment_format_options”，“ movflags = frag_keyframe + empty_moov + default_base_moof”，//编码5秒段“ -segment_time”，“ 5”，//通过索引“-写文件f“，” segment“，”％d.mp4“）。然后（（）=> {//发送其余文件，而（fileExists（`$ {index} .mp4`））{ 。 next（readFile（`$ {index} .mp4`））;索引++; }订户。完成（）; }）; setInterval（（）=> {//定期检查是否已写入文件if（fileExists（`$ {index + 1} .mp4`））{Subscriber。next（readFile（`$ {index} .mp4`）） ; index ++;}}，200）; }）;</p><p> The above code uses the same FFmpeg.wasm setup as previously, writing the file to be transcoded into the memory file system. The  ffmpeg.run has a different configuration than the previous example in order to create a segmented output, with  suitable transcoder settings. When run, FFmpeg writes files with an incremental index ( 0.mp4,  1.mp4, …) to the mem file-system.</p><p> 上面的代码使用与以前相同的FFmpeg.wasm设置，将要转码的文件写入内存文件系统。 ffmpeg.run具有与上一个示例不同的配置，以便创建具有适当代码转换器设置的分段输出。运行时，FFmpeg将具有增量索引（0.mp4，1.mp4等）的文件写入mem文件系统。</p><p> In order to stream the output, an interval time polls the file system for the transcoded output, emitting the data as events via  subscriber.next. Finally, when  ffmpeg.run completes the remaining files are emitted and the stream completed (closed).</p><p> 为了流式传输输出，间隔时间轮询文件系统以获取转码后的输出，并通过Subscriber.next将数据作为事件发出。最后，当ffmpeg.run完成时，将发射其余文件，并完成流（关闭）。</p><p> In order to stream data into a video element, you need to create a  MediaSource object, and wait for the  sourceopen event to fire. The following code uses RxJS  combineLatest to ensure the FFmpeg output is not processed until this event fires:</p><p> 为了将数据流传输到视频元素，您需要创建一个MediaSource对象，并等待sourceopen事件触发。以下代码使用RxJS CombineLatest来确保在触发此事件之前不处理FFmpeg输出：</p><p> const  mediaSource  =  new  MediaSource (); videoPlayer . src  =  URL . createObjectURL ( mediaSource ); videoPlayer . play (); const  mediaSourceOpen  =  fromEvent ( mediaSource ,  &#34; sourceopen &#34; ); const  bufferStreamReady  =  combineLatest (  mediaSourceOpen ,  bufferStream ( &#34; 4club-JTV-i63.avi &#34; ) ). pipe ( map (([,  a ])  =&gt;  a ));</p><p>const mediaSource = new MediaSource（）;视频播放器 。 src = URL。 createObjectURL（mediaSource）;视频播放器 。播放（）; const mediaSourceOpen = fromEvent（mediaSource，“ sourceopen”）; const bufferStreamReady = CombineLatest（mediaSourceOpen，bufferStream（“ 4club-JTV-i63.avi”））。管道（map（（[[，a]）=> a））;</p><p> When the first video segment / buffer is received, we need to add a  SourceBuffer to the  MediaSource with the correct time and append the raw buffer to the  SourceBuffer. Following this, there is another careful point of coordination, new buffers cannot be added to the  SourceBuffer until it emits the  updateend event to indicate that the previous buffer has been processed.</p><p> 收到第一个视频片段/缓冲区时，我们需要在正确的时间将SourceBuffer添加到MediaSource并将原始缓冲区附加到SourceBuffer。此后，还有一个仔细的协调点，新缓冲区不能添加到SourceBuffer中，直到它发出updateend事件以指示先前的缓冲区已被处理。</p><p> The following code uses  take to handle the first buffer, and the handy  mux.js library to read the mime type. It then returns a new observable stream from the  updateend event:</p><p> 以下代码使用take处理第一个缓冲区，并使用方便的mux.js库读取mime类型。然后，它从updateend事件返回一个新的可观察流：</p><p> const  sourceBufferUpdateEnd  =  bufferStreamReady . pipe (  take ( 1 ),  map ( buffer  =&gt;  {  // create a buffer using the correct mime type  const  mime  =  `video/mp4; codecs=&#34; ${ muxjs . mp4 . probe  . tracks ( buffer )  . map ( t  =&gt;  t . codec )  . join ( &#34; , &#34; )} &#34;` ;  const  sourceBuf  =  mediaSource . addSourceBuffer ( mime );  // append the buffer  mediaSource . duration  =  5 ;  sourceBuf . timestampOffset  =  0 ;  sourceBuf . appendBuffer ( buffer );  // create a new event stream   return  fromEvent ( sourceBuf ,  &#34; updateend &#34; ). pipe ( map (()  =&gt;  sourceBuf ));  }),  flatMap ( value  =&gt;  value ) );</p><p> const sourceBufferUpdateEnd = bufferStreamReady。 pipe（take（1），map（buffer => {//使用正确的mime类型创建缓冲区const mime =`video / mp4; codecs =“ $ {muxjs。mp4.probe.tracks（buffer）。map（t => t。codec）。join（“，”）}“`; const sourceBuf = mediaSource。addSourceBuffer（mime）; //追加缓冲区mediaSource。duration = 5; sourceBuf timestampOffset = 0; sourceBuf。appendBuffer（buffer） ; // //创建一个新的事件流fromEvent（sourceBuf，“ updateend”）。pipe（map（（）=> sourceBuf））;}），flatMap（value => value））;</p><p> All that’s left is to append the buffers as they arrive, and when the  SourceBuffer is ready. This can be achieved using the RxJS  zip function:</p><p> 剩下的就是在缓冲区到达时以及SourceBuffer准备好时追加缓冲区。这可以使用RxJS zip函数来实现：</p><p> zip ( sourceBufferUpdateEnd ,  bufferStreamReady . pipe ( skip ( 1 )))  . pipe (  map (([ sourceBuf ,  buffer ],  index )  =&gt;  {  mediaSource . duration  =  10  +  index  *  5 ;  sourceBuf . timestampOffset  =  5  +  index  *  5 ;  sourceBuf . appendBuffer ( buffer . buffer );  })  )  . subscribe ();</p><p> zip（sourceBufferUpdateEnd，bufferStreamReady。pipe（skip（1）））。管道（map（（[[sourceBuf，buffer]，index）=> {mediaSource。duration = 10 + index * 5; sourceBuf。timestampOffset = 5 + index * 5; sourceBuf.appendBuffer（buffer.buffer）;}）））。订阅（）;</p><p> And that’s it - a bit of careful coordination of events, but ultimately very little code is needed to transcode a video, progressively adding the result into a video element.</p><p> 就是这样-对事件进行了一些仔细的协调，但最终只需很少的代码即可对视频进行转码，并将结果逐渐添加到视频元素中。</p><p>  I am Technology Director at Scott Logic and am a prolific technical author, blogger and speaker on a range of technologies.</p><p>我是Scott Logic的技术总监，还是多领域的技术作家，博客作者和演讲者。</p><p> My blog includes posts on a wide range of topics, including WebAssembly, HTML5 / JavaScript and data visualisation with D3 and  d3fc. You&#39;ll also find a whole host of posts about previous technology interests including iOS, Swift, WPF and Silverlight.</p><p> 我的博客包含有关广泛主题的文章，包括WebAssembly，HTML5 / JavaScript和使用D3和d3fc的数据可视化。您还将找到大量有关以前的技术兴趣的帖子，包括iOS，Swift，WPF和Silverlight。</p><p> I&#39;m board member of  FINOS, which is encouraging open source collaboration in the financial sector. I&#39;m also  very active on GitHub, contributing to a number of different projects.</p><p> 我是FINOS的董事会成员，FINOS鼓励金融领域的开源合作。我在GitHub上也非常活跃，为许多不同的项目做出了贡献。</p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://blog.scottlogic.com/2020/11/23/ffmpeg-webassembly.html">https://blog.scottlogic.com/2020/11/23/ffmpeg-webassembly.html</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/ffmpeg/">#ffmpeg</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/分享/">#分享</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy; 2020 diglog.com </div></div></body></html>