<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>AMD凭借本能的MI100 GPU加速器达到临界点AMD at a Tipping Point with Instinct MI100 GPU Accelerators</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">AMD at a Tipping Point with Instinct MI100 GPU Accelerators<br/>AMD凭借本能的MI100 GPU加速器达到临界点</h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2020-11-16 22:53:05</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2020/11/5c4284ddb9e4bd84bc387789040e6785.png"><img src="http://img2.diglog.com/img/2020/11/5c4284ddb9e4bd84bc387789040e6785.png" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>It is hard enough to chase one competitor. Imagine how hard it is to chase two different ones in different but complementary markets while at the same time those two competitors are thinking about fighting each other in those two different markets and thus bringing even more intense competitive pressure on both fronts.</p><p>追逐一个竞争者已经够难的了。想象一下，在不同但互补的市场上追逐两个不同的公司是多么困难，而这两个竞争对手却在考虑在这两个不同的市场上相互竞争，从而在两条战线上带来更大的竞争压力。</p><p> Welcome to being AMD. Just as AMD has gotten two generations of its Epyc processors out the door to compete well against Intel’s Xeon SPs and is readying a third generation (in this case the “Milan” Epyc 7003s that will ship later this year for revenue and be launched formally in early 2021) to pull considerably ahead, and just as it has gotten two generations of its Instinct GPUs out the door –  the Instinct MI25 in 2017 and  the Instinct MI50 in 2018 – and is now at the SC20 supercomputing conference unveiling the Instinct MI100, Intel is preparing to enter the market with  its “Ponte Vecchio” X e HPC next year as AMD looks to compete pretty well against  Nvidia’s current “Ampere” A100 GPU compute engine, and Nvidia is in the process of  buying Arm Holdings for $40 billion to try to drive Arm server chips into the datacenter against AMD Epycs and Intel Xeons.</p><p>欢迎成为AMD。就像AMD已经推出了两代Epyc处理器，以便与英特尔的至强SPS竞争，并准备推出第三代处理器(在这种情况下，第三代Epyc 7003将于今年晚些时候发货，并将于2021年初正式推出)，遥遥领先，就像它已经推出了两代本能GPU--2017年的本能MI25和2018年的本能MI50--现在是SC20超级计算产品。同样，AMD也推出了两代EPEC处理器，与英特尔的至强SPS展开竞争，并准备推出第三代EPEC 7003s，这款处理器将于今年晚些时候发货，并于2021年初正式发布。英特尔正准备明年以其“Ponte Vecchio”X e HPC进入市场，因为AMD希望与Nvidia目前的“Ampere”A100 GPU计算引擎展开激烈竞争，而NVIDIA正在以400亿美元收购ARM控股公司，试图将ARM服务器芯片推向数据中心，与AMD Epycs和英特尔至强(Intel Xeons)相抗衡，英伟达正在以400亿美元的价格收购ARM Holdings，试图将ARM服务器芯片推向数据中心，对抗AMD Epycs和英特尔至强(Intel Xeons)。</p><p> But at the moment, if the upper echelon of the HPC market is any kind of leading indicator – and we definitely believe that it is – then AMD is doing a remarkable job setting itself up to take share away from Intel in CPUs and Nvidia in GPU accelerators. The Instinct MI100 GPU accelerator that AMD is announcing today as the SC20 supercomputing conference is in full swing is the first step in revealing how this has been done, and therefore, where at least some of the HPC and AI market will be heading in the coming years.</p><p>但目前，如果HPC市场的高端市场是任何一种领先指标--我们绝对相信是这样--那么AMD正在做一项了不起的工作，准备从英特尔(Intel)和英伟达(Nvidia)的GPU加速器中夺走市场份额。在SC20超级计算大会如火如荼召开之际，AMD今天宣布推出的本能MI100 GPU加速器是揭示这一过程的第一步，也是揭示未来几年至少部分高性能计算和人工智能市场将走向何方的第一步。</p><p> Unlike CPUs and FPGAs, where there seem to be endless variants of features turned on or off to provide a SKU stack, this does not happen much for HPC and AI compute engines based on GPUs. Nvidia has two variants of the A100 – on that speaks NVLink 3.0 and one that speaks PCI-Express 4.0 – and the “Arcturus” GPU at the heart of the Instinct MI100 (Radeon is no longer part of the server accelerator brand) has precisely one SKU. There is a chance that it may have two if all of the compute elements inherent in the die are able to be activate as yields improve on the 7 nanometer process from Taiwan Semiconductor Manufacturing Corp used to make the Arcturus chip improve. But we wouldn’t count on it.</p><p>与CPU和FPGA不同的是，似乎有无穷无尽的各种功能打开或关闭以提供SKU堆栈，而对于基于GPU的HPC和AI计算引擎来说，这种情况并不多见。NVIDIA的A100有两个版本--On支持NVLink 3.0，另一个支持PCI-Express 4.0--而本能MI100(Radeon不再是服务器加速器品牌的一部分)核心的“Arcturus”GPU正好只有一个SKU。如果芯片中固有的所有计算元件都能够被激活，那么它可能有两个，因为成品率提高了台积电制造公司用来改进Arcturus芯片的7纳米工艺。但我们不会指望它。</p><p> This certainly did not happen in the last generation of Instinct GPU accelerators, which came out two years using the “Vega 20” GPUs based on its Graphics Core Next (GCN) architecture clocking at 1.8 GHz. The top-bin Instinct MI60 had 64 compute elements with a total of 4,096 stream processors while the Instinct MI50 had only 60 of those compute elements and therefore 3,840 of those stream processors activated, and therefore had lower performance by that ratio. The Instinct MI50 actually came to market and was sold, but we never saw the Instinct MI60 anywhere and AMD never talked about it again.</p><p>这肯定不会发生在上一代本能GPU加速器中，它在两年内推出了基于其图形核心Next(GCN)架构的“织女星20”GPU，其时钟频率为1.8 GHz。TOP-BIN本能MI60有64个计算元素，总共有4096个流处理器，而本能MI50只有60个计算元素，因此有3840个流处理器被激活，因此性能低于这个比率。本能军情50实际上进入了市场并被出售，但我们从未在任何地方看到过本能军情60，AMD也再也没有谈论过它。</p><p> The MI60 card had 32 GB of HBM2 memory, while the MI50 card had only 16 GB of memory, like the prior generation MI25 card, which was also based on the GCN architecture but clocked at a lower 1.5 GHz using a 14 nanometer process from GlobalFoundries compared to the 1.8 GHz of the MI50 and MI60 and therefore did not offer more oomph. And just for completion’s sake, the Vega 10 GPU was 495 square millimeters in size and had 12.5 billion transistors, while the Vega 20 was a much smaller 331 square millimeters in area and had 13.2 billion transistors using an earlier iteration of TSMC’s 7 nanometer process.</p><p>MI60卡有32 GB的HBM2内存，而MI50卡只有16 GB的内存，就像上一代的MI25卡一样，MI25卡也基于GCN架构，但使用GlobalFoundries的14纳米工艺，时钟频率比MI50和MI60的1.8 GHz低1.5 GHz，因此没有提供更多的吸引力。为了完整起见，织女星10图形处理器的大小为495平方毫米，拥有125亿个晶体管，而织女星20的面积要小得多，仅为331平方毫米，拥有132亿个晶体管，采用台积电7纳米制程的早期迭代。</p><p> The die size, transistor count, and clock speed for Arcturus have not been announced, but given that we think that the die has 128 compute units (alright, we know because we counted them on the die shot), we suspect this one is roughly twice the area with roughly twice the transistor count, but with the clock slowed down somewhere around 1.2 GHz to reduce the heat but still increase the aggregate number crunching of the Arcturus chip over the Vega 20.</p><p>Arcturus的芯片大小、晶体管数量和时钟速度尚未公布，但鉴于我们认为该芯片有128个计算单元(好的，我们知道是因为我们在芯片快照上对其进行了计数)，我们怀疑这块芯片的面积大约是晶体管数量的两倍，但时钟在1.2 GHz左右放慢了速度以减少热量，但仍然增加了Arcturus芯片在VEGA 20上的总运算数量。</p><p> The big change with the Arcturus GPU is that AMD is forking its graphics card GPUs aimed at gamers, where the processing of frames per second is paramount, from its GPU accelerators aimed at HPC and AI compute, where floating point and integer operations per second is key. This is the split between RDNA and CDNA chips, in the AMD lingo, and the Arcturus chip is the first instantiation of the CDNA architecture. This split is akin to the split that AMD has between Turing T4 and Volta V100 GPUs or Ampere A40 and A100 GPUs, and that Intel is also making with its X e HP and X e HPC GPUs. ( The Intel X e line is actually quite a bit broader than that.) That doesn’t mean that some HPA and AI customers won’t use the RDNA chips to do compute jobs – many will because they are cheap and because they do not need 64-bit floating point math or matrix math, which makes these devices heftier GPU compute engines more expensive. But the CDNA chips are expressly aimed at GPU compute jobs and are optimized for this.</p><p>Arcturus GPU的最大变化是，AMD将其针对游戏玩家的显卡GPU从针对HPC和AI计算的GPU加速器转变为针对游戏玩家，而在游戏玩家中，每秒的帧处理是至关重要的。在HPC和AI计算中，每秒的浮点和整数运算是关键。用AMD术语来说，这是rDNA和cDNA芯片之间的分离，而Arcturus芯片是cDNA架构的第一个实例。这种划分类似于AMD在图灵T4和Volta V100 GPU或安培A40和A100 GPU之间的划分，英特尔也在用它的Xe HP和Xe HPC GPU进行划分。(英特尔Xe产品线实际上比这要宽泛得多。)。这并不意味着一些HPA和AI客户不会使用rDNA芯片进行计算工作-许多客户会使用，因为它们价格便宜，而且不需要64位浮点数学或矩阵数学，这使得这些设备的GPU计算能力更强</p><p> Specifically, the Arcturus chip takes all of the circuits out of the streaming processors related to graphics, such as graphics caches and display engines as well as rasterization, tessellation, and blending features but because of workloads that chew on multimedia data – such as object detection in machine learning applications – the dedicated logic for HEVC, H.264, and VP9 decoding is left in. This freed up die space to add more stream processors and compute units.</p><p>具体地说，Arcturus芯片去掉了与图形相关的流处理器的所有电路，例如图形缓存和显示引擎，以及光栅化、镶嵌和混合功能，但由于需要消耗多媒体数据的工作负载(例如机器学习应用程序中的对象检测)，因此保留了用于HEVC、H.264和VP9解码的专用逻辑。这释放了芯片空间以添加更多流处理器和计算单元。</p><p> Here is what the Arcturus die looks like with its four banks of HBM2 memory visually aligned with it (but obviously not logically connected:</p><p>下面是Arcturus骰子的外观，它的四个HBM2存储体在视觉上与之对齐(但显然没有逻辑连接：</p><p>  And here is the block diagram that shows what the elements of the Arcturus GPU are at a high level:</p><p>下面的框图显示了Arcturus GPU的高级元素：</p><p>  The compute elements are broken into eight banks, with two banks with a total of 32 compute elements sharing each HBM2 memory controller and therefore 8 GB of HBM2 memory. We strongly suspect that AMD will eventually double up the HBM2 memory on the Instinct MI100 accelerator cards at some point, particularly with Nvidia now boosting the HBM2 memory on its Ampere A100 card from 40 GB across five active controllers (the design has six, but one is latent) to 80 GB as part of its SC20 announcements today. The Arcturus memory controllers support HBM2 stacks that are four chips high or eight chips high, and we think the initial Instinct MI100 cards are using the four-high stacks at 2 GB per chip. If this is the case, then 64 GB is possible at some point in the future by stacking the memory twice as high. The current configuration has  the memory supporting 2.4 GT/sec, delivering 1.23 TB/sec of aggregate memory bandwidth, which AMD says is 20 percent more bandwidth than with the Instinct MI50 card but in the same power envelope for the memory.</p><p>计算元件分为八个存储体，其中两个存储体共有32个计算元件，共享每个HBM2内存控制器，因此共享8 GB的HBM2内存。我们强烈怀疑AMD最终会在某个时候将本能MI100加速卡上的HBM2内存增加一倍，特别是NVIDIA现在将其Ampere A100卡上的HBM2内存从40 GB提升到80 GB，包括五个活动控制器(设计有六个，但一个是潜在的)，这是其SC20声明的一部分。Arcturus内存控制器支持四个芯片高或八个芯片高的HBM2堆栈，我们认为最初的本能MI100卡使用的是每个芯片2 GB的四高堆栈。如果是这种情况，那么在将来的某个时候，通过将内存堆叠成两倍的高度，64 GB是可能的。目前的配置是内存支持2.4GT/秒，提供1.23TB/秒的聚合内存带宽，AMD表示，这比本能MI50卡的带宽高出20%，但内存的功率包络相同。</p><p> The Arcturus design has two blocks of compute engines, top and bottom, with two banks of 16-way associative L2 cache that has a total of 32 slices, linking them all to each other. The L2 cache capacity weighs in at a total of 8 MB and delivers an aggregate 6 TB/sec of bandwidth into and out of the compute engines. All of the memory has ECC error detection and correction, of course, which is necessary for compute workloads and less so for plain vanilla graphics, which can survive a bit error burp.</p><p>Arcturus设计有两个计算引擎块，顶部和底部，以及两组16路关联二级缓存，总共有32个切片，将它们全部链接在一起。L2缓存容量总计为8 MB，在进出计算引擎时提供总计6 TB/秒的带宽。当然，所有内存都具有ECC错误检测和纠正功能，这对于计算工作负载是必要的，而对于普通显卡则不是那么必要，因为它可以经受住位错误打嗝。</p><p> The whole shebang is wrapped up with AMD’s Infinity Fabric, a superset of the HyperTransport point-to-point link that was the heart and soul of the Opteron CPU architecture from more than a decade ago and that has been expanded and extended in many ways, including its use as a GPU-to-GPU interconnect and at some point in the future with CPU-to-GPU interconnect. The important thing is that Infinity Fabric supports coherent memory across devices, just like Nvidia’s NVLink does. On the Arcturus GPU compute engines, the Infinity Fabric runs at 23 GT/sec and is 16-bits wide, just like on the MI50 and MI60 Vega 20 GPUs, but with the Arcturus MI100 cards, there are three Infinity Fabric links coming off the die so that four GPUs can be crosslinked with only one hop between any two devices. Each one of those Infinity Fabric pipes has 92 GB/sec of bandwidth.</p><p>整个架构都被AMD的Infinity Fabric包住了，这是HyperTransport点对点链路的超集，从十多年前就是Opteron CPU架构的核心和灵魂，并在许多方面得到了扩展和延伸，包括用作GPU到GPU的互连，以及在未来的某个时候用于CPU到GPU的互连。重要的是，Infinity Fabric支持跨设备的一致内存，就像NVIDIA的NVLink一样。在Arcturus GPU计算引擎上，Infinity Fabric运行速度为23GT/秒，16位宽，就像在MI50和MI60织女星20 GPU上一样，但使用Arcturus MI100卡时，芯片上有三个Infinity Fabric链路，因此四个GPU可以通过任意两个设备之间的一跳进行交叉链接。每个Infinity光纤管道都有92 GB/秒的带宽。</p><p> Having three Infinity Fabric pipes per Arcturus GPU allows a NUMA-like coupling of four GPUs and 128 GB of HBM2 memory into a much bigger virtual GPU, much like UltraPath Interconnect at Intel (a follow-on of QuickPath Interconnect, which is itself inspired by the Opteron design) allows for four CPUs to be tightly linked and share memory with only one hop in the “Cooper Lake” Xeon SP generation. Here is what an Infinity Fabric “hive” of four GPUs looks like:</p><p>每个Arcturus GPU有三个Infinity Fabric管道，可以像NUMA一样将四个GPU和128 GB的HBM2内存耦合到一个大得多的虚拟GPU中，这很像英特尔的UltraPath互连(QuickPath互连的后续产品，其本身的灵感来自Opteron设计)允许四个CPU紧密连接在一起，并且在“Cooper Lake”Xeon SP一代中只需一跳即可共享内存。以下是由四个GPU组成的Infinity Fabric“蜂巢”的外观：</p><p>  With only two Infinity Fabric ports on the Instinct MI50 and MI60 cards, banks of GPUs could only be hooked to each other in a ring topology and the larger the number of GPUs in the ring, the more latency between the devices.</p><p>由于本能MI50和MI60卡上只有两个Infinity交换矩阵端口，GPU组只能在环形拓扑中相互连接，并且环中的GPU数量越多，设备之间的延迟就越大。</p><p> At some point in the future, the Epyc CPUs and the Instinct GPUs will have enough Infinity Fabric ports to cross couple a single CPU to a quad of GPUs, all with coherent memory across the devices. IBM has supported such coherence between Power9 processors and Nvidia V100 GPU accelerators for the past three years, and it is one reason that Big Blue won the contracts to build the “Summit” hybrid supercomputer at Oak Ridge National Laboratories and its companion “Sierra” supercomputer at Lawrence Livermore National Laboratories. For whatever reason, this coherence between CPU and GPU will not be available with the Power10 processors and the current Ampere GPUs and we presume future Nvidia GPUs because IBM wants to use OpenCAPI and Nvidia wants to use NVLink, and this may be one reason why Big Blue didn’t win the contracts for the follow-on “Frontier” and “El Capitan” exascale-class systems at these two labs in the United States. That said, the fallout over OpenCAPI and NVLink could be one result of losing the deal, not necessarily an effect.</p><p>在未来的某个时候，EPEC CPU和本能GPU将有足够的Infinity Fabric端口将单个CPU交叉耦合到四个GPU，所有这些设备都具有一致的内存。过去三年来，IBM一直支持Power9处理器和NVIDIA V100 GPU加速器之间的这种一致性，这也是蓝色巨人赢得在橡树岭国家实验室(Oak Ridge National Laboratory)和劳伦斯·利弗莫尔国家实验室(Lawrence Livermore National Laboratory)建造“Summit”混合超级计算机的合同的原因之一。无论出于什么原因，在Power10处理器和当前的安培GPU上都无法实现CPU和GPU之间的一致性，我们推测未来的NVIDIA GPU是因为IBM想要使用OpenCAPI，而NVIDIA想要使用NVLink，这可能是蓝色巨人没有赢得美国这两个实验室的后续“Frontier”和“El Capitan”亿级系统合同的原因之一。话虽如此，OpenCAPI和NVLink的余波可能是交易失败的一个结果，而不一定是影响。</p><p> At this point, the Instinct MI100 cards link to processors using standard PCI-Express 4.0 x16 links, which support 32 GB/sec of bandwidth in each direction, to and fro, between the devices. Add it all up, and each Instinct MI100 card has 64 GB/sec of PCI-Express 4.0 bandwidth and 276 GB/sec of Infinity Fabric bandwidth across its three pipes, for a total of 340 GB/sec of I/O bandwidth.</p><p>在这一点上，本能MI100卡使用标准的PCI-Express 4.0 x16链路连接到处理器，这些链路在设备之间的往返方向上支持32 GB/秒的带宽。所有这些加在一起，每一块本能MI100卡在其三个管道上有64 GB/秒的PCI-Express 4.0带宽和276 GB/秒的Infinity光纤带宽，总共有340 GB/秒的I/O带宽。</p><p> We will be doing a deep dive on the Arcturus GPU, including its new Matrix Core architecture and how it compares and contrasts with prior Instinct cards and Nvidia GPU compute engines, but for now, here are the raw feeds and speeds:</p><p>我们将深入研究Arcturus GPU，包括其新的Matrix Core架构，以及它与之前的本能显卡和NVIDIA GPU计算引擎的比较和对比，但目前，以下是原始馈送和速度：</p><p>  As you can see, only 120 of the 128 compute units on the Arcturus die, and therefore only 7,680 of its potential 8,192 streaming processors are activated. There is another 6.7 percent performance boost at the same clock speed inherent in the design as TSMC 7 nanometer yields improve – but as we say above, we wouldn’t count on it. The fun bit is that Arcturus is the first GPU accelerator to break through the 10 teraflops floating point barrier 64-bit precision – and AMD is doing it in a 300 watt thermal envelope for 11.5 teraflops, not a 400 watt one like Nvidia has with its Ampere A100, which weighs in at only 9.7 teraflops at 64-bit precision floating point. But, Nvidia has its own latent capacity in the Ampere device too. Who will get the TSMC yield up faster?  Hmmmm. . . .</p><p>如您所见，Arcturus上的128个计算单元中只有120个死机，因此其潜在的8,192个流处理器中只有7,680个被激活。随着台积电7纳米成品率的提高，在设计中固有的相同时钟速度下，还有6.7%的性能提升-但正如我们上面所说的，我们不会指望它。有趣的是，Arcturus是第一个突破64位精度10万亿次浮点运算限制的GPU加速器--AMD是在11.5万亿次浮点运算的300瓦热封套中做到这一点的，而不是像英伟达安培A100那样的400瓦，64位浮点运算时，安培A100的重量只有9.7万亿次浮点运算。但是，NVIDIA在安培设备上也有自己的潜力。谁会让台积电收益率上升得更快？嗯哼。。。。</p><p> Pricing on the Instinct MI100 was not divulged, but we are going to try to see what the OEMs are charging for it. Here are the initial OEM vendors and their machines that will support the MI100 GPU accelerator:</p><p>本能MI100的定价并未透露，但我们将试着看看原始设备制造商对它的定价。以下是将支持MI100 GPU加速器的初始OEM供应商及其机器：</p><p> Featuring highlights, analysis, and stories from the week directly from us to your inbox with nothing in between.</p><p>将本周的精彩内容、分析和故事直接从我们的收件箱发送到您的收件箱，中间没有任何内容。</p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://www.nextplatform.com/2020/11/16/amd-at-a-tipping-point-with-instinct-mi100-gpu-accelerators/">https://www.nextplatform.com/2020/11/16/amd-at-a-tipping-point-with-instinct-mi100-gpu-accelerators/</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/本能/">#本能</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/tipping/">#tipping</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/gpu/">#gpu</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/分享/">#分享</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy; 2020 diglog.com </div></div></body></html>