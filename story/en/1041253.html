<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>带有K3的裸机Kubernetes Bare-Metal Kubernetes with K3s</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">Bare-Metal Kubernetes with K3s<br/>带有K3的裸机Kubernetes </h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2020-12-22 21:21:34</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2020/12/bad86c310ab10fd610c85e1675d83c78.jpg"><img src="http://img2.diglog.com/img/2020/12/bad86c310ab10fd610c85e1675d83c78.jpg" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>Learn how to configure K3s on bare-metal to run a Kubernetes cluster with just as much resilience and fault tolerance as a managed service.</p><p>了解如何在裸机上配置K3来运行Kubernetes集群，该集群具有与托管服务一样的弹性和容错能力。</p><p> This tutorial is a follow-on from my post  Kubernetes on bare-metal in 10 minutes from 2017. The original post focused on getting  Kubernetes working across a number of bare-metal hosts running Ubuntu, and then it went on to deploy a microservice and the dashboard. It was a primer, and written to help new users kick the tires with Kubernetes. It used production-ready kubeadm, but only used one master node, meaning it couldn&#39;t tolerate a failure.</p><p> 本教程是我从2017年开始的10分钟内在裸机上发布Kubernetes的后续文章。原始文章的重点是让Kubernetes在运行Ubuntu的大量裸机上工作，然后继续部署微服务和仪表板。它是一本入门书，旨在帮助新用户使用Kubernetes来解决问题。它使用了可用于生产的kubeadm，但仅使用了一个主节点，这意味着它不能容忍故障。</p><p> In this post, I want to provide you with a HA, production-ready cluster on bare-metal infrastructure. We will use  Equinix Metal for the hosts, automate the boring parts, but do the rest step by step, so that you can get an understanding on what&#39;s going on under the hood.</p><p> 在这篇文章中，我想为您提供一个在裸机基础架构上可用于生产的HA集群。我们将对主机使用Equinix Metal，使无聊的零件自动化，但其余步骤将逐步进行，以便您可以了解引擎盖下的情况。</p><p> In the conclusion, we will review the setup and discuss other options for running on-premises or in a homelab with Raspberry Pis. We will also compare kube-vip to other solutions for bare-metal and self-hosted networking.</p><p> 最后，我们将回顾设置并讨论在本地或使用Raspberry Pis在homelab中运行的其他选项。我们还将kube-vip与其他用于裸机和自托管网络的解决方案进行比较。</p><p>  Conceptual diagram: kubectl access provided by the stable EIP. The IngressController also has an EIP which routes traffic for services exposed with Ingress such as the OpenFaaS gateway.</p><p>  概念图：稳定EIP提供的kubectl访问。 IngressController还具有一个EIP，可以为通过Ingress公开的服务（例如OpenFaaS网关）路由流量。</p><p> This post also moves from kubeadm to using  K3s (a  CNCF project), which requires fewer resources for its control-plane and has a built-in HA mode using embedded  etcd. K3s has been generally available (GA) and production ready since 2019.</p><p> 这篇文章也从kubeadm转移到使用K3s（CNCF项目），后者需要较少的控制面资源，并具有使用嵌入式etcd的内置HA模式。自2019年以来，K3现已全面上市（GA），并已准备就绪。</p><p>  We will use  Terraform to create the nodes on  Equinix Metal (aka Packet) servers, k3s to create a HA control-plane, and  kube-vip to configure a HA IP address for the API server.</p><p>  我们将使用Terraform在Equinix Metal（aka数据包）服务器上创建节点，使用k3s创建HA控制平面，并使用kube-vip为API服务器配置HA IP地址。 </p><p> The setup will be able to tolerate at least one failure of a server. So unlike the 2017 post, our servers will form a HA cluster, and will also have an Elastic IP (EIP) configured so that the Kubernetes API server will remain accessible if one or more of the servers becomes unavailable.</p><p>该设置将能够承受至少一台服务器的故障。因此，与2017年的发布不同，我们的服务器将组成一个HA集群，并且还将配置一个弹性IP（EIP），以便在其中一台或多台服务器不可用时，Kubernetes API服务器仍可访问。</p><p> In a Kubernetes cluster, the Cloud Controller Manager add-on has several responsibilities including node management, routing and managing services. At the end of the tutorial, not only will your cluster have a HA control-plane, a stable IP for the API Server, but Equinix Metal&#39;s (CCM) will also allow you to expose services as type LoadBalancer. Each IP address costs around 3.25 USD / mo, you can find out more details on the IP Addresses section of the dashboard.</p><p> 在Kubernetes集群中，Cloud Controller Manager插件具有多项职责，包括节点管理，路由和管理服务。在本教程的最后，不仅您的集群将具有HA控制平面，API服务器的稳定IP，而且Equinix Metal（CCM）还将允许您将服务公开为LoadBalancer类型。每个IP地址的费用约为3.25 USD / mo，您可以在信息中心的IP地址部分中找到更多详细信息。</p><p> Skill level: intermediate to advanced. You should be familiar with Kubernetes, networking and public cloud infrastructure.</p><p> 技能水平：中级到高级。您应该熟悉Kubernetes，网络和公共云基础架构。</p><p>  Download  arkade, a portable Kubernetes marketplace and downloader for DevOps CLIs. It will be used to download the tools we need for the tutorial. You are of course welcome to do things the hard way, if you prefer.</p><p>  下载arkade，一个可移植的Kubernetes市场和DevOps CLI的下载器。它将用于下载本教程所需的工具。当然，如果您愿意，也欢迎您用辛苦的方式做事。</p><p> curl -sLS https://dl.get-arkade.dev | sh# Install the binary using the command given as output, such as: sudo cp arkade-darwin /usr/local/bin/arkade# Or on Linux:sudo cp arkade /usr/local/bin/arkade</p><p> curl -sLS https://dl.get-arkade.dev | sh＃使用作为输出提供的命令安装二进制文件，例如：sudo cp arkade-darwin / usr / local / bin / arkade＃或在Linux上：sudo cp arkade / usr / local / bin / arkade</p><p>  terraform - an Infrastructure as code (IaC) tool, which we&#39;ll used to create the initial hosts</p><p>  terraform-基础架构即代码（IaC）工具，我们将使用该工具来创建初始主机</p><p>     We will use terraform to provision three servers and two agents. You can alter these numbers, but three is the minimum number required for K3s&#39; built-in HA mode using etcd.</p><p>     我们将使用terraform来配置三个服务器和两个代理。您可以更改这些数字，但K3所需的最小数字是三。使用etcd的内置HA模式。 </p><p> You may well ask why the entire blog post isn&#39;t just a single Terraform command. I can hear you Hacker News. This point of this post isn&#39;t to do all the work for you, but to help you understand what is required, and in what order. Creating hosts is boring, so we are going to automate that and save you some time.</p><p>您可能会问为什么整个博客文章不只是一个Terraform命令。我能听到你的黑客新闻。这篇文章的重点不是为您完成所有工作，而是帮助您了解所需的内容和顺序。创建主机很无聊，因此我们将使其自动化并为您节省一些时间。</p><p>  terraform { required_providers { packet = { source = &#34;terraform-providers/packet&#34; version = &#34;~&gt; 3.2.1&#34; } } required_version = &#34;&gt;= 0.13&#34;}variable &#34;api_token&#34; { description = &#34;Equinix Metal API token&#34;}variable &#34;project_id&#34; { description = &#34;Equinix Metal Project ID&#34;}variable &#34;servers&#34; { description = &#34;Count of servers&#34;}variable &#34;agents&#34; { description = &#34;Count of agents&#34;}provider &#34;packet&#34; { auth_token=var.api_token}resource &#34;packet_ssh_key&#34; &#34;key1&#34; { name = &#34;k3sup-1&#34; public_key = file(&#34;/home/alex/.ssh/id_rsa.pub&#34;)}resource &#34;packet_device&#34; &#34;k3s-server&#34; { count		 = var.servers hostname = &#34;k3s-server-${count.index+1}&#34; plan = &#34;c1.small.x86&#34; facilities = [&#34;ams1&#34;] operating_system = &#34;ubuntu_20_10&#34; billing_cycle = &#34;hourly&#34; project_id = var.project_id depends_on = [packet_ssh_key.key1]}resource &#34;packet_device&#34; &#34;k3s-agent&#34; { count 	 = var.agents hostname = &#34;k3s-agent-${count.index+1}&#34; plan = &#34;c1.small.x86&#34; facilities = [&#34;ams1&#34;] operating_system = &#34;ubuntu_20_10&#34; billing_cycle = &#34;hourly&#34; project_id = var.project_id depends_on = [packet_ssh_key.key1]}output &#34;server_ips&#34; { value = packet_device.k3s-server.*.access_public_ipv4}output &#34;agent_ips&#34; { value = packet_device.k3s-agent.*.access_public_ipv4}</p><p>  terraform {required_providers {包= {来源=＆＃34; terraform-providers / packet＆＃34;版本=＆＃34;〜＆gt; 3.2.1＆＃34; }} required_version =＆＃34;＆gt; = 0.13＆＃34;}变量＆＃34; api_token＆＃34; {description =＆＃34; Equinix Metal API令牌＆＃34;}变量＆＃34; project_id＆＃34; {description =＆＃34; Equinix Metal Project ID＆＃34;}变量＆＃34; servers＆＃34; {description =＆＃34; servers＆＃34;}变量＆＃34; agents＆＃34; {description =＆＃34; Agents＆＃34;}提供商＆＃34; packet＆＃34; {auth_token = var.api_token}资源＆＃34; packet_ssh_key＆＃34; ＆＃34; key1＆＃34; {name =＆＃34; k3sup-1＆＃34; public_key = file（＆＃34; /home/alex/.ssh/id_rsa.pub&#34;）}资源＆＃34; packet_device＆＃34; ＆＃34; k3s服务器＆＃34; {count = var.servers主机名=＆＃34; k3s-server-$ {count.index + 1}＆＃34;计划=＆＃34; c1.small.x86＆＃34;设施= [＆amp; ams1＆＃34;] operating_system =＆＃34; ubuntu_20_10＆＃34; billing_cycle =＆＃34;每小时＆＃34; project_id = var.project_iddepends_on = [packet_ssh_key.key1]}资源＆＃34; packet_device＆＃34; ＆＃34; k3s-agent＆＃34; {count = var.agents主机名=＆＃34; k3s-agent-$ {count.index + 1}＆＃34;计划=＆＃34; c1.small.x86＆＃34;设施= [＆amp; ams1＆＃34;] operating_system =＆＃34; ubuntu_20_10＆＃34; billing_cycle =＆＃34;每小时＆＃34; project_id = var.project_iddepends_on = [packet_ssh_key.key1]}输出＆＃34; server_ips＆＃34; {value = packet_device.k3s-server。*。access_public_ipv4}输出＆＃34; agent_ips＆＃34; {value = packet_device.k3s-agent。*。access_public_ipv4}</p><p>   Edit  api_token and  project_id with the values from the Equinix Metal dashboard. The API key is found on your user profile.</p><p>   使用Equinix Metal仪表板中的值编辑api_token和project_id。该API密钥可在您的用户个人资料中找到。</p><p> If you wish to change the size of the nodes, you can edit  c1.small.x86 and use a different value. You can find the options in your dashboard.</p><p> 如果要更改节点的大小，可以编辑c1.small.x86并使用其他值。您可以在信息中心中找到这些选项。</p><p>         K3s can run in a HA mode, where a failure of a master node can be tolerated. This isn&#39;t enough for public-facing clusters, where a stable IP address for the Kubernetes control-plane is required.</p><p>         K3可以在HA模式下运行，在该模式下可以容忍主节点的故障。对于面向公众的集群来说，这还不够，在集群中，需要Kubernetes控制平面的稳定IP地址。</p><p> We need a stable IP for port 6443, which we could also call an Elastic IP or EIP. Fortunately BGP can help us there. One of our three master nodes will advertise its IP address as the route for the EIP, then if it goes down, another will start advertising. This means our clients can always depend on a stable address of:  https://$EIP:6443 for connecting to the Kubernetes API server.</p><p> 我们需要端口6443的稳定IP，我们也可以将其称为弹性IP或EIP。幸运的是，BGP可以为我们提供帮助。我们的三个主节点之一将发布其IP地址作为EIP的路由，然后，如果发生故障，另一个将开始发布。这意味着我们的客户可以始终依赖以下稳定地址：https：// $ EIP：6443连接到Kubernetes API服务器。</p><p>      Add this line to  hosts.txt so that you have it, if you need it later.</p><p>      将此行添加到hosts.txt中，以便以后需要时使用。 </p><p>  Click on each server in the Equinix Metal dashboard. Click on its details page, then BGP. Find the Manage button on the IPv4 row and click &#34;Enable BGP&#34;.</p><p>单击Equinix Metal仪表板中的每个服务器。单击其详细信息页面，然后单击BGP。在IPv4行上找到“管理”按钮，然后单击＆＃34;启用BGP＆＃34;。</p><p>   For various reasons, we can only set up kube-vip after K3s has started, so we will create the first master node:</p><p>   由于各种原因，我们只能在K3启动后才能设置kube-vip，因此我们将创建第一个主节点：</p><p> k3sup install \ --ip $SERVER1 \ --tls-san $EIP \ --cluster \ --k3s-channel latest \ --k3s-extra-args &#34;--no-deploy servicelb --disable-cloud-controller&#34; \ --merge \ --local-path $HOME/.kube/config \ --context=em-ha-k3s</p><p> k3sup install \ --ip $ SERVER1 \ --tls-san $ EIP \ --cluster \ --k3s-channel最新\ --k3s-extra-args＆＃34;-no-deploy servicelb --disable-cloud -控制器＆＃34; \-合并\-本地路径$ HOME / .kube / config \ --context = em-ha-k3s</p><p> --tls-san is required to advertise the EIP, so that K3s will create a valid certificate for the API server.</p><p> 必须使用--tls-san来通告EIP，以便K3可以为API服务器创建有效的证书。</p><p> the  --k3s-channel is specifying the latest version of K3s, which in this instance will be 1.19, by the time you run this tutorial, it may have changed, in which can you can give  1.19 as the channel, or a specific version with  --k3s-version</p><p> --k3s-channel指定了K3s的最新版本，在本例中为1.19，在您运行本教程时，它可能已更改，您可以在其中指定1.19作为通道或特定版本使用--k3s-version</p><p> note the  --cluster flag, which tells the server to use etcd to create a cluster for the servers we will join later on</p><p> 注意--cluster标志，该标志告诉服务器使用etcd为服务器创建集群，我们稍后将加入</p><p> --local-path,  --context and  --merge all allow us to merge the KUBECONFIG from the K3s to our local file.</p><p> --local-path，-context和--merge都允许我们将KUBECONFIG从K3合并到本地文件。 </p><p> in  --k3s-extra-args we disable the built-in K3s service load-balancer, and also disable the cloud-controller, because we will use the Equinix Metal Cloud Controller Manager instead.</p><p>在--k3s-extra-args中，我们禁用了内置的K3s服务负载均衡器，并且也禁用了云控制器，因为我们将改用Equinix Metal Cloud Controller Manager。</p><p>       Now log into the first server using SSH. There is a one-time configuration option required for each server.</p><p>       现在，使用SSH登录到第一台服务器。每个服务器都需要一个一次性配置选项。</p><p> ssh root@$SERVER1ctr image pull docker.io/plndr/kube-vip:0.3.0alias kube-vip=&#34;ctr run --rm --net-host docker.io/plndr/kube-vip:0.3.0&#34;export INTERFACE=loexport EIP=&#34;147.75.100.237&#34;kube-vip vip /kube-vip manifest daemonset \ --interface $INTERFACE \ --vip $EIP \ --controlplane \ --services \ --inCluster \ --taint \ --bgp \ --packet \ --provider-config /etc/cloud-sa/cloud-sa.json | tee /var/lib/rancher/k3s/server/manifests/vip.yaml</p><p> ssh root @ $ SERVER1ctr镜像拉docker.io/plndr/kube-vip:0.3.0alias kube-vip =＆＃34; ctr运行--rm --net-host docker.io/plndr/kube-vip:0.3。 0＆＃34; export INTERFACE = loexport EIP =＆＃34; 147.75.100.237＆＃34; kube-vip vip / kube-vip清单守护程序\ --interface $ INTERFACE \ --vip $ EIP \ --controlplane \-服务\ --inCluster \ --taint \ --bgp \ --packet \ --provider-config /etc/cloud-sa/cloud-sa.json |开球/var/lib/rancher/k3s/server/manifests/vip.yaml</p><p> The manifest for kube-vip will be created at  /var/lib/rancher/k3s/server/manifests/vip.yaml, any files placed here will be run by K3s.</p><p> kube-vip的清单将在/var/lib/rancher/k3s/server/manifests/vip.yaml中创建，此处放置的所有文件都将由K3s运行。</p><p>   Now deploy the  Equinix Metal Cloud Controller Manager (CCM), which will create the  /etc/cloud-sa/cloud-sa.json file referenced in the command above.</p><p>   现在部署Equinix Metal Cloud Controller Manager（CCM），它将创建上面命令中引用的/etc/cloud-sa/cloud-sa.json文件。</p><p> As configured, the CCM will obtain IP addresses from the Equinix Metal API for any services that are exposed.</p><p> 按照配置，CCM将从Equinix Metal API获取公开的任何服务的IP地址。</p><p>  export API_KEY=&#34;&#34;export PROJECT_ID=&#34;&#34;cat &lt;&lt;EOF &gt; ccm-secret.yamlapiVersion: v1kind: Secretmetadata: name: packet-cloud-config namespace: kube-systemstringData: cloud-sa.json: | { &#34;apiKey&#34;: &#34;$API_KEY&#34;, &#34;projectID&#34;: &#34;$PROJECT_ID&#34; }EOF</p><p>  导出API_KEY =＆＃34;＆＃34;导出PROJECT_ID =＆＃34;＆＃34; cat＆lt;＆lt;＆lt;＆lt; EOF＆gt; ccm-secret.yamlapiVersion：v1kind：Secretmetadata：名称：packet-cloud-config名称空间：kube-systemstringData：cloud-sa.json：| {＆＃34; apiKey＆＃34 ;:＆＃34; $ API_KEY＆＃34 ;,＆＃34; projectID＆＃34 ;:＆＃34; $ PROJECT_ID＆＃34; } EOF </p><p>   The gist contains a forked version of the Equinix Metal CCM. This was developed by the author of kube-vip and will be upstreamed, at which point the URL will redirect to the  original repo for the CCM.</p><p>要点包含Equinix Metal CCM的分支版本。这是由kube-vip的作者开发的，将被上传到上游，这时URL将重定向到CCM的原始存储库。</p><p>     Now that we have the first server up and running, and advertising its EIP, we can use it to join our other servers, and later our agents using the EIP.</p><p>     现在，我们已经启动并运行了第一台服务器，并发布了它的EIP，我们可以使用它来加入其他服务器，然后再使用EIP来代理。</p><p> This is important, because if we used the IP of one of the servers, and that server went down, the agent would no longer be able to communicate with the API server.</p><p> 这很重要，因为如果我们使用其中一台服务器的IP，而该服务器已关闭，则代理将不再能够与API服务器通信。</p><p>  --server-ip - note that we specified the EIP, and not the IP of any one server here</p><p>  --server-ip-请注意，我们指定的是EIP，而不是此处指定的任何一台服务器的IP</p><p> This command will write a kubeconfig file into your local directory, ignore it and continue to use the one that was merged into your kubeconfig file.</p><p> 此命令会将kubeconfig文件写入您的本地目录，将其忽略，然后继续使用已合并到kubeconfig文件中的文件。</p><p>    To add an agent (or worker) node, use the join command from above, but remove the  --server flag.</p><p>    要添加代理（或工作程序）节点，请使用上方的join命令，但删除--server标志。</p><p> agents=(&#34;$AGENT1&#34; &#34;$AGENT2&#34;)for i in ${agents[*]} do k3sup join \ --ip $i \ --server \ --server-ip $EIP \ --k3s-channel latestdone</p><p> agent =（＆＃34; $ AGENT1＆＃34;＆＃34; $ AGENT2＆＃34;）为$ {agents [*]}中的i进行k3sup join \ --ip $ i \ --server \ --server- ip $ EIP \ --k3s-channel最新完成 </p><p>  From your own computer, switch your KUBECONFIG to use the EIP instead of the SERVER1 IP which k3sup will have set for you by default.</p><p>在您自己的计算机上，将KUBECONFIG切换为使用EIP而不是k3sup默认为您设置的SERVER1 IP。</p><p>         The arkade tool we installed earlier not only installs CLIs, but is an open-source Kubernetes marketplace. You can use it on your Raspberry Pi, your Equinix Metal cluster, at work, on your laptop, wherever you want. It provides around 40 Kubernetes applications and is open source, so you can fork it and add your own.</p><p>         我们之前安装的arkade工具不仅安装CLI，而且是开源Kubernetes市场。您可以在工作中的任意位置，在工作中的Raspberry Pi，Equinix Metal群集上使用它。它提供了大约40个Kubernetes应用程序，并且是开源的，因此您可以创建它并添加自己的。</p><p> kube-vip works in tandem with the CCM. The CCM will obtain a new IP address for you from Equinix Metal&#39;s API, then assign it to any LoadBalancer service in the Pending state. kube-vip then starts advertising the IP address and routing traffic to the nodes.</p><p> kube-vip与CCM协同工作。 CCM将通过Equinix Metal的API为您获取新的IP地址，然后将其分配给处于“待处理”状态的任何LoadBalancer服务。然后，kube-vip开始通告IP地址并将流量路由到节点。</p><p>    kubectl get svc -o wide -wNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTORkubernetes ClusterIP 10.43.0.1 &lt;none&gt; 443/TCP 151m &lt;none&gt;nginx-1 LoadBalancer 10.43.71.39 &lt;pending&gt; 80:30822/TCP 3s app=nginxnginx-1 LoadBalancer 10.43.71.39 &lt;pending&gt; 80:30822/TCP 5s app=nginxnginx-1 LoadBalancer 10.43.71.39 147.75.80.22 80:30822/TCP 5s app=nginxNGINX_IP=$(kubectl get svc/nginx-1 -o jsonpath=&#34;{.spec.loadBalancerIP}&#34;)curl -s http://$NGINX_IP | grep &#34;&lt;title&gt;&#34;&lt;title&gt;Welcome to nginx!&lt;/title&gt;kubectl delete svc/nginx-1</p><p>    kubectl get svc -o wide -wNAME类型集群IP外部IP端口年龄选择kubernetes ClusterIP 10.43.0.1＆lt; none＆gt; 443 / TCP 151m＆lt; none nginx-1 LoadBalancer 10.43.71.39＆lt; pending＆gt; 80：30822 / TCP 3s app = nginxnginx-1 LoadBalancer 10.43.71.39＆lt; pending＆gt; 80：30822 / TCP 5s app = nginxnginx-1 LoadBalancer 10.43.71.39 147.75.80.22 80：30822 / TCP 5s app = nginxNGINX_IP = $（kubectl get svc / nginx-1 -o jsonpath =＆＃34; {。spec.loadBalancerIP }＆＃34;）curl -s http：// $ NGINX_IP | grep＆＃34;＆lt; title＆gt;＆＃34;＆lt; title＆gt;欢迎使用nginx！＆lt; / title＆gt; kubectl删除svc / nginx-1</p><p>   The output will tell you how to obtain a token and how to log into the dashboard. You can get this information back at any time by typing in:</p><p>   输出将告诉您如何获取令牌以及如何登录到仪表板。您可以通过以下方式随时获取以下信息：</p><p>  By default Traefik 1.x is installed with K3s, you can disable that or delete it and then install your preferred IngressController with:</p><p>  默认情况下，Traefik 1.x与K3s一起安装，您可以将其禁用或删除，然后使用以下命令安装首选的IngressController：</p><p>  arkade already ships with four options for IngressControllers. You can also run  arkade get helm and then use your favourite helm chart, if it&#39;s not already available below.</p><p>  arkade已随附IngressControllers的四个选项。您还可以运行arkade get舵，然后使用您最喜欢的舵表（如果下面尚未提供）。 </p><p>    Once you find the IP address of your IngressController, you can create a DNS record for any ingress records you may create, and then get TLS certificates for free from  LetsEncrypt.</p><p>找到IngressController的IP地址后，您可以为可能创建的任何入口记录创建DNS记录，然后从LetsEncrypt免费获得TLS证书。</p><p>   In this example, you would need to create a DNS A record for  gateway.example.com using the IP of your IngressController. Then you can go ahead and log into OpenFaaS or open it in a browser using its URL of:  https://gateway.example.com.</p><p>   在此示例中，您将需要使用IngressController的IP为gateway.example.com创建DNS A记录。然后，您可以继续登录OpenFaaS或使用以下URL在浏览器中打开它：https://gateway.example.com。</p><p>   To get the domain working, you&#39;d just create the DNS record as per above for  registry.example.com and point it at the IngressController.</p><p>   为了使域正常工作，您只需按照上面为registry.example.com创建DNS记录并将其指向IngressController。</p><p> By using Ingress, you can save on costs and on IP addresses, which as I mentioned in the intro cost around 3.25 USD / mo.</p><p> 通过使用Ingress，您可以节省成本和IP地址，正如我在介绍中提到的那样，每月节省约3.25 USD。</p><p>    In the tutorial, we showed how  kube-vip can integrate with BGP when used on Equinix Metal&#39;s bare-metal cloud to provide a stable IP.</p><p>    在本教程中，我们展示了kube-vip在Equinix Metal的裸机云上使用时如何与BGP集成，以提供稳定的IP。</p><p> The control-plane is HA and can tolerate at least one failure, because we configured K3s to use its built-in clustering mode. The built-in clustering mode uses and embedded version of etcd to synchronise the servers.</p><p> 控制平面是HA，并且可以承受至少一个故障，因为我们将K3配置为使用其内置的群集模式。内置的集群模式使用etcd的嵌入式版本来同步服务器。</p><p> The API server on port 6443 was made HA and can also tolerate a failure. This is because the IP address of the API Server was the EIP, provided by BGP. We updated our kubeconfig file and our additional servers and agents to use the EIP for their cluster join commands.</p><p> 端口6443上的API服务器已设置为HA，并且也可以容忍故障。这是因为API服务器的IP地址是BGP提供的EIP。我们更新了kubeconfig文件以及其他服务器和代理，以将EIP用于其集群连接命令。 </p><p> The Cloud Controller Manager also uses BGP to provide an IP address for any services you wish to expose with a Kubernetes LoadBalancer.</p><p>Cloud Controller Manager还使用BGP为您希望通过Kubernetes LoadBalancer公开的任何服务提供IP地址。</p><p> Whilst this blog post took much longer to write, and is more involved than the initial post from 2017, it produces a cluster that is highly available, fast, and ready to run production workloads.</p><p> 尽管此博客文章的撰写时间更长，并且比2017年的第一篇文章投入了更多时间，但它产生了一个群集，该群集具有高可用性，快速度并可以运行生产工作负载。</p><p>  If you are running Kubernetes at your workplace or within your homelab and do not have access to BGP, then there are other options.</p><p>  如果您在工作场所或家庭实验室中运行Kubernetes，但无权访问BGP，则还有其他选择。</p><p> For instance, you may be able to use ARP instead. ARP will broadcast a virtual IP (VIP) within your local network, so that your clients can still use a stable IP address. ARP can also be used with your Raspberry Pi clusters, but bear in mind that  K3s is having issues with the older RPi3 and CM3.</p><p> 例如，您也许可以改用ARP。 ARP将在您的本地网络中广播虚拟IP（VIP），以便您的客户端仍可以使用稳定的IP地址。 ARP也可以与您的Raspberry Pi群集一起使用，但是请记住，K3与较旧的RPi3和CM3存在问题。</p><p> DNS round-robin is also an option for configuring a stable endpoint, but caching and the time taken to propagate to your clients could make it less practical.</p><p> DNS循环也是配置稳定终结点的一个选项，但是缓存和传播到客户端所花费的时间会使它不实用。</p><p> Alternatively, if you are using a managed cloud which offers native L4 load-balancers you do not need to use a tool like kube-vip. Clouds such as AWS, GCP, Azure, and DigitalOcean all offer their own managed load-balancers.</p><p> 另外，如果您使用的是提供本地L4负载平衡器的托管云，则无需使用kube-vip之类的工具。 AWS，GCP，Azure和DigitalOcean等云都提供了自己的托管负载均衡器。</p><p> See an example of using DigitalOcean&#39;s managed LB in a post I recently wrote for Rancher:  Set up Your K3s Cluster for High Availability on DigitalOcean</p><p> 在我最近为Rancher写的帖子中，可以看到使用DigitalOcean托管LB的示例：在DigitalOcean上设置K3s集群以实现高可用性 </p><p> The other missing piece for on-premises clusters is the lack of Ingress, of reachable, routable IP addresses. This can be a particular problem if firewall ports cannot be opened, or port-forwarding rules are unavailable. Then solutions like  Cloudflare&#39;s Argo Tunnel provide a way to expose services.</p><p>本地群集的另一个缺失之处是缺少Ingress，可访问的可路由IP地址。如果无法打开防火墙端口或端口转发规则不可用，这可能是一个特殊的问题。然后，诸如Cloudflare的Argo隧道之类的解决方案提供了一种公开服务的方法。</p><p> More recent open source projects like the  inlets-operator integrate directly into Kubernetes like a Cloud Controller Manager to provide TCP tunnels for services you expose, such as your IngressController or a microservice.  inlets PRO has also become popular for self-hosting on a  Raspberry Pi cluster or homelab.</p><p> 最新的开源项目（例如，入口操作员）直接集成到Kubernetes（例如云控制器管理器）中，以为您公开的服务（例如IngressController或微服务）提供TCP隧道。对于在Raspberry Pi群集或homelab上进行自我托管，inports PRO也已变得很流行。</p><p> MetalLB is also a popular tool for on-premises Kubernetes networking, however its primary use-case is for advertising service LoadBalancers instead of advertising a stable IP for the control-plane. kube-vip handles both use-cases, and is under active development by its author, Dan.</p><p> MetalLB还是用于本地Kubernetes网络的流行工具，但是其主要用例是用于广告服务LoadBalancers，而不是用于广告控制平面的稳定IP。 kube-vip处理这两个用例，并由作者Dan积极开发。</p><p>  Here are two additional blog posts on K3s and advanced networking, which may be of interest to you:</p><p>  这是有关K3和高级网络的另外两篇博客文章，您可能会感兴趣：</p><p>   inlets-operator - get Ingress and TCP LoadBalancers on private hosts behind a firewall or NAT</p><p>   entrys-operator-在防火墙或NAT之后的私有主机上获取Ingress和TCP LoadBalancers</p><p> For full disclosure:  Equinix Metal is a client of  OpenFaaS Ltd. Thank you to the team for providing clients and to Dan for bringing support to kube-vip for K3s.</p><p> 有关完整披露：Equinix Metal是OpenFaaS Ltd的客户。感谢您为团队提供客户的团队，也感谢Dan为kube-vip K3s提供支持。 </p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://blog.alexellis.io/bare-metal-kubernetes-with-k3s/">https://blog.alexellis.io/bare-metal-kubernetes-with-k3s/</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/带有/">#带有</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/metal/">#metal</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/分享/">#分享</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy; 2020 diglog.com </div></div></body></html>