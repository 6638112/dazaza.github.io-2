<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>深度学习是一种新型编程吗？ Is deep learning a new kind of programming?</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">Is deep learning a new kind of programming?<br/>深度学习是一种新型编程吗？ </h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2020-12-13 11:59:44</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2020/12/f8232204224c9cadece1b86e9b697869.jpg"><img src="http://img2.diglog.com/img/2020/12/f8232204224c9cadece1b86e9b697869.jpg" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>In most discussions about how to make programming better, someone eventually sayssomething along the lines of  &#34;we&#39;ll just have to wait until deep learning solvesthe problem!&#34; I think this is a  naively optimistic idea,but it raises one interesting question: In what sense are programs created using deeplearning a  different kind of programs than those written by hand?</p><p>在有关如何使编程更好的大多数讨论中，最终有人会说一些类似的话，我们只需要等到深度学习解决问题即可！＆＃34;我认为这是一个天真乐观的想法，但它提出了一个有趣的问题：从什么意义上说，使用深度学习创建的程序与通过手工编写的程序不同？</p><p>  This question recently arose in discussions that we have been having as part of the PROGRAMme project, which explores historical andphilosophical perspectives on the question &#34;What is a (computer) program?&#34; and so thisarticle owes much debt to  others involved in the project,especially Maël Pégny, Liesbeth De Mol and Nick Wiggershaus.</p><p>  这个问题最近出现在我们作为程序项目一部分的讨论中，该项目探讨了关于什么是（计算机）程序的历史和哲学观点。因此，本文欠参与该项目的其他人很多债，尤其是MaëlPégny，Liesbeth De Mol和Nick Wiggershaus。</p><p> Many people will intuitively think that, if you train a deep neural network to solve somea problem, you get a different kind of program than if you manually write some logic to solvethe problem. But what exactly is the difference? In both cases, the program is a sequence ofinstructions that are deterministically executed by a machine, one after another, to producethe result.</p><p> 许多人会直观地认为，如果您训练一个深度神经网络来解决某个问题，则得到的程序与手动编写一些逻辑来解决该问题的程序不同。但是到底有什么区别呢？在这两种情况下，程序都是一序列的指令，这些指令由一台机器确定性地执行以产生结果。</p><p> When reading the excellent book  Inventing Temperature by HasokChang recently, I came across the idea of  operationalism,which I believe provides a useful perspective for thinking about the issue of deep learning andprogramming. The operationalist point of view was introduced by a physicist Percy Williams Bridgman. Toquote:  we mean by any concept nothing more than a set of operations; the concept is synonymouswith the corresponding set of operations. What does this tell us about deep learning and programming?</p><p> 最近在阅读HasokChang的优秀著作Inventing Temperature时，我遇到了操作主义的概念，我认为它为思考深度学习和编程问题提供了有用的观点。物理学家珀西·威廉姆斯·布里奇曼介绍了操作论的观点。 Toquote：我们所说的任何概念不过是一组操作而已；该概念与相应的操作集同义。这对深度学习和编程有什么启示？</p><p>  Before I talk about programming, I need to say a bit about  operationalism. I will be relying onthe description from  Chang&#39;s book on Temperature, but Bridgman usedthe measurement of length as an example. The key idea is that a concept, such as a length, isdefined by the operations for working with it. This means that the  length that is measuredusing a ruler is a different kind of  length than an astronomical length measured in terms ofthe amount of time that light takes to travel.</p><p>  在谈论编程之前，我需要谈一谈操作主义。我将依靠Chang的有关温度的书中的描述，但Bridgman以长度的测量为例。关键思想是，诸如长度之类的概念由与其一起使用的操作所定义。这意味着，使用标尺测量的长度与根据光传播的时间量测的天文长度是不同的长度。</p><p>  We are so used to thinking of  length that this idea may seem odd, but take temperaturemeasurement as an example. One issue in the history of temperature was that regular thermometersdid not work for very high temperatures (the boiling point of mercury is 356.7 °C). Analternative way of measuring very high temperatures was invented by  Josiah Wedgwood,an English potter. His Wedgwood scale (°W) was based on the shrinking of small clay cylinders.In high heat, the cylinders contracted. After removing them from the heat, you then used aprovided ruler to read the temperature. (This only worked with a specific clay from Wedgwood&#39;sown mines, but he kindly donated all the clay to the Royal Society.)The temperature of  red heat was 0 °W, melting pointof copper 27 °W and the melting point of gold was 32 °W.</p><p>  我们习惯于思考长度，以至于这个想法看起来很奇怪，但以温度测量为例。温度历史上的一个问题是常规温度计无法在极高的温度下工作（汞的沸点为356.7°C）。英国陶工约西亚·韦奇伍德（Josiah Wedgwood）发明了另一种测量高温的方法。他的Wedgwood比例尺（°W）是基于小型粘土圆柱体的收缩而定的。在高温下，圆柱体会收缩。将它们从火上移开后，您可以使用随附的标尺读取温度。 （这仅适用于Wedgwood矿场生产的特定粘土，但他将所有粘土捐赠给了英国皇家学会）。赤热温度为0°W，铜的熔点为27°W，铜的熔点为0.5°C。金是32°W。</p><p> Figuring out how to match a temperature scale based on mercury thermometer with the Wedgwoodscale is hard, because the two do not operationally overlap. Wedgwood&#39;s own attempt at producinga conversion table was a way off, giving melting point of silver as 4,717 °F (rather than 1,763°F).</p><p> 弄清楚如何将基于水银温度计的温度刻度与Wedgwood刻度相匹配是很困难的，因为两者在操作上不会重叠。 Wedgwood自己尝试生产转换表是一个遥不可及的过程，其银的熔点为4,717°F（而不是1,763°F）。 </p><p>  Programming is not much like measuring temperature, but there are certainly practical &#34;operations&#34;that are employed for doing various things with programs. Many of the operations that you usewhen creating a program based on deep learning and an ordinary program are quite different.</p><p>编程与测量温度不一样，但是肯定有一些实用的操作用于通过程序执行各种操作。创建基于深度学习的程序和普通程序时，您使用的许多操作都大不相同。</p><p> Program execution.First of all, execution is the operation that is actually very similar for both regular programsand deep neural networks. In both cases, the program is a long sequence of instructionswith some data. It is provided with some inputs, performs a calculation using the inputs andproduces an output. If we looked only at execution, then we would likely not see much difference.</p><p> 程序执行首先，对于常规程序和深度神经网络来说，执行实际上是非常相似的操作。在这两种情况下，程序都是一长串指令以及一些数据。它提供了一些输入，使用这些输入执行计算并产生输出。如果我们只看执行力，那么我们可能不会看到太大的差异。</p><p> Programming or training.The difference becomes obvious when we start looking at how programs are constructed. In case ofordinary programs, you write some logic. In case of deep networks (or any other programs based onmachine learning), the program is obtained by training, i.e. adapting some numerical parametersbased on sample data.</p><p> 编程或培训。当我们开始研究程序的构造时，区别变得明显。对于普通程序，您需要编写一些逻辑。在深度网络（或任何其他基于机器学习的程序）的情况下，该程序是通过训练获得的，即根据样本数据调整一些数值参数。</p><p> Understanding programs.A more interesting issue is that of understanding what a program does. This may be a challengefor an ordinary program if it is large and complicated, but you can generally study the codeor ask people who wrote it. For machine learning, this depends on the type of algorithm used.While you can understand how a decision tree makes a decision, it is not clear how to &#34;understand&#34;what a deep neural network does.</p><p> 了解程序。一个更有趣的问题是了解程序的功能。如果它既大又复杂，这对于普通程序而言可能是一个挑战，但是您通常可以研究编码器或询问编写该程序的人。对于机器学习而言，这取决于所使用的算法的类型。虽然您可以了解决策树如何做出决策，但尚不清楚如何理解深度神经网络的功能。</p><p> Verifying programs.If you wanted to prove that an ordinary program is correct, you can (perhaps very laboriously)prove that it matches its specification, which describes its key properties. For deep neuralnetwork, you can verify that it correctly propagates weights, but proving anything about whatthe program actually does is tricky. (Incidentally, this is also why I always found that the 2015 AI Open Letter is missing the point in its emphasisof &#34;Verification&#34; as a research goal for AI systems.)</p><p> 验证程序。如果您想证明普通程序是正确的，则可以（也许很费力）证明它与描述其关键属性的规范相符。对于深层神经网络，您可以验证它是否正确传播了权重，但是要证明有关程序实际功能的任何事情都很棘手。 （顺便说一句，这也是为什么我总是发现2015年AI公开信在强调＆＃34; Verification＆＃34;作为AI系统的研究目标方面没有抓住重点的原因。）</p><p>   In the above list, the cases of execution and programming or training show fairly obvioussimilarities and differences, respectively. The more subtle cases are that of understandingand verifying programs. An interesting reference for thinking about these is the paper Computer simulations, machine learning and the Laplacean demon: Opacity in the case of high energyphysics, which looks at programs and ML algorithms inphysics experiments at CERN (thanks to Nick for the recommendation!)</p><p>   在上面的列表中，执行和编程或培训的情况分别显示出相当明显的异同。更微妙的情况是理解和验证程序。关于这些的有趣参考文献是《计算机模拟，机器学习和拉普拉斯恶魔：高能物理中的不透明性》一文，它研究了欧洲核子研究组织的程序和ML算法的物理实验（感谢尼克的建议！）</p><p> The paper compares opacity, i.e. the possibility of understanding, of deep neural networks andcomputer simulations, which are very large and complex, but otherwise &#34;ordinary&#34; programs.It identifies a number of different kinds of opacity.</p><p> 该论文比较了非常大和复杂的深度神经网络和计算机模拟的不透明性（即理解的可能性），但在其他方面则是“不透明”。程序。它标识许多不同类型的不透明度。 </p><p> Both computer simulations and deep networks are  algorithmically transparent, which means thatone can follow the sequence of instructions when they execute. To a human, this does not helpvery much when trying to understand a program (but it is enough for a  Laplacean deamon,and so neither of the types of programs have what the authors call  fundamental opacity).</p><p>计算机仿真和深度网络在算法上都是透明的，这意味着一个人可以在执行指令时遵循指令序列。对于人类来说，这在尝试理解程序时无济于事（但是对于拉普拉斯恶魔来说足够了，因此这两种程序都没有作者所谓的基本不透明性）。</p><p>  The opacity is then closely linked to the humans involved in the process.For computer simulations, the main issue is that they are large and complex.This is, by the way, the case for many other software systems and we couldreasonably argue that large systems (or simulations) are different kind ofprograms than small ones, precisely because the operation of &#34;understanding them&#34;is different for each. To quote Bridgman again:</p><p>  然后，不透明度与参与该过程的人员紧密相关。对于计算机仿真而言，主要问题是它们既庞大又复杂。顺便说一下，这对于许多其他软件系统而言都是如此，我们可以合理地认为大型系统（或模拟）是与小型程序不同的一种程序，正是因为了解这些程序的操作各不相同。再次引用Bridgman：</p><p> Mathematics does not recognize that as the physical range increases, the fundamentalconcepts become hazy, and eventually cease entirely to have physical meaningand therefore must be replaced by other concepts which are operationally quite different.</p><p> 数学并不认识到，随着物理范围的增加，基本概念变得模糊，并最终完全失去了物理意义，因此必须用其他在操作上有很大不同的概念来代替。</p><p> I think the issue of scale is something that computer scientists ignore waytoo easily. For example, the methods that we use for proving the correctness ofa small, several line long, algorithm are operationally very different than thosewe use for proving the correctness of a  compiler for a realistic programming language.</p><p> 我认为规模问题是计算机科学家很容易忽略的问题。例如，用于证明小的几行长算法正确性的方法与用于证明针对实际编程语言的编译器正确性的方法在操作上有很大不同。</p><p>  The issue of complexity is even worse in the case of deep neural networks.A useful concept referenced in the above paper is &#34;opaqueness of paths&#34;.In a deep neural network (with non-zero weight), the number of possible pathsthrough which data can flow increases exponentially with every layer. The numberof data-dependencies in a complex ordinary program may be large too, but itwon&#39;t grow exponentially with e.g. every new class.</p><p>  在深度神经网络的情况下，复杂性的问题更加严重。上一篇论文引用的一个有用概念是``路径的不透明度''。在深度神经网络（权重为非零）中，数字数据流经的可能路径的每一层都呈指数增长。复杂的普通程序中的数据依存关系的数量也可能很大，但是它不会随例如每个新班级。</p><p> The above paper makes one more excellent point about machine learning. TheML algorithm has a  quasi-autonomy and performs iterative tuning of parameters.For ordinary programs, the programmer writes every single line (and tunes all constants)of the program. In other words, even if we cannot immediately understand everysingle aspect of an ordinary program, we should be able to find someone who knows(or at least knew at some point in the past). For understanding a weight in adeep network, we&#39;d need to backtrack through the entire learning process...</p><p> 上一篇文章提出了关于机器学习的另一点。 ML算法具有拟自治性，并执行参数的迭代调整。对于普通程序，程序员编写程序的每一行（并调整所有常量）。换句话说，即使我们不能立即理解普通程序的每个方面，我们也应该能够找到认识的人（或至少在过去的某个时候知道）。为了了解深度网络中的权重，我们需要回溯整个学习过程...</p><p>  Looking at programs and machine learning from an operationalist perspective alsosuggests an interesting future research question. If we have two measurement operationsthat can both be applied over some domain, it is possible to make the operationsmatch over the common domain and unify the scales. Wedgewood himself tried to do thisby matching his scale to the Fahrenheit scale by using a scale based on metal expansionas the intermediary between mercury based thermometers and his clay cylinders.(The Wedgwood scale was forgotten before anybody produced a  correct mapping, buta correct mapping could certainly be created.)</p><p>  从操作员的角度看程序和机器学习也提出了一个有趣的未来研究问题。如果我们有两个可以同时应用于某个域的测量操作，则可以使这些操作在公共域上匹配并统一比例。韦奇伍德本人试图通过使用基于金属膨胀的刻度作为水银温度计与其黏土缸之间的中介，将其刻度与华氏刻度相匹配（韦奇伍德刻度被遗忘在任何人产生正确的映射之前，但是正确的映射肯定可以被创建。） </p><p> The curious question I want to conclude with is this: Are there operations forconstruction, understanding and verification that would work the same for both&#34;ordinary&#34; programs and machine learning algorithms? Certainly not today and certainly notanytime soon. However, I imagine that there might be a more interactive, machine-assisted way ofprogramming and doing some of the other tasks that can work with both kinds of entities -ordinary programs at one end of the spectrum and deep neural networks at the other end.</p><p>我想得出一个奇怪的问题是：是否存在用于构造，理解和验证的操作，而这两种操作对于“普通”而言都是相同的 程序和机器学习算法？ 当然不是今天，而且肯定不会很快。 但是，我想可能会有一种更具交互性，机器辅助的方式来编程和执行其他一些任务，这些任务可以与两种实体一起工作-频谱的一端是普通程序，而另一端是深度神经网络。 </p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="http://tomasp.net/blog/2020/learning-and-programming/">http://tomasp.net/blog/2020/learning-and-programming/</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/深度学习/">#深度学习</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/编程/">#编程</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/深度/">#深度</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/learning/">#learning</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/分享/">#分享</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy; 2020 diglog.com </div></div></body></html>