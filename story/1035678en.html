<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>随机矩阵入门：分步指南Getting Started with Random Matrices: A Step-by-Step Guide</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">Getting Started with Random Matrices: A Step-by-Step Guide<br/>随机矩阵入门：分步指南</h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2020-11-21 23:23:08</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2020/11/750c984af0ffdd34a987bb62e6ab009b.png"><img src="http://img2.diglog.com/img/2020/11/750c984af0ffdd34a987bb62e6ab009b.png" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>In the Deep Learning (DL) age, more and more people have encountered and used (knowingly or not) random matrices. Most of the time this use is limited to the initialization of the networks weights, that can be accomplished with a single line of code in your favorite DL framework. However, Random Matrices have a rich mathematical theory with far reaching applications in physics, network theory, machine learning, finance, etc. This fascinating range of applications also means that each field often developed its dedicated terminology to describe the same mathematical concept, often with confusing consequences. The aim of this article(s) is to introduce Random Matrix Theory (RMT) from a physicist&#39;s perspective while trying to relate different tools and terminology, especially across the math and physics literature. Although you do need to know basic calculus, I will try to introduce new concepts and give references in case you would like to go deeper.</p><p>在深度学习（DL）时代，越来越多的人遇到并使用（已知或不知道）随机矩阵。在大多数情况下，这种使用仅限于网络权重的初始化，这可以通过您喜欢的DL框架中的单行代码来完成。但是，随机矩阵具有丰富的数学理论，在物理学，网络理论，机器学习，金融等领域具有广泛的应用。这种引人入胜的应用范围还意味着每个领域都经常开发其专用术语来描述相同的数学概念，通常令人困惑的后果。本文的目的是从物理学家的角度介绍随机矩阵理论（RMT），同时尝试联系不同的工具和术语，尤其是整个数学和物理学文献。尽管您确实需要了解基本的演算，但是我将尝试介绍新的概念并提供参考，以备您想进一步了解。</p><p> This post is complemented by a numerical analysis you can find in this  GitHub repository in Jupyter notebook format. Some of the content of the notebook is also presented in the last section.</p><p> 这篇文章还辅以数值分析，您可以在此GitHub存储库中找到Jupyter笔记本格式的数值分析。最后一部分还介绍了笔记本的一些内容。</p><p>  Historically, random matrices were introduced in statistics by John Wishart (1928), and saw their first appearance in physics when Eugene Wigner [1] used them to model the nuclei of heavy atoms (1955). You may know that at the microscopic level, where quantum mechanical effects are dominant, the energy spectrum of an atom is not continuous, but comes in discrete energy levels. Evaluating these levels for complex atoms comes at an expensive numerical cost on modern computers, but it was basically impossible to evaluate at the time Wigner was looking into the problem. Instead, he conjectured that these spectra could be akin to the eigenvalues of a random matrix, whose properties should only depend on its symmetry class (more on this later). This is an example of universality: complex systems that differ at some microscopic scale, tend to have similar properties at a “macroscopic one”. Moving from &#34;micro to macro&#34;, many details are washed out from the description of a system, and the remaining  relevant degrees of freedom tend to be common to a larger class of systems that share some particular symmetry. This idea of symmetry classes in RMT was further developed by Freeman Dyson [2]. There are three classical RM ensembles:  orthogonal,  unitary and  symplectic; Dyson refer to them as the  threefold way. If all of this sounds a bit obscure do not worry, we will come back to this later on.</p><p>  历史上，约翰·怀沙特（John Wishart）（1928）在统计学中引入了随机矩阵，当尤金·维格纳（Eugene Wigner）[1]使用随机矩阵建模重原子的核时（1955），随机矩阵首次出现在物理学中。您可能知道，在量子力学作用占主导的微观水平上，原子的能谱不是连续的，而是处于离散的能级。在现代计算机上，对复杂原子的这些能级进行评估的代价是昂贵的，但是在维格纳研究问题时，基本上不可能进行评估。取而代之的是，他推测这些光谱可能类似于随机矩阵的特征值，而随机矩阵的特性应仅取决于其对称性类别（稍后再讨论）。这是普遍性的一个例子：在某些微观尺度上不同的复杂系统在“宏观”上往往具有相似的特性。从“微观”到“宏观”，许多细节都从系统描述中剔除掉了，剩余的相关自由度往往是共享某些特定对称性的较大型系统所共有的。 Freeman Dyson [2]进一步发展了RMT中对称类的想法。有三种经典的RM合奏：正交，unit和辛。戴森将它们称为三重方式。如果这一切听起来有些晦涩，请放心，我们稍后会再讲。</p><p>  Before diving deeper into RMT, let me recap some basic concepts of standard matrices. The purpose of this section is to define terminology, introduce the basic tools we will work with and refresh your memory in case you forgot some of these concepts. In doing so I will make no attempt for a thorough explanation, but I will assume some basic knowledge of calculus and linear algebra. Consider an N×N matrix  M; the typical problem setup is:</p><p>  在深入研究RMT之前，让我回顾一下标准矩阵的一些基本概念。本部分的目的是定义术语，介绍我们将使用的基本工具，并在您忘记其中一些概念时刷新您的记忆。这样做时，我将不做任何详尽的解释，但我将假设一些微积分和线性代数的基本知识。考虑一个N×N矩阵M；典型的问题设置是：</p><p>  where  x and  b are two vectors: the former is the variable we want to solve for and the latter a “source” term. You can think about this formula as a compact way to represent a system of coupled linear equations. A typical problem in linear algebra is to find the eigenvalues and eigenvectors of this matrix by finding the roots of the  characteristic equation:</p><p>  其中x和b是两个向量：前者是我们要求解的变量，后者是“源”项。您可以将此公式视为表示耦合线性方程组的紧凑方式。线性代数中的一个典型问题是通过找到特征方程的根来找到该矩阵的特征值和特征向量：</p><p>  where λ are the eigenvalues and  I is the identity matrix (in the equations I will use a hat to denote a matrix). From here, we can find the matrix  U that diagonalizes  M, i.e.  M =  U 𝚲  U^(-1), where 𝚲 =  diag (λ1, λ2, …, λN). Note that  M could have a rectangular shape, i.e. be an M × N matrix, in which case the so called  singular values need to be evaluated; although these rectangular matrices are not very popular in physics, they are prominent in Machine learning (input data, weights, etc…) or finance, but more on this in a follow up post. The N eigenvalues of  M form its “spectrum”, containing many important information about the system. For example, as mentioned in the introduction, they can describe the energy levels of a quantum mechanical system.</p><p>其中λ是特征值，I是单位矩阵（在等式中，我将用帽子来表示矩阵）。从这里，我们可以找到对角化M的矩阵U，即M = U 𝚲 U ^（-1），其中𝚲 = diag（λ1，λ2，...，λN）。注意，M可以具有矩形形状，即是M×N矩阵，在这种情况下，需要评估所谓的奇异值；尽管这些矩形矩阵在物理上不是很流行，但它们在机器学习（输入数据，权重等）或金融学中很突出，但在后续文章中会介绍更多。 M的N个特征值形成其“谱”，其中包含有关系统的许多重要信息。例如，如引言中所述，它们可以描述量子力学系统的能级。</p><p> It is often convenient to evaluate the spectrum of  M using the  resolvent method; this method has the advantage of generalizing quite easily to infinite dimensional spaces, and can be used to solve non-homogenous, linear or non-linear differential equations. In this latter context, the resolvent is known as the Green’s function, and it is one of the central objects to evaluate when doing calculations in quantum field theory, see e.g. Ref. [4] for a general introduction. Going back to Eq.[1], we want to solve  x =  M^(-1)  b. This inverse operator is represented by the resolvent:</p><p> 使用分辨方法评估M的光谱通常很方便。该方法的优点是可以很容易地将其推广到无限维空间，并且可以用于求解非齐次，线性或非线性微分方程。在后一种情况下，可分辨物被称为格林函数，它是在量子场论中进行计算时要评估的主要对象之一，例如参考[4]作一般介绍。回到等式[1]，我们想求解x = M ^（-1）b。此逆运算符由解析器表示：</p><p>  The idea is that the resolvent has poles (i.e. singularities) located at the real eigenvalues of  M. We can then use the toolbox of complex analysis by defining z= λ + i ε, such that the singularities are moved away from the real axis by an infinitesimal amount ε. This procedure is generally known as  regularization. The (normalized) trace of the resolvent is known as the  Stieltjes transform of  M in the mathematical literature, and it is a very familiar object for physicists:</p><p>  这个想法是，分解体的极点（即奇点）位于M的真实特征值处。然后，我们可以通过定义z =λ+ iε来使用复杂分析的工具箱，从而使奇点远离实轴无限小ε。此过程通常称为正则化。解析物的（归一化）迹线在数学文献中被称为M的Stieltjes变换，它是物理学家非常熟悉的对象：</p><p>  where we have defined the eigenvalues distribution ρ(λ), also known as the density of states in quantum mechanics. Here δ(.) is the Dirac delta function, see Ref.[5]. Our final task is to evaluate the eigenvalue distribution of the resolvent and hence the matrix  M. The last bit of information we need is how to link the eigenvalue distribution to the trace of the resolvent, that is by using the Plemelj formula, see Ref. [4]:</p><p>  在这里我们定义了特征值分布ρ（λ），也称为量子力学中的状态密度。此处的δ（。）是狄拉克δ函数，请参见参考文献[5]。我们的最终任务是评估分解物的特征值分布，从而评估矩阵M。我们需要的最后一点信息是如何使用Plemelj公式将特征值分布与分解物的轨迹联系起来。 [4]：</p><p>  In the random case, the entries of  M will be sampled from a distribution, so the above object needs to be averaged over all possible realizations of  M. Once the average of Tr[G(z)] is evaluated, we will analytically continue the result, i.e. use z → λ + i ε, take the Imaginary part and than the limit ε → 0^(+) at the end (the + sign means that we are approaching 0 from the positive real axis). In the next section we revise few key concept from probability theory that will be useful to accomplish our task.</p><p>  在随机情况下，将从分布中采样M的项，因此需要在M的所有可能实现上对上述对象求平均。一旦对Tr [G（z）]的平均值求值，我们将继续分析结果，即使用z→λ+ iε，取虚部，然后在极限ε→0 ^（+）处结束（+号表示我们从正实轴接近0）。在下一节中，我们将从概率论中修改一些关键概念，这些概念将对完成我们的任务有用。</p><p>  This section is meant to refresh few concepts from probability that will be useful to understand the next section. I assume you are familiar with the concept of a random variable x. Depending on its domain, x can assume a series of values depending on the underlying probability distribution P(x). Say x denotes the position in space of an object, than P(x) will be the probability of the object to be at position x. A random matrix  X is an extension of this concept; you may think about it as a collection or random variables. We may have two objects located at positions x1 and x2; in general, the two positions may not be independent, so we need now a joint probability distribution to describe our problem. If the two objects are independent then:</p><p>本部分旨在从概率中刷新一些概念，这些概念将有助于理解下一部分。我假设您熟悉随机变量x的概念。根据其域，x可以根据基础概率分布P（x）假设一系列值。说x表示物体在空间中的位置，则P（x）将是物体位于位置x的概率。随机矩阵X是该概念的扩展；您可以将其视为集合或随机变量。我们可能有两个对象位于x1和x2位置；通常，这两个职位可能不是独立的，因此我们现在需要一个联合概率分布来描述我们的问题。如果两个对象是独立的，则：</p><p>  that is one of the fundamental properties satisfied by the probabilities of two independent random processes. Think about the most common of the examples, rolling a dice. The probability that say number 3 comes out in one roll is 1/6; the probability that we get two consecutive 3 is 1/6 × 1/6 and so on. This is not true if the two events are correlated, i.e. if they can influence each other. So the positions of the two objects may not be independent, but once we observe one, we can ask what is the probability that the second object is in a certain position  given the fact we observed it in another; mathematically this is denoted as:</p><p>  这是两个独立随机过程的概率所满足的基本特性之一。想想最常见的例子，掷骰子。一口说出3个数字的概率为1/6；我们连续得到两个3的概率是1/6×1/6，依此类推。如果两个事件是相关的，即它们是否可以相互影响，则情况并非如此。因此，两个物体的位置可能不是独立的，但是一旦观察到一个物体，考虑到我们在另一个物体中观察到的事实，我们可以问第二个物体处于某个位置的概率是多少？在数学上，这表示为：</p><p>  where the | expresses the conditional statement. To see how this is connected to random matrices, let me show an explicit representation of the two above equations, assuming that the random matrix  X is Gaussian but bearing in mind that those two relations above are valid in general. To be explicit,  X is a 2 × 2 matrix with unitary variance:</p><p>  哪里|表示条件语句。为了了解这与随机矩阵的关系，让我展示上述两个方程的显式表示，假设随机矩阵X为高斯，但要记住上述两个关系通常是有效的。明确地说，X是一个2×2的具有一元方差的矩阵：</p><p>  Note that I am using Tr as a shorthand for a sum over all indices; this is not the usual definition of the trace (sum over diagonal elements) but it is often used in the physics literature. From Eq.(8) we see that even if the single elements of the RM are i.i.d. (independently, individually distributed), the RM itself encompasses a certain degree of correlations due to the presence of the off-diagonal terms. If the latter are zero, we clearly have:</p><p>  请注意，我使用Tr作为所有索引总和的简写；这不是通常的轨迹定义（对角元素的总和），但是在物理学文献中经常使用。从式（8）可以看出，即使RM的单个元素是i.i.d. （独立地，独立地分布），由于非对角项的存在，RM本身包含一定程度的相关性。如果后者为零，我们显然具有：</p><p>  On the other hand, we can rewrite the matrix distribution in terms of its elements as a conditional probability:</p><p>  另一方面，我们可以将矩阵分布的元素重写为条件概率：</p><p>  The second objects I need to briefly introduce is the moment and cumulant generating function. The former is defined as:</p><p>我需要简要介绍的第二个对象是矩和累积量生成函数。前者定义为：</p><p>  where x is a random variable, P(x) its probability distribution and ξ a parameter used to generate all the moments. In physics, this parameter goes under different names, depending on which field you are working in, but usually goes under the name of  source term. Formally, you can obtain all the moments of the function by repeatedly differentiating with respect to ξ:</p><p>  其中x是随机变量，P（x）是其概率分布，ξ是用于生成所有矩的参数。在物理学中，此参数使用不同的名称，具体取决于您在哪个领域工作，但通常使用源术语的名称。形式上，您可以通过反复地对ξ求微分来获得函数的所有矩：</p><p>  However, it is often more useful to work with the cumulants, as they often simplify calculations; The cumulant generating function is defined as:</p><p>  但是，使用累积量通常会更有用，因为它们经常简化计算。累积量生成函数定义为：</p><p>  How does this connect with RM or statistical mechanics? The central object of statistical mechanics is the partition function of the Boltzmann distribution (see below). In order to obtain average physical quantities we introduce a source term ξ and differentiate with respect to it. However, as we need a properly normalized quantity, we take the average of the logarithm of the partition function, that is the cumulant generating function defined above. You can generalize this concept to matrices or even functionals, as it is done in quantum field theory … but this is beyond the scope of this article:)</p><p>  这如何与RM或统计机制联系起来？统计力学的主要目标是玻耳兹曼分布的分配函数（见下文）。为了获得平均物理量，我们引入源项ξ并对其进行微分。但是，由于我们需要适当归一化的数量，因此我们取分区函数（即上面定义的累积量生成函数）的对数的平均值。您可以将此概念概括为矩阵，甚至可以泛函，就像量子场论中所做的那样……但这超出了本文的范围：）</p><p>  In this section I will give a “dirty” evaluation of the eigenvalue density. Although this evaluation gives the correct result, it hides several subtle points I will only briefly mention for now. I will follow a statistical mechanics approach, mostly focused on the calculation side. Also, we will focus for now only on the simplest of the RMT ensembles, the Gaussian Orthogonal Ensemble, or GOE for simplicity. Matrices belonging to this ensemble all have elements that are Gaussian variables; the other condition is the symmetry class under which these matrices are invariant, rotational invariance. Let be  O an orthogonal matrix, then  O^T =  O^{-1}, where the superscript “T” stands for the transpose operation. This matrix acts on the elements of a matrix  M and rotates them. For example, in two and three dimensions these matrices have the known form:</p><p>  在本节中，我将对特征值密度进行“肮脏”评估。尽管此评估给出了正确的结果，但它隐藏了我现在仅简要提及的几个细微之处。我将遵循统计力学方法，主要侧重于计算方面。此外，为简单起见，我们现在仅关注最简单的RMT乐团，高斯正交乐团或GOE。属于该整体的矩阵都具有作为高斯变量的元素；另一个条件是对称类别，在这些类别下这些矩阵是不变的，旋转不变的。设O为正交矩阵，则O ^ T = O ^ {-1}，其中上标“ T”代表转置运算。该矩阵作用于矩阵M的元素并旋转它们。例如，在二维和三维中，这些矩阵具有已知形式：</p><p>  where the suffix “z” in the three dimensional matrix means that rotations are performed around the z axis.</p><p>其中三维矩阵中的后缀“ z”表示围绕z轴执行旋转。</p><p> What does it mean for  M to be rotationally invariant? The rotated matrix $  M’ =  O  M  O^T and  M have the same eigenvalues but rotated eigenvectors  w=  O  v. So the spectrum of  M’ and  M is the same. The first step in the calculation consists in manipulating the trace of the resolvent as follows:</p><p> M旋转不变是什么意思？旋转后的矩阵$ M’= O M O ^ T和M具有相同的特征值，但是旋转后的特征向量w = O v。因此M’和M的频谱相同。计算的第一步是按如下方式处理解析物的轨迹：</p><p>  Looking at the above expression you may think we have taken a step behind instead of forward! The idea is, however, to rewrite the trace of the resolvent as a more familiar object in statistical mechanics. Consider the following m-dimensional Gaussian Matrix integral:</p><p>  查看以上表达式，您可能会认为我们已经落后而不是前进了！但是，该想法是将解析程序的轨迹重写为统计力学中更熟悉的对象。考虑以下m维高斯矩阵积分：</p><p>    where Z now has the form of a statistical mechanics partition function for a specific realization of  M and the measure 𝒟  𝜑 = ∏ d𝜑/(2 𝜋)^(N/2), where the product runs over  i=(1,2…,N). So far, we have just performed some formal manipulations to massage our initial expression in a form that can be treated using the tools of statistical mechanics. We can also identify F_N(z) =- 1/N log Z(z) as the free energy of the system (with inverse temperature β=1/T); note that from a probability point of view, this is the (average) cumulant generating function defined in Eq.(14). At this point we need to average the trace of the resolvent over the different realizations of  M using the rotationally invariant, Gaussian probability distribution:</p><p>    其中，Z现在具有针对M的特定实现的统计力学划分函数的形式，并且度量𝒟= d //（2）^（N / 2），其中乘积在i =（1,2 ... ，N）。到目前为止，我们刚刚进行了一些形式上的操作，以一种可以使用统计力学工具进行处理的形式来修饰我们的初始表达。我们还可以将F_N（z）=-1 / N log Z（z）标识为系统的自由能（逆温度β= 1 / T）；注意，从概率角度来看，这是公式（14）中定义的（平均）累积量生成函数。在这一点上，我们需要使用旋转不变的高斯概率分布对M的不同实现上的分解剂轨迹求平均：</p><p>  where the first term on the right hand side is a normalization constant and we have used a unit standard deviation scaled by N as σ = 1/√N and zero mean. This brings us to the first (and only for this post) subtlety I mentioned before: when we take the expectation value of the trace of the resolvent in Eq.(17), we need to evaluate &lt; log Z_M &gt;_M, where &lt; . &gt;_M denotes the expectation w.r.t.  M. The problem is: how do we evaluate the expectation value of the logarithm of a function and what is its meaning? A detailed answer to this question will be given in a follow up post, for the moment let me state few facts here without proof:</p><p>  其中右边的第一项是归一化常数，我们使用了按N缩放的单位标准偏差，σ= 1 /√N，均值为零。这将我们带到了我之前提到的第一个（并且仅针对此帖子）微妙之处：当我们取等式（17）中的解析物轨迹的期望值时，我们需要评估 _M，其中 _M表示期望w.r.t. M.问题是：我们如何评估函数对数的期望值，它的含义是什么？有关该问题的详细答案将在后续帖子中给出，此刻，让我在这里陈述一些没有证据的事实：</p><p> • &lt; log Z_M &gt;_M and log &lt;Z_M &gt;_M are known respectively as the quenched and annealed averages.</p><p>• _M和log  _M分别称为淬火和退火平均值。</p><p> For classical Random Matrix ensembles, it turns out that &lt;log Z_M &gt;_M = log &lt; Z_M &gt;_M$; the results presented here does give the right answer within a simpler calculation scheme. However, it is not clear why these two type of averages should be equal (or different) for now.</p><p> 对于经典的随机矩阵合奏，结果是 _M = log  _M $;在简单的计算方案中，此处给出的结果确实给出了正确的答案。但是，目前尚不清楚为什么这两种平均值应该相等（或不同）。</p><p> In what follows we evaluate the annealed average of the partition function. In order to get all pre-factors right, is it convenient to write everything in components and separate the diagonal from the off-diagonal part. In doing so, we use the fact that for a symmetric matrix  X we can separate the sum over the elements as:</p><p> 接下来，我们评估分配函数的退火平均值。为了使所有前置因子正确，将所有内容编写在组件中并将对角线与非对角线部分分开是否方便。在此过程中，我们使用以下事实：对于对称矩阵X，我们可以将元素上的和分离为：</p><p>  where the second summation spans only the upper triangular part of the matrix and the factor of 2 accounts for the fact that the matrix elements in the lower triangular part are identical. Using this property in both the probability distribution and the resolvent, we can take the expectation value of the diagonal and off-diagonal elements separately and then sum back the two components as follows:</p><p>  其中第二个求和仅跨越矩阵的上三角部分，且因子2解释了下三角部分中的矩阵元素相同的事实。在概率分布和分解变量中都使用此属性，我们可以分别获取对角线元素和非对角线元素的期望值，然后将两个分量求和如下：</p><p>  Pay attention to the newly generated non-gaussian term in the exponent proportional to 𝜑⁴; In a physical theory, this term would appear to describe interactions of some sort, e.g. a density-density interaction between “spins” at site  i and  j. More in general, this term describes how the fluctuations of 𝜑 (the variance) at site  i are correlated to those at site  j. In order to decouple this term we introduce an additional parameter that plays also the role of the order parameter in statistical mechanics. You may think about this as a change of variable in the integral or a generalized Hubbard-Stratonovich transformation in condensed matter theory. The idea is to use the delta function to enforce the scalar “constraint”:</p><p>  注意与proportional成比例的指数中新生成的非高斯项；在物理理论中，该术语似乎用来描述某种相互作用，例如：站点i和j处“旋转”之间的密度-密度相互作用。更一般而言，该术语描述了站点i处的𝜑（方差）波动与站点j处的波动如何相关。为了使该术语解耦，我们引入了一个附加参数，该参数在统计力学中也起着阶数参数的作用。您可能会认为这是凝聚态理论中积分或广义Hubbard-Stratonovich变换中变量的变化。这个想法是使用delta函数来执行标量“约束”：</p><p>  Before jumping into the calculation, let us understand what this parameter means. Certainly, it redefines a quadratic variable as a linear one. Its meaning however, is to measure the fluctuations of 𝜑 at site  i; clearly, this is not a simple change of variable! Order parameters are central objects in statistical mechanics and quantum field theory, as they are used to study transitions across different phases of the system.</p><p>在进行计算之前，让我们了解该参数的含义。当然，它将二次变量重新定义为线性变量。但是，它的含义是测量站点i处的波动。显然，这不是简单的变量更改！顺序参数是统计力学和量子场论中的中心对象，因为它们用于研究系统不同阶段之间的跃迁。</p><p>  This definitely looks better than our initial expression! In the second line of Eq.(23) we have used the Fourier representation of the Dirac-delta and introduced in this way the scalar Lagrange multiplier ξ [6]. This looks like a neat trick, but it is an incredibly useful and far reaching way of enforcing constraints in statistical mechanics and quantum field theory, where in the latter the delta becomes a functional that can be used, e.g. to regularize Gauge theories [7]! Before proceeding, it is convenient to redefine the Lagrange multiplier as follows: η = 2 i ξ/N and perform the Gaussian integral over 𝜑:</p><p>  这肯定比我们的最初表达更好！在等式（23）的第二行中，我们使用了狄拉克三角洲的傅立叶表示，并以此方式引入了标量拉格朗日乘数ξ[6]。这看起来像是一个巧妙的技巧，但是它是在统计力学和量子场论中强制执行约束的一种非常有用且意义深远的方法，其中在后者中，δ成为可以使用的函数，例如规范量规理论[7]！在继续之前，可以方便地按以下方式重新定义拉格朗日乘数：η= 2 iξ/ N并在𝜑上执行高斯积分：</p><p>  In case you wonder, the log η term comes from re-exponentiating the result of the Gaussian integral over 𝜑. We are interested in solving these two integrals in the limit of large N, i.e. we are looking for a continuous approximation to the eigenvalues density. In this limit, the evaluation of the two integrals becomes particularly simple, as we can use the steepest descent method [8]. If you are familiar with the concept of mean-field theory in physics, the steepest descent gives you exactly this result (for the moment just keep this in mind, I will come back on this in another post). The idea is to evaluate the integral in the stationary points of ℒ(η, q):</p><p>  如果您想知道，对数η项来自对上的高斯积分的结果求幂。我们有兴趣在大N的极限中求解这两个积分，即我们正在寻找特征值密度的连续近似值。在这个极限内，两个积分的求值变得特别简单，因为我们可以使用最速下降法[8]。如果您熟悉物理学中的均场理论的概念，那么最陡峭的下降将为您提供准确的结果（目前请记住这一点，我将在另一篇文章中再次介绍）。这个想法是要评估ℒ（η，q）的固定点的积分：</p><p>    As it is often the case in physics, only one of the two solutions makes sense; in this case we will select the solution giving a finite result. We can now use q* to evaluate the result of the integral and finally the trace of the resolvent in Eq.(15):</p><p>    就像物理学中经常发生的那样，只有两种解决方案之一才有意义。在这种情况下，我们将选择给出有限结果的解。现在，我们可以使用q *评估积分的结果，最后评估方程式（15）中的可分辨物轨迹：</p><p>  Note that the factor of N in the definition of the trace of the resolvent cancels out with our solution and we obtain a finite and N independent (remember this is a continuous approximation) result. In order to obtain the eigenvalue density, we need to perform first the analytic continuation z → λ + i ε, take the Imaginary part and then the limit ε → 0^(+). Note that the order of these operations is important! The tricky part is the imaginary part appearing in the square root; rather than having isolated poles, the square root has a  branch-cut in the complex plane. A neat and simple way to take care of this problem without using advanced complex analysis is given in Ref. [3] by means of the following identity:</p><p>  请注意，解析器迹线的定义中的N因子被我们的解决方案抵消，我们获得了一个有限且与N无关的结果（请记住，这是一个连续近似）。为了获得特征值密度，我们首先需要执行解析连续z→λ+ iε，取虚部，然后取极限ε→0 ^（+）。请注意，这些操作的顺序很重要！棘手的部分是出现在平方根中的虚部。平方根不是孤立的极点，而是在复平面上具有分支切口。参考文献中给出了一种无需使用高级复杂分析即可解决此问题的简洁方法。 [3]通过以下身份：</p><p>    Using this result back in the definition of the eigenvalue density, and taking the ε → 0^(+) limit, we obtain:</p><p>将该结果重新用于特征值密度的定义中，并取ε→0 ^（+）极限，我们得到：</p><p>  From a direst inspection you can see that if |λ| &gt; 2 the spectrum is zero (this is a real function!), while is it finite for |λ|&lt;2. As the spectrum is defined as a positive quantity, the sign of the solution should be chosen as + for positive λ and - otherwise. We finally obtain the celebrated Wigner semicircle law:</p><p>  从间接检查中，您可以看到|λ| > 2，频谱为零（这是一个实函数！），而对于|λ| <2则是有限的。由于将光谱定义为正数，对于正数λ，应将溶液的符号选择为+，否则选择-。我们终于获得了著名的维格纳半圆定律：</p><p>  So much sweat for such a little formula :) In the section I will plot the above expression against an explicit numerical evaluation.</p><p>  对于这么小的公式，真是太费力了：)在本节中，我将把上面的表达式与明确的数值评估作图。</p><p>  To conclude, we check results against a direct numerical evaluation. Details can be found in this G ithub repository, here I will go through the main steps only.</p><p>  总而言之，我们根据直接的数值评估来检查结果。可以在此G ithub存储库中找到详细信息，这里我将仅介绍主要步骤。</p><p> At the time Wigner solved this problem, it was probably prohibitive to check results numerically if not via lengthy processes on some gym-room size computer. Nowadays you can evaluate explicitly these expressions on your laptop and check they agree with the analytical results.</p><p> 当维格纳解决了这个问题时，如果不通过一些健身房大小的计算机进行冗长的过程，可能无法进行数字检查结果。如今，您可以在笔记本电脑上显式评估这些表达式，并检查它们是否与分析结果一致。</p><p> One of the problem you face when running simulations is the finite size of the system. Remember that Eq.(31) has been obtained in the limit of large N. But how large is large? How big our simulation needs to be in order to agree with the analytical formula? To answer this question, let us write a function to perform the all evaluation:</p><p>运行模拟时面临的问题之一是系统的大小有限。请记住，方程（31）是在大N的极限中获得的。但是，大有多少呢？为了与解析公式一致，我们的仿真需要多大？为了回答这个问题，让我们编写一个函数来执行所有评估：</p><p>   Generate an N×N matrix instance X by sampling from the normal distribution with mean zero and variance σ = 1/√N.</p><p>   通过从均值为零且方差σ= 1 /√N的正态分布进行采样来生成N×N矩阵实例X。</p><p>  Get the eigenvalues using  numpy.eigvalsh(Xs) note that this is a numerically optimized method to obtain eigenvalues of symmetric matrices.</p><p>  使用numpy.eigvalsh（Xs）获得特征值请注意，这是获得对称矩阵特征值的数值优化方法。</p><p>   You can see two things here: one is that the tails of the numerical distrbution exceeds the domain [-2,2] of the bulk semicircle. And two is that the bins do not agree too well with the analytical expression. We can reperat the evaluation for N=500:</p><p>   您可以在此处看到两件事：一是数字分布的尾部超过了整体半圆的域[-2,2]。二是垃圾箱与解析表达式不太吻合。我们可以对N = 500进行评估：</p><p>  You can see that the results gets definitely better. We can evaluate the error between the analytical and numerical values as a function of the matrix size. Here I compute the Mean Square Root error (MSRE):</p><p>  您可以看到结果肯定会更好。我们可以根据矩阵大小评估解析值和数值之间的误差。在这里，我计算均方根误差（MSRE）：</p><p>  In the above equation, the first eigenvalue density is the one evaluated numerically, while the second is the expression we have evaluated analytically, while S is the number of samples. In the plot below I separate the tails from the bulk error:</p><p>在上面的方程中，第一个特征值密度是用数字计算的一个，而第二个特征值密度是我们经过分析评估的表达式，而S是样本数。在下面的图中，我将尾部错误与批量错误分开：</p><p>  You can see how the error goes down to ~ 0 (you can add more points to get a better result here) as the matrix size increases, providing in this way a nice numerical validation of our calculation above.</p><p>  您可以看到随着矩阵大小的增加，误差如何降低到〜0（可以在此处添加更多点以获得更好的结果），从而以上述方式为我们的计算提供了很好的数值验证。</p><p>  In this article I presented a simple step-by-step introduction to Random Matrix theory, and in particular the Gaussian Orthogonal Ensemble. The calculation I presented is not the standard one you will find in books, the rea</p><p>  在本文中，我简单介绍了随机矩阵理论，特别是高斯正交合奏。我提出的计算方法不是您在书本中找到的标准，实际</p><p>......</p><p>......</p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://medium.com/cantors-paradise/getting-started-with-random-matrices-a-step-by-step-guide-81e5902384e">https://medium.com/cantors-paradise/getting-started-with-random-matrices-a-step-by-step-guide-81e5902384e</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/矩阵/">#矩阵</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/step/">#step</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/分享/">#分享</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy; 2020 diglog.com </div></div></body></html>