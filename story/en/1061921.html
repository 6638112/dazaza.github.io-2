<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>CMU研究人员展示了使用雷达的隐私保留活动跟踪的潜力 
				CMU researchers show potential of privacy-preserving activity tracking using radar			</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">
				CMU researchers show potential of privacy-preserving activity tracking using radar			<br/>CMU研究人员展示了使用雷达的隐私保留活动跟踪的潜力 </h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2021-05-11 19:58:24</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2021/5/1daf0a02eb976ea3eb13013b755d407d.png"><img src="http://img2.diglog.com/img/2021/5/1daf0a02eb976ea3eb13013b755d407d.png" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>Or — for an altogether healthier use-case — what if you could ask your speaker to keep count of reps as you do squats and bench presses? Or switch into full-on ‘personal trainer’ mode — barking orders to peddle faster as you spin cycles on a dusty old exercise bike (who needs a Peloton!).</p><p>或者 - 对于一个完全更健康的用例 - 如果您可以要求您的发言人将您的扬声器留在蹲下和卧脚时，您会询问代表的数量怎么办？或者切换到全面的“私人教练”模式 - 在尘土飞扬的旧运动自行车上旋转周期时，咆哮订单以更快地贩卖（谁需要一个Peloton！）。</p><p> And what if the speaker was smart enough to  just know you’re eating dinner and took care of slipping on a little mood music?</p><p> 如果扬声器足够聪明，怎么知道你正在吃晚餐，并照顾一下轻松的情绪音乐？</p><p>  Now imagine if all those activity tracking smarts were on tap without any connected cameras being plugged inside your home.</p><p>  现在想象一下，如果所有这些活动跟踪智能都在轻拍，没有任何连接的相机插入您的家中。</p><p> A nother bit of fascinating research from researchers at Carnegie Mellon University’s  Future Interfaces Group  opens up these sorts of possibilities — demonstrating a novel approach to activity tracking that does not rely on cameras as the sensing tool.</p><p> 来自Carnegie Mellon Universy未来的接口组的研究人员的漫画研究令人乐趣的一点开辟了这些可能性 - 展示了一种不依赖相机作为传感工具的活动跟踪的新方法。</p><p> Installing connected cameras inside your home is of course a horrible privacy risk. Which is why the CMU researchers set about investigating the potential of using millimeter wave (mmWave) doppler radar as a medium for detecting different types of human activity.</p><p> 在您的家中安装连接的相机当然是一个可怕的隐私风险。这就是为什么CMU研究人员设置了研究使用毫米波（MMWAVE）多普勒雷达作为检测不同类型人类活动的介质的电位。</p><p> The challenge they needed to overcome is that while mmWave offers a “signal richness approaching that of microphones and cameras”, as they put it, data-sets to train AI models to recognize different human activities as RF noise are not readily available (as visual data for training other types of AI models is).</p><p> 他们需要克服的挑战是，虽然MMWAVE提供了“方法丰富，即将到达麦克风和摄像机的信号丰富”，因为它们将其提交，以培训AI模型来识别不同人类活动，因为RF噪声不容易获得（如视觉培训其他类型AI模型的数据是）。</p><p> Not to be deterred, they set about sythensizing doppler data to feed a human activity tracking model — devising a software pipeline for training privacy-preserving activity tracking AI models.</p><p> 他们不被阻止，他们设置了Sythensizing多普勒数据，以喂养人类活动跟踪模型 - 设计用于培训隐私保留活动跟踪AI模型的软件管道。 </p><p> The results can be seen in  this video — where the model is shown correctly identifying a number of different activities, including cycling, clapping, waving and squats. Purely from its ability to interpret the mmWave signal the movements generate — and purely having been trained on public video data.</p><p>可以在该视频中看到结果 - 其中模型显示正确识别许多不同的活动，包括骑自行车，鼓掌，挥舞和蹲下。纯粹从其解释MMWAVE信号的能力，动作产生 - 并且纯粹已经在公共视频数据上培训。</p><p> “We show how this cross-domain translation can be successful through a series of experimental results,” they write. “Overall, we believe our approach is an important stepping stone towards significantly reducing the burden of training such as human sensing systems, and could help bootstrap uses in human-computer interaction.”</p><p> “我们展示了这种跨域翻译如何通过一系列实验结果取得成功，”他们写道。 “总的来说，我们相信我们的方法是一个重要的踏脚石，可以大大减少人类传感系统等培训的负担，并有助于在人机互动中使用自动启动。”</p><p> Researcher Chris Harrison confirms the  mmWave doppler radar-based sensing doesn’t work for “very subtle stuff” (like spotting different facial expressions). But he says it’s sensitive enough to detect less vigorous activity — like eating or reading a book.</p><p> 研究员Chris Harrison确认了MMWave多普勒雷达的感应不适用于“非常微妙的东西”（如发现不同的面部表情）。但他说它足够敏感，无法发现较少的剧烈活动 - 就像吃或读一本书一样。</p><p> The motion detection ability of doppler radar is also limited by a need for line-of-sight between the subject and the sensing hardware. (Aka: “It can’t reach around corners yet.” Which, for those concerned about future robots’ powers of human detection, will surely sound slightly reassuring.)</p><p> 多普勒雷达的运动检测能力也受到对象和传感硬件之间的视线的需要受限。 （又名：“它尚未达到角落。”这对于那些关注未来机器人的人类检测权的人来说，它肯定会听起来轻微放心。）</p><p> Detection does require special sensing hardware, of course. But things are already moving on that front: Google has been dipping its toe in already, via  project   Soli — adding a radar sensor to the  Pixel 4, for example.</p><p> 当然，检测确实需要特殊的传感硬件。但事情已经在这方面进行了移动：谷歌已经通过Project Soli  - 例如将雷达传感器添加到像素4中的雷达传感器来浸入其脚趾。</p><p> Google’s  Nest Hub also integrates the same radar sense to track sleep quality.</p><p> 谷歌的巢穴集线器还集成了相同的雷达感，以跟踪睡眠质量。</p><p>  “One of the reasons we haven’t seen more adoption of radar sensors in phones is a lack of compelling use cases (sort of a chicken and egg problem),” Harris tells TechCrunch. “Our research into radar-based activity detection helps to open more applications (e.g., smarter Siris, who know when you are eating, or making dinner, or cleaning, or working out, etc.).”</p><p>  “我们没有看到更多的原因之一，我们在手机中采用雷达传感器是缺乏引人注目的用例（种类的鸡肉和鸡蛋问题），”哈里斯告诉TechCrunch。 “我们对基于雷达的活动检测的研究有助于开放更多的应用程序（例如，更聪明的SIRIS，谁知道您正在吃饭或做饭或清洁或锻炼或锻炼等等）。” </p><p> Asked whether he sees greater potential in mobile or fixed applications, Harris reckons there are interesting use-cases for both.</p><p>询问他是否在移动或固定应用中看到更大的潜力，哈里斯审计对两者都有有趣的用例。</p><p> “I see use cases in both mobile and non mobile,” he says. “Returning to the Nest Hub… the sensor is already in the room, so why not use that to bootstrap more advanced functionality in a Google smart speaker (like rep counting your exercises).</p><p> “我看到了移动和非移动中的用例，”他说。 “返回巢穴中心......传感器已经在房间里，为什么不使用它在Google智能扬声器中引导更高级的功能（如Rep计算您的练习）。</p><p> “There are a bunch of radar sensors already used in building to detect occupancy (but now they can detect the last time the room was cleaned, for example).”</p><p> “建筑物已经使用了一堆雷达传感器来检测占用（但现在他们可以检测到最后一次清洗房间）。”</p><p> “Overall, the cost of these sensors is going to drop to a few dollars very soon (some on eBay are already around $1), so you can include them in everything,” he adds. “And as Google is showing with a product that goes in your bedroom, the threat of a ‘surveillance society’ is much less worry-some than with camera sensors.”</p><p> “总的来说，这些传感器的成本很快将降至几美元（一些关于eBay上的一些人已经在1美元上），因此您可以将它们包含在一切中，”他补充道。 “随着谷歌在卧室内展示了一个产品的产品，”监控会“的威胁要不那么担心 - 而不是相机传感器。”</p><p> Startups like  VergeSense are already using sensor hardware and computer vision technology to power real-time analytics of indoor space and activity for the b2b market (such as measuring office occupancy).</p><p> 像Vergersense这样的初创公司已经使用传感器硬件和计算机视觉技术来为B2B市场的室内空间和活动进行实时分析（例如衡量办公室占用）。</p><p> But even with local processing of low-resolution image data, there could still be a perception of privacy risk around the use of vision sensors — certainly in consumer environments.</p><p> 但即使利用局部处理低分辨率图像数据，仍然可能存在围绕使用视觉传感器的隐私风险的看法 - 当然在消费者环境中。</p><p> Radar offers an alternative to such visual surveillance that could be a better fit for privacy-risking consumer connected devices such as ‘ smart mirrors‘.</p><p> 雷达提供了这种视觉监控的替代方案，可以更适合隐私风险的消费者连接设备，例如“智能镜”。 </p><p> “If it is processed locally, would you put a camera in your bedroom? Bathroom? Maybe I’m prudish but I wouldn’t personally,” says Harris.</p><p>“如果它在本地处理，您会在卧室里放置相机吗？浴室？也许我是谨慎的，但我不会个人，“哈里斯说。</p><p> He also points to  earlier research which he says underlines the value of incorporating more types of sensing hardware: “The more sensors, the longer tail of interesting applications you can support. Cameras can’t capture everything, nor do they work in the dark.”</p><p> 他还指出了早期的研究，他说提出了利用更多类型的传感硬件的价值来强调：“传感器越多，可以支持的有趣应用程序的较长尾。相机无法捕捉一切，也不能在黑暗中工作。“</p><p> “Cameras are pretty cheap these days, so hard to compete there, even if radar is a bit cheaper. I do believe the strongest advantage is privacy preservation,” he adds.</p><p> “这些天相机非常便宜，这么难以在那里竞争，即使雷达有点便宜。我相信最强大的优势是隐私保存，“他补充道。</p><p> Of course having any sensing hardware — visual or otherwise — raises potential privacy issues.</p><p> 当然有任何感应硬件 - 视觉或其他 - 提高潜在的隐私问题。</p><p> A sensor that tells you when a child’s bedroom is occupied may be good or bad depending on who has access to the data, for example. And all sorts of human activity can generate sensitive information, depending on what’s going on. (I mean, do you really want your smart speaker to know when you’re having sex?)</p><p> 例如，一个传感器，可以占用孩子的卧室何时占用，这取决于谁可以访问数据。并且各种人类活动都可以产生敏感信息，具体取决于正在发生的事情。 （我的意思是，你真的希望你的智能演讲者知道你什么时候做爱吗？）</p><p> So while radar-based tracking may be less invasive than some other types of sensors it doesn’t mean there are no potential privacy concerns at all.</p><p> 因此，虽然基于雷达的跟踪可能比其他一些类型的传感器更少，但它并不意味着根本没有潜在的隐私问题。</p><p> As ever, it depends on where and how the sensing hardware is being used. Albeit, it’s hard to argue that the data radar generates is likely to be less sensitive than equivalent visual data were it to be exposed via a breach.</p><p> 依赖于何处以及如何使用传感硬件。尽管如此，很难争辩说数据雷达可能比等效视觉数据更少敏感，这是通过违规暴露。 </p><p> “Any sensor should naturally raise the question of privacy — it is a spectrum rather than a yes/no question,” agrees Harris.  “Radar sensors happen to be usually rich in detail, but highly anonymizing, unlike cameras. If your doppler radar data leaked online, it’d be hard to be embarrassed about it. No one would recognize you. If cameras from inside your house leaked online, well… ”</p><p>“任何传感器都应该自然地提出隐私问题 - 这是一个频谱而不是是/否的问题，”哈里斯同意。 “雷达传感器恰好通常详细富裕，而是与相机不同的匿名。如果您的多普勒雷达数据在线泄露，那么它很难尴尬。没有人会认出你。如果你的房子里面的相机泄露在线，那么......“</p><p> What about the compute costs of synthesizing the training data, given the lack of immediately available doppler signal data?</p><p> 鉴于缺乏立即可用的多普勒信号数据，鉴于缺乏立即可用的多普勒信号数据，构成培训数据的计算成本如何？</p><p> “It isn’t turnkey, but there are many large video corpuses to pull from (including things like Youtube-8M),” he says. “It is orders of magnitude faster to download video data and create synthetic radar data than having to recruit people to come into your lab to capture motion data.</p><p> “它不是交钥匙，但有许多大型视频群从（包括YouTube-8M这样的东西），”他说。 “下载视频数据并创建合成雷达数据的数量速度比必须招募人员进入您的实验室以捕获动作数据的秩序。</p><p> “One is inherently 1 hour spent for 1 hour of quality data. Whereas you can download hundreds of hours of footage pretty easily from many excellently curated video databases these days. For every hour of video, it takes us about 2 hours to process, but that is just on one desktop machine we have here in the lab. The key is that you can parallelize this, using Amazon AWS or equivalent, and process 100 videos at once, so the throughput can be extremely high.”</p><p> “一个固有的1小时花费1小时的质量数据。然而，这些天可以从许多精致的视频数据库中轻松地下载数百小时的镜头。对于每一小时的视频，需要我们需要大约2个小时的时间来处理，但这只是我们在实验室中拥有的一台桌面机。关键是您可以使用Amazon AWS或等效项并行化这一点，并一次处理100个视频，因此吞吐量可能非常高。“</p><p> And while RF signal does reflect, and do so to different degrees off of different surfaces (aka “multi-path interference”), Harris says the signal reflected by the user “is by far the dominant signal”. Which means they didn’t need to model other reflections in order to get their demo model working. (Though he notes that could be done to further hone capabilities “by extracting big surfaces like walls/ceiling/floor/furniture with computer vision and adding that into the synthesis stage”.)</p><p> 虽然RF信号确实反射，并且这样做到不同表面的不同程度（AKA“多路径干扰”），Harris表示由用户反射的信号“是迄今为止主导信号”。这意味着他们不需要建模其他反射，以便获得他们的演示模型工作。 （虽然他指出，可以通过用电脑视觉提取像墙壁/天花板/地板/家具等墙壁/天花板/地板/家具等大表面来完成进一步磨练能力，并将其添加到合成阶段“。）</p><p> “The [doppler] signal is actually very high level and abstract, and so it’s not particularly hard to process in real time (much less ‘pixels’ than a camera).” he adds. “Embedded processors in cars use radar data for things like collision breaking and blind spot monitoring, and those are low end CPUs (no deep learning or anything).”</p><p> “[多普勒]信号实际上是非常高的水平和摘要，因此它并不特别难以实时处理（远低于相机的像素'）。”他补充道。 “汽车中的嵌入式处理器使用碰撞破裂和盲点监测等东西的雷达数据，那些是低端CPU（没有深度学习或任何东西）。”</p><p> The research is being presented at the ACM CHI conference, alongside another Group project — called  Pose-on-the-Go — which uses smartphone sensors to approximate the user’s full-body pose without the need for wearable sensors.</p><p> 该研究在ACM Chi会议上展示，同时另一个群组项目 - 名为Go-Go-Go  - 这将使用智能手机传感器来近似用户的全身姿势，而无需可穿戴传感器。 </p><p> CMU researchers from the Group have also  previously demonstrated a method for indoor ‘smart home’ sensing on the cheap (also without the need for cameras), as well as —  last year — showing how smartphone cameras could be used to give an on-device AI assistant more contextual savvy.</p><p>本集团的CMU研究人员还展示了一种在便宜的室内'智能家居'感应的方法（也没有相机的需要），以及去年 - 展示如何使用智能手机相机如何提供设备AI Assistant更加上文精明。</p><p> In recent years they’ve also investigated using  laser vibrometry and  electromagnetic noise to give smart devices better environmental awareness and contextual functionality. Other interesting research out of the Group includes using conductive spray paint to  turn anything into a touchscreen. And various methods to extend the interactive potential of wearables — such as by using  lasers to project virtual buttons onto the arm of a device user or incorporating another wearable ( a ring) into the mix.</p><p> 近年来，他们还研究了激光振动和电磁噪声，为智能设备提供更好的环境意识和上下文功能。除了本集团的其他有趣的研究包括使用导电喷涂涂料将任何东西变成触摸屏。和各种方法来扩展可穿戴物的交互潜力 - 例如通过使用激光将虚拟按钮投影到设备用户的臂上或将另一个可穿戴（环）结合到混合物中。</p><p> The future of human computer interaction looks certain to be a lot more contextually savvy — even if current-gen ‘smart’ devices can still stumble on the basics and seem more than a little dumb.</p><p> 人类计算机互动的未来看起来肯定是更加上下文化的灵活 - 即使当前-Gen'Scart'设备仍然可以偶然偶然困扰，似乎不止一点愚蠢。 </p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://techcrunch.com/2021/05/11/cmu-researchers-show-potential-of-privacy-preserving-activity-tracking-using-radar/">https://techcrunch.com/2021/05/11/cmu-researchers-show-potential-of-privacy-preserving-activity-tracking-using-radar/</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/活动/">#活动</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/分享/">#分享</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy;2012-2021 diglog.com </div></div></body></html>