<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>科学处于“复制危机”已经十年了，我们学到了什么吗？</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">科学处于“复制危机”已经十年了，我们学到了什么吗？</h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2020-10-17 10:06:09</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2020/10/60a54d3b1f616ee1cc1bae4c556af08f.jpg"><img src="http://img2.diglog.com/img/2020/10/60a54d3b1f616ee1cc1bae4c556af08f.jpg" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>Much ink has been spilled over the “replication crisis” in the last decade and a half, including  here at Vox. Researchers have discovered, over and over, that lots of findings in fields like psychology, sociology, medicine, and economics  don’t hold up when other researchers try to replicate them.</p><p>在过去的15年里，包括这里的Vox在内的“复制危机”已经溢出了大量的墨水。研究人员一次又一次地发现，心理学、社会学、医学和经济学等领域的许多发现在其他研究人员试图复制它们时是站不住脚的。</p><p> This conversation was fueled in part by John Ioannidis’s 2005 article “ Why Most Published Research Findings Are False” and by the  controversy around a 2011 paper that  used then-standard statistical methods to find that people have precognition.  But since then, many researchers have explored the replication crisis from different angles. Why are research findings so often unreliable? Is the problem just that we test for “statistical significance” — the likelihood that similarly strong results could have occurred by chance — in a nuance-free way? Is it that null results (that is, when a study finds no detectable effects) are ignored while positive ones make it into journals?</p><p>这场对话在一定程度上是由约翰·约安尼迪斯(John Ioannidis)2005年的文章“为什么大多数发表的研究结果都是错误的”，以及围绕2011年一篇论文的争议所推动的，那篇论文使用了当时的标准统计方法，发现人们有预感。但自那以后，许多研究人员从不同的角度对复制危机进行了探索。为什么研究结果经常是不可靠的？问题是否仅仅在于我们以一种没有细微差别的方式测试“统计意义”--同样强劲的结果可能偶然发生的可能性？是不是空结果(即当一项研究发现没有可检测到的影响)被忽略，而积极的结果被发表在期刊上？</p><p> A recent write-up by Alvaro de Menard, a participant in the  Defense Advanced Research Project’s Agency’s (DARPA) replication markets project (more on this below), makes the case for a more depressing view: The processes that lead to unreliable research findings are routine, well understood, predictable, and in principle pretty easy to avoid. And yet, he argues, we’re still not improving the quality and rigor of social science research.</p><p>阿尔瓦罗·德·梅纳德(Alvaro De Menard)是国防高级研究计划局(DARPA)复制市场项目的参与者，他最近的一篇文章提出了一种更令人沮丧的观点：导致不可靠研究结果的过程是例行公事的、容易理解的、可预测的，原则上很容易避免。然而，他认为，我们仍然没有提高社会科学研究的质量和严谨性。</p><p> While other researchers  I spoke with pushed back on parts of Menard’s pessimistic take, they do agree on something: a decade of talking about the replication crisis hasn’t translated into a scientific process that’s much less vulnerable to it. Bad science is still frequently published, including in top journals — and that needs to change.</p><p>虽然与我交谈的其他研究人员驳斥了梅纳德的部分悲观观点，但他们确实同意一件事：十年来关于复制危机的讨论并没有转化为一个不那么容易受到影响的科学过程。糟糕的科学仍然经常发表，包括在顶级期刊上-这种情况需要改变。</p><p>  Let’s take a step back and explain what people mean when they refer to the “replication crisis” in scientific research.</p><p>让我们退后一步，解释一下人们提到科学研究中的“复制危机”是什么意思。</p><p> When research papers are published, they describe their methodology, so other researchers can copy it (or vary it) and build on the original research. When another research team tries to conduct a study based on the original to see if they find the same result, that’s an attempted replication. (Often the focus is not just on doing the exact same thing, but approaching the same question with a larger sample and preregistered design.)  If they find the same result, that’s a successful replication, and evidence that the original researchers were on to something. But when the attempted replication finds different or no results, that often suggests that the original research finding was spurious.</p><p>当研究论文发表时，他们描述了他们的方法，这样其他研究人员就可以复制(或修改)并在原始研究的基础上再接再厉。当另一个研究小组试图在原始研究的基础上进行研究，看看他们是否找到了相同的结果，那就是试图复制。(通常，重点不仅仅是做完全相同的事情，而是通过更大的样本和预先注册的设计来解决相同的问题。)。如果他们发现了同样的结果，那就是一次成功的复制，也证明了最初的研究人员发现了一些东西。但是，当尝试的复制发现不同的结果或没有发现结果时，这通常表明最初的研究结果是虚假的。</p><p> In an attempt to test just how rigorous scientific research is, some researchers have undertaken the task of replicating research that’s been published in a whole range of fields. And as more and more of those attempted replications have come back, the results have been striking — it is not uncommon to find that many, many published studies cannot be replicated.</p><p>为了测试科学研究的严谨性，一些研究人员承担了复制在整个领域发表的研究的任务。随着越来越多的这种尝试复制回来，结果令人震惊-发现许多许多已发表的研究无法复制的情况并不少见。</p><p> One 2015 attempt to reproduce 100 psychology studies was able to replicate only 39 of them. A  big international effort in 2018 to reproduce prominent studies found that 14 of the 28 replicated, and an  attempt to replicate studies from top journals  Nature and  Science found that 13 of the 21 results looked at could be reproduced.</p><p>2015年，一次试图复制100项心理学研究的尝试只能复制其中的39项。2018年，一项旨在复制知名研究的大型国际努力发现，28项研究中有14项是重复的，试图复制顶级期刊《自然》(Nature)和《科学》(Science)的研究发现，21项研究结果中有13项是可以复制的。</p><p> The replication crisis has led a few researchers to ask: Is there a way to guess if a paper will replicate? A growing body of research has found that guessing which papers will hold up and which won’t is often just a matter of looking at the same simple, straightforward factors.</p><p>复制危机让一些研究人员发问：有没有办法猜测一篇论文是否会复制？越来越多的研究发现，猜测哪些论文会站得住脚，哪些不会站得住脚，往往只是看着同样简单、直截了当的因素。</p><p>  Menard argues that the problem is not so complicated.  “Predicting replication is easy,” he said. “There’s no need for a deep dive into the statistical methodology or a rigorous examination of the data, no need to scrutinize esoteric theories for subtle errors — these papers have obvious, surface-level problems.”</p><p>梅纳德认为，问题并不是那么复杂。“预测复制很容易，”他说。“没有必要深入研究统计方法或对数据进行严格检查，也没有必要仔细检查深奥的理论以寻找细微的错误--这些论文存在明显的表面问题。”</p><p> A 2018 study  published in  Nature had scientists place bets on which of a pool of social science studies would replicate. They found that the predictions by scientists in this betting market were highly accurate at estimating which papers would replicate.</p><p>2018年发表在“自然”(Nature)上的一项研究让科学家们押注社会科学研究池中的哪一项会复制。他们发现，在这个博彩市场中，科学家们的预测在估计哪些论文将被复制方面非常准确。</p><p>   “These results suggest something systematic about papers that fail to replicate,” study co-author Anna Dreber argued after the study was released.</p><p>研究合著者安娜·德雷伯(Anna Dreber)在研究发布后表示：“这些结果表明，未能复制的论文存在系统性问题。”</p><p> Additional research has established that you don’t even need to poll experts in a field to guess which of its studies will hold up to scrutiny. A  study published in August had participants read psychology papers and predict whether they would replicate. “Laypeople without a professional background in the social sciences are able to predict the replicability of social-science studies with above-chance accuracy,” the study concluded, “on the basis of nothing more than simple verbal study descriptions.”</p><p>另一项研究已经证实，你甚至不需要对某一领域的专家进行民意调查，就可以猜测它的哪些研究经得起审查。8月份发表的一项研究让参与者阅读心理学论文，并预测他们是否会复制。“没有社会科学专业背景的外行能够以极高的精确度预测社会科学研究的可复制性，”该研究总结道，“仅仅基于简单的口头研究描述。”</p><p> The laypeople were not as accurate in their predictions as the scientists in the  Nature study, but the fact they were still able to predict many failed replications suggests that many of them have flaws that even a layperson can notice.</p><p>门外汉的预测不如“自然”研究中的科学家准确，但他们仍然能够预测到许多失败的复制，这表明他们中的许多人都有即使是门外汉也能注意到的缺陷。</p><p>  Publication of a peer-reviewed paper is not the final step of the scientific process. After a paper is published, other research might cite it — spreading any misconceptions or errors in the original paper. But research has established that scientists have good instincts for whether a paper will replicate or not. So, do scientists avoid citing papers that are unlikely to replicate?</p><p>发表同行评议的论文并不是科学过程的最后一步。一篇论文发表后，其他研究可能会引用它-传播原始论文中的任何误解或错误。但研究已经证实，科学家对一篇论文是否会复制有着良好的直觉。那么，科学家会避免引用不太可能复制的论文吗？</p><p> This striking chart from  a 2020 study by Yang Yang, Wu Youyou, and Brian Uzzi at UC Berkeley illustrates their finding that actually, there is no correlation at all between whether a study will replicate and how often it is cited. “Failed papers circulate through the literature as quickly as replicating papers,” they argue.</p><p>加州大学伯克利分校的杨阳、吴友友和布莱恩·尤齐在2020年的一项研究中绘制了这张引人注目的图表，说明了他们的发现：实际上，一项研究是否会重复与被引用的频率之间根本没有相关性。他们争辩说：“失败的论文在文献中流传的速度就像复制论文一样快。”</p><p>   Looking at a sample of studies from 2009 to 2017 that have since been subject to attempted replications, the researchers find that studies have about the same number of citations regardless of whether they replicated.</p><p>研究人员查看了2009至2017年间一直被尝试复制的研究样本，发现无论是否复制，研究的引用次数都大致相同。</p><p> If scientists are pretty good at predicting whether a paper replicates, how can it be the case that they are as likely to cite a bad paper as a good one? Menard theorizes that many scientists don’t thoroughly check — or even read — papers once published, expecting that if they’re peer-reviewed, they’re fine. Bad papers are published by a peer-review process that is not adequate to catch them — and once they’re published, they are not penalized for being bad papers.</p><p>如果科学家非常擅长预测一篇论文是否重复，那么他们怎么可能引用一篇糟糕的论文和一篇优秀的论文呢？梅纳德的理论认为，许多科学家在论文发表后不会彻底检查-甚至不会阅读--他们期望如果论文得到同行评审，它们就会很好。不好的论文是通过同行评议程序发表的，不足以抓住它们--一旦发表，它们就不会因为是不好的论文而受到惩罚。</p><p>  Here at Vox, we’ve written about how the replication crisis can   guide us to do better science. And yet blatantly shoddy work is still being published in peer-reviewed journals despite errors that a layperson can see.</p><p>在VOX这里，我们写了关于复制危机如何引导我们做更好的科学。然而，尽管有外行可以看到的错误，但粗制滥造的作品仍在同行评议的期刊上发表。</p><p> In many cases, journals effectively aren’t held accountable for bad papers — many, like  The Lancet, have  retained their prestige even after a long string of  embarrassing public incidents where they  published research that  turned out fraudulent or nonsensical.  (The Lancet said recently that, after a study on Covid-19 and  hydroxychloroquine this spring was retracted after questions were raised about the data source, the journal would  change its data-sharing practices.)</p><p>在许多情况下，期刊实际上不会对糟糕的论文负责-许多期刊，比如《柳叶刀》，即使在发生了一系列令人尴尬的公开事件后，仍然保持了自己的声望，因为它们发表的研究被证明是欺骗性的或无稽之谈。(“柳叶刀”最近表示，今年春天关于新冠肺炎和羟氯喹的一项研究在对数据来源提出质疑后被撤回，该杂志将改变其数据共享做法。)。</p><p> Even outright frauds often take a very long time to be repudiated, with some universities and journals dragging their feet and  declining to investigate widespread misconduct.</p><p>即使是彻头彻尾的欺诈行为也往往需要很长时间才能被否认，一些大学和期刊拖拖拉拉，拒绝调查普遍存在的不当行为。</p><p> That’s discouraging and infuriating. It suggests that the replication crisis isn’t one specific methodological reevaluation, but a symptom of a scientific system that needs rethinking on many levels. We can’t just teach scientists how to write better papers. We also need to change the fact that those better papers aren’t cited more often than bad papers; that bad papers are almost never retracted even when their errors are visible to lay readers; and that there are no consequences for bad research.</p><p>这令人沮丧和愤怒。它表明，复制危机不是一种具体的方法论重新评估，而是一个需要在多个层面上重新思考的科学体系的症状。我们不能只教科学家如何写更好的论文。我们还需要改变这样一个事实，即那些好的论文并不比糟糕的论文被引用得更多；坏的论文几乎从来不会被撤回，即使他们的错误对外行读者来说是显而易见的；而且糟糕的研究不会产生任何后果。</p><p> In some ways, the culture of academia actively selects for bad research. Pressure to publish lots of papers favors those who can put them together quickly — and one way to be quick is to be willing to cut corners. “Over time, the most successful people will be those who can best exploit the system,” Paul Smaldino, a cognitive science professor at the University of California Merced,  told my colleague Brian Resnick.</p><p>在某些方面，学术界的文化积极地选择不好的研究。发表大量论文的压力有利于那些能够迅速将它们组合在一起的人-而快速的一种方法是愿意偷工减料。加州大学默塞德分校(University Of California Merced)认知科学教授保罗·斯马尔迪诺(Paul Smaldino)告诉我的同事布莱恩·雷斯尼克(Brian Resnick)：“随着时间的推移，最成功的人将是那些最能利用这一系统的人。”</p><p> So we have a system whose incentives keep pushing bad research even as we understand more about what makes for good research.</p><p>因此，我们有一个系统，它的激励机制不断推动糟糕的研究，即使我们更多地了解什么是好的研究。</p><p> Researchers working on the replication crisis are more divided, though, on the question of whether the last decade of work on the replication crisis has left us better equipped to fight these problems — or left us in the same place where we started.</p><p>然而，研究复制危机的研究人员在以下问题上存在更大分歧：过去十年的复制危机研究工作是让我们更好地准备好了应对这些问题，还是让我们在开始的地方原地踏步。</p><p> “The future is bright,” concludes  Altmejd and Dreber’s 2019 paper about how to predict replications. “There will be rapid accumulation of more replication data, more outlets for publishing replications, new statistical techniques, and—most importantly—enthusiasm for improving replicability among funding agencies, scientists, and journals. An exciting replicability ‘upgrade’ in science, while perhaps overdue, is taking place.”</p><p>Altmejd和Dreber在2019年发表的关于如何预测复制的论文总结道：“未来是光明的。”“将迅速积累更多的复制数据、更多发布复制的渠道、新的统计技术，以及--最重要的是--在资助机构、科学家和期刊中提高可复制性的热情。科学领域令人兴奋的可复制性‘升级’虽然可能早该发生，但正在发生。“。</p><p> Menard, by contrast, argues that this optimism has not been borne out — none of our improved understanding of the replication crisis leads to more papers being published that actually replicate. The project that he’s a part of — an effort to design a better model to predict which papers replicate run by DARPA in the Defense Department — has  not seen papers grow any more likely to replicate over time.</p><p>相反，梅纳德认为，这种乐观并没有得到证实--我们对复制危机的理解没有得到改善，也没有导致发表更多实际复制的论文。他参与的项目-努力设计一个更好的模型来预测国防部DARPA运营的论文被复制的可能性-并没有看到论文随着时间的推移变得更有可能被复制。</p><p> “I frequently encounter the notion that after the replication crisis hit there was some sort of great improvement in the social sciences, that people wouldn’t even dream of publishing studies based on 23 undergraduates any more ... In reality there has been no discernible improvement,” he writes.</p><p>“我经常遇到这样的想法，即在复制危机来袭后，社会科学取得了某种巨大的进步，人们甚至不会再梦想发表基于23名本科生的研究成果……。实际上，没有明显的改善，“他写道。</p><p> Researchers who are more optimistic point to other metrics of progress. It’s true that papers that fail replication are still extremely common, and that the peer-review process hasn’t improved in a way that catches these errors. But other elements of the error-correction process are getting better.</p><p>更乐观的研究人员指出了其他衡量进展的指标。诚然，复制失败的论文仍然非常普遍，同行评审过程并没有以一种捕捉这些错误的方式得到改善。但纠错过程的其他要素正在变得更好。</p><p> “Journals now retract about 1,500 articles annually — a nearly 40-fold increase over 2000, and a dramatic change even if you account for the roughly doubling or tripling of papers published per year,” Ivan Oransky at  Retraction Watch argues. “Journals have improved,” reporting more details on retracted papers and improving their process for retractions.</p><p>Retaction Watch的伊万·奥兰斯基(Ivan Oransky)认为：“期刊现在每年撤回约1500篇文章--比2000年增加了近40倍，即使算上每年发表的论文大约翻了一番或三倍，这也是一个戏剧性的变化。”“期刊有所改善”，报道了更多关于撤回论文的细节，并改进了它们的撤回流程。</p><p> Other changes in common scientific practices seem to be helping too. For example, preregistrations — announcing how you’ll conduct your analysis before you do the study —  lead to more null results being published.</p><p>普通科学实践中的其他变化似乎也有帮助。例如，预先注册-在进行研究之前宣布您将如何进行分析-会导致发布更多的空结果。</p><p> “I don’t think the influence [of public conversations about the replication crisis on scientific practice] has been zero,” statistician Andrew Gelman at Columbia University told me. “This crisis has influenced my own research practices, and I assume it’s influenced many others as well. And it’s my general impression that journals such as Psychological Science and PNAS don’t publish as much junk as they used to.”</p><p>哥伦比亚大学的统计学家安德鲁·盖尔曼告诉我：“我不认为(关于复制危机的公开讨论)对科学实践的影响是零。”“这场危机影响了我自己的研究实践，我想它也影响了其他许多人。我的总体印象是，像“心理科学”和“美国国家科学院院刊”这样的期刊发表的垃圾文章不像以前那么多了。“</p><p> There’s some reassurance in that. But until those improvements translate to a higher percentage of papers replicating and a difference in citations for good papers versus bad papers, it’s a small victory. And it’s a small victory that has been hard-won. After tons of resources spent demonstrating the scope of the problem, fighting for more retractions, teaching better statistical methods, and trying to drag fraud into the open, papers still don’t replicate as  much as researchers  would hope,  and bad papers are still widely cited — suggesting a big part of the problem still hasn’t been touched.</p><p>这让人有些放心。但在这些改进转化为更高比例的论文复制和好论文与差论文的引用差异之前，这是一个小小的胜利。这是一个来之不易的小胜利。在花费了大量的资源来证明问题的范围，争取更多的撤回，教授更好的统计方法，并试图将欺诈行为公之于众之后，论文仍然没有像研究人员希望的那样复制，糟糕的论文仍然被广泛引用-这表明问题的很大一部分仍然没有被触及。</p><p> We need a more sophisticated understanding of the replication crisis, not as a moment of realization after which we were able to move forward with higher standards, but as an ongoing rot in the scientific process that a decade of work hasn’t quite  fixed.</p><p>我们需要对复制危机有一个更复杂的理解，不是把它看作是我们能够以更高的标准前进的实现时刻，而是把它看作是科学过程中的一种持续腐烂，十年的工作还没有完全修复这一腐烂的过程。</p><p> Our scientific institutions are valuable, as are the tools they’ve built to help us understand the world. There’s no cause for hopelessness here, even if some frustration is thoroughly justified. Science needs saving, sure — but science is very much worth saving.</p><p>我们的科学机构是有价值的，它们为帮助我们理解世界而建造的工具也是有价值的。这里没有绝望的理由，即使有些挫折感是完全合理的。当然，科学需要拯救--但科学非常值得拯救。</p><p>   Millions turn to Vox each month to understand what’s happening in the news, from the coronavirus crisis to a racial reckoning to what is, quite possibly, the most consequential presidential election of our lifetimes. Our mission has never been more vital than it is in this moment: to empower you through understanding. But our distinctive brand of explanatory journalism takes resources. Even when the economy and the news advertising market recovers, your support will be a critical part of sustaining our resource-intensive work. If you have already contributed, thank you. If you haven’t, please consider helping everyone make sense of an increasingly chaotic world:   Contribute today from as little as $3.</p><p>每个月都有数百万人转向Vox来了解新闻中正在发生的事情，从冠状病毒危机到种族清算，再到很可能是我们一生中最重要的总统选举。此时此刻，我们的使命从未像现在这样重要：通过理解来增强你们的能力。但是我们独特的解释性新闻需要资源。即使经济和新闻广告市场复苏，你们的支持也将是维持我们资源密集型工作的关键部分。如果您已经投稿了，谢谢您。如果你还没有，请考虑帮助每个人理解这个日益混乱的世界：现在就从3美元开始捐款吧。</p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://www.vox.com/future-perfect/21504366/science-replication-crisis-peer-review-statistics">https://www.vox.com/future-perfect/21504366/science-replication-crisis-peer-review-statistics</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/处于/">#处于</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/复制/">#复制</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/美国/">#美国</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/谷歌/">#谷歌</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/linux/">#linux</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/程序/">#程序</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy; 2020 diglog.com </div></div></body></html>