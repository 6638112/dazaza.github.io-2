<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>两个工人比一个工人好得多</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">两个工人比一个工人好得多</h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2020-11-06 07:16:15</div><div class="page_narrow text-break page_content"><p>A common architecture pattern is the “task queue”: tasks enter an ordered queue, workers pop tasks and process them. This pattern is used everywhere from  distributed systems to thread pools. It applies just as well to human systems, like waiting in line at a  supermarket or a bank. Task queues are popular because they are simple, easy to understand, and scale well.</p><p>一种常见的体系结构模式是“任务队列”：任务进入有序队列，工作器弹出任务并处理它们。从分布式系统到线程池，这种模式无处不在。它同样适用于人类系统，就像在超市或银行排队一样。任务队列很受欢迎，因为它们简单、易于理解，并且具有很好的伸缩性。</p><p> There are two primary performance metrics for a task queue.  Throughput is how many tasks are processed per time unit.  Latency is how long a task waits in the queue before being processed. Throughput scales as you’d expect (2x workers ≈ 2x throughput) but latency is less intuitive. For all their popularity, we don’t abstractly model the properties of task queues. We have tools to implement them and tools to trace/metric them, but we don’t use theoretical models to understand our systems in abstract. In this essay we will model a simple task queue and show how the latency is highly sensitive to our initial parameters.</p><p>任务队列有两个主要性能指标。吞吐量是指每个时间单位处理的任务数。延迟是指任务在处理之前在队列中等待的时间。吞吐量的扩展符合您的预期(2倍的工作进程≈2倍的吞吐量)，但延迟不那么直观。尽管它们很受欢迎，但我们并不抽象地对任务队列的属性进行建模。我们有工具来实现它们，也有工具来跟踪/度量它们，但是我们不使用理论模型来抽象地理解我们的系统。在本文中，我们将对一个简单的任务队列进行建模，并展示延迟是如何对初始参数高度敏感的。</p><p> We will be using PRISM to model this problem. PRISM is a probabilistic model checker, meaning it can take a software design and figure out how likely various outcomes are. I’ve  talked about PRISM before and criticized it for its restrictive syntax. But here it is the right tool for the job and with some cleverness we can make it shine. This essay will assume no prior knowledge of PRISM. Let’s get started.</p><p>我们将使用PRISM对这个问题进行建模。棱镜是一种概率模型检查器，这意味着它可以进行软件设计，并计算出各种结果的可能性有多大。我以前谈过PRISM，并批评它的限制性语法。但在这里，它是适合这项工作的工具，我们可以用一些聪明的方法让它闪耀光芒。这篇文章不会假设你对PRISM有任何先验知识。我们开始吧。</p><p>  PRISM supports many different kinds of probabilistic models. The simplest of these is the  Discrete Time Markov Process, or  dtmc. In this, time progresses one discrete step at the time and everything happens with known probabilities. You can think of it as randomly moving between states of a state machine, where one step is one transition. The step is an abstract amount of time. While you could design under the assumption that each step is a fixed time, like 5 seconds, we don’t need to here.</p><p>棱镜支持多种不同类型的概率模型。其中最简单的是离散时间马尔可夫过程(DTMC)。在这种情况下，时间一次按离散的一步前进，所有事情都以已知的概率发生。您可以将其视为在状态机的状态之间随机移动，其中一步就是一次转换。这一步是一个抽象的时间量。虽然你可以在假设每一步都是固定的时间(比如5秒)的情况下进行设计，但我们不需要在这里这样做。</p><p> We will assume that there are N tasks and that they are  independent. This means that how long a task takes to process is independent of how many tasks came before and how many tasks come after. However, different tasks will take a different amount of time to process. We can emulate this by flipping it around and saying that each worker has only a certain chance of completing a task each time step. If we say the chance is 50%, then half the tasks will be completed in exactly one step, a quarter will be completed in exactly two, etc. In aggregate, the worker will complete a task roughly every two steps.</p><p>我们将假设有N个任务，并且它们是独立的。这意味着处理一项任务所需的时间与之前有多少任务以及之后有多少任务无关。但是，不同的任务需要不同的处理时间。我们可以效仿这一点，把它翻转过来，说每个工人每一步只有一定的机会完成一项任务。如果我们说机会是50%，那么一半的任务将在恰好一步内完成，四分之一将在恰好两步内完成，以此类推。总的来说，工人将大约每两步完成一项任务。</p><p> PRISM is not expressive enough to let us individually track each task. Fortunately, all the tasks we have are interchangeable: while some tasks will take longer than others to process, this is abstracted away in the probability. We can instead say that there is some integer that represents the number of tasks left, where the worker has a chance each step of decrementing that number. Then if it takes four steps to decrement  left, we just say the worker was working on a complex task.</p><p>棱镜的表现力不足以让我们单独跟踪每项任务。幸运的是，我们拥有的所有任务都是可以互换的：虽然有些任务需要比其他任务更长的时间来处理，但这在概率上是抽象的。相反，我们可以说，有一个整数表示剩余任务的数量，其中工人有机会在每个步骤中递减该数字。然后，如果需要四个步骤才能减少左边，我们就可以说工人正在做一项复杂的任务。</p><p>    dtmc //type of modelconst int N; // Number of tasksmodule workers // number of tasks left to process // A number between 0 and N left : [0..N] init N;</p><p>Dtmc//模型类型const int N；//任务模块工作者数//待处理任务数//剩余0到N之间的数字：[0..N]init N；</p><p> We need to make a  command to represent the worker completing a task. First the full command, then the breakdown of how it works:</p><p>我们需要发出一个命令来代表工人完成一项任务。首先是完整的命令，然后是它的工作原理：</p><p>  Commands have three parts: a  label, a  guard, and an  update. We’ll start with the update. We can say this just means that we decrement  left. In PRISM syntax, we say that the new value of  left, written  left&#39;, is  left - 1</p><p>命令有三个部分：标签、保护和更新。我们先从最新消息说起。我们可以说，这只是意味着我们减少了左侧。在PRISM语法中，我们说Left的新值为Left-1。</p><p>  But it only succeeds 50% of the time. The other 50% of the time nothing happens. We could write  queue&#39; = queue, or we can use the shorthand  true:</p><p>但它的成功率只有50%。另外50%的时候什么都不会发生。我们可以写Queue&#39；=Queue，或者我们可以使用简写True：</p><p>  Next is the guard. The update is only possible if the guard is true. The obvious guard we need here is that we can’t work on a task if there aren’t any tasks left. That leaves just the label, which is an optional name we give to the command.</p><p>下一位是警卫。只有当守卫为真时，才能进行更新。这里我们需要的明显防范措施是，如果没有任何剩余的任务，我们就不能处理任务。这样就只剩下标签了，这是我们为命令指定的一个可选名称。</p><p> It’s good form to leave a “stutter state” at the end so that the model doesn’t deadlock. So if we’re out of tasks, we just say  true.</p><p>最好在最后保留一个“卡顿状态”，这样模型就不会死锁。所以，如果我们没有任务，我们就说是真的。</p><p> [worker] (left &gt; 0) -&gt; 0.5: (left&#39; = left - 1) + 0.5: true; [] (left = 0) -&gt; true;endmodule</p><p>[Worker](Left&gt；0)-&gt；0.5：(Left&#39；=Left-1)+0.5：True；[](Left=0)-&gt；True；endModule。</p><p>  dtmcconst int N; // Number of tasksmodule workers left : [0..N] init N; [worker] (left &gt; 0) -&gt; 0.5: (left&#39; = left - 1) + 0.5: true; [] (left = 0) -&gt; true;endmodule// see next sectionrewards &#34;total_time&#34; [] left &gt; 0: 1;endrewards</p><p>Dtmcconst int N；//剩余的任务模块工作线程数：[0..N]init N；[Worker](Left&gt；0)-&gt；0.5：(Left&#39；=Left-1)+0.5：True；[](Left=0)-&gt；True；End模块//参见下一节奖励&#34；Total_Time&34；[]Left&gt；0：1；End Rewards。</p><p>   In programs, we have one level of coding: the program itself. With specifications, we have two levels. We write the specs and then we write the properties about the specs. In PRISM we can also write properties as queries on the system and have the model checker tell us what the expect values are.</p><p>在程序中，我们有一个级别的编码：程序本身。在规格方面，我们有两个层次。我们先编写规格，然后再编写有关规格的属性。在PRISM中，我们还可以编写属性作为系统上的查询，并让模型检查器告诉我们期望值是什么。</p><p> Our first property is the total time taken to process all tasks. To track this we need to make a small change to our spec. A  reward function is a value we assign to each successive state in the evolution of the system. This will become much more important when we need to model latency, but for now we can get away with a very simple reward function:</p><p>我们的第一个属性是处理所有任务所用的总时间。为了跟踪这一点，我们需要对我们的规范做一个小小的更改。奖励函数是我们在系统演化过程中分配给每个连续状态的值。当我们需要对延迟进行建模时，这将变得更加重要，但目前我们可以使用一个非常简单的奖励函数：</p><p>  If there are any tasks left in the queue, we increment the total reward for that behavior by one.  1 The total reward is the number of steps taken to complete all tasks.</p><p>如果队列中还有任何任务，我们会将该行为的总奖励加1。1总奖励是完成所有任务所采取的步骤数。</p><p> Next we need a property that gets us the reward at the moment we run out of tasks. That looks like this:</p><p>接下来，我们需要一个在我们用完任务时获得奖励的属性。它看起来像这样：</p><p>  The reward will depend on the number of tasks we start with, or  N. We can run an  experiment, where we test the property for a set of  N and graph the result. Here’s the throughput for N from 10 to 100, in steps of 10:</p><p>奖励将取决于我们开始的任务(或N)的数量。我们可以进行一个实验，测试一组N的属性，并将结果绘制成图表。下面是N从10到100的吞吐量，以10为单位：</p><p>  That gives us  throughput. But our model can’t tell us anything about  latency yet, because we’ve assumed that all of the tasks start out in the queue. That models a batch process, not tasks coming in over time and waiting till their turn.</p><p>这给了我们吞吐量。但是我们的模型还不能告诉我们任何关于延迟的信息，因为我们假设所有的任务都是从队列开始的。这是一个批处理过程的模型，而不是随着时间的推移进入并等待轮到它们的任务。</p><p> This is where latency becomes very important. In addition to how long it takes to process a task, we want to account for how long tasks are waiting before being processed. Our model is incomplete until we add this in.</p><p>这就是延迟变得非常重要的地方。除了处理任务需要多长时间外，我们还需要考虑任务在处理之前等待了多长时间。在加入这个之前，我们的模型是不完整的。</p><p>   Instead of all the tasks being available for work immediately, we say that they come in over time. We add a new variable,  queue, to represent the number of tasks actually present in the queue. We also add an  enqueue command that adds tasks to the queue if there any left not yet in it. This will happen at the same “rate” that workers can process tasks.  2</p><p>我们说，不是所有的任务都可以立即投入工作，而是随着时间的推移才能完成。我们添加了一个新变量Queue来表示队列中实际存在的任务数。我们还添加了一个入队命令，如果队列中还有未完成的任务，该命令会将任务添加到队列中。这将以与员工处理任务相同的“速率”发生。2个。</p><p> queue: [0..N] init 0; [enqueue] (queue &lt; left) -&gt; 0.5: (queue&#39; = queue + 1) + 0.5: true;</p><p>Queue：[0..N]init 0；[enQueue](Queue&lt；Left)-&gt；0.5：(Queue&#39；=Queue+1)+0.5：TRUE；</p><p> The worker will only be able to process tasks if the queue is nonempty. When it processes a task, it will decrement from both the total  left and the  queue.</p><p>只有在队列非空的情况下，工作人员才能处理任务。当它处理一项任务时，它将同时从剩余总数和队列中递减。</p><p> [worker] (left &gt; 0 &amp; queue &gt; 0) -&gt; 0.5: (left&#39; = left - 1) &amp; (queue&#39; = queue - 1) + 0.5: true;</p><p>[Worker](Left&gt；0&amp；Queue&gt；0)-&gt；0.5：(Left&#39；=Left-1)&amp；(Queue&#39；=Queue-1)+0.5：TRUE；</p><p> Our two commands aren’t exclusive: when  0 &lt; queue &lt; left then both  [enqueue] and  [worker] are valid commands. In this case, all the possibilities are weighted together. Here this means that there are four equally-likely possibilities:</p><p>我们的两个命令并不是独占的：当0&lt；队列&lt；离开时，[enQueue]和[Worker]都是有效命令。在这种情况下，所有的可能性都被加权在一起。在这里，这意味着有四种可能性相等的可能性：</p><p>  (3) and (4) have the same outcome, but are different for modeling purposes. In my mental model,  worker commands model a longer span of time than  enqueue commands do. The worker needs time to process the task, while adding a task to the queue is instantaneous. Since we’re calculating total time taken, we only want to count the  worker commands as time passing. We can do this by adding a label to the reward function:</p><p>(3)和(4)具有相同的结果，但在建模目的上有所不同。在我的心理模型中，工作者命令比入队命令建模的时间跨度更长。工作人员需要时间来处理任务，而向队列添加任务是瞬间的。由于我们正在计算所用的总时间，因此我们只想在时间流逝时计算Worker命令的数量。我们可以通过向奖励函数添加标签来实现这一点：</p><p>   dtmcconst int N; // Number of tasksmodule workers left : [0..N] init N; queue: [0..N] init 0; [enqueue] (queue &lt; left) -&gt; 0.5: (queue&#39; = queue + 1) + 0.5: true; [worker] (left &gt; 0 &amp; queue &gt; 0) -&gt; 0.5: (left&#39; = left - 1) &amp; (queue&#39; = queue - 1) + 0.5: true; [] (left = 0) -&gt; true; endmodule// see next sectionrewards &#34;wait_time&#34; [worker] queue &gt; 1: queue - 1;endrewardsrewards &#34;total_time&#34; [worker] left &gt; 0: 1;endrewards</p><p>Dtmcconst int N；//剩余任务模块工作线程数：[0..N]init N；队列：[0..N]init 0；[enQueue](队列&lt；左)-&gt；0.5：(队列&#39；=队列+1)+0.5：真；[工人](左&gt；0&amp；队列&gt；0)-&gt；0.5：(左&#39；=左-1)&amp；(队列&#。=队列-1)+0.5：真；[](左=0)-&gt；真；结束模块//查看下一节奖励&#34；等待时间&#34；[工人]队列&&gt;1：队列-1；结束奖励&#34；总计_时间&#34；[工人]左&&gt;0：1；结束奖励。</p><p>   First, let’s sanity check that we didn’t change the throughput. Since we’re only modeling time passing with  worker commands, our new model shouldn’t change the total time. Here’s what we get:</p><p>首先，让我们检查一下是否没有更改吞吐量。由于我们只对带有Worker命令的时间进行建模，因此我们的新模型应该不会更改总时间。以下是我们得到的信息：</p><p>  Exactly the same, good. But we’re here to model latency, too. Latency is how long a task waits in the queue before it gets processed. Since we don’t have a way of singling out individual tasks, we can instead look at how long all of the tasks wait in total, which is a correlated value.</p><p>一模一样，很好。但我们来这里也是为了模拟延迟。延迟是指任务在处理之前在队列中等待的时间。因为我们没有方法来挑选单个任务，所以我们可以查看所有任务总共等待了多长时间，这是一个关联值。</p><p> The reward function will be similar to  total_time, except instead of incrementing the reward by 1, we increment it by  queue - 1. We subtract one because if the queue is nonempty then one of the tasks in the queue is being processed.</p><p>奖励函数类似于TOTAL_TIME，不同之处在于不是将奖励递增1，而是递增Queue-1。我们减1是因为如果队列非空，则队列中的一个任务正在被处理。</p><p>        The growth is quadratic! If we have 10 tasks, they wait a total of 30 steps. If we have 100, they wait a total of over 1300 steps. A 10x increase in volume gives us a 40x increase in total latency!</p><p>增长速度是平方的！如果我们有10个任务，他们总共要等待30个步骤。如果我们有100个人，他们总共要等1300多步。音量增加10倍，总延迟增加40倍！</p><p>  This surprises a lot of people when they first see it. PRISM provides a simulator view that helps you step through a possible timeline and see what’s happening. Unfortunately it’s not well suited for static text so instead here’s an informal explanation.</p><p>当许多人第一次看到它时，这让他们大吃一惊。棱镜提供了一个模拟器视图，可以帮助您逐步查看可能的时间线并查看正在发生的情况。不幸的是，它不太适合静态文本，所以这里有一个非正式的解释。</p><p> Imagine we have 4 tasks that come in a random order, spaced one step apart. We also know that three of the tasks will take a one step to finish, while the last will take 5. We know for certain that we will finish all 4 tasks in eight steps, but the latency depends on the order they come in. The best case scenario is  1 1 1 5. We complete the first three tasks in the first three steps. When the large task comes, it’s the only task in the queue so doesn’t count for latency, and the total wait time is zero.</p><p>假设我们有4个随机顺序的任务，间隔一步。我们还知道其中三个任务需要一个步骤来完成，而最后一个任务需要五个步骤。我们可以肯定地知道，我们将在八个步骤中完成所有四个任务，但延迟取决于它们进入的顺序。最好的情况是1115。我们在前三步中完成前三个任务。当大型任务到来时，它是队列中唯一不计入延迟的任务，总等待时间为零。</p><p> The worst case scenario is  5 1 1 1. By step four, all four tasks are in the queue, but we still haven’t finished the first one. We only finish the first task at step five, by which point our wait time is already 9. Our final wait time is 12.</p><p>最坏的情况是511。到了第四步，所有四个任务都在队列中，但我们还没有完成第一个任务。我们只在第五步完成了第一项任务，到那时我们的等待时间已经是9次了。我们最后的等待时间是12次。</p><p> Now instead try  2 2 2 2. Same total time, but now the last task is only in the queue for 3 steps before we start processing it. Our wait time is instead 6.  3</p><p>现在改为尝试2 2 2。总时间相同，但现在最后一个任务在我们开始处理它之前只在队列中等待了3个步骤。我们的等待时间是6.3。</p><p> The latency spike then comes from two places: first, more tasks means a higher chance of a long task that jams the queue. Second, if the queue gets jammed there are more tasks that can pile up behind it, adding latency.</p><p>然后，延迟峰值来自两个方面：第一，任务越多，长任务堵塞队列的可能性就越大。其次，如果队列被阻塞，可能会有更多任务堆积在队列后面，从而增加延迟。</p><p>  It’s time to finally add in two workers. The obvious way is to just add another command, like this:</p><p>现在终于到了增加两名工人的时候了。显而易见的方法是只需添加另一个命令，如下所示：</p><p> [worker2] (left &gt; 0 &amp; queue &gt; 0) -&gt; 0.5: (left&#39; = left - 1) &amp; (queue&#39; = queue - 1) + 0.5: true;</p><p>[工作器2](Left&gt；0&amp；Queue&gt；0)-&gt；0.5：(Left&#39；=Left-1)&amp；(Queue&#39；=Queue-1)+0.5：TRUE；</p><p> But this doesn’t work. Either  worker will happen or  worker2 will happen, but they can’t both happen in the same step. They both modify  left and  queue, and each variable can only be modified once per step. We instead have to be clever. Since the two workers are independent, we “simulate” both at once as part of a single command. Consider the following table:</p><p>但这不管用。工人或工人2都会发生，但它们不可能同时发生。它们都修改了Left和Queue，每个变量每一步只能修改一次。相反，我们必须变得聪明起来。由于这两个工人是独立的，我们将同时“模拟”这两个工人作为单个命令的一部分。请考虑下表：</p><p>  Each combination is equally likely, so there’s a 50% of exactly one worker processing a task, a 25% chance of both workers processing a task, and a 25% chance of both failing. That leads to the following command:</p><p>每种组合的可能性都是相等的，所以恰好有50%的人在处理一项任务，25%的可能性两个人都在处理一项任务，两个人都失败的可能性为25%。这将导致以下命令：</p><p> [worker] (left &gt; 1 &amp; queue &gt; 1) -&gt; 0.25: (left&#39; = left - 2) &amp; (queue&#39; = queue - 2) + 0.5: (left&#39; = left - 1) &amp; (queue&#39; = queue - 1) + 0.25: true;</p><p>[Worker](Left&gt；1&amp；Queue&gt；1)-&gt；0.25：(Left&#39；=Left-2)&amp；(Queue&#39；=Queue-2)+0.5：(Left&#39；=Left-1)&amp；(Queue&#39；=Queue-1)+0.25：真；</p><p> This only works if there are at least two tasks in the queue. Otherwise, one worker has to idle while the other processes it. If there’s only one task in the queue then we pretend we only have one worker.</p><p>只有当队列中至少有两个任务时，这才起作用。否则，一个工人不得不空闲，而另一个工人在处理它。如果队列中只有一个任务，那么我们就假装只有一个工人。</p><p> [worker] (left &gt;= 1 &amp; queue = 1) -&gt; 0.5: (left&#39; = left - 1) &amp; (queue&#39; = queue - 1) + 0.5: true;</p><p>[Worker](Left&gt；=1&amp；Queue=1)-&gt；0.5：(Left&#39；=Left-1)&amp；(Queue&#39；=Queue-1)+0.5：TRUE；</p><p> We also need to change our reward function. We only consider tasks after the first two in the queue to be waiting.</p><p>我们还需要改变我们的奖励功能。我们只将队列中前两个任务之后的任务视为正在等待。</p><p>   dtmcconst int N; // Number of tasksmodule workers left : [0..N] init N; queue: [0..N] init 0; [enqueue] (queue &lt; left) -&gt; 0.5: (queue&#39; = queue + 1) + 0.5: true; [worker] (left &gt;= 1 &amp; queue = 1) -&gt; 0.5: (left&#39; = left - 1) &amp; (queue&#39; = queue - 1) + 0.5: true; [worker] (left &gt; 1 &amp; queue &gt; 1) -&gt; 0.25: (left&#39; = left - 2) &amp; (queue&#39; = queue - 2) + 0.5: (left&#39; = left - 1) &amp; (queue&#39; = queue - 1) + 0.25: true; [] (left = 0) -&gt; true; endmodulerewards &#34;wait_time&#34; [worker] queue &gt; 2: queue - 2;endrewardsrewards &#34;total_time&#34; [worker] left &gt; 0: 1;endrewards</p><p>Dtmcconst int N；//剩余任务模块工作线程数：[0..N]init N；Queue：[0..N]init 0；[enQueue](Queue&lt；Left)-&gt；0.5：(Queue&#39；=Queue+1)+0.5：TRUE；[Worker](Left&gt；=1&amp；Queue=1)-&gt；0.5：(Left&#39；=Left-1)&amp；(Queue&#39；=Queue-1)+0.5：TRUE；[Worker](Left&gt；1&amp；Queue&gt；1)-&gt；0.25：(Left&#39；=Left-2)&amp；(Queue&#39；=Queue-2)+0.5：(Left&#39；=Queue-1)&amp；(Queue&#39；=Queue-1)+0.25：TRUE；[](Left=0)-&gt；TRUE；End Moderewards&#34；WAIT_TIME&#34；[Worker]队列&&gt;2：队列-2；End_rewards&#34；Total_Time&#34；[Worker]Left&gt；0：1；End Rewards。</p><p>       You’d think it’d take half the total time to complete all tasks, but it’s actually closer to 2/3rds. We can only use both workers when the queue length is at least 2, so for most of each run we’re wasting a worker. If we saturated the queue by making the inbound rate much higher then the total time would converge to half the total time for one worker.</p><p>你可能认为完成所有任务需要一半的时间，但实际上接近2/3。只有当队列长度至少为2时，我们才能同时使用这两个工作进程，因此在每次运行的大部分时间里，我们都浪费了一个工作进程。如果我们通过使入站速率更高来使队列饱和，那么总时间将收敛到一个工作者总时间的一半。</p><p>     For one worker the wait time was just about quadratic, while this is sublinear. The queue only jams if  both workers stall out, which is a lot less likely. Going back to our  5 1 1 1 case, by the time the first worker has finished the first task the second worker has already processed the other three.</p><p>对于一名员工来说，等待时间几乎是二次曲线，而这是次线性的。只有当两名员工都熄火时，排队才会拥堵，而这种情况发生的可能性要小得多。回到我们的511案例，当第一个工人完成第一个任务时，第二个工人已经处理了其他三个任务。</p><p>  Our model only covers a small part of the state space. We hardcoded the inbound probability, the outbound, and the number of workers. In particular I don’t like how we used the same probability for enqueuing and dequeuing. For all we know that leads to pathological results. A good spec should help us explore different parameters without us having to rewrite it.</p><p>我们的模型只覆盖了状态空间的一小部分。我们对入站概率、出站概率和工作人员数量进行了硬编码。特别是，我不喜欢我们在排队和出队时使用相同的概率。据我们所知，这会导致病理结果。一个好的规范应该可以帮助我们探索不同的参数，而不必重写它。</p><p> The first change is the simplest: changing the inbound rate. PRISM lets us use expressions in guard clauses, so by adding a  P_request constant we can vary in the inbound probability per step. All update probabilities must sum to 1, which is easy here.</p><p>第一个更改是最简单的：更改入站费率。PRISM允许我们在保护子句中使用表达式，因此通过添加一个P_REQUEST常量，我们可以改变每一步的入站概率。所有更新概率的总和必须为1，这在这里很简单。</p><p> const double P_request; // in [0, 1]// ...[enqueue] (queue &lt; left &amp; left &lt;= N) -&gt; P_request: (queue&#39; = queue + 1) + (1 - P_request): true;</p><p>Const Double P_Request；//in[0，1]//...[EnQueue](Queue&lt；Left&amp；Left&lt；=N)-&gt；P_Request：(Queue&#39；=Queue+1)+(1-P_Request)：TRUE；</p><p> Changing the task processing rate is more complicated. Let’s say the probability of a worker processing a task is P. With two workers, there’s four possibilities:</p><p>改变任务处理速率更为复杂。假设一个工人处理一项任务的概率是P。如果有两个工人，有四种可能性：</p><p>  You can check that all the possibilities add up to 1. If we combine terms and simplify, we get</p><p>你可以检查所有的可能性加起来是否为1。</p><p> 1 * p²(1-p)⁰: queue&#39; = queue - 22 * p¹(1-p)¹: queue&#39; = queue - 11 * p⁰(1-p)²: queue&#39; = queue - 0</p><p>1*p²(1-p)⁰：QUEUE&#39；=QUEUE-22*p？(1-p)？：QUEUE&#39；=QUEUE-11*p⁰(1-P)²：QUEUE&#39；=QUEUE-0。</p><p> This might remind you of Algebra 1:  (a + b)² = a² + 2ab + b². With a bit of combinatorics we can prove it’s the same. This is just the binomial expansion!  4 The corresponding probabilities for 3 workers would be:</p><p>这可能会让您想起代数1：(a+b)²=a²+2ab+b²。用一点组合学的知识，我们可以证明它们是一样的。这只是二项展开！4 3个工人的相应概率是：</p><p>  Not only can we use this to generalize the task processing rate, we can use this to scale up to an arbitrary number of workers. Unfortunately, that’s way too tedious to do by hand. So where’s what I did instead:</p><p>我们不仅可以用它来概括任务处理速度，还可以用它来扩展到任意数量的工作人员。不幸的是，手工操作太单调乏味了。那么我做的是什么呢？</p><p>  And then I made a Python script write it for me. You can get the template and the script  in this gist.</p><p>然后我让一个Python脚本为我写了它。您可以在这个要点中获得模板和脚本。</p><p> dtmcconst int N; // Max Tasksconst double P_request; // in [0, 1]const double P_worker; // in [0, 1]const int K; // [1, ]module queues left : [0..N] init N; queue: [0..N] init 0;[worker] (left &gt;= 1 &amp; ((queue &gt;= 1 &amp; K = 1) | (queue = 1 &amp; K &gt; 1))) -&gt; 1*pow(P_worker, 0)*pow(1-P_worker,1): (left&#39; = left - 0) &amp; (queue&#39; = queue - 0) + 1*pow(P_worker, 1)*pow(1-P_worker,0): (left&#39; = left - 1) &amp; (queue&#39; = queue - 1);[worker] (left &gt;= 2 &amp; ((queue &gt;= 2 &amp; K = 2) | (queue = 2 &amp; K &gt; 2))) -&gt; 1*pow(P_worker, 0)*pow(1-P_worker,2): (left&#39; = left - 0) &amp; (queue&#39; = queue - 0) + 2*pow(P_worker, 1)*pow(1-P_worker,1): (left&#39; = left - 1) &amp; (queue&#39; = queue - 1) + 1*pow(P_worker, 2)*pow(1-P_worker,0): (left&#39; = left - 2) &amp; (queue&#39; = queue - 2);[worker] (left &gt;= 3 &amp; ((queue &gt;= 3 &amp; K = 3) | (queue = 3 &amp; K &gt; 3))) -&gt; 1*pow(P_worker, 0)*pow(1-P_worker,3): (left&#39; = left - 0) &amp; (queue&#39; = queue - 0) + 3*pow(P_worker, 1)*pow(1-P_worker,2): (left&#39; = left - 1) &amp; (queue&#39; = queue - 1) + 3*pow(P_worker, 2)*pow(1-P_worker,1): (left&#39; = left - 2) &amp; (queue&#39; = queue - 2) + 1*pow(P_worker, 3)*pow(1-P_worker,0): (left&#39; = left - 3) &amp; (queue&#39; = queue - 3);[worker] (left &gt;= 4 &amp; ((queue &gt;= 4 &amp; K = 4) | (queue = 4 &amp; K &gt; 4))) -&gt; 1*pow(P_worker, 0)*pow(1-P_worker,4): (left&#39; = left - 0) &amp; (queue&#39; = queue - 0) + 4*pow(P_worker, 1)*pow(1-P_worker,3): (left&#39; = left - 1) &amp; (queue&#39; = queue - 1) + 6*pow(P_worker, 2)*pow(1-P_worker,2): (left&#39; = left - 2) &amp; (queue&#39; = queue - 2) + 4*pow(P_worker, 3)*pow(1-P_worker,1): (left&#39; = left - 3) &amp; (queue&#39; = queue - 3) + 1*pow(P_worker, 4)*pow(1-P_worker,0): (left&#39; = left - 4) &amp; (queue&#39; = queue - 4); [] (left = 0) -&gt; true; [enqueue] (queue &lt; left &amp; left &lt;= N) -&gt; P_request: (queue&#39; = queue + 1) + (1 - P_request): true;endmodulerewards &#34;wait_time&#34; [worker] queue &gt; K: queue - K;endrewardsrewards &#34;total_time&#34; [worker] left &gt; 0: 1;endrewards</p><p>Dtmcconst int N；//Max Tasksconst Double P_Request；//In[0，1]Const Double P_Worker；//In[0，1]Const int K；//[1，]模块队列左侧：[0..N]init N；Queue：[0..N]init 0；[Worker](Left&gt；=1&amp；((Queue&gt；=1&amp；K=1)|(Queue=1&amp；K。1*POW(P_Worker，0)*POW(1-P_Worker，1)：(Left&#39；=Left-0)&amp；(Queue&#39；=Queue-0)+1*Power(P_Worker，1)*Power(1-P_Worker，0)：(Left&#39；=Left-1)&amp；(Queue&#39；=Queue-1)；[Worker](Left&&gt;=2&amp；(Queue&&gt;。K=2)|(Queue=2&amp；K&&gt;2))-&gt;1*power(P_Worker，0)*power(1-P_Worker，2)：(Left&#39；=Left-0)&amp；(Queue&#39；=Queue-0)+2*Power(P_Worker，1)*Power(1-P_Worker，1)：(Left&#39；=Left-1)&amp；(Queue&#39；=Queue&39；=队列-1)+1*POW(P_Worker，2)*POW(1-P_Worker，0)：(Left&#39；=Left-2)&amp；(Queue&#39；=Queue-2)；[Worker](Left&&gt;；=3&amp；K=3)|(Queue=3&amp；K&&gt;3))-&&gt;。1*power(P_Worker，0)*power(1-P_Worker，3)：(Left&#39；=Left-0)&amp；(队列&#39；=队列-0)+3*power(P_Worker，1)*power(1-P_Worker，2)：(Left&#39；=Left-1)&amp；(队列#39；=队列-1)+3*power(P_Worker，2)*power(1-P_Worker，2)。=Left-2)&amp；(队列&#39；=队列-2)+1*power(P_Worker，3)*power(1-P_Worker，0)：(Left&#39；=Left-3)&amp；(队列&#39；=队列-3)；[Worker](Left&&gt;=4&amp；K=4)|(Queue=4&amp；K&&gt;4))-&G。1*power(P_Worker，0)*power(1-P_Worker，4)：(Left&#39；=Left-0)&amp；(队列&#39；=队列-0)+4*power(P_Worker，1)*power(1-P_Worker，3)：(Left&#39；=Left-1)&amp；(队列#39；=队列-1)+6*power(P_Worker，2)*power(1-P_Worker，3)。=Left-2)&amp；(队列#39；=队列-2)+4*power(P_Worker，3)*power(1-P_Worker，1)：(Left&#39；=Left-3)&amp；(队列&#39；=队列-3)+1*Power(P_Worker，4)*power(1-P_Worker，0)：(Left&#39；=Left-4)&amp；(Queue&#39；=Queue-4)；[](Left=0)-&gt；true；[enQueue](Queue&lt；Left&amp；Left&lt；=N)-&gt；P_Request：(Queue&#39；=Queue+1)+(1-P_Request)：TRUE；End模块转发&#34；Wait_Time&#34；[Worker]队列&&gt;K：Queue-K；End rewardsrewards&#34；Total_Time&#34；[Worker]Left&。</p><p>  I snuck in one more change there: I modified the guard clause to use a new constant  K. I didn’t like how I hardcoded the number of workers we were using, so now  K is the number of workers we have. That way if you want to play with it yourself you don’t have to modify the spec to switch between 1 or 2 (or 3 or 4) workers.</p><p>我偷偷地加入了另一个更改：我修改了Guard子句，使用了一个新的常量K。我不喜欢我硬编码我们使用的工人数量的方式，所以现在K就是我们拥有的工人数量。这样，如果你想自己玩它，你就不需要修改规格来在1或2(或3或4)个工人之间切换。</p><p>  This was a simple model of task queues. We didn’t cover priority, error handling, multiple queues, etc. Nonetheless, the spec was good enough to show how nonlinear latency is and how adding more workers can have a dramatic effect.</p><p>这是一个简单的任务队列模型。我们没有涵盖优先级、错误处理、多个队列等。尽管如此，该规范还是很好地展示了延迟的非线性，以及添加更多工作线程会产生多么显著的影响。</p><p> If you’re interested in PRISM, you can download it  here. I’m  happy to answer simple questions or provide tips if needed. If you’re interested in the broader mathematical theory of task queues, you’ll want to look into   queueing theory.</p><p>如果你对PRISM感兴趣，你可以在这里下载。如果需要，我很乐意回答简单的问题或提供建议。如果您对任务队列的更广泛的数学理论感兴趣，那么您将希望研究排队理论。</p><p> I shared the first draft of this essay on my  newsletter. If you like my writing, why not subscribe?</p><p>我在我的时事通讯上分享了这篇文章的初稿。如果你喜欢我的作品，为什么不订阅呢？</p><p> Here we are using it as cost, not reward. But since these are operationally the same thing PRISM only has syntax for reward functions.    [return]</p><p>在这里，我们把它当做成本，而不是奖励。但由于它们在操作上是相同的，所以PRISM只有奖励函数的语法。[返回]。</p><p> “Wait, how can it be the same inbound/outbound rate if the step is an abstract model of time?” Good question. In this case I set up the model in a precise way to make sure this works. In practice you’d write your PRISM spec in a “generic” way that’s a little tougher to read but easier to design correctly. I used the “more elegant” spec to keep the focus on task queues.   [return]</p><p>等等，如果这个步骤是时间的抽象模型，它怎么可能是相同的进出站速率呢？问得好。在本例中，我以一种精确的方式建立了模型，以确保它能正常工作。在实践中，您需要以一种“通用”的方式编写您的PRISM规范，这种方式更难阅读，但更容易正确设计。我使用了“更优雅”的规范来保持对任务队列的关注。[返回]</p><p> The numbers are slightly different if we make the reward  (queue) instead of  (queue-1), but the trend is the same.   [return]</p><p>如果我们进行奖励(队列)而不是(队列-1)，数字略有不同，但趋势是相同的。[返回]。</p><p> Given N workers, there are  N choose K different ways for exactly K workers to process a task in a given tick, and each case has a probability of  p^K*(1-p)^(N-K).    [return]</p><p>给定N个工人，有N个选择K种不同的方式让K个工人在给定的时间内处理一个任务，并且每种情况的概率为p^K*(1-p)^(N-K)。[返回]</p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://www.hillelwayne.com/post/queueing-prism/">https://www.hillelwayne.com/post/queueing-prism/</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/工人/">#工人</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/workers/">#workers</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/任务/">#任务</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/美国/">#美国</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/谷歌/">#谷歌</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/linux/">#linux</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/程序/">#程序</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy; 2020 diglog.com </div></div></body></html>