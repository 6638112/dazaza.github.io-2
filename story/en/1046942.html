<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>如何使用WebRTC和FFmpeg流媒体，以及为什么这是一个坏主意 How to stream media using WebRTC and FFmpeg, and why it's a bad idea</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">How to stream media using WebRTC and FFmpeg, and why it's a bad idea<br/>如何使用WebRTC和FFmpeg流媒体，以及为什么这是一个坏主意 </h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2021-01-31 02:13:53</div><div class="page_narrow text-break page_content"><p>Streaming media. specifically video, is a fickle beast. This will be a short post, but it will cover everything you need to know to stream media using FFmpeg to WebRTC clients. This technique has many applications, such as streaming synchronized videos to users. This post also covers some fundamental issues with FFmpeg that limits its utility for media streaming.</p><p>流媒体。特别是视频，是一个善变的野兽。这是一篇简短的文章，但它将涵盖您需要了解的所有使用FFmpeg流媒体到WebRTC客户端的知识。该技术具有许多应用程序，例如将同步视频流式传输到用户。这篇文章还介绍了FFmpeg的一些基本问题，这些问题限制了FFmpeg在媒体流中的实用性。</p><p>    These flags set the log level to info, generate pts if they’re missing, and sets up the protocols we can use. Next we need to provide the input to FFmpeg.</p><p>    这些标志将日志级别设置为info，如果缺少日志则生成pt，并设置我们可以使用的协议。接下来，我们需要将输入提供给FFmpeg。</p><p>  In this example, a file name  in.mp4 is used, but a http(s) URL could also be used. This command starts playback at the beginning of the input file. If you want to start playback in the middle of the input file, then you can add the  -ss &lt;time in secs&gt; flag  before  -i.</p><p>  在此示例中，使用文件名in.mp4，但也可以使用http（s）URL。此命令从输入文件的开头开始播放。如果要在输入文件的中间开始播放，则可以添加-ss＆lt; time in secs＆gt;。在-i之前标记。</p><p>  Now the video needs to be converted to an appropriate format for streaming. The format is specific to the application, but common codecs are H264, VP8, and VP9. This example uses H264 due to its ubiquitous support.</p><p>  现在，需要将视频转换为适当的格式以进行流式传输。该格式特定于应用程序，但是常见的编解码器是H264，VP8和VP9。由于其无处不在的支持，此示例使用H264。</p><p> -vf realtime,scale=w=min(iw\,1280):h=-2 \-map 0:v:0 \-c:v libx264 \-threads 3 \-profile:v baseline \-level:v 3.1 \-pix_fmt yuv420p \-tune zerolatency \-minrate 500K \-maxrate 1.3M \-bufsize 500K \-force_key_frames expr:gte(t,n_forced*4) \-bsv:v h264_metadata=level=3.1</p><p> -vf realtime，scale = w = min（iw \，1280）：h = -2 \ -map 0：v：0 \ -c：v libx264 \-线程3 \ -profile：v基线\ -level：v 3.1 \ -pix_fmt yuv420p \-调整零延迟\-最小500K \-最大1.3M \ -bufsize 500K \ -force_key_frames expr：gte（t，n_forced * 4）\ -bsv：v h264_metadata = level = 3.1</p><p> -vf specifies the video filters to apply. Here, two filters are applied. The first is  realtime, which causes playback to happen in real time, which is necessary for streaming. This filter is similar to the  -re flag, but works much better with the start time flag ( -ss). The second filter scales the video width to a maximum of 1280 pixels while maintaining the aspect ratio. This is important to keep the bitrate appropriate for real time streaming.</p><p> -vf指定要应用的视频过滤器。在这里，应用了两个过滤器。第一个是实时的，它导致回放实时发生，这对于流式传输是必需的。该过滤器与-re标志类似，但与开始时间标志（-ss）相比效果更好。第二个滤镜将视频宽度缩放到最大1280像素，同时保持宽高比。这对于保持适用于实时流的比特率很重要。</p><p> Another important parameter is the  -threads 3 flag. FFmpeg will use many threads by the default. Normally, this is good because it produces the final result as fast as possible. For real time encoding, however, using a large number of threads has some overhead that can slow down real time output. Using many threads is also a bad idea if you’re running multiple instances of FFmpeg concurrently.</p><p> 另一个重要的参数是-threads 3标志。 FFmpeg默认情况下将使用许多线程。通常，这很好，因为它会尽快产生最终结果。但是，对于实时编码，使用大量线程会产生一些开销，从而降低实时输出的速度。如果同时运行多个FFmpeg实例，则使用多个线程也是一个坏主意。 </p><p> The next two parametrs  -profile:v and  -level:v specify the profile and level to use for the encoding. These are specific to H264. WebRTC clients can only decode certain profiles and levels, so these need to match the specific configuration of the application. These roughly correspond to the profile-level-id of  42e01f.</p><p>接下来的两个参数-profile：v和-level：v指定用于编码的配置文件和级别。这些特定于H264。 WebRTC客户端只能解码某些配置文件和级别，因此它们需要与应用程序的特定配置相匹配。这些大致对应于42e01f的配置文件级别ID。</p><p> The pixel format is set to  yuv420p using the  -pix_fmt flag. This is required as this is the only pixel format supported by WebRTC.  -tune zerolatency tunes the encoder for low latency streaming.</p><p> 使用-pix_fmt标志将像素格式设置为yuv420p。这是必需的，因为这是WebRTC支持的唯一像素格式。 -tune zerolatency调整编码器以实现低延迟流传输。</p><p> Next up are the bitrate parameters, which reveal the shortcomings of using FFmpeg for media streaming. When streaming media, the bitrate should be as low as possible while maintaining the desired quality. This ensures all clients can consume the video in real time. Omitting the  -minrate parameter can cause FFmpeg to produce output with an unnecessarily high bitrate. Setting the  -maxrate is equally important. A DSL connection can only pull down around 2 Mbps. In order for users to watch the video, they must be able to download it in real time, so the maximum bitrate has to be lower than the slowest connection among your users. Another consideration is that the streaming video might not be the only bandwidth consuming task on the user’s network.</p><p> 接下来是比特率参数，这些参数揭示了使用FFmpeg进行媒体流传输的缺点。流媒体时，比特率应尽可能低，同时保持所需的质量。这样可以确保所有客户端都可以实时播放视频。省略-minrate参数可能导致FFmpeg产生不必要的高比特率输出。设置-maxrate同样重要。 DSL连接只能拉低2 Mbps。为了使用户能够观看视频，他们必须能够实时下载视频，因此最大比特率必须低于用户之间最慢的连接速度。另一个要考虑的因素是，流视频可能不是用户网络上唯一消耗带宽的任务。</p><p> And finally, we encounter a large issue without a good solution. In encoded videos, a key frame is a frame in the video that contains all the visual information needed to render itself without any additional metadata. These are much larger than normal frames, and contribute greatly to the bitrate. Ideally, there would be as a few keyframes as possible. However, when a new user starts consuming a stream, they need at least one keyframe to view the video. WebRTC solves this problem using the RTP Control Protocl (RTCP). When a new user consumes a stream, they send a Full Intra Request (FIR) to the producer. When a producer receives this request, they insert a keyframe into the stream. This keeps the bitrate low while ensuring all the users can view the stream.  FFmpeg does not support RTCP. This means that the default FFmpeg settings will produce output that won’t be viewable if consumed mid-stream, at least until a key frame is received. Therefore, the parameter  -force_key_frames expr:gte(t,n_forced*4) is needed, which produces a key frame every 4 seconds.</p><p> 最后，我们遇到了一个大问题，没有一个好的解决方案。在编码视频中，关键帧是视频中的帧，其中包含呈现自身所需的所有视觉信息，而没有任何其他元数据。这些比普通帧大得多，并且对比特率有很大贡献。理想情况下，将有尽可能少的关键帧。但是，当新用户开始使用流时，他们需要至少一个关键帧才能观看​​视频。 WebRTC使用RTP控制协议（RTCP）解决了此问题。当新用户使用流时，他们向生产者发送完整的内部请求（FIR）。当生产者收到此请求时，他们将关键帧插入流中。这样可以保持较低的比特率，同时确保所有用户都可以观看流。 FFmpeg不支持RTCP。这意味着默认的FFmpeg设置将产生中途消费的输出，至少在收到关键帧之前无法看到。因此，需要参数-force_key_frames expr：gte（t，n_forced * 4），该参数每4秒生成一个关键帧。</p><p>    The main thing to note here is that the  arealtime filter is used, which is similar to the  realtime filter, but for audio.</p><p>    这里要注意的主要事情是使用了arealtime过滤器，它类似于实时过滤器，但用于音频。</p><p>  The output can be piped to an RTP endpoint using the  tee psuedomuxer. Unfortunately, FFmpeg does not support multiplexing over RTP, so you’ll need two separate RTP endpoints, one for the video stream and one for the audio stream.</p><p>  可以使用tee psuedomuxer将输出通过管道传输到RTP端点。不幸的是，FFmpeg不支持RTP上的多路复用，因此您将需要两个单独的RTP端点，一个用于视频流，一个用于音频流。</p><p>   &gt; ffmpeg \ -v info \ -fflags +genpts \ -protocol_whitelist pipe,tls,file,http,https,tcp,rtp \ -i in.mp4 -vf realtime,scale=w=min(iw\,1280):h=-2 \ -map 0:v:0 \ -c:v libx264 \ -threads 3 \ -profile:v baseline \ -level:v 3.1 \ -pix_fmt yuv420p \ -tune zerolatency \ -minrate 500K \ -maxrate 1.3M \ -bufsize 500K \ -force_key_frames expr:gte(t,n_forced*4) \ -bsv:v h264_metadata=level=3.1 \ -af arealtime \ -map 0:a:0 \ -c:a libopus \ -ab 128k \ -ac 2 \ -ar 48000 \ -f tee \ [select=a:f=rtp:ssrc=1111:payload_type=&lt;payload_type&gt;]rtp://&lt;ip&gt;:&lt;port&gt;?rtcpport=&lt;rtcpport&gt;|[select=v:f=rtp:ssrc=2222:payload_type=&lt;payload_type&gt;]rtp://&lt;ip&gt;:&lt;port&gt;?rtcpport=&lt;rtcpport&gt;</p><p>   ＆gt; ffmpeg \ -v info \ -fflags + genpts \ -protocol_whitelist pipe，tls，file，http，https，tcp，rtp \ -i in.mp4 -vf realtime，scale = w = min（iw \，1280）：h = -2 \ -map 0：v：0 \ -c：v libx264 \-线程3 \ -profile：v基线\ -level：v 3.1 \ -pix_fmt yuv420p \-调谐零延迟\-最小500K \-最大1.3M \ -bufsize 500K \ -force_key_frames expr：gte（t，n_forced * 4）\ -bsv：v h264_metadata = level = 3.1 \ -af arealtime \ -map 0：a：0 \ -c：a libopus \ -ab 128k \- ac 2 \ -ar 48000 \ -f tee \ [select = a：f = rtp：ssrc = 1111：payload_type =＆lt; payload_type＆gt;] rtp：//＆lt; ip＆gt;：＆lt; port＆gt;？rtcpport =＆lt; rtcpport＆gt ; | [select = v：f = rtp：ssrc = 2222：payload_type =＆lt; payload_type＆gt;] rtp：//＆lt; ip＆gt;：＆lt; port＆gt;？rtcpport =＆lt; rtcpport＆gt; </p><p>  Unfortunately, there isn’t a good solution to the keyframe / bitrate / RTCP issue when using FFmpeg. Gstreamer, a similar media encoding utility, does support RTCP, and I’ll cover how to use that in a later post.</p><p>不幸的是，使用FFmpeg时，关键帧/比特率/ RTCP问题没有很好的解决方案。 Gstreamer（一种类似的媒体编码实用程序）确实支持RTCP，我将在以后的文章中介绍如何使用它。 </p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://blog.maxwellgale.com/2021/01/30/streaming-video-over-webrtc-using-ffmpeg/">https://blog.maxwellgale.com/2021/01/30/streaming-video-over-webrtc-using-ffmpeg/</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/webrtc/">#webrtc</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/media/">#media</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/分享/">#分享</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy; 2020 diglog.com </div></div></body></html>