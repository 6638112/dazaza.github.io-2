<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>数据分发和监控Data Distribution Shifts and Monitoring</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">Data Distribution Shifts and Monitoring<br/>数据分发和监控</h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2022-02-17 00:53:57</div><div class="page_narrow text-break page_content"><p>Note:  This note is a work-in-progress, created for the course  CS 329S: Machine Learning Systems Design  (Stanford, 2022). For the fully developed text, see  the book   Designing Machine Learning Systems (Chip Huyen, O’Reilly 2022).  Slides (much shorter 😁).  Original Google Docs version.</p><p>注：本说明是为课程CS 329S：机器学习系统设计（斯坦福大学，2022年）编写的正在进行中的工作。对于充分开发的文本，请参阅《设计机器学习系统》（Chip Huyen，O’Reilly 2022）一书。幻灯片（短得多）😁).  谷歌文档的原始版本。</p><p> Let’s start the note with a story I was told by an executive that many readers might be able to relate to. About two years ago, his company hired a consulting firm to develop an ML model to help them predict how many of each grocery item they’d need next week, so they could restock the items accordingly. The consulting firm took six months to develop the model. When the consulting firm handed the model over, his company deployed it and was very happy with its performance. They could finally boast to their investors that they were an AI-powered company.</p><p>让我们从一位高管给我讲的一个故事开始，许多读者可能都能理解这个故事。大约两年前，他的公司聘请了一家咨询公司开发了一个ML模型，以帮助他们预测下周他们需要多少种杂货，这样他们就可以相应地重新进货。这家咨询公司花了六个月的时间开发这个模型。当咨询公司交出模型时，他的公司部署了它，并对其性能非常满意。他们终于可以向投资者吹嘘自己是一家人工智能驱动的公司。</p><p> However, a year later, their numbers went down. The demand for some items was consistently being overestimated, which caused the extra items to expire. At the same time, the demand for some items was consistently being underestimated, leading to lost sales. Initially, his inventory team manually changed the model’s predictions to correct the patterns they noticed, but eventually, the model’s predictions had become so bad that they could no longer use it. They had three options: pay the same consulting firm an obscene amount of money to update the model, pay another consulting firm even more money because this firm would need time to get up to speed, or hire an in-house team to maintain the model onwards.</p><p>然而，一年后，他们的人数下降了。一些商品的需求一直被高估，这导致额外的商品过期。与此同时，一些商品的需求一直被低估，导致销量下降。最初，他的库存团队手动更改模型的预测，以纠正他们注意到的模式，但最终，模型的预测变得如此糟糕，以至于他们无法再使用它。他们有三个选择：付给同一家咨询公司一大笔钱来更新模型，付给另一家咨询公司更多的钱，因为这家公司需要时间来跟上进度，或者雇佣一个内部团队来维护模型。</p><p> His company learned the hard way an important lesson that the rest of the industry is also discovering: deploying a model isn’t the end of the process. A model’s performance degrades over time in production. Once a model has been deployed, we still have to continually monitor its performance to detect issues as well as deploy updates to fix these issues.</p><p>他的公司艰难地吸取了一个重要的教训，业内其他人也发现了这一点：部署模型并不是过程的终点。模型在生产中的性能会随着时间的推移而下降。一旦部署了一个模型，我们仍然必须持续监控其性能以检测问题，并部署更新以修复这些问题。</p><p>      Tasks with natural ground truth labels are tasks where the model’s predictions can be automatically evaluated or partially evaluated by the system. An example is the model that estimates time of arrival on Google Maps. By the end of a trip, Google Maps knows how long the trip actually took, and thus can evaluate the accuracy of the predicted time of arrival.</p><p>带有自然地面真值标签的任务是系统可以自动评估或部分评估模型预测的任务。谷歌地图上估计到达时间的模型就是一个例子。在旅行结束时，谷歌地图知道旅行实际花费了多长时间，因此可以评估预测到达时间的准确性。</p><p> Natural labels are ideal for evaluating a model’s performance. However, even if your task doesn’t inherently have natural labels, it’s possible to set up your system in a way that allows you to collect some feedback on your model. For example, if you’re building a translation system like Google Translate, you can have the option for the community to submit alternative translations for bad translations. Newsfeed ranking is not a task with inherent labels, but by adding the like button and other reactions to each newsfeed item, Facebook is able to collect feedback on their ranking algorithm.</p><p>自然标签是评估模型性能的理想选择。然而，即使你的任务本身没有自然的标签，也可以通过某种方式设置你的系统，让你可以收集一些关于模型的反馈。例如，如果你正在构建一个像Google Translate这样的翻译系统，你可以选择让社区为糟糕的翻译提交替代翻译。新闻源排名不是一项带有固有标签的任务，但通过在每个新闻源项目中添加like按钮和其他反应，Facebook能够收集关于其排名算法的反馈。</p><p> For tasks with natural ground truth labels, the time it takes from when a prediction is served until when the feedback on it is provided is the feedback loop length.</p><p>对于具有自然地面真值标签的任务，从提供预测到提供反馈所需的时间是反馈回路长度。</p><p> Tasks with short feedback loops are tasks where ground truth labels are generally available within minutes. The canonical example of this type of task is recommender systems. The goal of a recommender system is to recommend users items they would like. Whether a user clicks on the recommended item or not can be seen as the feedback for that recommendation. A recommendation that gets clicked on can be presumed to be a good recommendation (i.e. the label is POSITIVE) and a recommendation that doesn’t get clicked on can be presumed to be bad (i.e. the label is NEGATIVE). Many tasks can be framed as recommendation tasks. For example, you can frame the task of predicting ads’ click-through rates as recommending the most relevant ads to users based on their activity histories and profiles.</p><p>具有短反馈回路的任务通常在几分钟内就可以获得地面真相标签。这类任务的典型例子是推荐系统。推荐系统的目标是向用户推荐他们想要的项目。无论用户是否点击了推荐项目，都可以被视为对该推荐的反馈。被点击的推荐可以被认为是好的推荐（即标签是肯定的），而没有被点击的推荐可以被认为是坏的推荐（即标签是否定的）。许多任务可以被定义为推荐任务。例如，你可以将预测广告点击率的任务设定为根据用户的活动历史和个人资料向用户推荐最相关的广告。</p><p> However, not all recommender systems have short feedback loops. Depending on the nature of the item to be recommended, the delay until labels can be seconds to hours, and in some extreme cases, days or weeks. If the recommended items are subreddits to subscribe to on Reddit, people to follow on Twitter, videos to watch next on Tiktok, etc., the time between when the item is recommended until it’s clicked on, if it’s clicked on at all, is seconds. If you work with longer content types like blog posts or articles or YouTube videos, it can be minutes, even hours. However, if you build a system to recommend clothes for users like the one Stitch Fix has, you wouldn’t get feedback until users have received the items and tried them on, which could be weeks later.</p><p>然而，并不是所有的推荐系统都有短反馈回路。根据所推荐物品的性质，标签的延迟时间可以是几秒到几小时，在某些极端情况下，可以是几天或几周。如果推荐的项目是要在Reddit上订阅的SubReddit、要在Twitter上关注的人、要在Tiktok上观看的下一个视频等，那么从推荐项目到点击它（如果点击了它）之间的时间是秒。如果你处理较长的内容类型，如博客文章、文章或YouTube视频，可能需要几分钟甚至几小时。然而，如果你建立了一个系统，像one Stitch Fix那样为用户推荐衣服，那么在用户收到这些衣服并试穿之前，你不会得到反馈，这可能需要几周后。</p><p> Unless next to each recommended item, there’s a prompt that says: “ Do you like this recommendation? Yes / No”, recommender systems don’t have explicit negative labels. Even if you add that prompt, there’s no guarantee that users will respond to it. Typically, a recommendation is presumed to be bad if there’s a lack of positive feedback. After a certain time window, if there is no click, the label is presumed to be negative. Choosing the right window length requires thorough consideration, as it involves the speed and accuracy tradeoff. A short window length means that you can capture labels faster, which allows you to use these labels for monitoring and continual learning. However, a short window length also means that you might prematurely label an item as no click before it’s being clicked on.</p><p>除非每个推荐项目旁边都有一个提示：“你喜欢这个推荐吗？是/否”，否则推荐系统没有明确的负面标签。即使你添加了这个提示，也不能保证用户会响应。通常，如果缺乏正面反馈，建议被认为是不好的。在特定的时间窗口后，如果没有点击，则假定标签为负片。选择正确的窗口长度需要仔细考虑，因为它涉及速度和精度的权衡。短窗口长度意味着您可以更快地捕获标签，这允许您使用这些标签进行监控和持续学习。然而，短窗口长度也意味着您可能会过早地将某个项目标记为“在被单击之前不单击”。</p><p> No matter how long you set your window length to be, there might still be premature negative labels. In early 2021, a  study by the Ads team at Twitter found that even though the majority of clicks on ads happen within the first 5 minutes, some clicks happen hours after when the ad is shown. This means that this type of label tends to give an underestimate of the actual click-through rate. If you only record 1000 clicks, the actual number of clicks might be a bit over 1000 clicks.</p><p>无论你将窗口长度设置为多长，都可能会出现过早的负面标签。2021年初，推特广告团队的研究发现，即使广告点击次数最多发生在5分钟内，但点击广告后几小时就会出现一些点击。这意味着这类标签往往低估了实际点击率。如果你只记录了1000次点击，实际的点击次数可能会超过1000次。</p><p> For tasks with long feedback loops, natural labels might not arrive for weeks or even months. Fraud detection is an example of a task with long feedback loops. For a certain period of time after a transaction, users can dispute whether that transaction is fraudulent or not. For example, when a customer read their credit card’s statement and saw a transaction they didn’t recognize, they might dispute with their bank, giving the bank the feedback to label that transaction as fraudulent. A typical dispute window is a month to three months. After the dispute window has passed, if there’s no dispute from the user, you can presume the transaction to be legitimate.</p><p>对于反馈循环较长的任务，自然标签可能需要数周甚至数月才能到达。欺诈检测就是一个长反馈循环任务的例子。在交易结束后的一段时间内，用户可以质疑该交易是否欺诈。例如，当客户阅读信用卡对账单，发现一笔他们不认识的交易时，他们可能会与银行发生争议，向银行提供反馈，将该交易标记为欺诈。一个典型的争议窗口是一个月到三个月。争议窗口过后，如果用户没有争议，您可以假定该交易是合法的。</p><p> Labels with long feedback loops are helpful for reporting a model’s performance on quarterly or yearly business reports. However, they are not very helpful if you want to detect issues with your models as soon as possible. If there’s a problem with your fraud detection model and it takes you months to catch, by the time the problem is fixed, all the fraudulent transactions your faulty model let through might have caused a small business to go bankrupt.</p><p>带有长反馈循环的标签有助于在季度或年度业务报告中报告模型的性能。然而，如果你想尽快发现模型的问题，它们并不是很有帮助。如果你的欺诈检测模型有问题，需要几个月才能发现，等到问题解决时，你的错误模型泄露的所有欺诈交易都可能导致一家小企业破产。</p><p>  Before we identify the cause of ML system failures, let’s briefly discuss what an ML system failure is. A failure happens when one or more expectations of the system is violated. In traditional software, we mostly care about a system’s operational expectations: whether the system executes its logics within the expected operational metrics such as the expected latency and throughput.</p><p>在确定ML系统故障的原因之前，让我们简要讨论一下什么是ML系统故障。当违反系统的一个或多个预期时，就会发生故障。在传统软件中，我们主要关心系统的操作预期：系统是否在预期的操作指标（如预期的延迟和吞吐量）内执行其逻辑。</p><p> For an ML system, we care about both its operational metrics and its ML performance metrics. For example, consider an English-French machine translation system. Its operational expectation might be that given an English sentence, the system returns a French translation within a second latency. Its ML performance expectation is that the returned translation is an accurate translation of the original English sentence 99% of the time.</p><p>对于ML系统，我们关心它的操作指标和ML性能指标。例如，考虑一个英法机器翻译系统。它的操作预期可能是，给定一个英语句子，系统会在第二个延迟内返回一个法语翻译。它的ML性能预期是，返回的译文在99%的时间内是对原始英语句子的准确翻译。</p><p> If you enter an English sentence into the system and don’t get back a translation, the first expectation is violated, so this is a system failure.</p><p>如果你在系统中输入了一个英语句子，但没有得到翻译，那么第一个期望值就被违反了，因此这是一个系统故障。</p><p> If you get back a translation that isn’t correct, it’s not necessarily a system failure because the accuracy expectation allows some margin of error. However, if you keep entering different English sentences into the system and keep getting back wrong translations, the second expectation is violated, which makes it a system failure.</p><p>如果你得到了一个不正确的翻译，这不一定是系统故障，因为精度预期允许一定的误差范围。然而，如果你不断地在系统中输入不同的英语句子，并且不断地得到错误的翻译，那么第二个期望就被违背了，这就导致了系统故障。</p><p> Operational expectation violations are easier to detect, as they’re usually accompanied by an operational breakage such as a timeout, a 404 error on a webpage, an out of memory error, a segmentation fault, etc. However, ML performance expectation violations are harder to detect as it requires measuring and monitoring the performance of ML models in production. In the example of the English-French machine translation system above, detecting whether the returned translations are correct 99% of the time is difficult if we don’t know what the correct translations are supposed to be. There are countless examples of Google Translate’s painfully wrong translations being used by users because they aren’t aware that these are wrong translations. For this reason, we say that ML systems often fail silently.</p><p>操作预期违规更容易检测，因为它们通常伴随着操作中断，例如超时、网页上的404错误、内存不足错误、分段错误等。然而，ML性能预期违规更难检测，因为它需要在生产中测量和监控ML模型的性能。在上面的英法机器翻译系统的例子中，如果我们不知道正确的翻译应该是什么，那么在99%的时间里检测返回的翻译是否正确是很困难的。有无数的例子表明，谷歌翻译的错误翻译被用户使用，因为他们不知道这些翻译是错误的。出于这个原因，我们说ML系统通常会无声地失败。</p><p> To effectively detect and fix ML system failures in production, it’s useful to understand why a model, after proving to work well during development, would fail in production. We’ll examine two types of failures:  Software system failures and ML-specific failures. Software system failures are failures that would have happened to non-ML systems. Here are some examples of software system failures.</p><p>为了有效地检测和修复生产中的ML系统故障，了解一个模型在开发过程中运行良好后，为什么会在生产中失败是很有用的。我们将研究两种类型的故障：软件系统故障和特定于ML的故障。软件系统故障是非ML系统可能发生的故障。下面是一些软件系统故障的例子。</p><p> Dependency failure: a software package or a codebase that your system depends on breaks, which leads your system to break. This failure mode is common when the dependency is maintained by a third party, and especially common if the third-party that maintains the dependency no longer exists  1.</p><p>依赖失败：系统依赖的软件包或代码库中断，导致系统中断。当依赖关系由第三方维护时，这种故障模式很常见，如果维护依赖关系的第三方不再存在，这种故障模式尤其常见1。</p><p>  Deployment failure: failures caused by deployment errors, such as when you accidentally deploy the binaries of an older version of your model instead of the current version, or when your systems don’t have the right permissions to read or write certain files.</p><p>部署失败：由部署错误引起的失败，例如，当您意外地部署了模型的旧版本而不是当前版本的二进制文件时，或者当您的系统没有读取或写入某些文件的正确权限时。</p><p>  Hardware failures: when the hardware that you use to deploy your model, such as CPUs or GPUs, doesn’t behave the way it should. For example, the CPUs you use might overheat and break down  2.</p><p>硬件故障：当您用于部署模型的硬件（如CPU或GPU）表现不正常时。例如，您使用的CPU可能过热并出现故障。</p><p>  Downtime or crashing: if a component of your system runs from a server somewhere, such as AWS or a hosted service, and that server is down, your system will also be down.</p><p>停机或崩溃：如果系统的某个组件从某个服务器（如AWS或托管服务）运行，而该服务器已关闭，则系统也将关闭。</p><p> Just because some failures are not specific to ML doesn’t mean it’s not important for ML engineers to understand. In 2020, Daniel Papasian and Todd Underwood, two ML engineers at Google, looked at 96 cases where a large ML pipeline at Google broke. They reviewed data from over the previous 15 years to determine the causes and found out that  60 out of these 96 failures happened due to causes not directly related to ML  3. Most of the issues are related to distributed systems e.g. where the workflow scheduler or orchestrator makes a mistake, or related to the data pipeline e.g. where data from multiple sources is joined incorrectly or the wrong data structures are being used.</p><p>仅仅因为一些故障不是特定于ML的，并不意味着ML工程师理解这些故障并不重要。2020年，谷歌的两名ML工程师丹尼尔·帕帕西安（Daniel Papasian）和托德·安德伍德（Todd Underwood）研究了96起谷歌大型ML管道破裂的案例。他们回顾了过去15年的数据，以确定原因，并发现96次故障中有60次是由于与ML3无直接关系的原因造成的。大多数问题与分布式系统有关，例如工作流调度器或编排器出错，或与数据管道有关，例如来自多个源的数据连接错误或使用了错误的数据结构。</p><p> Addressing software system failures requires not ML skills, but traditional software engineering skills, and addressing them is beyond the scope of this class. Because of the importance of traditional software engineering skills in deploying ML systems, the majority of ML engineering is engineering, not ML  4. For readers interested in learning how to make ML systems reliable from the software engineering perspective, I highly recommend the book   Reliable Machine Learning, also published by O’Reilly with Todd Underwood as one of the authors.</p><p>解决软件系统故障需要的不是ML技能，而是传统的软件工程技能，解决它们超出了本课程的范围。由于传统软件工程技能在部署ML系统中的重要性，大多数ML工程都是工程，而不是ML 4。对于有兴趣从软件工程的角度学习如何使ML系统可靠的读者，我强烈推荐O’Reilly与Todd Underwood合著的《可靠的机器学习》一书。</p><p> A reason for the prevalence of software system failures is that because ML adoption in the industry is still nascent, tooling around ML production is limited and best practices are not yet well developed or standardized. However, as toolings and best practices for ML production mature, there are reasons to believe that the proportion of software system failures will decrease and the proportion of ML-specific failures will increase.</p><p>软件系统故障普遍存在的一个原因是，由于业界对ML的采用尚处于初级阶段，围绕ML生产的工具有限，最佳实践尚未得到充分开发或标准化。然而，随着ML生产工具和最佳实践的成熟，有理由相信软件系统故障的比例将减少，而特定于ML的故障的比例将增加。</p><p> ML-specific failures are failures specific to ML systems. Examples include data collection and processing problems, poor hyperparameters, changes in the training pipeline not correctly replicated in the inference pipeline and vice versa, data distribution shifts that cause a model’s performance to deteriorate over time, edge cases, and degenerate feedback loop.</p><p>特定于ML的故障是特定于ML系统的故障。例如，数据收集和处理问题、超参数差、训练管道中的变化未在推理管道中正确复制，反之亦然、导致模型性能随时间恶化的数据分布变化、边缘情况和退化的反馈回路。</p><p> In this lecture, we’ll focus on addressing ML-specific failures. Even though they account for a small portion of failures, they can be more dangerous than non-ML failures as they’re hard to detect and fix, and can prevent ML systems from being used altogether. We’ve covered data problems, hyperparameter tuning, and the danger of having two separate pipelines for training and inference in previous lectures. In this lecture, we’ll discuss three new but very common problems that arise after a model has been deployed: changing data distribution, edge cases, and degenerate feedback loops.</p><p>在本课中，我们将重点讨论特定于ML的故障。尽管它们只占故障的一小部分，但它们可能比非ML故障更危险，因为它们很难检测和修复，并且可能会阻止ML系统被完全使用。在之前的课程中，我们已经讨论了数据问题、超参数调整，以及使用两条单独的管道进行训练和推理的危险。在本课中，我们将讨论部署模型后出现的三个新但非常常见的问题：改变数据分布、边缘情况和退化反馈循环。</p><p>  When we say that an ML model learns from the training data, it means that the model learns the underlying distribution of the training data with the goal of leveraging this learned distribution to generate accurate predictions for unseen data — data that it didn’t see during training. We’ll go into what this means mathematically in the  Data Distribution Shifts section below. When the model is able to generate accurate predictions for unseen data, we say that this model “generalizes to unseen data.  5” The test data that we use to evaluate a model during development is supposed to represent unseen data, and the model’s performance on the test data is supposed to give us an idea of how well the model will generalize.</p><p>当我们说ML模型从训练数据中学习时，这意味着该模型学习训练数据的基本分布，目的是利用学习到的分布为看不见的数据生成准确的预测，这些数据是它在训练期间没有看到的。我们将在下面的数据分布部分从数学上探讨这意味着什么。当模型能够为看不见的数据生成准确的预测时，我们说这个模型“推广到看不见的数据。5”我们在开发过程中用来评估模型的测试数据应该代表看不见的数据，模型在测试数据上的表现应该让我们了解模型推广的效果。</p><p> One of the first things I learned in ML courses is that it’s essential for the training data and the unseen data to come from the same distribution. The assumption is that the unseen data comes from a  stationary distribution that is  the same as the training data distribution. If the unseen data comes from a different distribution, the model might not generalize well  6.</p><p>我在ML课程中学到的第一件事是，训练数据和看不见的数据必须来自同一个分布。假设看不见的数据来自与训练数据分布相同的平稳分布。如果看不见的数据来自不同的分布，该模型可能无法很好地推广。</p><p> This assumption is incorrect in most cases for two reasons. First, the underlying distribution of the real-world data is unlikely to be  the same as the underlying distribution of the training data. Curating a training dataset that can accurately represent the data that a model will encounter in production turns out to be very difficult  7. Real-world data is multi-faceted, and in many cases, virtually infinite, whereas training data is finite and constrained by the time, compute, and human resources available during the dataset creation and processing. There are many different selection and sampling biases that can happen and make real-world data diverge from training data. The divergence can be something as minor as real-world data using a different type of encoding of emojis. This type of divergence leads to a common failure mode known as  the train-serving skew: a model that does great in development but performs poorly when deployed.</p><p>这种假设在大多数情况下是不正确的，原因有二。首先，真实世界数据的潜在分布不太可能与训练数据的潜在分布相同。策划一个能够准确表示模型在生产中会遇到的数据的训练数据集是非常困难的。现实世界中的数据是多方面的，在许多情况下几乎是无限的，而训练数据是有限的，并且受数据集创建和处理期间可用的时间、计算和人力资源的限制。可能会出现许多不同的选择和采样偏差，使现实世界的数据与训练数据产生偏差。这种差异可能与使用不同类型表情编码的真实世界数据一样小。这种类型的分歧导致了一种常见的故障模式，称为“列车服务倾斜”：这种模式在开发中表现出色，但在部署时表现不佳。</p><p> Second, the real world isn’t  stationary. Things change. Data distributions shift. In 2019, when people searched for Wuhan, they likely wanted to get travel information, but since COVID-19, when people search for Wuhan, they likely want to know about the place where COVID-19 originated. Another common failure mode is that a model does great when first deployed, but its performance degrades over time as the data distribution changes. This failure mode needs to be continually monitored and detected for as long as a model remains in production.</p><p>第二，现实世界不是静止的。事情变了。数据分布发生了变化。2019，2019冠状病毒疾病2019冠状病毒疾病，但当人们搜索武汉时，他们可能想得到旅游信息，但是自从COVID-19，当人们搜索武汉时，他们可能想知道COVID-19起源的地方。另一种常见的故障模式是，模型在首次部署时表现出色，但随着数据分布的变化，其性能会随着时间的推移而下降。只要模型仍在生产中，就需要持续监控和检测这种故障模式。</p><p> When I use COVID-19 as an example that causes data shifts, some people have the impression that data shifts only happen because of unusual events, which implies they don’t happen often. Data shifts happen all the time, suddenly, gradually, or seasonally. They can happen suddenly because of a specific event, such as when your existing competitors change their pricing policies and you have to update your price predictions in response, or when you launch your product in a new region, or when a celebrity mentions your product which causes a surge in new users, and so on. They can happen gradually because social norms, cultures, languages, trends, industries, and more just change over time. They can also happen due to seasonal variations, such as people might be more likely to request rideshares in the winter when it’s cold and snowy than in the spring.</p><p>当我使用2019冠状病毒疾病引起数据转移时，一些人会觉得数据转移只是因为不寻常的事件发生，这意味着它们不会经常发生。数据变化总是发生的，突然的、逐渐的或季节性的。它们可能会因为某个特定事件而突然发生，例如，当现有竞争对手改变其定价政策时，你必须更新价格预测以作出回应，或者当你在一个新的地区推出产品时，或者当一位名人提到你的产品从而导致新用户激增时，等等。它们可以逐渐发生，因为社会规范、文化、语言、趋势、行业等等都会随着时间而改变。这种情况也可能因季节变化而发生，比如人们可能更倾向于在寒冷下雪的冬季而不是春季要求乘坐野兔。</p><p> When talking about data shifts, many people imagine that they are due to external changes, such as natural disasters, holiday seasons, or user behaviors. But in reality, due to the complexity of ML systems and the poor practices in deploying them, a large percentage of what might look like data shifts on monitoring dashboards are caused by internal errors  8, such as bugs in the data pipeline, missing values incorrectly filled in, inconsistencies between the features extracted during training and inference, features standardized using statistics from the wrong subset of data, wrong model version, or bugs in the app interface that forces users to change their behaviors.</p><p>当谈到数据转移时，许多人认为这是由于外部变化造成的，比如自然灾害、假期或用户行为。但在现实中，由于ML系统的复杂性和部署过程中的不良做法，监控仪表盘上看起来像数据转移的大部分都是由内部错误8造成的，例如数据管道中的错误、错误填写的缺失值、，在训练和推理期间提取的特征、使用错误数据子集的统计数据标准化的特征、错误的模型版本或应用程序界面中迫使用户改变其行为的缺陷之间的不一致。</p><p> Since this is an error mode that affects almost all ML models, we’ll cover this in detail in the section  Data Distribution Shifts.</p><p>由于这是一种影响几乎所有ML模型的错误模式，我们将在“数据分布”一节中详细介绍这一点。</p><p>  Imagine there existed a self-driving car that can drive you safely 99.99% of the time, but the other 0.01% of the time, it might get into a catastrophic accident that can leave you permanently injured or even dead  9. Would you use that car?</p><p>想象一下，有一辆自动驾驶汽车可以在99.99%的时间里安全驾驶你，但在另外0.01%的时间里，它可能会陷入一场灾难性事故，导致你永久受伤甚至死亡。你会用那辆车吗？</p><p> If you’re tempted to say no, you’re not alone. An ML model that performs well on most cases but fails on a small number of cases might not be usable if these failures cause catastrophic consequences. For this reason, major self-driving car companies are focusing on making their systems work on edge cases  10  11  12.</p><p>如果你想说不，你并不孤单。如果ML模型在大多数情况下表现良好，但在少数情况下失败，那么如果这些失败导致灾难性后果，它可能不可用。出于这个原因，主要的自动驾驶汽车公司正专注于使他们的系统在边缘情况下工作10 11 12。</p><p> Edge cases are the data samples so extreme that they cause the model to make catastrophic mistakes. Even though edge cases generally refer to data samples drawn from the same distribution, if there is a sudden increase in the number of data samples in which your model doesn’t perform well on, it could be an indication that the underlying data distribution has shifted.</p><p>边缘情况是指数据样本非常极端，导致模型出现灾难性错误。尽管边缘案例通常指的是从同一分布中提取的数据样本，但如果模型在其中表现不佳的数据样本数量突然增加，则可能表明基础数据分布发生了变化。</p><p> Autonomous vehicles are often used to illustrate how edge cases can prevent an ML system from being deployed. But this is also true for any safety-critical application such as medical diagnosis, traffic control, eDiscovery  13, etc. It can also be true for non-safety-critical applications. Imagine a customer service chatbot that gives reasonable responses to most of the requests, but sometimes, it spits out outrageously racist or sexist content. This chatbot will be a brand risk for any company that wants to use it, thus rendering it unusable.</p><p>自动驾驶车辆通常用于说明边缘情况如何阻止部署ML系统。但这也适用于任何安全关键型应用，如医疗诊断、交通控制、eDiscovery 13等。非安全关键型应用也适用。想象一下，一个客户服务聊天机器人对大多数请求都给出了合理的响应，但有时它会吐出极端种族主义或性别歧视的内容。这个聊天机器人对任何想使用它的公司来说都是一个品牌风险，因此无法使用。</p><p>  You might wonder about the differences between an outlier and an edge case. The definition of what makes an edge case varies by discipline. In ML, because of its recent adoption in production, edge cases are still being discovered, which makes their definition contentious.</p><p>你可能想知道异常值和边缘情况之间的区别。边缘案例的定义因学科而异。在ML中，由于其最近在生产中的采用，边缘案例仍在被发现，这使得它们的定义有争议。</p><p> In this lecture, outliers refer to data: an example that differs significantly from other examples. Edge cases refer to performance: an example where a model performs significantly worse than other examples. An outlier can cause a model to perform unusually poorly, which makes it an edge case. However, not all outliers are edge cases. For example, a person jay-walking on a highway is an outlier, but it’s not an edge case if your self-driving car can accurately detect that person and decide on a motion response appropriately.</p><p>在这堂课中，离群值指的是数据：一个与其他例子截然不同的例子。边缘情况指的是性能：一个模型的性能明显低于其他示例的示例。异常值可能会导致模型表现异常糟糕，这使其成为边缘情况。然而，并非所有的异常值都是边缘情况。例如，在高速公路上行走的人是一个异常值，但如果你的自动驾驶汽车能够准确地检测到那个人并适当地决定运动响应，那就不是边缘情况。</p><p> During model development, outliers can negatively affect your model’s performance. In many cases, it might be beneficial to remove outliers as it helps your model to learn better decision boundaries and generalize better to unseen data. However, during inference, you don’t usually have the option to remove o</p><p>在模型开发过程中，异常值可能会对模型的性能产生负面影响。在许多情况下，删除异常值可能是有益的，因为它有助于您的模型更好地了解决策边界，并更好地概括未知数据。然而，在推理过程中，你通常没有删除o的选项</p><p>......</p><p>......</p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/分发/">#分发</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/模型/">#模型</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/谷歌/">#谷歌</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy;2012-2021 diglog.com </div></div></body></html>