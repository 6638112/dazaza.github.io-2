<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>PPROF ++：具有硬件性能监控的GO Profiler Pprof++: A Go Profiler with Hardware Performance Monitoring</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">Pprof++: A Go Profiler with Hardware Performance Monitoring<br/>PPROF ++：具有硬件性能监控的GO Profiler </h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2021-05-11 23:47:27</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2021/5/37cca5a8c63abbefef509f193201a61d.png"><img src="http://img2.diglog.com/img/2021/5/37cca5a8c63abbefef509f193201a61d.png" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>Golang is the lifeblood of thousands of Uber’s back-end services, running on millions of CPU cores. Understanding our CPU bottlenecks is critical, both for reducing service latencies and also for making our compute fleet efficient. The scale at which Uber operates demands in-depth insights into codes and microarchitectural implications.</p><p>Golang是成千上万的超级后端服务的生命线，以数百万CPU核心运行。了解我们的CPU瓶颈是至关重要的，用于减少服务延迟，也是为了使我们的计算舰队有效。优步操作的规模需要深入了解代码和微体系结构的洞察。</p><p> While the built-in Go profiler is better than having no profiler compared with several other languages, the de facto CPU profiler in Go has serious limitations on Linux-based systems (and likely on other OSes as well) and lacks many [  1 ,   2 ,   3 ,   4 ] of the details needed for fully understanding CPU bottlenecks.</p><p> 虽然内置的Go Profiler与其他语言没有任何其他语言，但Go的事实上的CPU分析器对基于Linux的系统（并且可能在其他oS的其他语言中具有严重限制，并且缺少许多[1,2 ，3,4]完全了解CPU瓶颈所需的详细信息。</p><p> With these concerns in mind, we set out to build a custom Go profiler that is better suited to our needs and the scale of Uber’s business operations. Specifically, we enhance Go’s default   pprof  profiler by integrating rich hardware performance-monitoring features into it. This advancement offers the following key benefits:</p><p> 通过这些担忧，我们旨在建立一个完全适合我们的需求和优步业务的规模的自定义Go探查器。具体而言，通过将丰富的硬件性能监控功能集成到其中，我们通过将丰富的硬件性能监控功能集成来增强Go的默认PPROF分析器。此进步提供以下主要优惠：</p><p> The ability to monitor various CPU events such as cache misses, inter-socket (NUMA) traffic, CPU branch mispredictions, to name a few</p><p> 能够监控各种CPU事件，如缓存未命中，套接字间（NUMA）流量，CPU分支错误预测，命名</p><p> The ability to monitor go programs with a very high sampling frequency — up to 10s of microseconds</p><p> 能够监控GO程序的采样频率非常高的 - 高达10秒的微秒</p><p> All these features are available with the same, familiar pprof interface(s) and the ability to reuse all downstream tools that previously worked with pprof’s profile (protocol buffer) files. This means we can reuse call stack attribution, call-graphs, and flame-graphs, to name a few.</p><p> 所有这些功能都具有相同，熟悉的PPROF接口和能够重用先前与PPROF的配置文件（协议缓冲区）文件一起使用的所有下游工具。这意味着我们可以重用调用堆栈归属，呼叫图和火焰图来命名几个。</p><p>  Profiling is one of Golang’s built-in features. The Go profiler covers aspects such as CPU time, memory allocation, etc. This article pertains to the most common and familiar form of profiling — the CPU profiling. There are 3 well-known approaches to obtaining CPU profiles from a Go program:</p><p>  剖析是戈兰内置的功能之一。 Go Profiler涵盖了CPU时间，内存分配等方面的方面。本文涉及最常见和熟悉的分析形式 -  CPU分析。从GO程序获取CPU配置文件有3个众所周知的方法： </p><p> Getting CPU profiles over an exposed http port   First, expose profiling endpoints on a designated port by including the following code snippet in the Go program:</p><p>通过在Go程序中包含以下代码片段，在公开的HTTP端口缩短CPU配置文件，在指定端口上公开分析端点：</p><p>  Then, fetch the profiles from the profiling endpoint from the running Go program; for example, the following command contains  5 seconds  of CPU profiles and stores it in the  timer.prof  file.</p><p>  然后，从运行Go程序中获取配置文件的配置文件;例如，以下命令包含5秒的CPU配置文件并将其存储在Timer.prof文件中。</p><p>  At Uber, we rely extensively on our ability to fetch profiles from thousands of our production microservices, and we have an elaborate set of downstream tools to post-process them.</p><p>  在Uber，我们依靠我们从数千个生产微服务中获取配置文件的能力，我们有一个精心制作的下游工具来处理它们。</p><p> 2. Getting CPU profiles from Go benchmarking    The Go testing framework allows for benchmarking a program and then profiling the benchmark by passing the extra  -cpuprofile  flag to collect the CPU profiles</p><p> 2.从Go基准测试Go测试框架获取CPU配置文件允许基准测试程序，然后通过传递额外的-cpuprofile标志来分析基准，以收集CPU配置文件</p><p>  Getting CPU profiles from code instrumentation   One can insert   start /  stop  profiling APIs around the code region of interest and provide an   io.writer  to flush the resulting profiles to a file, as shown below:</p><p>  从代码仪器获取CPU配置文件可以在兴趣区域周围插入开始/停止分析API，并提供IO.WRITER以将结果的配置文件刷新到文件，如下所示：</p><p>  All three interfaces produce a pprof protocol buffer file, which can be viewed with the  go tool  pprof &lt;profile file&gt;  command line or other downstream tools. A Go CPU profile includes time attribution to call stack samples. They can be visualized with call-graphs and flame-graphs.</p><p>  所有三个接口都生成PPROF协议缓冲区文件，可以使用GO工具PPROF＆lt; profile文件＆gt查看。命令行或其他下游工具。 GO CPU配置文件包括调用堆栈样本的时间归因。它们可以通过呼叫图和火焰图可视化。</p><p>   A profiling datum is said to be   accurate  if it is close to the ground truth. For example, if  API_A()  consumes 25% of the total execution time and a profiler attributes it 24% of the total execution time, the measurement has 96% accuracy.</p><p>   如果它接近地面真相，则据说一个分析数据准确。例如，如果api_a（）消耗总执行时间的25％和分析器属性的24％的总执行时间，则测量的精度为96％。 </p><p> Profiling data are said to be   precise  if there is low variability among multiple measurements. Precision of a set of measurements of the same variable is often expressed either as min and max from the sample mean, or as standard error or coefficient of variation of the sample.</p><p>据说分析数据是精确的，如果多次测量的可变性低。相同变量的一组测量的精​​度通常表示为min且来自样本的最小值，或者是样本的标准误差或变异系数。</p><p> Unfortunately, the current pprof CPU profiles meet neither of these two criteria.  Inside the Go runtime, the CPU profiling employs operating system timers to periodically (~100 times a second) interrupt the execution. On each interrupt (aka a sample), it collects call stacks occurring at the same time.</p><p> 不幸的是，目前的PPROF CPU配置文件既不会遇到这两个标准。在Go运行时，CPU分析采用操作系统定时器定期（〜100次）中断执行。在每个中断（aka样本）上，它收集同时发生的呼叫堆栈。</p><p>  Inaccuracy of profiles arises from 2 sources:   sampling frequency  and   sampling bias .  Sampling frequency:  The accuracy of a sampling-based profiler is loosely related to   Nyquist Sampling Theorem . In order to faithfully recover the input signal, the sampling frequency should be greater than twice the highest frequency contained in the signal. If a microservice takes, say, 10 milliseconds, to handle a request, we should sample at least every 5 milliseconds to get some sense of what happens within a request. But, the OS timers cannot go below one sample per 10ms. In fact, for accurate profiles at function level, we need samples at microseconds granularity.</p><p>  曲线的不准确性产生2个来源：采样频率和采样偏置。采样频率：基于采样的分析器的准确性与Nyquist采样定理松散地相关。为了忠实地恢复输入信号，采样频率应大于信号中包含的最高频率的两倍。如果MicroService需要，例如10毫秒，请处理请求，我们应该至少每5毫秒来进行样本，以获得某种意义。但是，操作系统定时器不能低于每10毫秒的一个样本。实际上，对于功能级别的准确配置文件，我们需要在微秒粒度下的样品。</p><p> A larger number of samples  may make profiles closer to reality and one can obtain more samples by increasing the length of a measurement window. Linearly scaling the measurement time to collect more samples is impractical if orders of magnitude more samples are necessary to correct the small samples size issue. Hence, there is a dire need to collect more samples within a measurement window and obtain fine-grained samples of sub-millisecond executions.</p><p> 更大数量的样本可以使易于现实更靠近现实的配置，并且可以通过增加测量窗口的长度来获得更多样本。线性缩放测量时间以收集更多样本是不切实际的，如果需要更多的样本以纠正小样本尺寸问题。因此，存在尖端需要在测量窗口内收集更多样本并获得细粒的子毫秒执行样本。</p><p> Sampling bias:  A larger sample size alone does not improve accuracy if the samples are biased. OS timer (itimer) samples in Linux are biased because a timer interrupt from one OS thread, say  T1  may be handled by an arbitrary (not to be confused with uniformly random) thread, say  T2 . This means,  T2  will handle the interrupt and incorrectly attribute the sample to its call stack, which results in biased samples. If more timer interrupts are handled by  T2  compared to  T1 , a systematic sampling bias will occur, which leads to inaccurate profiles.</p><p> 取样偏置：如果样品偏置，则单独的样本大小不提高精度。 OS定时器（ITIMER）Linux中的样本被偏置，因为从一个OS线程中断定时器中断，例如可以通过任意（不与均匀随机）的方式处理T2，说T2。这意味着T2将处理中断和错误地将样本属性归因于其呼叫堆栈，这导致偏置样本。如果与T1相比处理的更多定时器中断，则会发生系统采样偏差，这导致不准确的轮廓。</p><p>   Sample size:  Fewer number of samples directly contributes to a large   standard error . The low resolution of OS timers is responsible for fewer samples in a measurement window, which results in a lower precision of pprof profiles. Conversely, a higher resolution of samples will improve precision.</p><p>   样本大小：更少数量的样本直接有助于大量标准误差。 OS定时器的低分辨率负责测量窗口中的样本较少，这导致PPROF配置文件的较低精度。相反，样品的更高分辨率将提高精度。</p><p> Measurement skid:  The second source of measurement error is the   random error  inherent in any given measurement apparatus. An OS timer apparatus configured to expire after N milliseconds is only guaranteed to generate an interrupt some time after N milliseconds—not precisely at N milliseconds. This randomness introduces a large “skid” in measurement. Assume a periodic timer set to fire every 10ms. Assume it has 1ms left before its expiry when the OS scheduler with a 4ms resolution inspects it. This means the timer will fire 4ms later, which is 3ms after the scheduled expiry time. This results in up to 30% imprecision for a 10ms periodic timer. Although random error may not be entirely eliminated, a superior measurement apparatus reduces the effects of random error.</p><p> 测量SKID：第二测量误差是任何给定测量设备固有的随机误差。配置为在N毫秒后到期的操作系统定时器设备仅保证在N毫秒后的一段时间 - 不准确地在N毫秒内生成中断。这种随机性在测量中引入了大的“滑动”。假设定期定时器设置为每10ms射击。假设它在其到期前剩余1ms，当OS调度程序带有4ms分辨率检查它时。这意味着计时器将在以后将射击4ms，在预定的到期时间之后是3ms。这导致10ms定期定时器的不精确度高达30％。虽然可能不完全消除随机误差，但是卓越的测量装置减少了随机误差的影响。 </p><p>  Consider the Go program   goroutine.go , which has 10 exactly similar goroutines  main.f1-main.f10  where each function takes exactly the same amount of CPU time (i.e., 10% of the overall execution). Table 1 summarizes the results of using the default pprof cpu profile for this program, running on a 12-core Intel Skylake server-class machine with a Linux OS:</p><p>考虑Go Program Goroutine.go，它具有10个完全相似的Goroutines Main.f1-main.f10，其中每个功能采用完全相同的CPU时间（即，总体执行的10％）。表1总结了使用该程序的默认PPROF CPU配置文件的结果，在带有Linux操作系统的12核Intel Skylake服务器类计算机上运行：</p><p>   The measurements were taken 3 times under the same configuration represented by the  RUN 1 ,  RUN 2 , and  RUN 3  header columns in Table 1. The  Expected (%)  column shows the expected relative time in each routine. The  Flat (ms)  columns show the absolute millisecond measurement attributed to each of the 10 routines, and the  Flat (%)  columns show the relative time in a routine with respect to the total execution time in each run. The  Rank order  columns assign ranks in the descending order of execution time for each function for each run.</p><p>   测量值3次在运行1，RUN 2，并在表1中运行3个标题列的相同配置。预期的（％）列显示每个例程中的预期相对时间。扁平（MS）列显示出归因于10个例程中的每一个的绝对毫秒测量，并且扁平（％）列在每个运行中的总执行时间方面显示了例程中的相对时间。等级排列列为每个运行的每个函数的执行时间的降序排列排列。</p><p> Consider the data in  RUN 1 .  main.f1-main.f10  have a wide variance in the time attributed to them, whereas we expected each one of them to be 10% of the total time. There is up to a 6x difference in the time attributed to the routine with the highest amount of attribution ( main.f7  with 4210ms, 23.31%) and the routine with the lowest amount of attribution ( main.f9  with 700ms, 3.88%). This demonstrates the poor accuracy (deviation from the ground truth) of pprof timer-based profiles.</p><p> 考虑运行1中的数据。 main.f1-main.f10在归因于它们的时间内具有广泛的差异，而我们预计其中每一个是总时间的10％。归因于归因于归因于最高归属量（Main.f7，带有4210ms，23.31％）和归因最低的例程的时间差异（Main.f9，具有700ms，3.88％）的例程。这证明了基于PPROF定时器的配置文件的差的准确性差（偏差）。</p><p> Now focus on the 3 runs   RUN 1,  RUN2 ,  and  RUN 3  together. The time attributed to any routine widely varies from one run to another. The rank order of the routines changes significantly from run to run. In  RUN 1 ,  main.f7  is shown to run for 4210ms with the rank order of 1, whereas in  RUN 2 , it is shown to run for only 520ms with the rank order 10. The expectation is that the measurements remain the same from run to run. There is a 71% coefficient of variance among the 3 runs of the  main.f1  routine and the average coefficient of variance across all functions is 28%. This demonstrates imprecision of pprof timer-based profiles. Increasing the running time of this program by 10x or even 100x does not correct this profiling error.</p><p> 现在专注于3运行运行1，Run2，并一起运行3。归因于任何例程的时间从一个跑到另一个例程都广泛变化。常规的等级顺序从运行运行显着变化。在Run 1中，Main.f7显示为使用级别为1的4210ms，而在运行2中，它显示为仅使用秩序10运行520ms。期望是测量结果与运行相同跑步。主要的3次运行中存在71％的差异系数。所有功能的平均方差系数是28％。这表明PPROF基于定时器的配置文件的不精确。增加此程序的运行时间为10x甚至100倍不正确的此分析错误。</p><p>   The second aspect of a profiler is making it offer more details than mere hotspots to aid developers in taking corrective actions. All profiles show hotspots, but hotspots are, at best, only symptoms, and don’t fully reflect underlying problems. For example, if a profiler shows that the program spends 90% time in a matrix-matrix multiplication, it does not tell whether it is good or bad; the matrix multiplication may be highly optimized already! However, if a profiler can pinpoint that 50% of the data accessed during a matrix-matrix multiplication were fetched from a remote DRAM of a NUMA system it was running on, it immediately highlights data locality problems in the program, and hence also opportunities for optimization. Such details are hard to come by in basic profilers, the default Go profiler included.</p><p>   分析器的第二个方面正在使其提供更多细节，而不是仅仅是热点，以帮助开发人员采取纠正措施。所有档案显示热点，但热点是最多只有症状，而且没有完全反映出潜在的问题。例如，如果探查器显示该程序在矩阵矩阵乘法中花费90％的时间，则不判断它是否好坏;矩阵乘法可能高度优化！但是，如果探查器可以精确地从其运行的NUMA系统的远程DRAM获取矩阵矩阵乘法期间访问的50％的数据，它立即突出了程序中的数据局部问题，因此优化。这些细节难以通过基本探查器来实现，默认的Go Profiler包括在内。</p><p>  To address these concerns, we developed  pprof++ , which enhances the default Go CPU profiler to use hardware performance monitoring features .</p><p>  为了解决这些问题，我们开发了PPROF ++，它增强了默认的GO CPU分析器来使用硬件性能监控功能。</p><p> Improved accuracy and precision:  Modern commodity CPUs are equipped with hardware performance monitoring units (PMUs). One can configure hardware performance counters to very fine measurement granularity, which enhances profiling accuracy. Furthermore, the advancements in PMUs offer features that record the CPU state at the time of an interrupt, which allows for reconstructing the precise state of a program, resulting in higher precision. Finally, the interrupts from hardware PMUs can be configured to be delivered to a specific thread in question, which avoids the problem of incorrect attribution, leading to higher profiling accuracy.</p><p> 提高准确性和精确度：现代商品CPU配备了硬件性能监控单位（PMU）。可以将硬件性能计数器配置为非常精细的测量粒度，这提高了分析精度。此外，在中断时，PMU提供功能的提升功能，该功能记录CPU状态，这允许重建程序的精确状态，从而提高精度。最后，可以将来自硬件PMU的中断配置为被传递到有问题的特定线程，这避免了归因不正确的问题，导致更高的分析精度。 </p><p> Insights into many kinds of CPU events for better diagnosis of performance problems : Time alone is not sufficient when diagnosing complex performance problems. For example, if a lot of time is attributed to a data structure walk, it may not be obvious why. Hardware performance monitoring reveals a lot of internal functioning of the CPU and the memory subsystem that allows diagnosing the root causes of performance problems. For example, if a lot of new data is fetched before previously-accessed data is accessed again, it will be evicted from the CPU caches, and this becomes visible if one were to profile CPU cache misses. Similarly, if 2 adjacent data items are accessed by 2 independent threads, but they happen to reside on the same CPU cache line, it results in the shared cache line ping-ponging between the private caches of the 2 CPUs, commonly known as false-sharing, which can be diagnosed via a counter called as HITM in modern Intel CPUs.</p><p>探讨多种CPU事件，以便更好地诊断性能问题：在诊断复杂性能问题时，单独的时间不充分。例如，如果大量时间归因于数据结构步行，可能是显而易见的原因。硬件性能监控显示CPU和内存子系统的大量内部功能，允许诊断性能问题的根本原因。例如，如果在再次访问了预先访问的数据之前，将从CPU缓存中访问很多新数据，则如果要配置CPU高速缓存未命中，则会显示出可见。同样，如果2个独立线程访问2个相邻的数据项，但它们碰巧驻留在同一CPU高速缓存行上，它会导致2 CPU的私有高速缓存之间的共享高速缓存行ping ping，通常称为假 - 共享，可以通过现代英特尔CPU中称为HITM的计数器诊断。</p><p> High-frequency measurement:  Since PMUs can be configured with arbitrarily low sampling thresholds, one can monitor events at extremely high frequency (of the order of 10s or 100s of microseconds), which becomes necessary for latency-sensitive services where individual requests last for a only tens of milliseconds.</p><p> 高频测量：由于PMU可以配置任意低采样阈值，因此可以以极高的频率（10s或100s的10秒）以极高的频率监测事件，这对于延迟敏感的服务成为个人请求的持续敏感服务所必需的只有数十毫秒。</p><p> PMUs are ubiquitous in modern CPUs, exposed by OSes such as Linux, and they can be programmatically controlled to deliver interrupts on accumulating a threshold number of events. For example, Intel publishes its   performance monitoring events  for each member of its processor family, and Linux exposes PMUs via  perf_event  subsystem.  pprof++  makes changes to the Go runtime, subscribes to these hardware events, and gets periodic interrupts. This mechanism is often referred to as hardware event-based sampling. The choice of events makes the hardware performance monitoring rich and insightful. Like OS timer profiling,  pprof++  performs call stack unwinding on each PMU interrupt and attributes events to call stack samples. This allows  pprof++  profiles to highlight which functions and source lines cause different architectural bottlenecks, such as CPU cache misses.</p><p> PMU在现代CPU中是普遍存在的，由Linux等SUSE公开，它们可以编程方式控制，以提供累积阈值事件数量的中断。例如，英特尔为其处理器系列的每个成员发布其性能监视事件，Linux通过Perf_Event子系统公开PMus。 PPROF ++对Go运行时的更改进行了更改，订阅这些硬件事件，并获取定期中断。该机制通常被称为基于硬件的基于事件的采样。活动选择使硬件性能监测丰富和洞察力。与OS定时器分析一样，PPROF ++在每个PMU中断和属性事件上执行呼叫堆栈，以调用堆栈样本。这允许PPROF ++配置文件突出显示哪些函数和源线导致不同的架构瓶颈，例如CPU缓存未命中。</p><p> For beginners, identifying which hardware performance event to monitor can be daunting; hence, we simplify the process and expose the following most common events. The events have a   preset  sampling period, which can be overridden.</p><p> 对于初学者来说，识别要令人生畏的监视器的硬件性能事件;因此，我们简化了过程并公开了以下最常见的事件。事件具有预设的采样周期，可以覆盖。</p><p>      The output of  pprof++  is the same, familiar pprof protocol buffer profile files, which can be viewed with a pprof tool as call-graphs (Figure 1) or flame-graphs (Figure 2), and also be fed to other downstream profile-processing workflows. If a profile is taken with PMU  cycles  event, the pprof call-graph and flame-graph will pinpoint and quantify which code regions (contexts) account for what amount of CPU cycles; if a profile is taken with PMU  cacheMisses  event, the pprof call-graph and flame-graph will pinpoint and quantify which code regions (contexts) account for what amount of CPU last-level cache misses, and so on.</p><p>      PPROF ++的输出是相同的熟悉的PPROF协议缓冲区文件文件，可以用PPROF工具作为呼叫图（图1）或火焰图（图2），并且还被馈送到其他下游轮廓处理工作流程。如果使用PMU循环事件拍摄了配置文件，则PPROF呼叫图和火焰图将针对哪些CPU周期进行查明和量化哪个代码区域（上下文）占多样的CPU周期;如果使用PMU Cacchemisses事件拍摄了配置文件，则PPROF呼叫图和FLAME-GRAPL将针对哪些代码区域（上下文）帐户占用哪些CPU上次级别缓存未命中等。</p><p>  In order to take advantage of  pprof++ , recompile your Go program with our custom Go compiler, augmented with PMU profiling facilities; see the   availability  section below.</p><p>  为了利用PPROF ++，通过我们的自定义GO编译器重新编译您的GO程序，使用PMU分析设施增强;请参阅下面的可用性部分。</p><p> The 3 techniques of profile collection described in the   background  section remain largely the same when using  pprof++ :</p><p> 在使用PPROF ++时，在后台部分中描述的配置文件集合的3种技术在很大程度上是相同的： </p><p>  As in case of pprof, include the same code snippet to expose profiling endpoints; no change is needed to the application code. A developer can now fetch the numerous varieties of profiles. We introduce 2 new parameters to the  /debug/pprof/profile  endpoint</p><p>在PPROF的情况下，包括相同的代码片段以暴露分析端点;应用程序代码不需要更改。开发人员现在可以取消许多品种的简档。我们向/ debug / pprof / profile端点介绍2个新参数</p><p>   Collect profiles using CPU cycles by sampling the call stack once in 5 million CPU cycles, and collect the profiles for 25 seconds.</p><p>   通过在500万CPU周期中采样一次调用呼叫堆栈，使用CPU周期收集配置文件，并收集配置文件25秒。</p><p>  event=cycles  indicates to the profiler to sample CPU cycles. The default is “timer” present in pprof.   period= 5000000  indicates to the profiler to take one sample every 5M CPU cycles. This will result in about 500 samples per second on a 2.5GHz CPU.   seconds= 25  indicates to the profiler to measure the application for 25 seconds. The default is 30 seconds.</p><p>  Event =循环指示对样本CPU周期的分析器。默认值是PPROF中的“计时器”。周期= 5000000表示分析器每5M CPU周期拍摄一个样本。这将导致2.5GHz CPU上每秒约500个样本。秒= 25表示分析器测量申请25秒。默认值为30秒。</p><p> b. Collect profiles using CPU-retired instructions event by sampling the call stack once in 1 million retired instructions and collect the profiles for 30 seconds (default).</p><p> 湾通过在100万退休指令中对呼叫堆叠进行采样一次，使用CPU退休指令事件收集配置文件，并收集30秒（默认）的配置文件。</p><p>  c. Collect profiles using last-level cache misses by sampling the call stack once in 10K cache misses and collect the profiles for 30 seconds.</p><p>  C。通过在10k缓存未命中采样调用堆栈一次，使用上级缓存未命中收集配置文件并收集30秒的配置文件。</p><p>  d. Collect profiles to detect cache line contention due to true or false sharing between 2 cores on 2 different NUMA sockets. This is easily done with the   MEM_LOAD_L3_MISS_RETIRED.REMOTE_HITM  event which has the  mask  0x4  and  event code  0xD3  on a skylake architecture. Hence we set  event=r04d3 . Let’s take call stack samples for one in 10K such events.</p><p>  天。收集配置文件以检测由于2个不同NUMA套接字的2个核心之间的真实或假共享而导致缓存行争用。这很容易使用MEM_LOAD_L3_MISS_RETIFD.REMOTE_HITM事件，该事件在天窗架构上具有蒙版0x4和事件代码0xD3。因此，我们设置了Event = R04D3。让我们在10K这样的事件中呼叫堆栈样本。</p><p>  2. Getting CPU profiles from Go benchmarking    We introduce 2 new parameters to the command line:   cpuevent=&lt;timer|cycles|instructions|cacheMisses|cacheReferences|branches|branchMisses|rHexValue&gt;  and  cpuperiod=&lt;Int64Value&gt; . Here are a few usage examples:</p><p>  2.从GO基准测试CPU配置文件我们向命令行介绍2个新参数：CPUEVENT =＆lt;计时器|周期|指示| Cacchemisses | Cachereferences |分支机构| Branchmisses | rhexvalue＆gt;和cpuperiod =＆lt; int64value＆gt; 。以下是一些使用示例： </p><p> Collect profiles from CPU  cycles  counter on the  BenchmarkXYZ  by sampling one in every  1 million  cycles and write the profiles to  cycles.prof  file.</p><p>通过每1000万个周期中的一个在BenchmarkXYZ上采样将CPU周期计数器收集配置文件，并将配置文件写入Cycles.prof文件。</p><p>  b. Collect profiles of  mispredicted branches in the  BenchmarkXYZ by sampling one in every  10000 mispredicted branches and write the profiles to  mispredbranch.prof .</p><p>  湾通过每10000个错误预定的分支中的一个在每10000个错误的分支中采样，收集BenchmarkXYZ中错误预定的分支的配置文件，并将配置文件写入MispredBranch.prof。</p><p>  c. Identify where the code incurs frequent misses in the first-level instruction cache of the CPU. This can be profiled on Intel Skylake machines with the event   FRONTEND_RETIRED.L1I_MISS,  which has the   mask  0x1  and  event code  0xc6 . Let us sample this once in  10000  misses.</p><p>  C。确定代码在CPU的第一级指令缓存中频繁未命中的位置。这可以在Intel Skylake机器上与事件FrontEnd_retired.l1i_miss上的Intel Skylake Machine剖析，具有蒙版0x1和事件代码0xC6。让我们在10000次失误中进行一次样本。</p><p>   pprof++ introduces a new API to the runtime/pprof package.   pprof.StartCPUProfileWithConfig(opt ProfilingOption, moreOpts    …ProfilingOption) error,  where  ProfilingOption  can be  one of the following:</p><p>   PPROF ++将新API引入运行时/ PPROF包。 pprof.startcpuprofilewithconfig（opt profilingoption，morepts ... profilingoption）错误，其中profilingoption可以是以下之一：</p><p> func  OSTimer (w io.Writer)  ProfilingOption func  CPUCycles (w io.Writer, period uint64)  ProfilingOption func  CPUInstructions (w io.Writer, period uint64)  ProfilingOption func  CPUCacheReferences (w io.Writer, period uint64)  ProfilingOption func  CPUCacheMisses (w io.Writer, period uint64)  ProfilingOption func  CPUBranchInstructions (w io.Writer, period uint64)  ProfilingOption func  CPUBranchMisses (w io.Writer, period uint64)  ProfilingOption func  CPURawEvent (w io.Writer, period uint64, hex uint64)  ProfilingOption</p><p> func oosimer（w io.writer）profilingoption func cpucycles（w io.writer，uint64）profilingoption func cpuinstructions（w io.writer，uint64）profilingoption func cpucacherences（w io.writer，uint64）profilingoption func cpucachemisses（w io .writer，uint64）profilingoption func cpubranchinalstructions（w io.writer，uint64）profilingoption func cpubranchmisses（w io.writer，uint64）profilingoption func cpurawevent（w io.writer，周期Uint64，hex uint64）profilloption</p><p>  Profile a code region with CPU cycles event sampling once in 1 million CPU cycles.</p><p>  配置CPU循环事件采样一次的代码区域，在100万CPU周期中。</p><p>  b. We allow power users to simultaneously collect multiple events in a single run. This facility is protected under an environment variable   GO_PPROF_ENABLE_MULTIPLE_CPU_PROFILES=&lt; true | false &gt; . Each event needs its own   io.writer . The example below shows collecting 4 simultaneous profiles: CPU cycles (one in 10M), retired instructions (one in 1M), last-level cache misses (one in 10K), and retired load instructions that miss in the second-level TLB (one in 1K), which is available with event   MEM_INST_RETIRED.STLB_MISS_LOADS ,  mask=0x11 ,  event code=0xd0 .</p><p>  湾我们允许Power用户在一次运行中同时收集多个事件。该设施在环境变量GO_PPROF_ENABLE_MULTIPLE_CPU_PROFILES =＆lt;真实|假＆gt; 。每个事件都需要自己的IO.Writer。下面的例子显示收集4个同时配置文件：CPU周期（一个10米），退休指令（一个1M），最后一级缓存未命中（一个10K中的一个），并在第二级TLB中错过的退休加载指令（一个在1K）中，可用事件mem_inst_retive.stlb_miss_load，mask = 0x11，事件代码= 0xD0。 </p><p> cyc, _ := os.Create( &#34;cycprof.prof&#34; ) defer cyc.Close() ins, _ := os.Create( &#34;insprof.prof&#34; ) defer ins.Close() cache, _ := os.Create( &#34;cacheprof.prof&#34; ) defer cache.Close() tlb, _ := os.Create( &#34;tlb.prof&#34; ) defer brMiss.Close() pprof.StartCPUProfileWithConfig(CPUCycles(cyc,  1000000 ), CPUInstructions(ins,  1000000 ), CPUCacheMisses(cache,  10000 ), CPURawEvent( &#34;r11d0&#34; ,  1000 )) MyCodeToProfile() pprof.StopCPUProfile()</p><p>cyc，_：= os.create（＆＃34; cycprof.prof＆＃34;）defer cyc.close（）ins，_：= os.create（＆＃34; insprof.prof＆＃34;）defer ins.close （）缓存，_：= os.Create（＆＃34; cacheprof.prof＆＃34;）defer cache.close（）tlb，_：= os.create（＆＃34; tlb.prof＆＃34;）defer brmiss .close（）pprof.startcpuprofilewithconfig（C cyccles（cyc，1000000），cpuiningsions（Ins，1000000），cpucachemisses（cache，10000），cpurawevent（＆＃34; r11d0＆＃34;，1000））mycodetoprofile（）pprof.stopcpuprofile（ ）</p><p>  The video below demonstrates the download, initial setup, and usage to get started with  pprof++ .</p><p>  下面的视频演示了使用PPROF ++的下载，初始设置和用法来开始。</p><p>     Accurate and precise profiles that can give deeper and actionable insights into program executions are necessary for any programming language. Uber’s extensive use of Go for its microservices has led us to bring these capabilities into Golang’s Pprof profiler. While there exist many other third-party profiles with similar capabilities, the integration of PMU profiling within Go’s runtime offers seamless integration with myriad execution environments and downstream post-processing tools.</p><p>     任何编程语言都需要准确和精确的简档，这些简档可以为程序执行提供更深层次和可操作的见解。优步使用Go for The SicroServices已导致我们将这些功能带入Golang的PPROF Profiler。虽然存在许多具有相似能力的其他第三方配置文件，但在GO的运行时内的PMU分析集成了与Myriad执行环境和下游后处理工具的无缝集成。</p><p> We  have released a prototype of the current implementation of  pprof++  on   GitHub.  We have made it available on top of the   Go 1.15.8  and    Go 1.16  release branches.</p><p> 我们发布了GitHub上目前实施PPROF ++的原型。我们已经在1.15.8的顶部提供了1.16个释放分支。</p><p> pprof++  is currently available only on Linux OS.  For quick download, we have made x86_64 (aka AMD64) versions of the Go binaries available:</p><p> PPROF ++目前仅在Linux操作系统上使用。为了快速下载，我们制作了X86_64（AKA AMD64）的Go二进制文件：</p><p>    Pengfei Su , now assistant professor at UC Merced, developed the initial prototype while interning at Uber Programming System Group in the summer of 2019.</p><p>    鹏飞苏，UC默塞德的助理教授，在2019年夏天在Uber编程系统组中开展了初始原型。 </p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://eng.uber.com/pprof-go-profiler/">https://eng.uber.com/pprof-go-profiler/</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/性能/">#性能</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/硬件/">#硬件</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/具有/">#具有</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/profiler/">#profiler</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/cpu/">#cpu</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/分享/">#分享</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy;2012-2021 diglog.com </div></div></body></html>