<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>即将陷于贫困中的隐藏算法之战 The coming war on the hidden algorithms that trap people in poverty</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">The coming war on the hidden algorithms that trap people in poverty<br/>即将陷于贫困中的隐藏算法之战 </h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2020-12-05 02:13:13</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2020/12/fc45860af5f5840fa3d3529e341979ab.jpg"><img src="http://img2.diglog.com/img/2020/12/fc45860af5f5840fa3d3529e341979ab.jpg" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>Miriam was only 21 when she met Nick. She was a photographer, fresh out of college, waiting tables. He was 16 years her senior and a local business owner who had worked in finance. He was charming and charismatic; he took her out on fancy dates and paid for everything. She quickly fell into his orbit.</p><p>遇到尼克时，米里亚姆只有21岁。她是一名摄影师，刚大学刚毕业，正在等待餐桌。他年仅16岁，是一位曾在金融业工作的当地企业主。他很迷人，很有魅力。他花了很多时间就把她带出去，花了一切。她很快掉入他的轨道。</p><p>  It began with one credit card. At the time, it was the only one she had. Nick would max it out with $5,000 worth of business purchases and promptly pay it off the next day. Miriam, who asked me not to use their real names for fear of interfering with their ongoing divorce proceedings, discovered that this was boosting her credit score. Having grown up with a single dad in a low-income household, she trusted Nick’s know-how over her own. He readily encouraged the dynamic, telling her she didn’t understand finance. She opened up more credit cards for him under her name.</p><p>  它始于一张信用卡。当时，这是她唯一的一个。尼克会通过购买价值5,000美元的商品来使之最大化，并在第二天立即偿还。由于担心干扰他们正在进行的离婚程序，Miriam要求我不要使用他们的真实姓名，她发现这在提高她的信用评分。她与一个单身父亲一起在低收入家庭中长大，因此她信任尼克的专有技术。他欣喜地鼓励这种动力，并告诉她她不懂财务。她用她的名字为他开了更多的信用卡。</p><p>  The trouble started three years in. Nick asked her to quit her job to help out with his business. She did. He told her to go to grad school and not worry about compounding her existing student debt. She did. He promised to take care of everything, and she believed him. Soon after, he stopped settling her credit card balances. Her score began to crater.</p><p>  麻烦始于三年。尼克请她辞掉工作，以帮助他开展业务。她做过。他告诉她去读研究生，而不用担心增加她现有的学生债务。她做过。他答应照顾好一切，她相信他。此后不久，他停止清算她的信用卡余额。她的分数开始下降。</p><p>  Still, Miriam stayed with him. They got married. They had three kids. Then one day, the FBI came to their house and arrested him. In federal court, the judge convicted him on nearly $250,000 of wire fraud. Miriam discovered the full extent of the tens of thousands of dollars in debt he’d racked up in her name. “The day that he went to prison, I had $250 cash, a house in foreclosure, a car up for repossession, three kids,” she says. “I went within a month from having a nanny and living in a nice house and everything to just really abject poverty.”</p><p>  尽管如此，米里亚姆还是陪在他身边。他们结了婚。他们有三个孩子。然后有一天，联邦调查局来到他们家并逮捕了他。在联邦法院，法官裁定他犯有近25万美元的电汇欺诈罪。 Miriam发现了他以她的名义累积的数万美元的债务。她说：“他入狱的那一天，我有250美元现金，一栋止赎房屋，一辆可以收回的汽车，三个孩子。” “我只有一​​个保姆，住在一个漂亮的房子里，一个月之内就摆脱了贫困。”</p><p>  Miriam is a survivor of what’s known as “coerced debt,” a form of abuse usually perpetrated by an intimate partner or family member. While economic abuse is a long-standing problem, digital banking has made it easier to open accounts and take out loans in a victim’s name, says Carla Sanchez-Adams, an attorney at Texas RioGrande Legal Aid. In the era of automated credit-scoring algorithms, the repercussions can also be far more devastating.</p><p>  Miriam是“强迫债务”的幸存者，“强迫债务”通常是亲密伴侣或家庭成员实施的一种虐待形式。德州RioGrande法律援助机构的律师卡拉·桑切斯·亚当斯（Carla Sanchez-Adams）表示，虽然经济滥用是一个长期存在的问题，但数字银行业务使以受害者的名义开户和提取贷款变得更加容易。在自动信用评分算法时代，影响还可能更大。</p><p>  Credit scores have been used for decades to assess consumer creditworthiness, but their scope is far greater now that they are powered by algorithms: not only do they consider vastly more data, in both volume and type, but they increasingly affect whether you can buy a car, rent an apartment, or get a full-time job. Their comprehensive influence means that if your score is ruined, it can be nearly impossible to recover. Worse, the algorithms are owned by private companies that don’t divulge how they come to their decisions. Victims can be sent in a downward spiral that sometimes ends in homelessness or a return to their abuser.</p><p>  信用评分已被用于评估消费者的信用度数十年，但由于采用了算法，因此信用评分的范围要大得多：它们不仅会考虑大量的数据（无论是数量还是类型）​​，而且会越来越影响您是否可以购买商品。汽车，租住公寓或获得全职工作。他们的综合影响力意味着，如果您的分数被破坏，几乎不可能恢复。更糟糕的是，这些算法归私有公司所有，它们不会透露他们如何做出决策。被害人可能会呈螺旋形下降，有时会导致无家可归或重返施虐者。</p><p>  Credit-scoring algorithms are not the only ones that affect people’s economic well-being and access to basic services. Algorithms now decide which children enter foster care, which patients receive medical care, which families get access to stable housing. Those of us with means can pass our lives unaware of any of this. But for low-income individuals, the rapid growth and adoption of automated decision-making systems has created a hidden web of interlocking traps.</p><p>  信用评分算法并不是唯一会影响人们的经济状况和获得基本服务的算法。现在，算法可以确定哪些儿童接受寄养，哪些患者接受医疗护理，哪些家庭可以使用稳定的住房。我们这些有钱的人可以在没有意识到任何这些的情况下度过我们的生活。但是对于低收入个人，自动决策系统的快速增长和采用已经创建了一个隐藏的环环相扣的网络。 </p><p>  Fortunately, a growing group of civil lawyers are beginning to organize around this issue. Borrowing a playbook from the criminal defense world’s pushback against risk-assessment algorithms, they’re seeking to educate themselves on these systems, build a community, and develop litigation strategies. “Basically every civil lawyer is starting to deal with this stuff, because all of our clients are in some way or another being touched by these systems,” says Michele Gilman, a clinical law professor at the University of Baltimore. “We need to wake up, get training. If we want to be really good holistic lawyers, we need to be aware of that.”</p><p>幸运的是，越来越多的民事律师开始围绕这一问题进行组织。他们借鉴了刑事辩护世界对风险评估算法的抵制中的一本剧本，他们寻求在这些系统上进行自我教育，建立社区并制定诉讼策略。巴尔的摩大学临床法教授米歇尔·吉尔曼（Michele Gilman）说：“基本上，每个民事律师都开始处理这些问题，因为我们的所有客户在某种程度上都受到这些系统的影响。” “我们需要醒来，接受培训。如果我们想成为真正的优秀整体律师，我们需要意识到这一点。”</p><p>    Gilman has been practicing law in Baltimore for 20 years. In her work as a civil lawyer and a poverty lawyer, her cases have always come down to the same things: representing people who’ve lost access to basic needs, like housing, food, education, work, or health care. Sometimes that means facing off with a government agency. Other times it’s with a credit reporting agency, or a landlord. Increasingly, the fight over a client’s eligibility now involves some kind of algorithm.</p><p>    Gilman在巴尔的摩执业20年。在担任民事律师和贫困律师的过程中，她的案件总是归结为同一件事：代表那些无法获得基本需求（例如住房，食物，教育，工作或医疗保健）的人们。有时，这意味着要与政府机构对峙。有时是与信用报告机构或房东联系。现在，争夺客户资格的斗争越来越多地涉及某种算法。</p><p>  “This is happening across the board to our clients,” she says. “They’re enmeshed in so many different algorithms that are barring them from basic services. And the clients may not be aware of that, because a lot of these systems are invisible.”</p><p>  她说：“这对我们的客户来说是全方位的。” “他们陷入了许多不同的算法中，从而无法使用基本服务。客户可能没有意识到这一点，因为其中许多系统都是不可见的。”</p><p>    She doesn’t remember exactly when she realized that some eligibility decisions were being made by algorithms. But when that transition first started happening, it was rarely obvious. Once, she was representing an elderly, disabled client who had inexplicably been cut off from her Medicaid-funded home health-care assistance. “We couldn’t find out why,” Gilman remembers. “She was getting sicker, and normally if you get sicker, you get more hours, not less.”</p><p>    她不记得确切的时间，当她意识到某些资格决策是由算法做出的。但是，当这种转变首次开始发生时，这种情况很少见。曾经，她代表一位残疾的老年患者，她莫名其妙地被医疗补助资助的家庭医疗保健服务切断了。 “我们找不到原因，”吉尔曼回忆道。 “她病了，通常，如果你病了，你会得到更多的时间，而不是更少。”</p><p>  Not until they were standing in the courtroom in the middle of a hearing did the witness representing the state reveal that the government had just adopted a new algorithm. The witness, a nurse, couldn’t explain anything about it. “Of course not—they bought it off the shelf,” Gilman says. “She’s a nurse, not a computer scientist. She couldn’t answer what factors go into it. How is it weighted? What are the outcomes that you’re looking for? So there I am with my student attorney, who’s in my clinic with me, and it’s like, ‘Oh, am I going to cross-examine an algorithm?’”</p><p>  直到他们在听证会中站在法庭上时，代表国家的证人才透露政府刚刚采用了一种新算法。证人，护士，对此无能为力。 “当然不是，他们是现成的，”吉尔曼说。 “她是护士，而不是计算机科学家。她无法回答是什么因素造成的。如何加权？您正在寻找什么结果？因此，我和我的诊所的学生律师在一起，就像，‘哦，我要对算法进行交叉检查吗？’”</p><p>  For Kevin De Liban, an attorney at Legal Aid of Arkansas, the change was equally insidious. In 2014, his state also instituted a new system for distributing Medicaid-funded in-home assistance, cutting off a whole host of people who had previously been eligible. At the time, he and his colleagues couldn’t identify the root problem. They only knew that something was different. “We could recognize that there was a change in assessment systems from a 20-question paper questionnaire to a 283-question electronic questionnaire,” he says.</p><p>  对于阿肯色州法律援助处的律师凯文·德利班（Kevin De Liban）而言，这项变更同样具有隐蔽性。 2014年，他所在的州还建立了一种新的系统，用于分配医疗补助资助的家庭援助，从而切断了一大批以前有资格的人。当时，他和他的同事们无法确定根本问题。他们只知道有些不同。他说：“我们可以意识到评估系统已经从20个问题的纸质问卷转变为283个问题的电子问卷。”</p><p>  It was two years later, when an error in the algorithm once again brought it under legal scrutiny, that De Liban finally got to the bottom of the issue. He realized that nurses were telling patients, “Well, the computer did it—it’s not me.” “That’s what tipped us off,” he says. “If I had known what I knew in 2016, I would have probably done a better job advocating in 2014,” he adds.</p><p>  两年后，当算法中的错误再次使其受到法律审查时，De Liban终于找到了根底。他意识到护士在告诉病人：“好吧，电脑做到了–不是我。”他说：“这就是给我们的提示。”他补充说：“如果我知道2016年的知识，我可能会在2014年做得更好。” </p><p>    Gilman has since grown a lot more savvy. From her vantage point representing clients with a range of issues, she’s observed the rise and collision of two algorithmic webs. The first consists of credit-reporting algorithms, like the ones that snared Miriam, which affect access to private goods and services like cars, homes, and employment. The second encompasses algorithms adopted by government agencies, which affect access to public benefits like health care, unemployment, and child support services.</p><p>从那以后，吉尔曼变得更加精明。从代表客户解决一系列问题的角度出发，她观察到两种算法网络的兴起和冲突。第一种方法包括信用报告算法，例如困扰Miriam的算法，这会影响对私人物品和服务（如汽车，房屋和就业机会）的获取。第二类包括政府机构采用的算法，这些算法会影响人们获得诸如医疗保健，失业和儿童抚养服务之类的公共利益。</p><p>  On the credit-reporting side, the growth of algorithms has been driven by the proliferation of data, which is easier than ever to collect and share. Credit reports aren’t new, but these days their footprint is far more expansive. Consumer reporting agencies, including credit bureaus, tenant screening companies, or check verification services, amass this information from a wide range of sources: public records, social media, web browsing, banking activity, app usage, and more. The algorithms then assign people “worthiness” scores, which figure heavily into background checks performed by lenders, employers, landlords, even schools.</p><p>  在信用报告方面，算法的增长受到数据扩散的推动，数据的收集和共享比以往任何时候都更加容易。信用报告并不是什么新鲜事物，但是如今，它们的影响范围要大得多。消费者报告机构（包括征信机构，租户筛选公司或支票验证服务）从广泛的来源收集此信息：公共记录，社交媒体，Web浏览，银行活动，应用使用情况等。然后，算法为人们分配“有价值”分数，这些分数在贷方，雇主，房东甚至学校进行的背景调查中占很大比重。</p><p>  Government agencies, on the other hand, are driven to adopt algorithms when they want to modernize their systems. The push to adopt web-based apps and digital tools began in the early 2000s and has continued with a move toward more data-driven automated systems and AI. There are good reasons to seek these changes. During the pandemic, many unemployment benefit systems struggled to handle the massive volume of new requests, leading to significant delays. Modernizing these legacy systems promises faster and more reliable results.</p><p>  另一方面，当政府机构想要现代化其系统时，他们被迫采用算法。采用基于Web的应用程序和数字工具的努力始于2000年代初，并随着向更多数据驱动的自动化系统和AI的发展而继续。有充分的理由寻求这些改变。在大流行期间，许多失业救济金制度都在努力处理大量的新要求，导致大量延误。这些旧系统的现代化有望带来更快，更可靠的结果。</p><p>  But the software procurement process is rarely transparent, and thus lacks accountability. Public agencies often buy automated decision-making tools directly from private vendors. The result is that when systems go awry, the individuals affected——and their lawyers—are left in the dark. “They don’t advertise it anywhere,” says Julia Simon-Mishel, an attorney at Philadelphia Legal Assistance. “It’s often not written in any sort of policy guides or policy manuals. We’re at a disadvantage.”</p><p>  但是软件采购流程很少透明，因此缺乏责任感。公共机构通常直接从私人供应商那里购买自动决策工具。结果是，当系统出现故障时，受影响的个人（及其律师）就被蒙在鼓里。费城法律援助律师事务所的茱莉亚·西蒙·米希尔（Julia Simon-Mishel）说：“他们不会在任何地方做广告。” “通常不会以任何形式的政策指南或政策手册来撰写。我们处于不利地位。”</p><p>  The lack of public vetting also makes the systems more prone to error. One of the most egregious malfunctions happened in Michigan in 2013. After a big effort to automate the state’s unemployment benefits system, the algorithm  incorrectly flagged over 34,000 people for fraud. “It caused a massive loss of benefits,” Simon-Mishel says. “There were bankruptcies; there were unfortunately suicides. It was a whole mess.”</p><p>  缺乏公众审查也使系统更容易出错。最严重的故障之一发生在2013年的密歇根州。在努力使该州的失业救济金系统自动化之后，该算法错误地将34,000多人标记为欺诈。 “这造成了福利的巨大损失，”西蒙·米瑟尔（Simon-Mishel）说。 “有破产；不幸的是有自杀。真是一团糟。”</p><p>    Low-income individuals bear the brunt of the shift toward algorithms. They are the people most vulnerable to temporary economic hardships that get codified into consumer reports, and the ones who need and seek public benefits. Over the years, Gilman has seen more and more cases where clients risk entering a vicious cycle. “One person walks through so many systems on a day-to-day basis,” she says. “I mean, we all do. But the consequences of it are much more harsh for poor people and minorities.”</p><p>    低收入者首当其冲地转向算法。他们是最容易受到暂时经济困难影响的人，这些人被编入消费者报告，是需要和寻求公共利益的人。多年来，吉尔曼（Gilman）看到越来越多的客户冒着进入恶性循环的风险。她说：“一个人每天都要走过这么多系统。” “我是说，我们都这样做。但是它给穷人和少数民族带来的后果更加严峻。”</p><p>  She brings up a current case in her clinic as an example. A family member lost work because of the pandemic and was denied unemployment benefits because of an automated system failure. The family then fell behind on rent payments, which led their landlord to sue them for eviction. While the eviction won’t be legal because of  the CDC’s moratorium, the lawsuit will still be logged in public records. Those records could then feed into tenant-screening algorithms, which could make it harder for the family to find stable housing in the future. Their failure to pay rent and utilities could also be a ding on their credit score, which once again has repercussions. “If they are trying to set up cell-phone service or take out a loan or buy a car or apply for a job, it just has these cascading ripple effects,” Gilman says.</p><p>  她以自己诊所中的一个当前病例为例。一名家庭成员因大流行而失业，并由于自动系统故障而被剥夺了失业救济金。一家人随后拖欠房租，导致房东起诉他们驱逐。尽管由于疾病预防控制中心的暂停而驱逐将不合法，但诉讼仍将记录在公共记录中。这些记录然后可以输入到租户筛选算法中，这会使家庭在将来很难找到稳定的住房。他们未能支付房租和水电费也可能是其信用评分的低谷，这再次产生了影响。吉尔曼说：“如果他们试图建立手机服务，贷款，购买汽车或申请工作，就会产生连锁反应。” </p><p>    In September, Gilman, who is currently a faculty fellow at the Data and Society research institute,  released a report documenting all the various algorithms that poverty lawyers might encounter. Called  Poverty Lawgorithms, it’s meant to be a guide for her colleagues in the field. Divided into specific practice areas like consumer law, family law, housing, and public benefits, it explains how to deal with issues raised by algorithms and other data-driven technologies within the scope of existing laws.</p><p>9月，现任数据与社会研究所研究员的吉尔曼（Gilman）发表了一份报告，记录了贫困律师可能会遇到的所有各种算法。这就是所谓的“贫困法”，旨在为她在该领域的同事们提供指导。它分为特定的实践领域，例如消费者法，家庭法，住房法和公共利益法，解释了如何在现有法律范围内处理算法和其他数据驱动技术引起的问题。</p><p>  If a client is denied an apartment because of a poor credit score, for example, the report recommends that a lawyer first check whether the data being fed into the scoring system is accurate. Under the Fair Credit Reporting Act, reporting agencies are required to ensure the validity of their information, but this doesn’t always happen. Disputing any faulty claims could help restore the client’s credit and, thus, access to housing. The report acknowledges, however, that existing laws can only go so far. There are still regulatory gaps to fill, Gilman says.</p><p>  例如，如果客户因信用评分差而被拒绝入住公寓，该报告建议律师首先检查输入计分系统的数据是否准确。根据《公平信用报告法》，报告机构必须确保其信息的有效性，但这并非总是如此。对任何错误的索赔提出异议可以帮助恢复客户的信誉，从而获得住房。该报告承认，然而，现有法律只能走得那么远。吉尔曼说，仍有监管空白需要填补。</p><p>  Gilman hopes the report will be a wake-up call. Many of her colleagues still don’t realize any of this is going on, and they aren’t able to ask the right questions to uncover the algorithms. Those who are aware of the problem are scattered around the US, learning about, navigating, and fighting these systems in isolation. She sees an opportunity to connect them and create a broader community of people who can help one another. “We all need more training, more knowledge—not just in the law, but in these systems,” she says. “Ultimately it’s like every case is going to turn into an algorithm case.”</p><p>  吉尔曼希望这份报告能引起人们的注意。她的许多同事仍然没有意识到这一切正在发生，并且他们无法提出正确的问题来揭示算法。那些意识到问题的人分散在美国各地，孤立地学习，导航和对抗这些系统。她认为有机会将他们联系起来，并创建一个可以互相帮助的广泛社区。她说：“我们所有人都需要更多的培训，更多的知识-不仅在法律上，而且在这些系统上。” “最终，好像每种情况都将变成算法情况。”</p><p>  In the long run, she looks to the criminal legal world for inspiration. Criminal lawyers have been “ahead of the curve,” she says, in organizing as a community and pushing back against risk-assessment algorithms that determine sentencing. She wants to see civil lawyers do the same thing: create a movement to bring more public scrutiny and regulation to the hidden web of algorithms their clients face. “In some cases, it probably should just be shut down because there’s no way to make it equitable,” she says.</p><p>  从长远来看，她希望从刑事法律界获得启发。她说，在作为一个社区组织起来并反对确定判决的风险评估算法时，刑事律师一直处于“领先地位”。她希望看到民事律师也做同样的事情：发起一项运动，将更多的公众审查和监管带给客户面对的隐藏算法网络。她说：“在某些情况下，可能应该将其关闭，因为没有办法使它公平。”</p><p>  As for Miriam, after Nick’s conviction, she walked away for good. She moved with her three kids to a new state and connected with a nonprofit that supports survivors of coerced debt and domestic violence. Through them, she took a series of classes that taught her how to manage her finances. The organization helped her dismiss many of her coerced debts and learn more about credit algorithms. When she went to buy a car, her credit score just barely cleared the minimum with her dad as co-signer. Since then, her consistent payments on her car and her student debt have slowly replenished her credit score.</p><p>  至于米莉安（Miriam），在尼克被定罪后，她永远离开了。她带着三个孩子搬到了一个新州，并与一家非营利组织建立了联系，该组织为遭受债务逼迫和家庭暴力的幸存者提供支持。通过他们，她参加了一系列的课程，教她如何管理财务。该组织帮助她解除了许多强制性债务，并了解了有关信贷算法的更多信息。当她去买车时，她的信用评分几乎没有超过父亲作为共同签字人的最低要求。从那以后，她对汽车的一贯付款和学生的欠款逐渐补充了她的信用评分。</p><p>  Miriam still has to stay vigilant. Nick has her Social Security number, and they’re not yet divorced. She worries constantly that he could open more accounts, take out more loans in her name. For a while, she checked her credit report daily for fraudulent activity. But these days, she also has something to look forward to. Her dad, in his mid-60s, wants to retire and move in. The two of them are now laser-focused on preparing to buy a home. “I’m pretty psyched about it. My goal is by the end of the year to get it to a 700,” she says of her score, “and then I am definitely home-buyer ready.”</p><p>  Miriam仍然必须保持警惕。尼克拥有她的社会安全号码，他们尚未离婚。她一直担心他会开更多的账户，以她的名义借出更多的贷款。有一段时间，她每天检查她的信用报告是否存在欺诈行为。但是这些天，她也有期待的事情。她的父亲在六十多岁的时候想退休并搬进来。他们两个现在都集中精力准备买房。 “我对此很激动。我的目标是到今年年底达到700分，”她谈到自己的成绩时说，“然后我肯定会为购房者做好准备。”</p><p>  “I’ve never lived in a house that I’ve owned, ever,” she adds. “He and I are working together to save for a forever home.”</p><p>  她补充说：“我从未住过自己拥有的房屋。” “他和我正在共同努力，以保存一个永久的家。” </p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://www.technologyreview.com/2020/12/04/1013068/algorithms-create-a-poverty-trap-lawyers-fight-back/">https://www.technologyreview.com/2020/12/04/1013068/algorithms-create-a-poverty-trap-lawyers-fight-back/</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/算法/">#算法</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/war/">#war</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/分享/">#分享</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy; 2020 diglog.com </div></div></body></html>