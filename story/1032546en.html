<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>为什么皮肤损伤是花生，而脑瘤是坚硬的坚果</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">为什么皮肤损伤是花生，而脑瘤是坚硬的坚果</h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2020-11-01 05:42:28</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2020/11/d5e8e075af2e9e7b24f2df6f0866e641.png"><img src="http://img2.diglog.com/img/2020/11/d5e8e075af2e9e7b24f2df6f0866e641.png" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>Why are some problems in medical image analysis harder than others for AI, and what can we do about them?</p><p>为什么医学图像分析中的一些问题对AI来说比其他问题更难，我们能做些什么呢？</p><p> In a landmark paper [1], Alan Turing proposed a test to evaluate the intelligence of a computer. This test, later aptly named the  Turing Test, describes a person interacting with either a computer or another human through written notes. If the person cannot tell who is who, the computer passes the test and we can conclude it displays human-level intelligent behavior.</p><p>在一篇里程碑式的论文[1]中，艾伦·图灵提出了一项评估计算机智能的测试。这项测试后来被恰当地命名为图灵测试，描述了一个人通过书面笔记与计算机或另一个人进行互动。如果这个人分不清谁是谁，计算机就会通过测试，我们可以得出结论，它显示出人类水平的智能行为。</p><p> In another landmark paper [2] a bit over a decade later, Gwilym Lodwick, a musculoskeletal radiologist far ahead of his time, proposed using computers to examine medical images and imagined</p><p>在十多年后的另一篇里程碑式的论文[2]中，远远领先于他那个时代的肌肉骨骼放射科医生格威姆·洛德威克(Gwilym Lodwick)提出使用计算机检查医学图像，并设想。</p><p> &#34;[...] a library of diagnostic programs effectively employed may permit any competent diagnostic radiologist to become the equivalent of an international expert [...].&#34;</p><p>&#34；[...]。有效使用的诊断程序库可以使任何称职的诊断放射科医生成为国际专家的等价物[...]。</p><p> He coined the term computer-aided diagnosis (CAD) to refer to computer systems that help radiologists interpret and quantify abnormalities from medical images. This led to a whole new field of research combining computer science with radiology.</p><p>他创造了计算机辅助诊断(CAD)这个术语，指的是帮助放射科医生解释和量化医学图像中的异常情况的计算机系统。这导致了计算机科学和放射学相结合的一个全新的研究领域。</p><p> With the advent of efficient deep learning algorithms, people have become more ambitious and the field of computer &#34;aided&#34; diagnosis is slowly changing to &#34;computerized&#34; diagnosis. Geoffrey Hinton even went as far as stating that we should stop training radiologists immediately because deep neural networks will likely outperform humans in all areas,  five or ten years from now.</p><p>随着高效深度学习算法的出现，人们变得更加雄心勃勃，计算机辅助诊断领域正慢慢转向计算机化诊断。杰弗里·辛顿甚至声称，我们应该立即停止培训放射科医生，因为从现在开始的五年或十年后，深层神经网络很可能在所有领域都会比人类表现得更好。</p><p> For a computer to be accepted as a viable substitute for a trained medical professional, however, it seems fair to require it to surpass or at least perform on par with humans. This  &#34;Turing test for medical image analysis&#34;, as it is often referred to, is close to being solved for some medical problems but many are still pending. What explains this difference? What makes one problem harder than the other?</p><p>然而，要让计算机被接受为训练有素的医学专业人员的可行替代品，要求它超过人类，或者至少与人类平起平坐，似乎是公平的。这个医学图像分析的图灵测试，就像它经常被提到的那样，对于一些医学问题即将得到解决，但许多问题仍然悬而未决。如何解释这种差异呢？是什么让一个问题比另一个更难？</p><p> This article presents an informal analysis of the learnability of medical imaging problems and decomposes it into three main components:</p><p>本文对医学成像问题的可学习性进行了非正式分析，并将其分解为三个主要部分：</p><p>  We will subsequently analyze a set of papers, all claiming human-level performance on some medical image analysis tasks to see what they have in common. After that, we will summarize the insights and present an outlook.</p><p>我们随后将分析一组论文，所有这些论文都声称在一些医学图像分析任务中具有人类水平的性能，看看它们有什么共同之处。之后，我们将总结真知灼见，并提出展望。</p><p>  Machine learning algorithms essentially extract and compress information from a set of training examples to solve a certain task. In the case of supervised learning, this information can come from different sources: the labels and the samples. Roughly, the more data there is, the easier the problem is to learn. The less contaminated the data is, the easier the problem is to learn. The cleaner the labels are, the easier the problem is to learn. This is elaborated on below.</p><p>机器学习算法本质上是从一组训练样本中提取和压缩信息来解决某一特定任务。在监督学习的情况下，这些信息可以来自不同的来源：标签和样本。粗略地说，数据越多，问题就越容易学习。数据污染越少，问题就越容易学习。标签越干净，问题就越容易学。这一点将在下面详细阐述。</p><p>  Training data is one of the most important elements for a successful machine learning application. For many computer vision problems, images can be mined from social media and annotated by non-experts. For medical data, this is not the case. It is often harder to obtain and requires expert knowledge to generate labels. Therefore, large publicly-available and well-curated datasets are still scarce.</p><p>训练数据是机器学习应用成功的最重要的元素之一。对于许多计算机视觉问题，图像可以从社交媒体中挖掘出来，并由非专家进行注释。对于医疗数据来说，情况并非如此。通常很难获得，并且需要专业知识来生成标签。因此，大型的公开可用的和精心策划的数据集仍然很稀缺。</p><p>  In spite of this, several (semi) publicly available datasets have emerged, such as the Kaggle diabetic retinopathy challenge [3], the LIDC-IDRI chest CT dataset [4], the NIH chest X-ray dataset [5], Stanford’s chest X-ray dataset [6], Radboud’s digital pathology datasets [7], the HAM10000 skin lesion dataset [8] and the OPTIMAM mammography dataset [9]. Example images of these datasets are shown in  Figure 1. The availability of these public datasets has accelerated the research and development of deep learning solutions for medical image analysis.</p><p>尽管如此，一些(半)公开的数据集已经出现，例如Kaggle糖尿病视网膜病变挑战[3]、LIDC-IDRI胸部CT数据集[4]、NIH胸部X射线数据集[5]、斯坦福的胸部X射线数据集[6]、Radboud的数字病理数据集[7]、HAM10000皮肤病变数据集[8]和OPTIMAM乳房X光照相数据集[9]。这些数据集的示例图像如图1所示。这些公共数据集的可用性加速了医学图像分析深度学习解决方案的研究和开发。</p><p>  Although the amount of available data is very important and often a limiting factor in many machine learning applications, it is not the only variable. Irrespective of the size of the data, feeding random noise to a statistical model will not result in the model learning to differentiate cats from dogs. We separate the data complexity into three types: image quality, dimensionality, and variability.</p><p>虽然在许多机器学习应用程序中，可用数据量非常重要，而且往往是一个限制因素，但它不是唯一的变量。无论数据的大小如何，向统计模型提供随机噪声不会导致模型学习区分猫和狗。我们将数据复杂性分为三种类型：图像质量、维数和可变性。</p><p>  Image quality has been an important topic of research from the beginning of medical image analysis and there are several aspects that define it [11]. The signal to noise ratio is often used to characterize quality, though other aspects such as the presence of artifacts, motion blur, and proper handling of the equipment also determine quality [12]. For example, in the case of mammography, the breast can be misplaced in the machine resulting in poor visibility of important structures. The image can be under or overexposed and artifacts such as pacemakers, implants or chemo ports can make the images hard to read. Examples of these are shown in  Figure 2.</p><p>从医学图像分析开始，图像质量就一直是一个重要的研究课题，它有几个方面的定义[11]。信噪比通常被用来表征质量，尽管其他方面，如伪影的存在、运动模糊和设备的正确处理也决定了质量[12]。例如，在乳房X光照相的情况下，乳房可能会被错放在机器中，导致重要结构的可见性很差。图像可能曝光不足或过度曝光，起搏器、植入物或化疗端口等伪影可能会使图像难以阅读。这些示例如图2所示。</p><p> There are many definitions of signal to noise ratio. From an ML perspective, one of the easiest is the fraction of task-relevant information over the total information in the image.</p><p>信噪比的定义有很多种。从ML的角度来看，最简单的方法之一是与任务相关的信息占图像中总信息的比例。</p><p>   The curse of dimensionality, a well-known problem from machine learning theory, describes the observation that with every feature dimension added, exponentially more data points are needed to get a reasonable filling of the space. Part of the curse has been lifted by the introduction of weight sharing in the form of convolutions and using very deep neural networks. However, medical images often come in far higher dimensional form than natural images (e.g., ImageNet has images of only 224x224).</p><p>维数灾难是机器学习理论中的一个众所周知的问题，它描述了这样的观察结果，即随着每个特征维数的增加，需要指数级增加的数据点才能获得合理的空间填充。通过引入卷积形式的权重分担和使用非常深入的神经网络，部分诅咒已经解除。然而，医学图像通常具有比自然图像高得多的维度形式(例如，ImageNet仅具有224x224的图像)。</p><p> 2D images with complex structures, 3D images from MRI and CT, and even 4D images (for instance, a volume evolving over time) are the norm. Complex data structures typically mean you have to handcraft an architecture that works well for the problem and exploit structures that you know are in the data to make models work, see for example [13, 14].</p><p>具有复杂结构的2D图像，来自MRI和CT的3D图像，甚至4D图像(例如，体积随着时间的演变)都是标准。复杂的数据结构通常意味着您必须手工制作一个能够很好地解决问题的体系结构，并利用您知道的数据中的结构来使模型工作，例如，请参见[13，14]。</p><p>  Scanners from different manufacturers use different materials, acquisition parameters, and post-processing algorithms [15, 16]. Different pathology labs use different stains [17]. Sometimes even data from the same lab taken with the same scanner will look different because of the person who handled the acquisition. These add complexity to the learning problem, because the model needs to become invariant, or engineers have to compensate for it by handcrafting preprocessing algorithms that normalize the data, employ heavy data augmentation or change network architectures to make them invariant to each irrelevant source.</p><p>不同制造商的扫描仪使用不同的材料、采集参数和后处理算法[15，16]。不同的病理实验室使用不同的染色方法[17]。有时，由于处理采集的人不同，即使是用同一扫描仪从同一实验室采集的数据看起来也会有所不同。这些都增加了学习问题的复杂性，因为模型需要变得不变，或者工程师必须通过手工制作预处理算法来弥补这一点，这些预处理算法对数据进行标准化，使用大量数据增强，或者改变网络体系结构，使它们对每个不相关的源都是不变的。</p><p>   Although unsupervised methods are rising in popularity, most problems are still tackled using supervision, in which case we have another source of complexity: the labels. We again separate three factors: (1) the label granularity which describes the detail at which the labels are provided, (2) the class complexity which refers to the complexity of the output space, and (3) the annotation quality, which relates to the label noise.</p><p>尽管无监督的方法越来越受欢迎，但大多数问题仍然是通过监督来解决的，在这种情况下，我们还有另一个复杂性的来源：标签。我们再次分离了三个因素：(1)描述提供标签的细节的标签粒度，(2)涉及输出空间复杂性的类别复杂度，以及(3)与标签噪声相关的标注质量。</p><p>  Data can be annotated at different levels of granularity. In general, the granularity of the label used during training, does not have to be the same as the granularity generated during inference. For instance, segmentation maps (a label for every pixel in the image) can be generated when training on image-level labels only (e.g., multiple-instance learning), reports can be generated when training on class labels only, class-level labels can be generated when training on pixel-level labels, etc. An overview is given in  Figure 4 and the configurations are elaborated on below.</p><p>数据可以在不同的粒度级别进行注释。通常，在训练期间使用的标签的粒度不必与在推理期间生成的粒度相同。例如，当仅在图像级标签上训练(例如，多实例学习)时可以生成分割图(图像中每个像素的标签)，当仅在类标签上训练时可以生成报告，当在像素级标签上训练时可以生成类级标签，等等。图4中给出了概述，下面详细说明配置。</p><p>  Pixel level labels - Segmentation: In this setting the algorithm is supplied with contour annotations and/or output labels for every pixel in the case. In earlier medical imaging systems, segmentations were often employed as a form of preprocessing for detection algorithms, but this became less common after the ImageNet revolution in 2012. Segmentation algorithms are also used for quantification of abnormalities which can again be used to get consistent readings in clinical trials or as preparation for treatment such as radiotherapy. For natural images, a distinction is often made between  instance-based and  semantic segmentation. In the first case, the algorithm should provide a different label for every instance of a class and in the second case, only for each class separately. This distinction is less common in biomedical imaging, where there is often only one instance of a class in an image (such as a tumor), and/or detecting one instance is enough to classify the image as positive.</p><p>像素级标签-分段：在此设置中，算法为案例中的每个像素提供轮廓注释和/或输出标签。在早期的医学成像系统中，分割通常被用作检测算法的一种预处理形式，但在2012年ImageNet革命之后，这种情况变得不那么常见了。分割算法也被用来量化异常，这可以再次用于在临床试验中获得一致的读数，或者作为放射治疗等治疗的准备。对于自然图像，通常在基于实例的分割和语义分割之间进行区分。在第一种情况下，算法应该为类的每个实例提供不同的标签，在第二种情况下，只为每个类单独提供不同的标签。这种区别在生物医学成像中不太常见，在生物医学成像中，图像(例如肿瘤)中通常只有一个类别的实例，和/或检测一个实例就足以将图像分类为阳性。</p><p> Bounding boxes - Detection: Instead of providing/generating a label for every pixel in the image, the annotator can also just draw a box around a region of interest. This can save time during annotation, but may provide lesser information: a box has four degrees of freedom, a contour usually more. It is difficult to tell the effect this has on algorithms.</p><p>边界框-检测：注释器也可以只在感兴趣的区域周围画一个框，而不是为图像中的每个像素提供/生成标签。这可以节省注释过程中的时间，但提供的信息可能较少：长方体有四个自由度，轮廓通常更多。很难说这对算法有什么影响。</p><p> Study level labels - Classification: Yet another simpler way to annotate would be to just flag cases with a specific abnormality. This makes a lot of sense for problems where the whole study is already a crop around the pathology in question, such as skin lesion classification and classifying abnormalities in color fundus imaging. This is much harder for other problems, such as the detection of breast cancer where a study is typically a time series of four large images and pathologies only constitute a fraction of the total study size. The algorithm first has to learn which parts of the image are relevant and then learn the actual features.</p><p>研究级别标签-分类：另一种更简单的注释方式是只标记具有特定异常的病例。这对于整个研究已经是围绕相关病理的作物的问题很有意义，例如皮肤病变分类和彩色眼底成像中的异常分类。对于其他问题来说，这要困难得多，比如乳腺癌的检测，在这种情况下，一项研究通常是由四张大图像组成的时间序列，而病理只占总研究规模的一小部分。该算法首先要学习图像的哪些部分是相关的，然后才能学习实际的特征。</p><p> Reports - R  eport generation: Again, a simpler way to annotate is to use labels extracted directly from the radiology reports, instead of annotators. This type of label is sometimes referred to as silver standard annotation [18]. Learning from this data is likely difficult because natural language processing needs to be employed first, to extract labels from the report, potentially increasing label noise. Within this type of label, we can make one more distinction: structured or unstructured reports. In the first case, the doctor was constrained to a specific standard, in the latter case the doctor was free to write what they wanted. Whichever is best is an interesting debate: unstructured reports have the potential to contain more information but are more difficult to parse.</p><p>报告-报告生成：同样，更简单的注解方式是使用直接从放射学报告中提取的标签，而不是注释器。这种类型的标签有时被称为银标注释[18]。从这些数据中学习可能很困难，因为需要首先使用自然语言处理来从报告中提取标签，这可能会增加标签噪声。在这类标签中，我们可以再做一个区分：结构化报告或非结构化报告。在第一种情况下，医生被限制在一个特定的标准，在后一种情况下，医生可以自由地写他们想要的东西。无论哪一个最好，都是一个有趣的争论：非结构化报告有可能包含更多信息，但更难解析。</p><p>    There is a difference between classifying images into two different classes or 1000 different classes. The first case means splitting the space in two separable regions, the latter into 1000, which is likely harder.</p><p>将图像分类为两个不同的类别或1000个不同的类别之间存在差异。第一种情况意味着将空间分成两个可分离的区域，后者分成1000个，这可能更难。</p><p>  In many applications, for example, detecting abnormalities in chest X-ray, one sample can have multiple labels at the same time. This is illustrated in  Figure 6, which shows a circular diagram of the co-occurrence of classes in the Chest X-ray 8 dataset.</p><p>在许多应用中，例如，检测胸部X光中的异常，一个样本可以同时具有多个标签。这如图6所示，它显示了胸部X光8数据集中的类的共现关系的圆形图。</p><p>   Apart from the granularity of annotation, there is one more factor that can influence learnability and the eventual performance of the AI algorithm: the accuracy of the annotation. There are essentially two ways to handle annotations for most medical imaging problems: using a human reference or some other test that is known to be more accurate than the human.</p><p>除了标注的粒度外，还有一个因素可以影响人工智能算法的可学习性和最终性能：标注的准确性。对于大多数医学成像问题，基本上有两种方法来处理注释：使用人类参考或其他已知比人类更准确的测试。</p><p>  If the labels are generated by medical professionals there is often a significant amount of  inter-reader variability (different readers give different labels for the same sample) and  intra-reader variability (the same reader gives different labels for the same sample, when annotated at different times). This disagreement results in label noise which makes it more difficult to train good models.</p><p>如果标签是由医学专业人员生成的，则通常存在大量的读取器间的可变性(不同的读取器对同一样本给出不同的标签)和读取器内的可变性(同一读取器在不同的时间对同一样本进行注释时给出不同的标签)。这种不一致导致了标签噪声，这使得训练好的模型变得更加困难。</p><p> An important corollary of this is that using these labels to evaluate the model, it will be hard to show you actually outperform humans. Problems using this type of label are therefore label-limited: even if we have the best possible architecture, an infinite amount of training data, and compute power, we will never be able to outperform humans by a large margin, since they define the ground truth.</p><p>这其中一个重要的推论是，使用这些标签来评估模型，很难证明你实际上比人类表现得更好。因此，使用这类标签的问题是受标签限制的：即使我们拥有最好的可能架构、无限数量的训练数据和计算能力，我们也永远无法大幅超越人类，因为他们定义了基本事实。</p><p>  Imaging is often used as a first test because it is typically cheap and non-invasive. If something suspicious is found, the patient is subjected to more tests that have a higher accuracy. For example, in chest X-ray images, we sometimes have microbial culture to confirm the patient has tuberculosis. For the detection of tumors, biopsies and histopathological outcomes can be employed. These types of labels provide a less noisy and more accurate ground truth.</p><p>成像通常被用作第一次检查，因为它通常是廉价和非侵入性的。如果发现可疑的东西，患者会接受更多的、准确度更高的检查。例如，在胸部X光图像中，我们有时会进行微生物培养，以确认患者是否患有结核病。对于肿瘤的检测，可以采用活组织检查和组织病理学结果。这些类型的标签提供了更少的噪音和更准确的地面事实。</p><p> Problems using these labels are data-limited: if we just give an algorithm enough data, train it well and use the right architecture it should be able to outperform humans at some point, provided the second test is better than the human reading the image.</p><p>使用这些标签的问题是受数据限制的：如果我们只给一个算法足够的数据，对它进行良好的训练，并使用正确的架构，它应该能够在某个时候超越人类，前提是第二次测试比阅读图像的人更好。</p><p>  To get a better understanding of the state-of-the-art and what more is in store, we will analyze a few recent papers. This is by no means intended as an exhaustive list nor do we claim the results in the papers are accurate. All claims about (super) human performance become more trustworthy in prospective clinical trials, when data and source code are made publicly available, or when methods are evaluated in challenges.</p><p>为了更好地了解最新的技术和未来的发展，我们将分析几篇最近的论文。这绝不是一个详尽的清单，我们也不认为论文中的结果是准确的。在未来的临床试验中，当数据和源代码公之于众时，或者当方法在挑战中进行评估时，所有关于(超级)人类表现的说法都变得更加可信。</p><p> The table below presents a summary of each paper, the data the model was trained on, and the labels that were used for the problem. For a more rigorous, clinically oriented overview, please refer to [19] and [20].</p><p>下表提供了每篇论文的摘要、模型训练所依据的数据以及用于问题的标签。有关更严格的、面向临床的概述，请参考[19]和[20]。</p><p> Rajpurkar, Pranav, et al. &#34;Chexnet: Radiologist-level pneumonia detection on chest x-rays with deep learning.&#34; arXiv preprint arXiv:1711.05225 (2017).</p><p>Rajpurkar，Pranav等人。Chexnet：基于深度学习的胸部x光片的放射科医师级肺炎检测。arxiv预印本：1711.05225(2017年)。</p><p>  A model for the automatic detection of (radiological evidence of) pneumonia.Human performance is claimed by comparing it to the radiological label of several radiologists</p><p>一种自动检测肺炎(的放射证据)的模型。通过将其与几位放射科医生的放射标签进行比较来断言人类的表现。</p><p>    The dataset contains labels for 14 pathologies, which are extracted using NLP, therefore, silver standard labels were used. However, only signs of pneumonia or not is used as a label.The problem is label limited, the system is compared against labels defined by radiologists.</p><p>该数据集包含14种病理的标签，这些标签是使用NLP提取的，因此，使用了银标准标签。不过，只有肺炎的征兆才用作标签，问题只限於标签，该系统会与放射科医生所订的标签作比较。</p><p>  Putha, Preetham, et al. &#34;Can Artificial Intelligence Reliably Report Chest X-Rays?: Radiologist Validation of an Algorithm trained on 2.3 Million X-Rays.&#34; arXiv preprint arXiv:1807.07455 (2018).</p><p>Putha，Preetham等人。人工智能可以可靠地报告胸部X光吗？：放射科医生对训练了230万次X光的算法进行了验证。&#34；arxiv预印本：1807.07455(2018年)。</p><p>  Nine different findings were detected using different models trained for each finding.Human performance was shown for about four pathologies.</p><p>使用为每个发现训练的不同模型检测到九种不同的发现。大约有四种病理显示了人类的表现。</p><p>  Around 120K frontal view X-rays.2D single view images downscaled to 224 x 224.A total of 1.2 million chest X-rays were used, downscaled to an unspecified size.Normalization techniques were applied to reduce variation.</p><p>大约120K正视X光。2D单视图像缩小到224x222。总共使用了120万张胸部X光，缩小到未指明的大小。应用归一化技术来减少变异。</p><p>  The labels were extracted using NLP from the radiology reports and are therefore silver standard labels. Multi-class labels, treated as a binary classification problem.</p><p>这些标签是使用NLP从放射学报告中提取的，因此是银标准标签。多类标签，将其视为二进制分类问题。</p><p>  Irvin, Jeremy, et al. &#34;Chexpert: A large chest radiograph dataset with uncertainty labels and expert comparison.&#34; Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 33. 2019.</p><p>欧文、杰里米等人。ChExpert：具有不确定性标签和专家比较的大型胸部X光照片数据集。AAAI人工智能会议论文集。第33卷。2019年。</p><p>  A model was trained to discriminate between 14 different findings. Human performance is shown for five of those abnormalities.</p><p>一个模型被训练来区分14个不同的发现。这些异常中的五个都显示了人类的表现。</p><p>    Labels extracted using NLP (silver standard labels), label limited.One model is trained for each pathologyIn addition, uncertainty based labels were used.</p><p>采用NLP(银色标准标签)提取标签，标签受限，为每个病理组织训练一个模型，并使用基于不确定性的标签。</p><p>  Hwang, Eui Jin, et al. &#34;Development and validation of a deep learning–based automated detection algorithm for major thoracic diseases on chest radiographs.&#34; JAMA network open 2.3 (2019): e191095-e191095.</p><p>Hwang，Eui jin，等人。基于深度学习的胸片上主要胸部疾病自动检测算法的开发和验证。&#34；JAMA NETWORK OPEN 2.3(2019年)：e191095-e191095。</p><p>  An algorithm is proposed to detect four abnormalities in chest radiographs.The model is compared to 15 physicians and shown to have higher performance</p><p>提出了一种检测四种胸片异常的算法，并与15名医生进行了比较，结果表明该算法具有较高的检测性能。</p><p>  About 55K radiographs with normal findings and 35K with abnormal findings where used to develop the model.</p><p>约有55K张X线片发现正常，35K张发现异常，用来制作模型。</p><p>  Binary classification, four abnormalities merged into one. Mix of histopathology/external test and radiological labels were used. Largely a label limited problem.</p><p>二分类，四种异常合并为一种。采用组织病理学/外部试验和放射学标签相结合的方法。很大程度上是标签限制的问题。</p><p>  Nam, Ju Gang, et al. &#34;Development and validation of deep learning–based automatic detection algorithm for malignant pulmonary nodules on chest radiographs.&#34; Radiology 290.1 (2019): 218-228.</p><p>南、鞠刚等人。基于深度学习的胸片恶性肺结节自动检测算法的开发与验证。放射学290.1(2019年)：第218-228页。</p><p>  A model was trained to detect malignant pulmonary nodules on chest radiographs.The model was compared to 18 human readers and showed superior performance to the majority of them.</p><p>一个模型被训练来检测胸片上的恶性肺结节，该模型与18个人类读取器进行了比较，显示出优于大多数读取器的性能。</p><p>    Both pixel level and image level labels were used for training. The malignancies were biopsy proven, this is therefore a daa limited problem. The problem was phrased as a binary classification.</p><p>像素级和图像级标签都用于训练。恶性肿瘤是经活检证实的，因此这是一个非常有限的问题。这个问题被表述为二进制分类。</p><p>  Ardila, Diego, et al. &#34;End-to-end lung cancer screening with three-dimensional deep learning on low-dose chest computed tomography.&#34; Nature medicine 25.6 (2019): 954-961.</p><p>阿迪拉、迭戈等人。基于低剂量胸部CT的三维深度学习的端到端肺癌筛查。自然医学25.6(2019)：954-961。</p><p>  A deep neural network is shown to outperform 6 human readers in classifying lung cancer in low dose CT</p><p>深度神经网络在低剂量CT肺癌分类中的表现优于6位人类阅读器。</p><p>  42K low dose CT scans, cropped and resized to 240 x 240 x 240. (3D data)</p><p>42K低剂量CT扫描，裁剪并调整大小为240x240x240。(3D数据)。</p><p>  Different components of the model were trained on either the region level or case level labels (outcome determined by biopsy).Biopsy proven malignancies were used (data limited). Binary classification</p><p>模型的不同部分在区域水平或病例水平的标签上进行训练(结果由活检决定)。使用的是经生物学证实的恶性肿瘤(数据有限)。二进制分类。</p><p>  McKinney, Scott Mayer, et al. &#34;International evaluation of an AI system for breast cancer screening.&#34; Nature 577.7788 (2020): 89-94.</p><p>麦金尼、斯科特·迈耶等人。乳腺癌筛查人工智能系统的国际评估，“自然”杂志577.7788(2020年)：89-94页。</p><p>  A DNN is trained to detect breast cancer in screening mammography. The model is compared to a UK and US dataset and shown to outperform radiologists on both sets.</p><p>DNN被训练来在筛查乳房X光检查中检测乳腺癌。该模型与英国和美国的数据集进行了比较，并显示出在这两个数据集上的表现都优于放射科医生。</p><p>  The model was trained on about 130K mammograms. A mammogram comprises four views, two of each breast.</p><p>这位模特接受了大约130K的乳房X光检查培训。乳房X光照片由四个视图组成，每个乳房两个视图。</p><p>  Binary classification. The ground truth was determined based on histopathology reports. This is a data limited problem.</p><p>二进制分类。基本事实是根据组织病理学报告确定的。这是一个数据受限的问题。</p><p>  Esteva, A., Kuprel, B., Novoa, R.A., Ko, J., Swetter, S.M., Blau, H.M. and Thrun, S., 2017. Dermatologist-level classification of skin cancer with deep neural networks. Nature, 542(7639), pp.115-118.</p><p>Esteva，A.，Kuprel，B.，Novoa，R.A.，Ko，J.，Swetter，S.M.，Blau，H.M.和Thrun，S.，2017。用深度神经网络对皮肤癌进行皮肤科医生级分类。“自然”，542(7639)，第115-118页。</p><p>  A model is proposed that classifies dermatology images into malignant or benign and is compared to 21 certified dermatologists.</p><p>提出了一种将皮肤病图像分为恶性或良性的模型，并与21名认证皮肤科医生进行了比较。</p><p>  The model was developed on roughly 130K images. The dataset consisted of both color images from a regular camera and dermoscopy images. Images were scaled to 299 x 299.</p><p>该模型是基于大约130K的图像开发的。数据集包括来自普通相机的彩色图像和皮肤镜图像。图像缩放到299x299。</p><p>  The model was trained on a combination of biopsy proven and radiologists labeled cases. It is therefore a label limited problem. The model was trained using many different classes, comparison to humans done on a binary classification problem</p><p>该模型在活检证实和放射科医生标记的病例的组合上进行了训练。因此，这是一个标签受限的问题。该模型使用许多不同的类别进行训练，与人类在二进制分类问题上所做的比较。</p><p>  Han, S.S., Kim, M.S., Lim, W., Park, G.H., Park, I. and Chang, S.E., 2018. Classification of the clinical images for benign and malignant cutaneous tumors using a deep learning algorithm. Journal of Investigative Dermatology, 138(7), pp.1529-1538.</p><p>韩秀生，Kim，M.S.，Lim，W.，Park，G.H.，Park，I.，Chang，S.E.，2018。基于深度学习算法的皮肤良恶性肿瘤临床图像分类。皮肤病研究杂志，138(7)页，1529-1538页。</p><p>  A model is proposed that can classify 12 different cutaneous tumors. The performance of the algorithm was compared to a group of 16 dermatologists, using biopsy proven cases only. The model performed comparable to the panel of dermatologists.</p><p>提出了一种可以对12种不同皮肤肿瘤进行分类的模型。该算法的性能与一组16名皮肤科医生进行了比较，这些皮肤科医生只使用经活检证实的病例。该模型的表现与皮肤科医生小组相当。</p><p>  The network was developed on about 17K images. The set comprised color images from a regular camera of varying size (size used in CNN not specified)</p><p>该网络是在大约17K图像上开发的。这组图像包括来自不同大小的普通相机的彩色图像(CNN使用的大小未指明)。</p><p>  Most pathologies were biopsy confirmed this is therefore a data limited problem. The final model used 12 class classification.</p><p>大多数病理检查都被活检证实，因此这是一个数据有限的问题。最终的模型采用12类分类。</p><p>  Bejnordi, B.E., Veta, M., Van Diest, P.J., Van Ginneken, B., Karssemeijer, N., Litjens, G., Van Der Laak, J.A., Hermsen, M., Manson, Q.F., Balkenhol, M. and Geessink, O., 2017. Diagnostic assessment of deep learning algorithms for detection of lymph node metastases in women with breast cancer. Jama, 318(22), pp.2199-2210.</p><p>Bejnordi，B.E.，Veta，M.，Van Diest，P.J.，Van Ginneken，B.，Karssemeijer，N.，Litjens，G.，Van Der Laak，J.A.，Hermsen，M.，Manson，Q.F.，Balkenholh，M.和Geessink，O.。深度学习算法检测女性乳腺癌淋巴结转移的诊断评估。“美国医学会杂志”，318(22)，第2199-2210页。</p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://thegradient.pub/why-skin-lesions-are-peanuts-and-brain-tumors-harder-nuts/">https://thegradient.pub/why-skin-lesions-are-peanuts-and-brain-tumors-harder-nuts/</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/损伤/">#损伤</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/lesions/">#lesions</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/标签/">#标签</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/美国/">#美国</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/谷歌/">#谷歌</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/linux/">#linux</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/程序/">#程序</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy; 2020 diglog.com </div></div></body></html>