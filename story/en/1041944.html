<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>DeepMind的首席研究科学家David Silver在AlphaGo，AlphaZero和MuZero上的研究将强化学习应用于现实世界中的问题等 David Silver, a principal research scientist at DeepMind, on AlphaGo, AlphaZero, and MuZero, applying reinforcement learning to real world problems, and more</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">David Silver, a principal research scientist at DeepMind, on AlphaGo, AlphaZero, and MuZero, applying reinforcement learning to real world problems, and more<br/>DeepMind的首席研究科学家David Silver在AlphaGo，AlphaZero和MuZero上的研究将强化学习应用于现实世界中的问题等 </h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2020-12-27 07:34:03</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2020/12/7e5dd78c45a450a379b511dac96a35eb.jpg"><img src="http://img2.diglog.com/img/2020/12/7e5dd78c45a450a379b511dac96a35eb.jpg" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>David Silver is responsible for several eye-catching demonstrations of  artificial intelligence in recent years, working on advances that helped revive interest in the field after the last great  AI Winter.</p><p>戴维·西尔弗（David Silver）负责近年来的几次引人注目的人工智能演示，并致力于在上个伟大的AI Winter大会之后重新唤起人们对该领域的兴趣。</p><p> At  DeepMind, a subsidiary of Alphabet, Silver has led the development of techniques that let computers learn for themselves how to solve problems that once seemed intractable.</p><p> 在Alphabet的子公司DeepMind，Silver领导了技术的开发，这些技术可以使计算机自己学习如何解决曾经棘手的问题。</p><p> Most famously, this includes  AlphaGo, a program revealed in 2017 that taught itself to play the ancient board game Go to a grandmaster level. Go is too subtle and instinctive to be tamed using conventional programming, but AlphaGo learned to play through practice and positive reward—an AI technique known as “reinforcement learning.”</p><p> 最著名的是AlphaGo，该程序于2017年发布，该程序自学了玩古代棋盘游戏Go到大师级别。 Go太微妙和本能，无法使用常规编程来驯服，但是AlphaGo学会了通过实践和积极奖励来玩游戏-一种称为“强化学习”的AI技术。</p><p>  In 2018, Silver and colleagues developed  a more general version of the program, called AlphaZero, capable of learning to play expert chess and shogi as well as Go. Then, in November 2019, DeepMind released details of MuZero, a version that learns to play these and other games—but crucially without needing to know the rules beforehand.</p><p>  在2018年，Silver和同事开发了该程序的更通用版本，称为AlphaZero，能够学习下棋和将棋以及围棋的专家。然后，在2019年11月，DeepMind发布了MuZero的详细信息，该版本可学习玩这些游戏和其他游戏-但至关重要的是，无需事先了解规则。</p><p> Silver met with senior writer Will Knight over Zoom from London to discuss MuZero, reinforcement learning, and the secret to making further progress in AI. This transcript has been edited for length and clarity.</p><p> Silver与伦敦的Zoom资深作家Will Knight会面，讨论了MuZero，强化学习以及在AI方面取得进一步进步的秘密。此笔录已过编辑，以确保篇幅和清晰度。</p><p>  WIRED: Your MuZero work is published in the journal   Nature  today. For the uninitiated, tell us why it is important.</p><p>  连线：您的MuZero作品发表在《自然》杂志上。对于没有经验的人，告诉我们为什么它很重要。</p><p> David Silver: The big step forward with MuZero is we don&#39;t tell it the dynamics of the environment; it has to figure that out for itself in a way that still lets it plan ahead and figure out what&#39;s going to be the most effective strategy. We want to have algorithms that work in the real world, and the real world is complicated and messy and unknown. So you can&#39;t just look ahead, like in a game of chess. You, you have to learn how the world works.</p><p> 戴维·西尔弗（David Silver）：与MuZero相比，向前迈出的一大步是我们不告诉环境动态。它必须以一种仍然可以让自己提前计划并弄清楚什么将是最有效的策略的方式自己弄清楚这一点。我们希望有在现实世界中可以工作的算法，而现实世界却是复杂，混乱且未知的。因此，您不能像国际象棋一样向前看。您，您必须学习世界如何运转。 </p><p>  Some observers point out that MuZero, AlphaGo, and AlphaZero don’t really start from scratch. They use algorithms crafted by clever humans to learn how to perform a particular task. Does this miss the point?</p><p>一些观察者指出，MuZero，AlphaGo和AlphaZero并非真正从头开始。他们使用聪明人制作的算法来学习如何执行特定任务。这会错过重点吗？</p><p> I think it does, actually. You never truly have a blank slate. There&#39;s even a theorem in  machine learning—the no-free-lunch theorem—that says you have to start with something or you don&#39;t get anywhere. But in this case, the slate is as blank as it gets. We&#39;re providing it with a  neural network, and the neural network has to figure out for itself, just from the feedback of the wins and losses in games or the score, how to understand the world.</p><p> 我认为确实如此。您永远不会真正拥有一片空白。机器学习中甚至有一个定理—非自由午餐定理—说您必须从某件事开始，否则就无所适从。但是在这种情况下，板岩是空白的。我们正在为它提供一个神经网络，而神经网络必须自己从游戏或得分的得失反馈中了解如何理解世界。</p><p> One thing people picked up on is that we tell MuZero the legal moves in each situation. But if you take reinforcement learning, which is all about trying to solve problems in situations where the world is unknown, it&#39;s normally assumed that you&#39;re told what you can do. You have to tell the agent what choices it has available, and then it takes one of them.</p><p> 人们接受的一件事是，我们告诉MuZero在每种情况下的合法举动。但是，如果您进行强化学习，而这仅仅是在世界未知的情况下试图解决问题的方法，通常会假设您被告知可以做什么。您必须告诉代理它有哪些选择，然后再选择其中之一。</p><p> You might critique what we&#39;ve done with it so far. The real world is massively complex, and we haven&#39;t built something which is like a human brain that can adapt to all these things. So that&#39;s a fair critique. But I think MuZero really is discovering for itself how to build a model and understand it just from first principles.</p><p> 您可能会批评我们到目前为止所做的事情。现实世界非常复杂，我们还没有建立像人类大脑那样可以适应所有这些东西的东西。因此，这是一个公平的批评。但是我认为MuZero确实是在为自己寻找如何建立模型并仅从最初的原理对其进行理解的方法。</p><p> DeepMind recently announced that it had used the technology behind AlphaZero to solve an important practical problem—  predicting the shape that a protein will fold into . Where do you think MuZero will have its first big impact?</p><p> DeepMind最近宣布，已利用AlphaZero背后的技术解决了一个重要的实际问题-预测蛋白质将折叠成的形状。您认为MuZero将在哪里产生第一个重大影响？</p><p>  We are, of course, looking at ways to apply MuZero to real world problems, and there are some encouraging initial results. To give a concrete example, traffic on the internet is dominated by video, and a big open problem is how to compress those videos as efficiently as possible. You can think of this as a reinforcement learning problem because there are these very complicated programs that compress the video, but what you see next is unknown. But when you plug something like MuZero into it, our initial results look very promising in terms of saving significant amounts of data, maybe something like 5 percent of the bits that are used in compressing a video.</p><p>  当然，我们正在寻找将MuZero应用到现实世界中的方法，并且有一些令人鼓舞的初步结果。举一个具体的例子，互联网上的流量主要是视频，而一个开放的大问题是如何尽可能有效地压缩这些视频。您可以认为这是一个强化学习问题，因为有许多非常复杂的程序可以压缩视频，但是接下来看到的是未知的。但是，当您将诸如MuZero之类的东西插入其中时，就节省大量数据而言，我们的初步结果看起来很有希望，也许大约占压缩视频所用位的5％。</p><p> “There may be this one very clear and simple way to think about all of intelligence, which is that it&#39;s a goal-optimizing system.”</p><p> “可能有一种非常清晰和简单的方式来考虑所有智能，这就是它是一个目标优化系统。” </p><p>   I think of a system that can help you as a user achieve your goals as effectively as possible. A really powerful system that sees all the things that you see, that has all the same senses that you have, which is able to help you achieve your goals in your life. I think that is a really important one. Another transformative one, looking long term, is something which could provide a personalized health care solution. There are privacy and ethical issues that have to be addressed, but it will have huge transformative value; it will change the face of medicine and people&#39;s quality of life.</p><p>我认为有一个系统可以帮助您作为用户尽可能有效地实现您的目标。一个真正强大的系统，可以看到您所看到的所有事物，具有与您相同的感觉，能够帮助您实现人生目标。我认为那是非常重要的。从长远来看，另一个变革性的东西可以提供个性化的医疗保健解决方案。有一些隐私和道德问题需要解决，但是它将具有巨大的变革价值；它将改变医学的面貌和人们的生活质量。</p><p>  I don&#39;t want to put a timescale on it, but I would say that everything that a human can achieve, I ultimately think that a machine can. The brain is a computational process, I don&#39;t think there&#39;s any magic going on there.</p><p>  我不想在上面加上时间表，但是我想说人类可以实现的一切，我最终认为机器可以实现。大脑是一个计算过程，我认为那里没有任何魔术。</p><p> Can we reach the point where we can understand and implement algorithms as effective and powerful as the human brain? Well, I don&#39;t know what the timescale is. But I think that the journey is exciting. And we should be aiming to achieve that. The first step in taking that journey is to try to understand what it even means to achieve intelligence? What problem are we trying to solve in solving intelligence?</p><p> 我们能否达到可以理解和实现像人脑一样有效和强大的算法的地步？好吧，我不知道时间表是多少。但是我认为旅途是令人兴奋的。我们应该以实现这一目标为目标。踏上这一旅程的第一步是尝试了解获得智慧甚至意味着什么？我们在解决智力方面试图解决什么问题？</p><p> Beyond practical uses, are you confident that you can go from mastering games like chess and Atari to real intelligence? What makes you think that reinforcement learning will lead to   machines with common sense understanding ?</p><p> 除了实际用途之外，您是否有信心可以从象棋和Atari等精通游戏到真正的智力？是什么让您认为强化学习将导致对机器具有常识的理解？</p><p> There&#39;s a hypothesis, we call it the reward-is-enough hypothesis, which says that the essential process of intelligence could be as simple as a system seeking to maximize its reward, and that process of trying to achieve a goal and trying to maximize reward is enough to give rise to all the attributes of intelligence that we see in natural intelligence. It&#39;s a hypothesis, we don&#39;t know whether it is true, but it kind of gives a direction to research.</p><p> 有一个假设，我们称其为“报酬足够”假设，该假设说，智力的基本过程可能与寻求最大化其报酬的系统一样简单，而试图实现目标并尝试最大化报酬足以产生我们在自然智能中看到的所有智能属性。这是一个假设，我们不知道它是否正确，但这为研究提供了方向。</p><p> If we take common sense specifically, the reward-is-enough hypothesis says well, if common sense is useful to a system, that means it should actually help it to better achieve its goals.</p><p> 如果我们具体地理解常识，那么“报酬足够”假设就很好地说明了这一点，如果常识对系统有用，则意味着它实际上应该帮助它更好地实现其目标。</p><p> It sounds like you think that your area of expertise—reinforcement learning—is in some sense fundamental to understanding, or “solving,” intelligence. Is that right?</p><p> 听起来您认为您的专长领域-强化学习-在某种意义上是理解或“解决”智力的基础。是对的吗？ </p><p>  I really see it as very essential. I think the big question is, is it true? Because it certainly flies in the face of how a lot of people view AI, which is that there&#39;s this incredibly complex collection of mechanisms involved in intelligence, and each one of them has its own kind of problem that it’s solving or its own special way of working, or maybe there&#39;s not even any clear problem definition at all for something like common sense. This theory says, no, actually there may be this one very clear and simple way to think about all of intelligence, which is that it&#39;s a goal-optimizing system, and that if we find the way to optimize goals really, really well, then all of these other things will will will emerge from that process.</p><p>我真的认为这是非常必要的。我认为最大的问题是，这是真的吗？因为它肯定会面对很多人如何看待AI，这就是情报中涉及到的这种极其复杂的机制集合，并且每个机制都有其自己要解决或解决的种种问题。自己的特殊工作方式，或者甚至根本没有针对常识之类的明确问题定义。这个理论说，不，实际上可能存在着一种非常清晰，简单的方式来考虑所有智能，这就是它是一个目标优化系统，并且如果我们真的找到了一种优化目标的方法，好吧，那么所有其他这些事情将在该过程中显现出来。</p><p>  Reinforcement learning has been around for decades, but for a while it seemed like a dead end. One of your old advisers in fact told me that she tried to dissuade you from working on it. Why did you ignore her and keep going?</p><p>  强化学习已经存在了数十年，但有一段时间似乎是死胡同。实际上，您的一位老顾问告诉我，她试图劝阻您不要这样做。你为什么不理her她并继续前进？</p><p> Many people view reinforcement learning as one of many hammers that you could apply to solve the many problems that we need to solve in AI. I don&#39;t view it that way. I view reinforcement learning as the whole thing. If we want to try and describe intelligence as best as possible, I think reinforcement learning essentially characterizes what we really mean by intelligence. And once you start to see it that way, it&#39;s like, how can I not work on this? If this really is the thing that is closest to what we mean by intelligence—if we solve it, we will crack that.</p><p> 许多人将强化学习视为您可以用来解决我们在AI中需要解决的许多问题的众多锤子之一。我不这样看。我将强化学习视为整体。如果我们想尝试并尽可能地描述智力，我认为强化学习从本质上描述了我们对智力的真正理解。当您开始以这种方式看到它时，我该如何处理呢？如果这确实是最接近我们的智能含义的事物，那么，如果我们解决它，我们将予以破解。</p><p>  If you look at the work I&#39;ve done, I’ve consistently tried to focus on that problem. When tackling things like Go, in solving it, we learn about what intelligence means in the process. You can think of reinforcement learning as the ability that enables an agent to acquire all other abilities—all the other pieces of intelligence that it needs . You see a little bit of that in something like AlphaGo, where all we asked it to do was to win games, and yet it learned all these things—endgames and openings—that people used to have specialized subsystems for.</p><p>  如果您看一下我所做的工作，那么我一直都在努力解决这个问题。解决诸如Go之类的问题时，在解决它时，我们了解了智能在此过程中意味着什么。您可以将强化学习视为使代理能够获得所有其他能力（它需要的所有其他智能）的能力。您会在AlphaGo之类的产品中看到一点点，我们要求它做的就是赢得比赛，但它了解了人们过去曾经拥有专门子系统的所有这些东西-比赛结束和开局。</p><p> Is there pressure at DeepMind to do another big demonstration, something like AlphaGo? Do you feel that at all?</p><p> DeepMind是否有压力进行另一个大型展示，例如AlphaGo？你有感觉吗？</p><p> That&#39;s a great question. I feel that we&#39;re in a really privileged position in the sense that we are secure in our positions, in our funding, all of these things are very, very secure.</p><p> 这是一个很好的问题。我觉得我们处于非常特权的位置，因为我们在位置上，资金上都是安全的，所有这些事情都是非常非常安全的。</p><p> The only pressure for trying to build a new, big demonstration is the drive to make progress towards general intelligence. It’s a real privilege that you don&#39;t have when you&#39;re either in a startup and trying to secure your funding, or in academia, where you&#39;re trying to secure your grants and so forth.</p><p> 试图建立一个新的大型示范的唯一压力是朝着通用情报迈进的动力。当您在初创企业中尝试获得资金时，或者在学术界中尝试获得补助金等时，这是您没有的真正特权。 </p><p> Powerful AI systems now require enormous amounts of computer power to work. Are you worried that this will hold progress back?</p><p>强大的AI系统现在需要大量的计算机功能才能工作。您是否担心这会阻碍进度？</p><p>  To bring this back to MuZero, it is an example of an algorithm that scales very well and gracefully with computation. We ran an experiment in Atari, where we showed that even using a very modest amount of compute—roughly equivalent to one GPU for a couple of weeks—it works really, really well, and you get performance that far exceeds a human.</p><p>  为了将其带回MuZero，它是算法的一个示例，可以很好地扩展计算。我们在Atari进行了一项实验，结果表明即使使用非常少量的计算（大约相当于一个GPU数周的时间），它的效果也非常好，而且您获得的性能远远超过了人类。</p><p> There are some figures that suggest if you add up all the compute power that you can leverage right now we&#39;re reaching something comparable to the human brain. So it&#39;s probably more us needing to come up with smarter algorithms.</p><p> 有一些数字表明，如果您将现在可以利用的所有计算能力加在一起，我们将达到与人脑可比的水平。因此，可能更多的是我们需要提出更智能的算法。</p><p> But the beauty of MuZero is that because it&#39;s building its own model, it&#39;s starting to understand how the world works—to imagine things. And that imagination is a way that you can actually leverage computation to start to look ahead, imagine what might happen next.</p><p> 但是MuZero的优点在于，因为它正在建立自己的模型，所以它开始了解世界是如何运转的-想象事物。这种想象力是您实际上可以利用计算开始展望未来，想象接下来会发生什么的一种方式。</p><p> Some military contractors are using reinforcement learning to   build better weapons systems . How do you feel about that? Do you ever think that some of your work should not be published openly?</p><p> 一些军事承包商正在利用强化学习来建立更好的武器系统。你对这件事有什么感想？您是否曾经认为您的某些作品不应该公开发表？</p><p> I oppose the use of AI in any deadly weapon, and I wish we had made more progress toward a  ban on lethal autonomous weapons. DeepMind and its co-founders are signatories of the  Lethal Autonomous Weapons Pledge, which outlines the company’s belief in the principle that offensive technology should always remain under appropriate human control.</p><p> 我反对在任何致命武器中使用AI，并希望我们在禁止致命自动武器方面取得更大进展。 DeepMind及其联合创始人是《致命自动武器承诺》的签署方，该承诺概述了公司对进攻性技术应始终在适当的人为控制下的信念。</p><p> However, we continue to believe that the appropriate publication of our methods is a cornerstone of science and that the development of general-purpose AI algorithms will lead to greater overall societal benefit across a raft of positive applications.</p><p> 但是，我们仍然认为，适当地发布我们的方法是科学的基石，通用AI算法的开发将在众多积极应用中带来更大的总体社会效益。 </p><p>   🎧 Things not sounding right? Check out our favorite  wireless headphones,  soundbars, and  Bluetooth speakers</p><p>🎧听起来不对吗？ 查看我们最喜欢的无线耳机，条形音箱和蓝牙扬声器 </p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://www.wired.com/story/what-alphago-teach-how-people-learn">https://www.wired.com/story/what-alphago-teach-how-people-learn</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/科学家/">#科学家</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/研究/">#研究</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/silver/">#silver</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/muzero/">#muzero</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/分享/">#分享</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy; 2020 diglog.com </div></div></body></html>