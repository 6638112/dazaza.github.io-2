<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>张量处理单元 Tensor Processing Unit</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">Tensor Processing Unit<br/>张量处理单元 </h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2020-12-22 08:26:17</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2020/12/3112316e27f60e7bede06bb8c3267fd0.png"><img src="http://img2.diglog.com/img/2020/12/3112316e27f60e7bede06bb8c3267fd0.png" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>A tensor processing unit (TPU)—sometimes referred to as a TensorFlow processing unit—is a special-purpose accelerator for machine learning. It is processing IC designed by Google to handled neural network processing using TensorFlow. TPUs are ASICs (application specific integrated circuits) used for accelerating specific machine learning workloads using processing elements—small DSPs with local memory—on a network so these elements can communicate with each other and pass the data through.</p><p>张量处理单元（TPU）（有时称为TensorFlow处理单元）是用于机器学习的专用加速器。它是Google设计的处理IC，用于使用TensorFlow处理神经网络处理。 TPU是ASIC（专用集成电路），用于通过网络上的处理元件（带有本地存储器的小型DSP）来加速特定的机器学习工作负载，以便这些元件可以相互通信并传递数据。</p><p> TensorFlow is an open-source platform for machine learning used in image classification, object detection, language modeling, speech recognition, among others.</p><p> TensorFlow是一个用于机器学习的开源平台，可用于图像分类，对象检测，语言建模，语音识别等。</p><p> TPUs have libraries of optimized models, use on-chip high bandwidth memory (HBM) and in each core have scalar, vector, and matrix units (MXUs). The MXUs do the processing at 16K multiply-accumulate operations in each cycle. 32-bit floating point input and output is simplified via Bfloat16. Cores execute user computations (XLA ops) separately. Google offers access to Cloud TPUs on their servers.</p><p> TPU具有优化模型的库，使用片上高带宽存储器（HBM），并且每个内核中都有标量，矢量和矩阵单元（MXU）。 MXU在每个周期以16K乘法累加运算进行处理。通过Bfloat16简化了32位浮点输入和输出。内核分别执行用户计算（XLA ops）。 Google可以访问其服务器上的Cloud TPU。</p><p>   Otherwise, CPUs and GPUs are better suited to quick prototyping, simple models, small and medium batch sizes, pre-existing code that cannot be changed, some math problems, among others. *See more at  Cloud Tensor Processing Units (TPUs).</p><p>   否则，CPU和GPU更适合于快速原型设计，简单的模型，中小型批处理大小，无法更改的预先存在的代码，一些数学问题等。 *有关更多信息，请参见云张量处理单元（TPU）。</p><p> It became apparent to Google in 2013 that they would have to double the number of data centers they had unless they could design a chip that could handle machine learning inferencing. The resulting TPU, Google  says, has “15–30X higher performance and 30–80X higher performance-per-watt than contemporary CPUs and GPUs.”</p><p> 在2013年，对于Google显而易见的是，除非他们能够设计能够处理机器学习推理的芯片，否则他们将不得不将其拥有的数据中心数量增加一倍。谷歌表示，最终的TPU的性能比目前的CPU和GPU高15-30倍，每瓦性能高30-80倍。”</p><p> “The fundamental trend that drives that phenomenon is specialization versus general-purpose. Using a GPU from Nvidia for an ML application is about 84% inefficient. You waste 84% of that part. If you’re deploying millions and millions of graphics processors at Google, you’ve got a pretty big incentive to go build a TPU instead of buying a GPU from Nvidia. That’s true across the board,”  said Jack Harding, eSilicon.</p><p> 导致这种现象的基本趋势是专业化与通用化。将Nvidia的GPU用于ML应用程序的效率大约为84％。您浪费了那部分的84％。如果您要在Google上部署数以百万计的图形处理器，那么您就有很大的动力去构建TPU，而不是从Nvidia购买GPU。全面都是如此。” eSilicon的杰克·哈丁（Jack Harding）说。</p><p>   The latest Google TPU contains 65,536 8-bit MAC blocks and consumes so much power that the chip has to be water-cooled. The power consumption of a TPU is likely between 200W and 300W.</p><p>   最新的Google TPU包含65,536个8位MAC块，消耗的功率如此之大，以至于该芯片必须进行水冷。 TPU的功耗可能在200W至300W之间。 </p><p>   Pods are multiple devices linked together. See  Google’s TPU pages for more information.</p><p>Pod是链接在一起的多个设备。 有关更多信息，请参见Google的TPU页面。 </p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://semiengineering.com/knowledge_centers/integrated-circuit/ic-types/processors/tensor-processing-unit-tpu/">https://semiengineering.com/knowledge_centers/integrated-circuit/ic-types/processors/tensor-processing-unit-tpu/</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/张量/">#张量</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/tpu/">#tpu</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/分享/">#分享</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy; 2020 diglog.com </div></div></body></html>