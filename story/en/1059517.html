<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>装配与内在（2014） Assembly vs. Intrinsics (2014)</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">Assembly vs. Intrinsics (2014)<br/>装配与内在（2014） </h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2021-04-22 11:28:23</div><div class="page_narrow text-break page_content"><p>Assembly v. intrinsics    Every once in a while, I hear how intrinsics have improved enough that it&#39;s safe to use them for high performance code. That would be nice. The promise of intrinsics is that you can write optimized code by calling out to functions (intrinsics) that correspond to particular assembly instructions. Since intrinsics act like normal functions, they can be cross platform. And since your compiler has access to more computational power than your brain, as well as a detailed model of every CPU, the compiler should be able to do a better job of micro-optimizations. Despite decade old claims that intrinsics can make your life easier, it never seems to work out.</p><p>组装v。每次偶尔固定内在，我听到了金属内部的改善了，它可以使用它们来用于高性能代码。那样就好了。内在机构的承诺是您可以通过呼叫对应于特定装配说明的功能（内在）来编写优化的代码。由于内在函数就像正常功能，它们可以是跨平台。由于您的编译器可以访问比大脑的更多计算能力，以及每个CPU的详细模型，编译器应该能够做出更好的微优化工作。尽管有十年的旧声称，固有内部可以让你的生活更轻松，但似乎永远不会锻炼身体。</p><p>  The last time I tried intrinsics was around 2007; for more on why they were hopeless then ( see this exploration by the author of VirtualDub). I gave them another shot recently, and while they&#39;ve improved, they&#39;re still not worth the effort. The problem is that intrinsics are so unreliable that you have to manually check the result on every platform and every compiler you expect your code to be run on, and then tweak the intrinsics until you get a reasonable result. That&#39;s more work than just writing the assembly by hand. If you don&#39;t check the results by hand, it&#39;s easy to get bad results.</p><p>  我最后一次尝试了内在的内在是2007年的;有关它们为什么他们无望的原因（请参阅VirtualDub作者的探索）。我最近给了他们另一个镜头，而他们改善了，他们仍然不值得努力。问题是，内在函数是如此不可靠，您必须手动检查每个平台和每个编译器的结果，您希望将代码运行，然后在获得合理的结果之前调整内在函数。那个＆＃39;比只需用手写作大会的工作。如果你不要用手检查结果，它＆＃39;很容易得到糟糕的结果。</p><p>  For example, as of this writing, the first two Google hits for  popcnt benchmark (and 2 out of the top 3 bing hits) claim that Intel&#39;s hardware  popcnt instruction is slower than a software implementation that counts the number of bits set in a buffer, via a table lookup using the  SSSE3  pshufb instruction. This turns out to be untrue, but it must not be obvious, or this claim wouldn&#39;t be so persistent. Let&#39;s see why someone might have come to the conclusion that the  popcnt instruction is slow if they coded up a solution using intrinsics.</p><p>  例如，如本撰写，前两个Google for for popcnt基准（以及前3名Bing Hits中的2个）声明了英特尔＆＃39; s硬件popcnt指令比计算位数数量的软件实现慢在缓冲区中，使用SSSE3 PSHUFB指令通过表查找。这结果是不真实的，但它绝不能是明显的，或者这一索赔不会如此持久。让＆＃39;为什么有人可能得出结论，如果他们使用内在机构编码解决方案，Popcnt指令很慢。</p><p>  One of the top search hits has sample code and benchmarks for both native  popcnt as well as the software version using  pshufb.  Their code requires MSVC, which I don&#39;t have access to, but their first  popcnt implementation just calls the  popcnt intrinsic in a loop, which is fairly easy to reproduce in a form that gcc and clang will accept. Timing it is also pretty simple, since we&#39;re just timing a function (that happens to count the number of bits set in some fixed sized buffer).</p><p>  其中一个顶级搜索命中率为使用PSHUFB的本机POPCNT以及软件版本的示例代码和基准。他们的代码需要msvc，我没有访问，但他们的第一个popcnt实现只需在循环中调用popcnt内部，这在gcc和clang将接受的形式中相当容易再现。时间它也很简单，因为我们＆＃39;重新定时一个函数（它发生在一些固定大小的缓冲区中设置的位数）。</p><p>  uint32_t builtin_popcnt(const uint64_t* buf, int len) { int cnt = 0; for (int i = 0; i &lt; len; ++i) { cnt += __builtin_popcountll(buf[i]); } return cnt;}</p><p>  UINT32_T构建_popcnt（const uint64_t * buf，int len）{int cnt = 0; for（int i = 0; i＆lt; len; ++ i）{cnt + = __builtin_popcountll（buf [i]）; }返回cnt;}</p><p>  This is slightly different from the code I linked to above, since they use the dword (32-bit) version of  popcnt, and we&#39;re using the qword (64-bit) version. Since our version gets twice as much done per loop iteration, I&#39;d expect our version to be faster than their version.</p><p>  这与上面链接的代码略有不同，因为它们使用Popcnt的DWORD（32位）版本，以及使用QWORD（64位）版本。由于我们的版本获得了两倍于每循环迭代完成的两倍，我＆＃39; D期望我们的版本比他们的版本更快。</p><p>  Running  clang -O3 -mpopcnt -funroll-loops produces a binary that we can examine. On macs, we can use  otool -tv to get the disassembly. On linux, there&#39;s  objdump -d.</p><p>  运行clang -o3 -mpopcnt -funroll-loops会产生我们可以检查的二进制文件。在Mac上，我们可以使用Otool -TV来获得拆卸。在Linux上，有＃39; s Objdump -d。 </p><p>  _builtin_popcnt:; address instruction0000000100000b30 pushq %rbp0000000100000b31 movq %rsp, %rbp0000000100000b34 movq %rdi, -0x8(%rbp)0000000100000b38 movl %esi, -0xc(%rbp)0000000100000b3b movl $0x0, -0x10(%rbp)0000000100000b42 movl $0x0, -0x14(%rbp)0000000100000b49 movl -0x14(%rbp), %eax0000000100000b4c cmpl -0xc(%rbp), %eax0000000100000b4f jge 0x100000bd40000000100000b55 movslq -0x14(%rbp), %rax0000000100000b59 movq -0x8(%rbp), %rcx0000000100000b5d movq (%rcx,%rax,8), %rax0000000100000b61 movq %rax, %rcx0000000100000b64 shrq %rcx0000000100000b67 movabsq $0x5555555555555555, %rdx0000000100000b71 andq %rdx, %rcx0000000100000b74 subq %rcx, %rax0000000100000b77 movabsq $0x3333333333333333, %rcx0000000100000b81 movq %rax, %rdx0000000100000b84 andq %rcx, %rdx0000000100000b87 shrq $0x2, %rax0000000100000b8b andq %rcx, %rax0000000100000b8e addq %rax, %rdx0000000100000b91 movq %rdx, %rax0000000100000b94 shrq $0x4, %rax0000000100000b98 addq %rax, %rdx0000000100000b9b movabsq $0xf0f0f0f0f0f0f0f, %rax0000000100000ba5 andq %rax, %rdx0000000100000ba8 movabsq $0x101010101010101, %rax0000000100000bb2 imulq %rax, %rdx0000000100000bb6 shrq $0x38, %rdx0000000100000bba movl %edx, %esi0000000100000bbc movl -0x10(%rbp), %edi0000000100000bbf addl %esi, %edi0000000100000bc1 movl %edi, -0x10(%rbp)0000000100000bc4 movl -0x14(%rbp), %eax0000000100000bc7 addl $0x1, %eax0000000100000bcc movl %eax, -0x14(%rbp)0000000100000bcf jmpq 0x100000b490000000100000bd4 movl -0x10(%rbp), %eax0000000100000bd7 popq %rbp0000000100000bd8 ret</p><p>_builtin_popcnt :;地址指令0000000100000B30 PUSPQ％RBP0000000100000B31 MOVQ％RSP，％RBP0000000100000B34 MOVQ％RDI，-0x8（％RBP）0000000100000B38 MOVL％ESI，-0xc（％RBP）000000000100000B3B MOVL $ 0x0，-0x10（％RBP）0000000100000B42 MOVL $ 0x0，-0x14 （％RBP）0000000100000B49 MOVL -0x14（％RBP），％EAX0000000100000B4C CMPL -0xC（％RBP），％EAX0000000100000B4F JGE 0x100000B55 MOVSLQ -0X14（％RBP），％RAX0000000100000B59 MOVIQ -0x8（％RBP），％RCX0000000100000B5D MOVED（％ RCX，％RAX，8），％rax0000000100000b61 MOVQ％RAX，％rcx0000000100000b64 SHRQ％rcx0000000100000b67 movabsq $ 0x5555555555555555，％rdx0000000100000b71和Q％的RDX，％rcx0000000100000b74 SUBQ％RCX，％rax0000000100000b77 movabsq $ 0x3333333333333333，％rcx0000000100000b81 MOVQ％RAX，％rdx0000000100000b84和Q ％RCX，％rdx0000000100000b87 SHRQ $ 0X2，％rax0000000100000b8b和Q％RCX，％rax0000000100000b8e addq％RAX，％rdx0000000100000b91 MOVQ％的RDX，％rax0000000100000b94 SHRQ $为0x4，％rax0000000100000b98 addq％RAX，％rdx0000000100000b9b movabsq $ 0xf0f0f0f0f0f0f0f，％rax000000010000 0BA5和Q％RAX，％rdx0000000100000ba8 movabsq $ 0x101010101010101，％rax0000000100000bb2 imulq％RAX，％rdx0000000100000bb6 SHRQ $ 0x38，％rdx0000000100000bba MOVL％EDX，％esi0000000100000bbc MOVL -0x10（％RBP），％edi0000000100000bbf ADDL％ESI，％edi0000000100000bc1 MOVL％EDI ，-0x10（％RBP）0000000100000BC4 MOVL -0x14（％RBP），％eax0000000100000bc7 addl $ 0x1，％eax0000000100000bcc modl％eax，-0x14（％rbp）000000000100000bcf jmpq 0x100000b490000000100 000bd4 mov1 -0x10（％rbp），％eax0000000100000bd7 popq％rbp00000001000bd8雷</p><p>  Well, that&#39;s interesting. Clang seems to be calculating things manually rather than using  popcnt. It seems to be using  the approach described here, which is something like</p><p>  好吧，那个＆＃39;有趣。 Clang似乎是手动计算事物而不是使用popcnt。它似乎正在使用这里描述的方法，这是类似的</p><p>  x = x - ((x &gt;&gt; 0x1) &amp; 0x5555555555555555);x = (x &amp; 0x3333333333333333) + ((x &gt;&gt; 0x2) &amp; 0x3333333333333333);x = (x + (x &gt;&gt; 0x4)) &amp; 0xF0F0F0F0F0F0F0F;ans = (x * 0x101010101010101) &gt;&gt; 0x38;</p><p>  X = X  - （（X＆GT;＆GT;为0x1）及0x5555555555555555）; X =（X安培; 0x3333333333333333）+（（X＆GT;＆GT; 0X2）及0x3333333333333333）; X =（X +（X GT; ＆gt; 0x4））＆amp; 0xf0f0f0f0f0f0f0f0f; ans =（x * 0x101010101010101101）＆gt;＆gt; 0x38;</p><p>  That&#39;s not bad for a simple implementation that doesn&#39;t rely on any kind of specialized hardware, but that&#39;s going to take a lot longer than a single  popcnt instruction.</p><p>  这与一个不符合任何类型的专业硬件的简单实现，而不是依赖于任何一种专业化的硬件，而是比单个Popcnt指令更长的时间更长。</p><p>  I&#39;ve got a pretty old version of clang (3.0), so let me try this again after upgrading to 3.4, in case they added hardware  popcnt support “recently”.</p><p>  我有一个漂亮的旧版克朗（3.0），所以让我在升级到3.4后再次尝试，以防他们添加了“最近”的硬件popcnt支持。</p><p>  0000000100001340 pushq %rbp ; save frame pointer0000000100001341 movq %rsp, %rbp ; new frame pointer0000000100001344 xorl %ecx, %ecx ; cnt = 00000000100001346 testl %esi, %esi0000000100001348 jle 0x100001363000000010000134a nopw (%rax,%rax)0000000100001350 popcntq (%rdi), %rax ; “eax” = popcnt[rdi]0000000100001355 addl %ecx, %eax ; eax += cnt0000000100001357 addq $0x8, %rdi ; increment address by 64-bits (8 bytes)000000010000135b decl %esi ; decrement loop counter; sets flags000000010000135d movl %eax, %ecx ; cnt = eax; does not set flags000000010000135f jne 0x100001350 ; examine flags. if esi != 0, goto popcnt0000000100001361 jmp 0x100001365 ; goto “restore frame pointer”0000000100001363 movl %ecx, %eax0000000100001365 popq %rbp ; restore frame pointer0000000100001366 ret</p><p>  0000000100001340 PUSHQ％RBP;保存帧Pointer0000000100001341 MOVQ％RSP％RBP;新帧指针10000000100001344 XORL％ECX，％ECX; CNT = 00000000100001346 Testl％ESI，％ESI0000000100001348 JLE 0x10000136300000000010000134A NOPW（％rax，％rax）0000000100001350 popcntq（％rdi），％r​​ax; “eax”= popcnt [rdi] 0000000100001355 addl％ECX，％EAX; EAX + = CNT0000000100001357 ADDQ $ 0x8，％RDI;递增地址64位（8字节）000000010000135B DELL％ESI;减量回路计数器; SET FLAGS000000010000135D MOVL％EAX，％ECX; cnt = eax;没有设置FLAGS000000010000135F JNE 0x100001350;检查标志。如果是ESI！= 0，GOTO POPCNT0000000100001361 JMP 0x100001365;转到“恢复帧指针”0000000100001363 MOVL％ECX，％eax0000000100001365 popq％rbp;恢复框架pointer0000000100001366 RET</p><p>  That&#39;s better! We get a hardware  popcnt! Let&#39;s compare this to the SSSE3  pshufb implementation  presented here as the fastest way to do a popcnt. We&#39;ll use a table like the one in the link to show speed, except that we&#39;re going to show a rate, instead of the raw cycle count, so that the relative speed between different sizes is clear. The rate is GB/s, i.e., how many gigs of buffer we can process per second. We give the function data in chunks (varying from 1kb to 16Mb); each column is the rate for a different chunk-size. If we look at how fast each algorithm is for various buffer sizes, we get the following.</p><p>  那个更好的＆＃39;我们得到一个硬件popcnt！让＆＃39; s将此与此处呈现的SSSE3 PSHUFB实现进行比较，作为执行POPCNT的最快方法。我们＆＃39; ll使用一个表链接中的一个表来显示速度，除了我们＆＃39;重新显示一个速率，而不是原始循环计数，使不同大小之间的相对速度很清楚。该速率是GB / s，即，我们每秒可以处理多少次缓冲区。我们在块中提供功能数据（从1KB到16MB而变化）;每列是不同块大小的速率。如果我们查看每种算法用于各种缓冲区大小的速度，我们都会得到以下内容。 </p><p>    That&#39;s not so great. Relative to the the benchmark linked above, we&#39;re doing better because we&#39;re using 64-bit  popcnt instead of 32-bit  popcnt, but the PSHUFB version is still almost twice as fast  1.</p><p>那个＆＃39;不是那么伟大。相对于上面链接的基准，我们＆＃39;重新做得更好，因为我们使用64位popcnt而不是32位popcnt，但PSHUFB版本仍然是快速的两倍。</p><p>  One odd thing is the way  cnt gets accumulated.  cnt is stored in  ecx. But, instead of adding the result of the  popcnt to  ecx, clang has decided to add  ecx to the result of the  popcnt. To fix that, clang then has to move that sum into  ecx at the end of each loop iteration.</p><p>  一个奇怪的是CNT累积的方式。 CNT存储在ECX中。但是，而不是将Popcnt的结果添加到ECX，Clang已决定将ECX添加到Popcnt的结果。要解决此问题，则CLANG必须在每个循环迭代结束时将该总和移动到ECX中。</p><p>  The other noticeable problem is that we only get one  popcnt per iteration of the loop, which means the loop isn&#39;t getting unrolled, and we&#39;re paying the entire cost of the loop overhead for each  popcnt. Unrolling the loop can also let the CPU extract more instruction level parallelism from the code, although that&#39;s a bit beyond the scope of this blog post.</p><p>  另一个明显的问题是，我们只获得循环的迭代只能获得一个popcnt，这意味着循环isn＆＃39; t ungered，我们＆＃39;重新支付每个popcnt的循环开销的整个成本。展开循环也可以让CPU从代码中提取更多的指令级并行性，虽然这是一个超出这个博客文章的范围。</p><p>  Using clang, that happens even with  -O3 -funroll-loops. Using gcc, we get a properly unrolled loop, but gcc has other problems, as we&#39;ll see later. For now, let&#39;s try unrolling the loop ourselves by calling  __builtin_popcountll multiple times during each iteration of the loop. For simplicity, let&#39;s try doing four  popcnt operations on each iteration. I don&#39;t claim that&#39;s optimal, but it should be an improvement.</p><p>  使用CLANG，即使与-O3 -FUNROLL-LOOPS也会发生。使用GCC，我们得到一个正确的展开循环，但GCC还有其他问题，就像我们＆＃39; LL见稍后。目前，让＆＃39; s尝试通过在循环的每个迭代期间多次调用__builtin_popcountll来展开循环。为简单起见，请尝试在每次迭代中执行四项POPCNT操作。我不声明它的最佳状态，但它应该是一个改进。</p><p>  uint32_t builtin_popcnt_unrolled(const uint64_t* buf, int len) { assert(len % 4 == 0); int cnt = 0; for (int i = 0; i &lt; len; i+=4) { cnt += __builtin_popcountll(buf[i]); cnt += __builtin_popcountll(buf[i+1]); cnt += __builtin_popcountll(buf[i+2]); cnt += __builtin_popcountll(buf[i+3]); } return cnt;}</p><p>  Uint32_t build_popcnt_unrolled（const uint64_t * buf，int len）{sssert（len％4 == 0）; int cnt = 0; for（int i = 0; i＆lt; len; i + = 4）{cnt + = __builtin_popcountll（buf [i]）; cnt + = __builtin_popcountll（buf [i + 1]）; cnt + = __builtin_popcountll（buf [i + 2]）; cnt + = __builtin_popcountll（buf [i + 3]）; }返回cnt;}</p><p>    0000000100001390 popcntq (%rdi,%rcx,8), %rdx0000000100001396 addl %eax, %edx0000000100001398 popcntq 0x8(%rdi,%rcx,8), %rax000000010000139f addl %edx, %eax00000001000013a1 popcntq 0x10(%rdi,%rcx,8), %rdx00000001000013a8 addl %eax, %edx00000001000013aa popcntq 0x18(%rdi,%rcx,8), %rax00000001000013b1 addl %edx, %eax</p><p>    0000000100001390 popcntq（％rdi，％rcx，8），％rdx％eax，％edx0000000100001398 popcntq 0x8（％rdi，％rcx，8），％rax000000010000139f addl％edx，％eax00000001000013A1 popcntq 0x10（％rdi，％rcx，8 ），％RDX00000001000013A8 ADDL％EAX，％EDX00000001000013AA POPCNTQ 0x18（％RDI，％RCX，8），％RAX00000001000013B1 ADDL％EDX，％EAX</p><p>  with pretty much the same code surrounding the loop body. We&#39;re doing four  popcnt operations every time through the loop, which results in the following performance:</p><p>  围绕循环体围绕相同的代码。我们每次都通过循环执行四个popcnt操作，这导致以下性能： </p><p>    Between using 64-bit  popcnt and unrolling the loop, we&#39;ve already beaten the allegedly faster  pshufb code! But it&#39;s close enough that we might get different results with another compiler or some other chip. Let&#39;s see if we can do better.</p><p>在使用64位popcnt和展开循环之间，我们已经击败了据称更快的pshufb代码！但它与另一个编译器或其他芯片相比，我们可能会获得不同的结果。让＆＃39;我们看看我们是否可以做得更好。</p><p>  So, what&#39;s the deal with this  popcnt false dependency bug that&#39;s been getting a lot of publicity lately? Turns out,  popcnt has a false dependency on its destination register, which means that even though the result of  popcnt doesn&#39;t depend on its destination register, the CPU thinks that it does and will wait until the destination register is ready before starting the  popcnt instruction.</p><p>  那么，与这个popcnt虚假依赖虫子的交易是什么，＆＃39最近得到了很多宣传？结果，popcnt对其目的地寄存器具有错误的依赖性，这意味着即使popcnt的结果也不依赖于其目标寄存器，CPU认为它确实并等到目标寄存器在开始之前准备好了popcnt指令。</p><p>  x86 typically has two operand operations, e.g.,  addl %eax, %edx adds  eax and  edx, and then places the result in  edx, so it&#39;s common for an operation to have a dependency on its output register. In this case, there shouldn&#39;t be a dependency, since the result doesn&#39;t depend on the contents of the output register, but that&#39;s an easy bug to introduce, and a hard one to catch  2.</p><p>  X86通常具有两个操作数操作，例如Addl％EAX，％EDX添加EAX和EDX，然后将结果放在EDX中，因此它＆＃39;对于操作寄存器的依赖性，＆＃39。在这种情况下，有一个依赖关系，因为结果不依赖于输出寄存器的内容，但是＆＃39;是介绍的一个容易的错误，以及一个难以捕获的错误。</p><p>  In this particular case,  popcnt has a 3 cycle latency, but it&#39;s pipelined such that a  popcnt operation can execute each cycle. If we ignore other overhead, that means that a single  popcnt will take 3 cycles, 2 will take 4 cycles, 3 will take 5 cycles, and n will take n+2 cycles, as long as the operations are independent. But, if the CPU incorrectly thinks there&#39;s a dependency between them, we effectively lose the ability to pipeline the instructions, and that n+2 turns into 3n.</p><p>  在这种特殊情况下，POPCNT具有3个周期延迟，但它＆＃39; s流水线，使得POPCNT操作可以执行每个循环。如果我们忽略其他开销，这意味着单个popcnt将需要3个周期，2个将需要4个周期，3个将需要5个周期，并且n将采用n + 2个周期，只要操作是独立的。但是，如果CPU不正确地认为它们之间的依赖关系，我们有效地失去了管道指令的能力，并且N + 2变成了3N。</p><p>  We can work around this by buying a CPU from AMD or VIA, or by putting the  popcnt results in different registers. Let&#39;s making an array of destinations, which will let us put the result from each  popcnt into a different place.</p><p>  我们可以通过从AMD或VIA中购买CPU或将POPCNT结果放在不同的寄存器中来解决此问题。让＆＃39;制作一系列目的地，这将让我们将结果从每个popcnt放入不同的地方。</p><p>  uint32_t builtin_popcnt_unrolled_errata(const uint64_t* buf, int len) { assert(len % 4 == 0); int cnt[4]; for (int i = 0; i &lt; 4; ++i) { cnt[i] = 0; } for (int i = 0; i &lt; len; i+=4) { cnt[0] += __builtin_popcountll(buf[i]); cnt[1] += __builtin_popcountll(buf[i+1]); cnt[2] += __builtin_popcountll(buf[i+2]); cnt[3] += __builtin_popcountll(buf[i+3]); } return cnt[0] + cnt[1] + cnt[2] + cnt[3];}</p><p>  UINT32_T构建_popcnt_unrolled_errate（const uint64_t * buf，int len）{sssert（len％4 == 0）; int cnt [4]; for（int i = 0; i＆lt; 4; ++ i）{cnt [i] = 0; for（int i = 0; i＆lt; len; i + = 4）{cnt [0] + = __builtin_popcountll（buf [i]）; cnt [1] + = __builtin_popcountll（buf [i + 1]）; cnt [2] + = __builtin_popcountll（buf [i + 2]）; cnt [3] + = __builtin_popcountll（buf [i + 3]）; }返回CNT [0] + CNT [1] + CNT [2] + CNT [3];}</p><p>    0000000100001420 popcntq (%rdi,%r9,8), %r80000000100001426 addl %ebx, %r8d0000000100001429 popcntq 0x8(%rdi,%r9,8), %rax0000000100001430 addl %r14d, %eax0000000100001433 popcntq 0x10(%rdi,%r9,8), %rdx000000010000143a addl %r11d, %edx000000010000143d popcntq 0x18(%rdi,%r9,8), %rcx</p><p>    0000000100001420 popcntq（％rdi，％r9,8），％r80000000100001426 addl％ebx，％r8d0000000100001429 popcntq 0x8（％rdi，％r9,8），％rax0000000100001430 addl％r14d，％eax0000000100001433 popcntq 0x10（％rdi，％r9,8 ），％RDX000000010000143A ADDL％R11D，％EDX000000010000143D POPCNTQ 0x18（％RDI，％R9,8），％RCX </p><p>  That&#39;s better -- we can see that the first popcnt outputs into  r8, the second into  rax, the third into  rdx, and the fourth into  rcx. However, this does the same odd accumulation as the original, where instead of adding the result of the  popcnt to  cnt[i], it does the opposite, which necessitates moving the results back to  cnt[i] afterwards.</p><p>＆＃39; s更好 - 我们可以看到第一个popcnt输出到r8，第二个进入rax，第三到rdx，以及第四到RCX。但是，这与原始累积相同，而不是将popcnt的结果添加到cnt [i]，它与之相反，这需要将结果移动回之后的cnt [i]。</p><p>    Well, at least in clang (3.4). Gcc (4.8.2) is too smart to fall for this separate destination thing and “optimizes” the code back to something like our original version.</p><p>    嗯，至少在铿cl（3.4）。 GCC（4.8.2）太智能了，无法为此单独的目的地进行，并且“优化”代码回到像我们原始版本的内容。</p><p>    To get a version that works with both gcc and clang, and doesn&#39;t have these extra  movs, we&#39;ll have to write the assembly by hand  3:</p><p>    要获得与GCC和CLANG合作的版本，并且没有这些额外的MOV，我们＆＃39; LL必须用手写组装3：</p><p>  uint32_t builtin_popcnt_unrolled_errata_manual(const uint64_t* buf, int len) { assert(len % 4 == 0); uint64_t cnt[4]; for (int i = 0; i &lt; 4; ++i) { cnt[i] = 0; } for (int i = 0; i &lt; len; i+=4) { __asm__( &#34;popcnt %4, %4 \n\ &#34;add %4, %0 \n\t&#34; &#34;popcnt %5, %5 \n\t&#34; &#34;add %5, %1 \n\t&#34; &#34;popcnt %6, %6 \n\t&#34; &#34;add %6, %2 \n\t&#34; &#34;popcnt %7, %7 \n\t&#34; &#34;add %7, %3 \n\t&#34; // +r means input/output, r means intput : &#34;+r&#34; (cnt[0]), &#34;+r&#34; (cnt[1]), &#34;+r&#34; (cnt[2]), &#34;+r&#34; (cnt[3]) : &#34;r&#34; (buf[i]), &#34;r&#34; (buf[i+1]), &#34;r&#34; (buf[i+2]), &#34;r&#34; (buf[i+3])); } return cnt[0] + cnt[1] + cnt[2] + cnt[3];}</p><p>  UINT32_T构建_popcnt_unrolled_errata_manual（const uint64_t * buf，int len）{sssert（len％4 == 0）; UINT64_T CNT [4]; for（int i = 0; i＆lt; 4; ++ i）{cnt [i] = 0; for（int i = 0; i＆lt; len; i + = 4）{__asm __（＆＃34; popcnt％4，％4 \ n \＆＃34;加％4，％0 \ n \ t＆＃34; ＆＃34; popcnt％5，％5 \ n \ t＆＃34;＆＃34;加％5，％1 \ n \ t＆＃34;＆＃34; popcnt％6，％6 \ n \ t＆＃34 ;＆＃34;加％6，％2 \ n \ t＆＃34;＆＃34; popcnt％7，％7 \ n \ t＆＃34;＆＃34;添加％7，％3 \ n \ t＆＃t＆＃34 34; // + R表示输入/输出，R表示intput：＆＃34; + R＆＃34;（CNT [0]），＆＃34; + R＆＃34;（CNT [1]），＆＃34 ; + R＆＃34;（CNT [2]），＆＃34; + R＆＃34;（CNT [3]）：＆＃34; R＆＃34;（Buf [i]），＆＃34; r＆＃ 34;（Buf [i + 1]），＆＃34; R＆＃34;（Buf [i + 2]），＆＃34; R＆＃34;（Buf [i + 3]））; }返回CNT [0] + CNT [1] + CNT [2] + CNT [3];}</p><p>    00000001000013c3 popcntq %r10, %r1000000001000013c8 addq %r10, %rcx00000001000013cb popcntq %r11, %r1100000001000013d0 addq %r11, %r900000001000013d3 popcntq %r14, %r1400000001000013d8 addq %r14, %r800000001000013db popcntq %rbx, %rbx</p><p>    00000001000013C3 POPCNTQ％R10，％R1000000001000013C8 ADDQ％R10，％RCX00000001000013CB POPCNTQ％R11，％R1100000001000013D0 ADDQ％R11，％R900000001000013D3 POPCNTQ％R14，％R1400000001000013D8 ADDQ％R14，％R800000001000013DB POPCNTQ％RBX，％RBX</p><p>  Great! The  adds are now going the right direction, because we specified exactly what they should do.</p><p>  伟大的！此添加现在正在进行正确的方向，因为我们确切的是他们应该做的事情。</p><p>    Finally! A version that blows away the  PSHUFB implementation. How do we know this should be the final version? We can see from  Agner&#39;s instruction tables that we can execute, at most, one  popcnt per cycle. I happen to have run this on a 3.4Ghz Sandy Bridge, so we&#39;ve got an upper bound of  8 bytes / cycle * 3.4 G cycles / sec = 27.2 GB/s. That&#39;s pretty close to the  26.3 GB/s we&#39;re actually getting, which is a sign that we can&#39;t make this much faster  4.</p><p>    最后！吹掉PSHUFB实现的版本。我们如何知道这应该是最终版本？我们可以从Agner＆＃39;我们最多可以执行的指令表中看到一个popcnt。我碰巧在3.4GHz的桑迪桥上跑了这个，所以我们＆＃39; ve有8个字节/循环的上限* 3.4g cycles / sec = 27.2 gb / s。那个＆＃39;非常接近26.3 GB / s的我们＆＃39;重复实际上，这是我们可以＆＃39; t的标志更快4。 </p><p>  In this case, the hand coded assembly version is about 3x faster than the original intrinsic loop (not counting the version from a version of clang that didn&#39;t emit a  popcnt). It happens that, for the compiler we used, the unrolled loop using the  popcnt intrinsic is a bit faster than the  pshufb version, but that wasn&#39;t true of one of the two unrolled versions when I tried this with  gcc.</p><p>在这种情况下，手编码的装配版本比原始内在循环快3倍（不计算来自＆＃39的克朗版本的版本，响起了一个popcnt）。正碰巧，对于我们使用的编译器，使用Popcnt内在的展开循环比Pshufb版本更快，但是当我尝试使用GCC时，这是两个展开版本中的一个。</p><p>  It&#39;s easy to see why someone might have benchmarked the same code and decided that  popcnt isn&#39;t very fast. It&#39;s also easy to see why using intrinsics for performance critical code can be a huge time sink  5.</p><p>  它＆＃39;很容易看出为什么有人可能有基准相同的代码，并决定非常快地＆＃39; t非常快。它＆＃39; S也很容易看出为什么使用内在的临界代码可以是一个巨大的时间汇5。</p><p>    If you liked this, you&#39;ll probably enjoy  this post about how CPUs have changed since the 80s.</p><p>    如果你喜欢这一点，你＆＃39; ll可能享受这篇文章，因为它是如何从80年代开始改变的CPU。</p><p>  see this for the actual benchmarking code. On second thought, it&#39;s an embarrassingly terrible hack, and I&#39;d prefer that you don&#39;t look.   [return]</p><p>  看到实际的基准测试代码。在第二次思想中，它＆＃39;是一个尴尬的可怕的黑客，我更喜欢你的看起来。 [返回]</p><p>  If it were the other way around, and the hardware didn&#39;t realize there was a dependency when there should be, that would be easy to catch -- any sequence of instructions that was dependent might produce an incorrect result. In this case, some sequences of instructions are just slower than they should be, which is not trivial to check for.   [return]</p><p>  如果它是另一种方式，硬件没有意识到应该有一个依赖性，这很容易捕获 - 任何依赖的指令序列都可能产生不正确的结果。在这种情况下，一些指令序列比应慢慢慢，这是检查的差异。 [返回]</p><p>    That&#39;s not quite right, since the CPU has TurboBoost, but it&#39;s pretty close. Putting that aside, this example is pretty simple, but calculating this stuff by hand can get tedious for more complicated code. Luckily, the  Intel Architecture Code Analyzier can figure this stuff out for us. It finds the bottleneck in the code (assuming infinite memory bandwidth at zero latency), and displays how and why the processor is bottlenecked, which is usually enough to determine if there&#39;s room for more optimization.</p><p>    那个＆＃39; S不是很好的，因为CPU具有TBATOBOOST，但它非常接近。放在旁边，这个例子很简单，但用手计算这个东西可以令人疑惑，因为更复杂的代码。幸运的是，英特尔架构代码分析可以为我们解决这个问题。它找到了代码中的瓶颈（假设零延迟处的无限内存带宽），并显示处理器是瓶颈的方式和原因，这通常足以确定是否有更多优化的房间。</p><p>  You might have noticed that the performance decreases as the buffer size becomes larger than our cache. It&#39;s possible to do a back of the envelope calculation to find the upper bound imposed by the limits of memory and cache performance, but working through the calculations would take a lot more space this this footnote has available to it. You can see a good example of how do it for one simple case  here. The comments by Nathan Kurz and John McCaplin are particularly good.</p><p>  您可能已经注意到，随着缓冲区大小的大于我们的缓存，性能会降低。它可能会做一下信封计算的背面，以找到因内存限制和缓存性能而强制的上限，但通过计算工作会花费更多的空间，这脚注可用。您可以看到一个很好的例子，其中一个简单的案例如何在这里。 Nathan Kurz和John McCaplin的评论特别好。 </p><p>   [return]</p><p>[返回]</p><p>  In the course of running these benchmarks, I also noticed that  _mm_cvtsi128_si64 produces bizarrely bad code on gcc (although it&#39;s fine in clang).  _mm_cvtsi128_si64 is the intrinsic for moving an SSE (SIMD) register to a general purpose register (GPR). The compiler has a lot of latitude over whether or not a variable should live in a register or in memory. Clang realizes that it&#39;s probably faster to move the value from an SSE register to a GPR if the result is about to get used. Gcc decides to save a register and move the data from the SSE register to memory, and then have the next instruction operate on memory, if that&#39;s possible. In our  popcnt example, clang uses about 2x for not unrolling the loop, and the rest comes from not being up to date on a CPU bug, which is understandable. It&#39;s hard to imagine why a compiler would do a register to memory move when it&#39;s about to operate on data unless it either doesn&#39;t do optimizations at all, or it has some bug which makes it unaware of the register to register version of the instruction. But at least it gets the right result,  unlike this version of MSVC.</p><p>  在运行这些基准的过程中，我也注意到_mm_cvtsi128_si64在gcc上产生奇异的坏代码（虽然它＆＃39;铿fine有良好）。 _MM_CVTSI128_SI64是将SSE（SIMD）寄存器移动到通用寄存器（GPR）的内在。编译器是否有很多纬度，而不是变量是否应该生活在寄存器中或内存中。 Clang意识到它＆＃39;如果结果即将使用，则可能更快地将来自SSE寄存器的值移动到GPR。 GCC决定保存寄存器并将数据从SSE寄存器移动到内存，然后将下一个指令运行在内存上，如果是，如果是的话，则可以进行操作。在我们的popcnt示例中，clang使用大约2x以便不展开循环，其余的来自于CPU错误的最新，这是可理解的。它很难想象为什么编译器会在它＆＃39;关于数据上运行时，编译器会对内存进行注册，除非它没有做到的＆＃39; t＆＃39; t做优化，否则它有一些错误不知道注册到注册版本的指令。但至少它得到了正确的结果，与此版本的MSVC不同。</p><p>  icc and armcc are reputed to be better at dealing with intrinsics, but they&#39;re non starters for most open source projects. Downloading icc&#39;s free non-commercial version has been disabled for the better part of a year, and even if it comes back, who&#39;s going to trust that it won&#39;t disappear again? As for armcc, I&#39;m not sure it&#39;s ever had a free version?</p><p>  ICC和ARMCC被誉为在处理内在机构时更好地更好地处理，但它们＆＃39;重新启动最开源项目的非启动器。下载ICC＆＃39;免费的非商业版已被禁用为一年的更好的部分，即使它回来，谁将相信它赢得了＆＃39; T再次消失？至于ARMCC，I＆＃39;不确定它有没有免费版本？</p><p>   [return]</p><p>   [返回] </p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://danluu.com/assembly-intrinsics/">https://danluu.com/assembly-intrinsics/</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/装配/">#装配</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/assembly/">#assembly</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/popcnt/">#popcnt</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/分享/">#分享</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy;2012-2021 diglog.com </div></div></body></html>