<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>我写了一个最快的dataframe库 I wrote one of the fastest DataFrame libraries</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">I wrote one of the fastest DataFrame libraries<br/>我写了一个最快的dataframe库 </h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2021-03-14 09:40:09</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2021/3/d632f36a75980488e4bd2ae331704447.webp"><img src="http://img2.diglog.com/img/2021/3/d632f36a75980488e4bd2ae331704447.webp" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>At the time of writing this, the coronavirus has been in our country for a year, which means I have been sitting at home for a very long time. At the start of the pandemic, I had a few pet projects in Rust under my belt and I noticed that the  “are we DataFrame yet”, wasn’t anywhere near my satisfaction. So I wondered if I could make a minimalistic crate that solved a specific use case of mine. But boy, did that get out of hand.</p><p>在撰写本文时，冠状病毒已经在我国一年，这意味着我一直在家里坐在家里。在大流行的开始时，我在腰带下有一些宠物项目，我注意到“我们是Dataframe”，并不是在我满意的附近。所以我想知道我是否可以制定一个简约的箱子，解决了我的具体用例。但是男孩，这是脱离的。</p><p> A year later with lots of programming resulting in one of the fastest DataFrame libraries available in Rust and Python. This is my first official “Hello World” from  polars on my personal blog. With this post, I hope I can take the reader along with some design decisions I encountered and get a more thorough understanding of how Polars works under the hood.</p><p> 一年后，有很多编程导致Rest和Python中可用的最快的DataFrame库之一。这是我个人博客上的波拉的第一个官方“Hello World”。通过这篇文章，我希望我能把读者赶上一些我遇到的设计决策，并更彻底了解波拉斯在引擎盖下的工作原理。</p><p>  I know it is quite a bold claim to make, and I would not make it lightly. There is a benchmark for database systems that does a benchmark on in-memory tools ran by h2o.ai. This benchmark consists of 10 groupby tests on different data cardinalities and query complexity to give a well-rounded view of a tool’s performance, and 5 tests on different join questions. At the time of writing this blog, Polars is the fastest DataFrame library in the benchmark second to R’s data.table, and Polars is top 3 all tools considered.</p><p>  我知道它是一个粗体的主张，我不会轻视。数据库系统有一个基准测试，该系统在内存工具上进行了基准，由H2O.AI运行。该基准测试由10个GroupBy测试组成，用于不同的数据基数和查询复杂性，以提供刀具性能的圆满观察，以及对不同连接问题的5个测试。在撰写本博客时，POLARS是基准测试中最快的DataFrame库.Table，Polars是Top 3所考虑的所有工具。</p><p> Below are shown the summaries of the 5GB dataset test, and you can see the whole  benchmark here.</p><p> 下面显示了5GB数据集测试的摘要，您可以在此处看到整个基准。</p><p>   If you want to design for optimal performance you cannot ignore hardware. There are cases where algorithmic complexity doesn’t give you a good intuition of the real performance due to hardware-related issues like cache hierarchies and branch prediction. For instance, up to a certain number of elements (a few 100, depending on the datatype), it is faster to lookup a given element in an array than to look it up in hashmap, whereas the time complexity of those data structures are $ \mathcal{O}(n) $, and $ \mathcal{O}(1) $ respectively.This makes design decisions also very temporal, what is a bottleneck in this day, may not be in the future. This is clearly seen in database systems. DB systems from the previous generation like PostgreSQL or MySQL are all row-based volcano models [1], which was an excellent design decision in that era when disks were much slower and RAM was very limited. Nowadays we have fast SSD disks and large amounts of memory available, and wide SIMD registers, we see that columnar databases like cockroachDB, DuckDB are among the best performing DBMSes.</p><p>   如果您想设计以获得最佳性能，则无法忽略硬件。由于硬件层次结构和分支预测等硬件相关问题，存在算法复杂性的情况下，算法复杂性不会让您对实际性能的良好直觉。例如，最多数量的元素（几个100，根据数据类型），在阵列中查找比在HashMap中查找的给定元素更快，而那些数据结构的时间复杂性是$ \ mathcal {o}（n）$和$ \ mathcal {o}（1）美元分别。这使得设计决策也是非常颞的，这是这一天的瓶颈，可能不会在未来。在数据库系统中清楚地看到了这一点。来自PostgreSQL或MySQL这样的前一代的DB系统都是基于行的Volcano模型[1]，这是当磁盘较慢而RAM非常有限时的一个优秀的设计决策。如今，我们有快速的SSD磁盘和大量的可用内存，以及宽的SIMD寄存器，我们看到坐标数据库等蟑螂，DuckDB是最好的DBMSE之一。</p><p>  Oversimplifying, RAM comes in two flavors, large and slow or fast and small. For this reason, you have memory caches in a hierarchy. You’ve got main memory that’s large and slow. And memory you’ve used last is stored in L1, L2, L3 cache with more latency respectively. The summation below gives you an idea of the relative latency of the different cache levels:</p><p>  过度简化，RAM有两种口味，大而缓慢或快速且小。因此，您在层次结构中有内存缓存。你有主要的记忆，这很大又慢。您使用的内存分别存储在L1，L2，L3缓存中，分别具有更多延迟。下面的求和使您了解不同缓存级别的相对延迟：</p><p>   When accessing data sequentially we want to make sure that data is in cache as much as possible, or we could easily have a ~100x performance penalty. Caches are loaded and deleted in cache lines. When we load a single data point, we get a whole cache line, but we also remove a whole cache line. They are typically 64, or 128 bytes long and aligned on 64-byte memory adresses.</p><p>   顺序访问数据时，我们希望尽可能确保数据处于缓存中，或者我们可以轻松地具有〜100x的性能损失。缓存已加载并删除缓存行中。当我们加载单个数据点时，我们得到一个整个缓存行，但我们也删除了一个整个缓存行。它们通常为64，或128个字节长，并在64字节内存地址上对齐。 </p><p>  CPUs prefetch data and instructions to a local cache to reduce the high penalty of memory latency. If you have a tight loop without any branches (if-else-then structures) the CPU has no problem knowing which data to prefetch and can fully utilize  instruction pipelines.</p><p>CPU预取数据和指令到本地缓存，以减少内存延迟的高损失。如果您在没有任何分支的情况下有一个紧密的循环（如果 - 然后 - 那么结构），CPU没有知道要预取的数据并可以充分利用指令管道的问题。</p><p> Instruction pipelines hide latency by doing work in parallel. Every CPU instruction goes through a  Fetch, Decode, Execute, Write-back sequence. Instead of doing these 4 instructions sequentially in a single pipeline, there are multiple pipelines that already pre-fetch (decode, execute, etc.) the next instructions. This increases throughput and hides latency. However, if this process is interrupted, you start with empty pipelines and you have to wait the full latency period for the next instruction. Below we see a visual of instruction pipelines.</p><p> 指令管道通过并行工作来隐藏延迟。每个CPU指令都通过获取，解码，执行，回写序列。而不是在单个管道中顺序顺序执行这条指令，而是有多个管道已经预先获取（解码，执行等）下一个指令。这增加了吞吐量并隐藏延迟。但是，如果此过程中断，则开始使用空管道，您必须等待下一个指令的完整延迟时间。下面我们看到了指令管道的视觉。</p><p>  The CPU does its best to predict which conditional jump is taken and speculatively execute that code in advance (i.e. keep the pipelines filled), but if it has mispredicted it must clear that work and we pay the latency price until the pipelines are full again.</p><p>  CPU确实最佳地预测，预测哪个条件跳跃并引导地提前执行该代码（即将管道填写），但如果它已经错误预测，则必须清除这项工作，我们支付延迟价格，直到管道再次支付延迟价格。</p><p>  Modern processors have SIMD registers (Single Instruction Multiple Data), which operate on whole vectors of data in a single CPU cycle. The vector lane widths vary from 128 bits to 512 bits, and the speedup depends on the width of the registers and the number of bits needed to represent the datatype. These register greatly improve the performance of simple operations if you can fill them fast enough (linear data). A columnar memory format can therefore fully utilize SIMD instructions. Polars and its memory backend Arrow, utilize SIMD to get optimal performance.</p><p>  现代处理器具有SIMD寄存器（单指令多数据），其在单个CPU周期中的整个数据向量上运行。矢量通道宽度从128位变化到512位，加速度取决于寄存器的宽度和表示数据类型所需的比特数。这些寄存器大大提高了简单操作的性能，如果您可以填充足够快（线性数据）。因此，柱状存储器格式可以充分利用SIMD指令。 POLARS及其内存后端箭头，利用SIMD获得最佳性能。</p><p>   Polars is based on the Rust native implementation  Apache Arrow. Arrow can be seen as middleware software for DBMS, query engines and DataFrame libraries. Arrow provides very cache-coherent data structures and proper missing data handling.</p><p>   波拉基于生锈本机实现Apache箭头。箭头可以被视为DBMS，查询引擎和DataFrame库的中间件软件。 arrow提供非常缓存相干的数据结构和正确缺少的数据处理。</p><p>   An Arrow numeric array consists of a data buffer containing some typed data, e.g.  f32,  u64, etc. , shown in the figure as an orange colored array. Besides the value data, an Arrow array alwas has a validity buffer. This buffer is a bit array where the bits indicate missing data. Because the missing data is represented by bits there is minimal memory overhead.</p><p>   箭头数字阵列由包含一些键入数据的数据缓冲区组成，例如， F32，U64等，如图所示为橙色彩色阵列。除了值数据之外，箭头数组alwas还有一个有效性缓冲区。此缓冲区是位数的位数，其中位指示缺失数据。因为缺失的数据由位表示有最小的内存开销。</p><p> This directly shows a clear advantage over Pandas for instance, where there is no clear distinction between a float  NaN and missing data, where they really should represent different things.</p><p> 这直接显示了Pandas的明显优势，例如，在浮动NaN和缺失数据之间没有明确区分，在那里他们真正应该代表不同的东西。 </p><p>   The figure below shows the memory layout of an Arrow  LargeString array. This figure encodes the following array  [&#34;foo&#34;, &#34;bar&#34;, &#34;ham&#34;]. The Arrow array consists of a data buffer where all string bytes are concatenated to a single sequential buffer (good for cache coherence!). To be able to find the starting and ending position of a string value there is a separate offset array, and finally, there is the null-bit buffer to indicate missing values.</p><p>下图显示了箭头最大阵列的存储器布局。这个数字编码了以下数组[＆＃34; foo＆＃34 ;,＃34;酒吧和＃34 ;,＃34;火腿＆＃34;]。箭头阵列由数据缓冲区组成，其中所有字符串字节都连接到单个顺序缓冲区（适用于缓存一致性！）。为了能够找到字符串值的起始和结束位置，有一个单独的偏移量阵列，最后，有空白位缓冲区以指示缺失值。</p><p>  Let’s compare this with a pandas string array. Pandas strings are actually Python objects, therefore they are boxed (which means there is also memory overhead to encode the type next to the data). Sequential string access in pandas will lead to cache miss after cache miss, because every string value may point to a completely different memory location.</p><p>  让我们将此与Pandas String阵列进行比较。 Pandas字符串实际上是Python对象，因此它们被盒装（这意味着还有内存开销来编码数据旁边的类型）。 Pandas中的顺序字符串访问将导致缓存未命中后的缓存未命中，因为每个字符串值都可能指向完全不同的内存位置。</p><p>  For cache coherence, the Arrow representation is a clear winner. However, there is a price. If we want to filter this array or we want to take values based on some index array we need to copy a lot more data around. The pandas string array only holds pointers to the data and can cheaply create a new array with pointers. Arrow string arrays have to copy all the string data, especially when you have large string values this can become a very large overhead. It is also harder to estimate the size of the string data buffer, as this comprises the length of all string values.</p><p>  对于缓存同时，箭头表示是一个明确的赢家。但是，有一个价格。如果我们想要过滤此数组，或者我们希望根据某些索引数组取值，我们需要复制更多的数据。 Pandas String数组仅将指针保存到数据，并且可以便宜地创建一个带指针的新数组。箭头字符串阵列必须复制所有字符串数据，尤其是当您有大字符串值时，这可能会成为一个非常大的开销。估计字符串数据缓冲区的大小也更难，因为这包括所有字符串值的长度。</p><p> Polars also has a  Categorical type which helps you mitigate this problem. Arrow also has a solution for this problem, called the  Dictionary type, which is similar to Polars&#39;  Categorical type.</p><p> Polars还具有一个分类类型，可以帮助您缓解此问题。 arrow还有一个解决这个问题的解决方案，称为字典类型，它类似于波拉＆＃39;分类类型。</p><p>  Arrow buffers are reference counted and immutable. Meaning that copying a DataFrame, Series, Array is almost a no-op, making it very easy to write purely functional code. The same counts for slicing operations, which are only an increment of the reference count and a modification of the offset.</p><p>  箭头缓冲器是参考计数和不可变的。意思是复制DataFrame，系列，数组几乎是一个无操作，使其非常容易写出纯粹的功能代码。切片操作的相同计数，这只是参考计数的增量和偏移的修改。</p><p>  As we’ve seen, the missing data is encoded in a separate buffer. This means we can easily write branchless code by just ignoring the null buffer during an operation. When the operation is finished the null bit buffer is just copied to the new array. When a branch miss would be more expensive than the execution of an operation this is an easy win and used in many operations in Arrow and Polars.</p><p>  正如我们所见，缺失的数据在单独的缓冲区中编码。这意味着我们可以通过仅在操作期间忽略空缓冲区来轻松编写无分支代码。操作完成后，空白位缓冲区仅复制到新数组。当一个分支未命中比执行操作更昂贵时，这很容易获胜并在箭头和点中的许多操作中使用。</p><p>  An operation that has to be done often in a DBMS, is a filter. Based on some predicate (boolean mask) we filter rows. Arrows null bit buffer allow for very fast filtering using a  filter-trick (unofficially named by me).  *Credits to the filter-trick go the Apache Arrow implementation. Note, that this filter-trick often leads to faster filters, but it may not always be the case. If your predicate consists of alternating boolean values e.g.   [true, false, true, false, ... , true, false] this trick has a slight overhead.</p><p>  必须在DBMS中进行的操作是过滤器。基于一些谓词（布尔掩码），我们过滤行。箭头空白位缓冲区允许使用筛选器技巧（非正式名称为ME）非常快速过滤。 *对筛选器的抵押符号GOACHE arrow实现。注意，此筛选器诀窍通常导致更快的过滤器，但情况并不总是如此。如果您的谓词包括交替布尔值，则[true，false，true，false，......，true，false]这个技巧有轻微的开销。 </p><p> The core idea of the filter-trick is that we can load the bit array from memory as any integer type we want. Let’s say that we load the bit array as an unsigned integer  u64 then we know that the maximum encoded value is $2^{64}$ (64 consecutive one value in binary), and the minimum encoded value is 0 (64 consecutive 0 values in binary). We can make a table of 64 entries that represent how many consecutive values we can filter and skip. If this integer is in this table we know have many values to filter in very few CPU cycles and can do a  memcpy to efficiently copy data. If the integer is not present in the table we have to iterate through the bits one by one and hope for a hit in the following 64 bits we load.</p><p>筛选器诀窍的核心思想是，我们可以将位数从内存加载为我们想要的任何整数类型。假设我们将位数组加载为无符号整数U64，然后我们知道最大编码值为$ 2 ^ {64} $（二进制中64个连续一个值），最小编码值为0（连续64个连续0值二进制）。我们可以制作一个64个条目的表，表示我们可以过滤和跳过的连续值。如果此整数在此表中，我们知道在很少几个CPU周期中过滤许多值，并且可以进行MEMCPY以有效复制数据。如果表格中不存在整数，我们必须逐一迭代位，并且希望在我们加载以下64位的以下64位命中。</p><p>  This filter-trick is used of course in any operation that includes a predicate mask, such as  filter,  set, and  zip.</p><p>  当然，在包括谓词掩模的任何操作中使用此滤波器技巧，例如过滤器，设置和zip。</p><p>  With the plateauing of CPU clock speeds and the end of Moore’s law in sight, the free lunch  [2] is over. Single-threaded performance isn’t going to increase much anymore. To mitigate this, almost all hardware nowadays has multiple cores. My laptop has 12 logical cores, so there is a tremendous potential for parallelization. Polars is written to exploit parallelism as much as possible.</p><p>  随着CPU时钟速度的平台和摩尔法在视线中，免费午餐[2]结束了。单线程性能不会再增加了。为了缓解这一点，现在几乎所有硬件都有多个核心。我的笔记本电脑有12个逻辑核心，因此有一个巨大的并行潜力。单击选材以尽可能多地剥削并行性。</p><p>  The best parallelization is of course where is no need for communication and there are no data dependencies. Polars utilizes this kind of parallelism as much as possible.</p><p>  最佳的并行化当然是不需要通信，没有数据依赖性。波拉尽可能利用这种并行性。</p><p> This is for instance the case if we do an aggregation on the columns in a DataFrame. All columns can be aggregated on in parallel.</p><p> 例如，如果我们在DataFrame中的列上执行聚合，则这是这样的。可以并行聚合所有列。</p><p>    Hashing is the core of many operations in a DataFrame library, a groupby-operation creates a hash table with the group index pointers, and a join operation needs a hash table to find the tuples mapping the rows of the left to the right DataFrame.</p><p>    散列是DataFrame库中许多操作的核心，GroupBy-Operation创建一个哈希表，其中包含组索引指针，并且加入操作需要一个哈希表，以查找映射左侧的行的组与右侧数据帧的组。</p><p>  In both operations, we cannot simply split the data among the threads. There is no guarantee that all the same keys would end up in the same hash table on the same thread. Therefore we would need an extra synchronization-phase where we build a new hashtable. This principle is shown in the figure below for 2 threads.</p><p>  在这两个操作中，我们不能简单地拆分线程之间的数据。无法保证所有相同的密钥将在同一线程上的相同哈希表中最终结束。因此，我们需要一个额外的同步阶段，我们构建了一个新的哈希表。该原理如下图所示，2个线程。 </p><p>   Another option that is found too expensive is hashing the data on separate threads and have a single hash table in a  mutex. As you can imagine, thread contention is very high in this algorithm and the parallelism doesn’t really pay of.</p><p>发现太贵的另一个选项是散列单独的线程上的数据，并在互斥锁中具有单个哈希表。正如您可以想象的那样，在这种算法中，线程争用非常高，并行性并不真正支付。</p><p>   Instead of the before mentioned approaches, Polars uses a lock-free hashing algorithm. This approach does do more work than the previous  Expensive locking approach, but this work is done in parallel and all threads are guaranteed to not have to wait on any other thread. Every thread computes the hashes of the keys, but depending on the outcome of the hash, it will determine if that key belongs to the hash table of that thread. This is simply determined by the  hash value % thread number. Due to this simple trick, we know that every threaded hash table has unique keys and we can simply combine the pointers of the hash tables on the main thread.</p><p>   代替之前提到的方法，POLARS使用锁定散列算法。这种方法确实比以前昂贵的锁定方法更多的工作，但是这项工作并行完成，保证所有线程都不必等待任何其他线程。每个线程计算键的哈希值，但根据散列的结果，它将确定该键是否属于该线程的哈希表。这只是由哈希值％线程编号确定。由于这个简单的技巧，我们知道每个线程哈希表都有唯一的键，我们可以简单地将哈希表的指针组合在主线程上。</p><p>   The best performance gains are simply not doing any work at all. Polars consists of two public APIs, one that is eager, procedural programming, and one that is lazy declarative programming. I would recommend using the lazy API as much as possible when dealing with performance-critical code.</p><p>   最好的性能收益根本不是在做任何工作。 Polars由两个公共API组成，一个是渴望，程序编程的一个，以及一个是懒惰的声明性编程。我建议在处理性能关键代码时尽可能多地使用懒惰API。</p><p> The declarative DSL allows Polars to analyze a logical plan of your query and it can apply several optimization/ heuristics such that your query can be executed by just doing less work. If you want to read more about the optimizations that are done to the query plan, there is a  section with examples in the polars book.</p><p> 声明性DSL允许POLARS分析查询的逻辑计划，它可以应用几种优化/启发式，使得您的查询可以通过较少的工作来执行。如果您想了解有关对查询计划所做的优化的更多信息，则在选项中有一个章节。</p><p>  This post only highlighted a few of the performance related designs in the Polars and Arrow library. Other things that are implemented are for instance:</p><p>  这篇文章仅突出了各个性能相关的设计，在波拉和箭头库中。实现的其他事项例如：</p><p>  Now the “hello world” is officially out there, I may highlight those other subjecst in later posts. Check out  polars on github, and if you have any remarks, feature requests, etc. let me know!</p><p>  现在，“Hello World”正式在那里，我可能会在后来的帖子中突出那些其他的子宫。检查GitHub上的选项，如果您有任何备注，功能请求等。请告诉我！</p><p>  [1] Graefe G.. Volcano (1994)  an extensible and parallel query evaluation system.  IEEE Trans. Knowl. Data Eng.   [2] Herb Sutter (2005)  The Free Lunch Is Over: A Fundamental Turn Toward Concurrency in Software  Weblog  [3] Angela Chang: CockroachDB (2019)  40x faster hash joiner with vectorized execution  Weblog</p><p>  [1] GRAEFE G。火山（1994）一个可扩展和并行查询评估系统。 IEEE Trans。知识。数据ENG。 [2] Herb Sutter（2005）免费午餐结束：在软件博客中的并发性的基本转向[3] Angela Chang：蟑螂（2019）40x速度哈希木匠与矢量化执行挂图 </p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://www.ritchievink.com/blog/2021/02/28/i-wrote-one-of-the-fastest-dataframe-libraries/">https://www.ritchievink.com/blog/2021/02/28/i-wrote-one-of-the-fastest-dataframe-libraries/</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/dataframe/">#dataframe</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/fastest/">#fastest</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/数据/">#数据</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/分享/">#分享</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy;2012 - 2021 diglog.com </div></div></body></html>