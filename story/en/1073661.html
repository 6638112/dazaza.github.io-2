<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>缓存编程风格的要素（2000）The Elements of Cache Programming Style (2000)</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">The Elements of Cache Programming Style (2000)<br/>缓存编程风格的要素（2000）</h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2022-02-17 01:41:39</div><div class="page_narrow text-break page_content"><p>Cache memories work on the carrot and stick principle. Thecarrot is the Principle of Locality and the stick is Amdahl&#39;s Law.The Principle of Locality says that programs tend to cluster theirmemory references. A memory location referenced once is likely to bereferenced again: temporal locality. A memory location nearby areferenced location is likely to be referenced soon: spatiallocality. And Amdahl&#39;s Law says that the performance improvement tobe gained from using some faster component is limited by the fractionof time the faster component is used. In this case, CPU and cache arefast components and memory is slow.</p><p>缓存内存的工作原理是胡萝卜加大棒。卡罗是地方性原则，棍子是阿姆达尔&#39；这是法律。局部性原则认为程序倾向于将它们的内存引用聚集在一起。一次引用的内存位置可能会再次被引用：时间位置。参考位置附近的记忆位置很可能很快就会被引用：空间性。阿姆达尔&#39；s Law表示，使用速度更快的组件所获得的性能改善受到使用速度更快组件的时间的限制。在这种情况下，CPU和缓存是快速组件，而内存则是缓慢的。</p><p> If your program adheres to the Principle of Locality, it benefitsfrom fast cache memory and runs at processor speed. If it doesn&#39;t, itis held accountable to Amdahl&#39;s Law and runs at memory speed. Hitrates have to be very high, say 98%, before incremental increases inprocessor speed are even noticeable.</p><p>如果您的程序遵循局部性原则，它将受益于快速缓存并以处理器速度运行。如果没有&#39；t、 它对阿姆达尔和#39负责；s定律并以内存速度运行。命中率必须非常高，比如说98%，然后处理器速度才能显著增加。</p><p> Amdahl&#39;s Law has a special circumstances penalty for multiprocessors[Schimmel94]. Thrashing on a multiprocessor can slow down all of theprocessors. They each wait for each other waiting for memory and theleverage a multiprocessor offers works in reverse. Adherence to thePrinciple of Locality for multiprocessors, but not to the point ofFalse Sharing, isn&#39;t just a nicety, it is a necessity.</p><p>阿姆达尔和#39；s定律对多处理器有特殊情况惩罚[Schimmel94]。在多处理器上进行抖动会降低所有处理器的速度。它们各自等待对方等待内存，而多处理器提供的内存则相反。遵守多处理器的局部性原则，但不遵守软件共享的原则，不是吗&#39；这不仅是一件好事，也是一种必需品。</p><p> The object of cache programming style is to increase this locality.It is important to understand the structure and behavior of caches,but it is more important to know the basic properties to takeadvantage of and the worst cases to avoid. This article goes intodetails and the summary provides guidelines.</p><p>缓存编程风格的目标是增加本地性。了解缓存的结构和行为很重要，但更重要的是了解要利用的基本属性和要避免的最坏情况。本文将详细介绍，摘要将提供指导。</p><p>   As a running example, I am going to look at Linux [Maxwell99]and at the scheduler in particular. The idea is to modify datastructures and code just slightly, trying to use the cache moreeffectively. Hopefully I will achieve two goals: a practical tutorialon caches and some performance improvements for Linux.</p><p>作为一个运行示例，我将研究Linux[Maxwell99]，尤其是调度程序。其想法是稍微修改数据结构和代码，尝试更有效地使用缓存。希望我能实现两个目标：一个实用的缓存教程和一些Linux性能改进。</p><p> Instead of talking about cache memory systems in general, I willmostly use my circa 1998 350 MHz Deschutes Pentium II system as aspecific example. It has these characteristics:</p><p>我将主要使用circa 1998 350 MHz Deschutes Pentium II系统作为一个具体的例子，而不是一般性地讨论高速缓存系统。它有以下特点：</p><p>  Storage    Size      Latency    Notes ----------------------------------------- ---------------------------- register   32 bytes   3ns       register renaming file L1         32K       6ns       on-chip, half Pentium-II clockrate L2         256K      57 ns     off-chip, on-package [Intel99a] memory     64 MB     162 ns     100 MHz SDRAM, single bank disk       10GB      9ms       DMA IDE network    whatever   whenever  56K PPP</p><p>存储大小延迟注释-------------------------------------------------------------------寄存器32字节3ns寄存器重命名文件L1 32K 6ns片上，半奔腾II时钟速率L2 256K 57 ns片外，在[Intel99a]封装内存64 MB 162 ns 100 MHz SDRAM、单银行磁盘10GB 9ms DMA IDE网络上，56K PPP</p><p>   These numbers are subject to change. CPU performance improves atabout 55%/year and memory improves at about 7%/year. Memory is big,cheap and slow while cache is small, fast and expensive. Double DataRate SDRAM and Rambus, when available, will improve memory bandwidthbut not latency. These improvements will help more predictableapplications like multimedia but not less predictable programs suchas Linux.</p><p>这些数字可能会发生变化。CPU性能每年提高约55%，内存每年提高约7%。内存大、成本低、速度慢，而缓存小、速度快、成本高。双数据速率SDRAM和Rambus（如果可用）将改善内存带宽，但不会改善延迟。这些改进将有助于多媒体等更具可预测性的应用程序，但不会影响Linux等可预测性较差的程序。</p><p>   First, a few words about caches in general. Cache memory fitsinto the storage hierarchy in terms of both size and speed. Cacheline misses, page faults and HTTP requests are the same thing atdifferent levels of this hierarchy. When a Squid proxy doesn&#39;t havean object in its cache, it forwards the HTTP request to the originserver. When a CPU requests an address which isn&#39;t in memory, a pagefault occurs and the page is read from disk. When a CPU requests anaddress which isn&#39;t in cache, the containing cache line is read frommemory. LRU, working set, associative, coherency, hashing,prefetching are all techniques and terminology which are used in eachlevel of the storage hierarchy.</p><p>首先，简单介绍一下缓存。缓存在大小和速度方面都与存储层次结构相匹配。缓存线未命中、页面错误和HTTP请求在这个层次结构的不同级别上是相同的。当Squid代理没有&#39；如果缓存中没有对象，它会将HTTP请求转发到原始服务器。当CPU请求的地址不是&#39；t在内存中，出现页面错误，从磁盘读取页面。当CPU请求的地址不是&#39；t在缓存中，包含的缓存线从内存中读取。LRU、工作集、关联性、一致性、哈希、预取都是存储层次结构的每一层中使用的技术和术语。</p><p> In each case, one smaller faster level in the hierarchy is backed byanother bigger slower level. If performance is limited by excessiveuse of the slower level, then according to Amdahl&#39;s Law, littleimprovement can be made by just making the faster level faster.</p><p>在每种情况下，层次结构中一个较小的较快级别都有另一个较大的较慢级别作为后盾。如果性能受到过度使用较慢级别的限制，则根据Amdahl和#39；根据s定律，只需加快速度，就可以实现微小的改进。</p><p> With respect to cache memory [Handy98], the most important thing tounderstand is the cache line. Typically a cache line is 32 bytes longand it is aligned to a 32 byte offset. First a block of memory, amemory line, is loaded into a cache line. This cost is a cache miss,the latency of memory. Then, after loading, bytes within a cache linecan be referenced without penalty as long as it remains in the cache.If the cache line isn&#39;t used it will be dropped eventually whenanother memory line needs to be loaded. If the cache line ismodified, it will need to be written before it is dropped.</p><p>关于缓存[Handy98]，最重要的是要理解缓存线。通常，缓存线的长度为32字节，并与32字节的偏移量对齐。首先，将内存块amemory line加载到缓存线中。这个代价是缓存丢失，即内存延迟。然后，加载后，只要缓存线中的字节仍在缓存中，就可以引用它，而不会受到惩罚。如果缓存线不是&#39；当需要加载另一个内存行时，它最终会被删除。如果修改了缓存线，则需要先写入缓存线，然后才能删除缓存线。</p><p> This is the simplest and most important view of a cache memory. Itslesson is two-fold: pack as much into a cache line as possible anduse as few cache lines as possible. Future memory bandwidth increases(DDR and Rambus) will reward this practice. The more complexcharacteristics of cache, the structure and behavior, are importantfor understanding and avoiding worst case cache behavior:thrashing.</p><p>这是最简单也是最重要的缓存视图。它的教训有两个：将尽可能多的数据打包到缓存线中，并使用尽可能少的缓存线。未来内存带宽的增加（DDR和Rambus）将奖励这种做法。缓存更复杂的特性，即结构和行为，对于理解和避免最坏情况下的缓存行为：抖动非常重要。</p><p> Competing for and sharing of cache lines is a good thing, up to apoint, when it becomes a bad thing. Ideally a fast cache will have ahigh cache hit rate and the performance will not be bound to thespeed of the memory. But a really bad thing, thrashing, happens whenthere is too much competition for too few cache lines. This happensin worst case scenarios for data structures. Unfortunately thecurrent profiling tools look at the instructions rather than data.This means that a programmer must be aware of worst case scenariosfor data structures and avoid them. A useful tool for finding a hotspot is cacheprof [Seward].</p><p>竞争和共享缓存线是一件好事，直到apoint成为一件坏事。理想情况下，快速缓存将具有较高的缓存命中率，并且性能不受内存速度的限制。但是，当缓存线太少而竞争太激烈时，就会发生一件非常糟糕的事情，即抖动。这种情况发生在数据结构的最坏情况下。不幸的是，当前的分析工具关注的是指令而不是数据。这意味着程序员必须了解数据结构的最坏情况，并避免它们。查找热点的有用工具是cacheprof[Seward]。</p><p>   The Pentium II [Shanley97] 32K L1 cache consists of 1024 32 bytecache lines partitioned into instruction and data banks of 512 lineseach. It uses the color bits 5-11 to index into an array of sets ofcache lines. In parallel, it compares the tag bits 12-31 (12-35 withPentium III Physical Address Extension) for each of the cache linesin the indexed set. L1 uses a 4-way set associative mapping whichdivides the 512 lines into 128 sets of 4 cache lines.</p><p>奔腾II[Shanley97]32K一级缓存由1024条32字节缓存线组成，这些缓存线被划分为512行缓存的指令和数据库。它使用颜色位5-11索引成一组缓存线。并行地，它比较索引集中每个缓存线的标记位12-31（12-35与Pentium III物理地址扩展）。L1使用4路集合关联映射，将512行划分为128组4条缓存线。</p><p> Each of these sets is really a least recently used (LRU) list. Ifthere is a match, the matching cache line is used and it is moved tothe front of the list. If there isn&#39;t a match, the data is fetchedfrom L2, the cache line at the end of the list is replaced and thenew entry is put at the front of the list.</p><p>这些集合中的每一个都是最近使用最少的（LRU）列表。如果有匹配项，则使用匹配的缓存线，并将其移动到列表的前面。如果没有&#39；如果匹配，则从二级获取数据，替换列表末尾的缓存线，并将新条目放在列表的前面。</p><p> Two memory lines of the same color compete for the same set of 4 L1cache lines. They are off the same color if their color bits (5-11)are the same. Alternatively they are of the same color if theiraddresses differ by a multiple of 4096: 2 ^ (7 color bits + 5 offsetbits). For example, address 64 and 12352 differ by 12288 which is3*4096. So, 64 and 12352 compete for a total of 4 L1 cache lines. But64 and 12384 differ by 12320, not a multiple of 4096, so they don&#39;tcompete for the same L1 cache lines.</p><p>同一颜色的两条内存线竞争同一组4条缓存线。如果它们的颜色位（5-11）相同，则它们的颜色不相同。或者，如果它们的衣服相差4096:2^（7个颜色位+5个偏移位）的倍数，则它们的颜色相同。例如，地址64和12352的差值为12288，即3*4096。因此，64和12352竞争总共4条一级缓存线。但是64和12384的差值是12320，不是4096的倍数，所以它们不&#39；t对相同的一级缓存线进行补偿。</p><p> Instructions are also cached. The Pentium II L1 cache is a Harvard,or split instruction/data cache. This means that instructions anddata never compete for the same L1 cache lines. L2 is a unifiedcache. Unified means that there is a single cache bank and thatinstructions and data compete for cache lines.</p><p>指令也被缓存。奔腾II一级缓存是哈佛（Harvard）或分割指令/数据缓存。这意味着指令和数据永远不会竞争相同的一级缓存线。L2是一个统一的缓存。统一意味着只有一个缓存库，指令和数据竞争缓存线。</p><p> L2 is similar to L1 except larger and much slower. The on-package256K L2 cache on my Pentium II has 8192 cache lines. It is also 4-wayset associative but is unified. There are Pentium II&#39;s with 512K ofL2 which increase the set size to 8. Also, there are PIII&#39;s with upto 2 MB of L2. If there is a cache line miss for L2, the cache lineis fetched from memory. Two memory lines compete for the same L2cache lines if they differ by a multiple of 64K: 2 ^ (11 cache colorbits + 5 offset bits).</p><p>L2与L1相似，只是更大、速度更慢。我的奔腾II上的联机包256K二级缓存有8192条缓存线。它也是4路集关联的，但是统一的。有奔腾II&#39；使用512K ofL2将集合大小增加到8。还有PIII&#39；具有高达2MB的L2的s。如果二级缓存线未命中，将从内存中提取缓存线。如果两条内存线相差64K:2^（11个缓存色位+5个偏移位）的倍数，则它们将竞争相同的L2cache线。</p><p>      We will start with the simple stuff. It is better to align justabout everything to a long word boundary. Linux is written in the gccprogramming language and a careful study of the gcc standardsdocument, &#34;Using and Porting GNU CC&#34; [Stallman00], istherefore necessary: no one embraces and extends quite like RichardStallman. gcc is particularly helpful with structure field alignmentwhich are intelligently and automatically aligned. ANSI C Standardallows for packing or padding according to the implementation.</p><p>我们将从简单的事情开始。最好是把每件事都和一个长单词的边界对齐。Linux是用gcc编程语言编写的，并且仔细研究了gcc标准文档&#34；使用和移植GNU CC&#34；[Stallman 00]因此是必要的：没有人像RichardStallman那样拥抱和延伸。gcc对智能自动对齐的结构字段对齐特别有用。ANSI C标准允许根据实施情况进行包装或填充。</p><p>     gcc automatically aligns d_reclen to a long boundary. This workswell for unsigned short, but for short on the x86 the compiler mustinsert sign extension instructions. If you are using a short to savespace, consider using an unsigned short. For example, in&lt;linux/mm.h&gt; changing the field vm_avl_height into an unsignedshort saves 32 bytes of instructions for a typical build. It couldjust as well be an int.</p><p>gcc自动将d_Recen与长边界对齐。这适用于无符号short，但对于x86上的short，编译器必须插入符号扩展指令。如果使用的是SaveSaveStEdStudio，请考虑使用无符号短。例如，在&lt；linux/mm。h&gt；将vm_avl_height字段更改为unsignedshort可以为典型构建节省32字节的指令。它也可以是一个int。</p><p>     Strings should be aligned as well. For example, strncmp() cancompare two long words at a time, cheap SIMD, if both source anddestination are long word aligned. The x86 code generator for egcs2.95.2 has a nice little bug that doesn&#39;t align short strings at alland aligns long strings to the cache line:</p><p>字符串也应该对齐。例如，如果源和目标都是长字对齐的，则strncmp（）可以一次比较两个长字，即廉价的SIMD。egcs2的x86代码生成器。95.2有一个不错的小bug，它不&#39；t ALL对齐短字符串并将长字符串与缓存线对齐：</p><p>  char* short_string = &#34;a_short_string&#34;; char* long_string = &#34;a_long_long_long_long_long_long_long_st ring&#34;;  .LC0:     .string   &#34;a_short_string&#34;           // an unaligned string     ...     .align 32 .LC1:                                       // aligned to cacheline     .string   &#34;a_long_long_long_long_long_long_long_st ring&#34;</p><p>char*short_string=&#34；短串&#34；；字符*长字符串=&#34；a_long_long_long_long_long_long_long_long_long_long_long_long_long_long_long_long_圣戒指&#34。LC0:。字符串&#34；一根短线&#34；//未对齐的字符串。。。    .对齐32。LC1://与缓存线对齐。字符串&#34；a_long_long_long_long_long_long_long_long_long_long_long_圣戒指&#34；</p><p>   What is necessary here is to align both strings to long wordswith .align 4. This uses less space and has better alignment. On atypical Linux build, this saves about 8K.</p><p>这里需要的是将两个字符串与长单词对齐。对齐4。这样使用的空间更少，对齐效果更好。在非典型Linux构建中，这节省了大约8K。</p><p>   Arrays and lists of structures offer an opportunity to cachealign large amounts of data. If the frequently accessed fields arecollected into a single cache line, they can be loaded with a singlememory access. This can reduce latency and cache footprint. However,it can also increase cache footprint if large amounts of data arebeing accessed. In this case, packing efficiency and also cachepollution are more important.</p><p>数组和结构列表提供了缓存大量数据的机会。如果频繁访问的字段被收集到单个缓存线中，则可以通过单内存访问加载它们。这可以减少延迟和缓存占用。然而，如果访问大量数据，它也会增加缓存占用空间。在这种情况下，包装效率和污染更为重要。</p><p> So for arrays, the base of an array should be cache aligned. The sizeof a structure must be either an integer multiple or an integerdivisor of the cache line size. If these conditions hold, then byinduction, each element of the array the cache line will be alignedor packed. Linked structures are analogous for alignment but don&#39;thave the size constraint.</p><p>因此，对于阵列，阵列的底部应该与缓存对齐。结构的大小必须是缓存线大小的整数倍或整数除数。如果这些条件保持不变，那么通过归纳，缓存线阵列的每个元素都将对齐或压缩。连接结构在对齐方面类似，但don&#39；有尺寸限制。</p><p> An array of structures of type mem_map_t is used by the pageallocator as a software page table:</p><p>mem_map_t类型的结构数组被pageallocator用作软件页表：</p><p>  /*  * Try to keep the most commonly accessed fields in single cachelines  * here (16 bytes or greater).  This ordering should beparticularly  * beneficial on 32-bit processors. ...  */ typedef struct page{                     //from linux-2.4.0-test2     structlist_head       list;        // 2,4     struct address_space*  mapping;     // 1,2     unsignedlong          index;       // 1,2     structpage*             next_hash;   // 1,2    atomic_t                count;       // 1,1+1     unsignedlong          flags;       // 1,2     structlist_head       lru;         // 2,4    wait_queue_head_t      wait;        // 5,10     structpage**          pprev_hash;  // 1,2     struct buffer_head*    buffers;     // 1,2     unsignedlong          virtual;     // 1,2     struct zone_struct*    zone;        // 1,2 }mem_map_t;                               // 18* 4 ==  72 x86                                            // 36 * 4 == 144 Alpha</p><p>/**尝试将最常访问的字段保存在单个缓存线*中（16字节或更大）。这种排序在32位处理器上应该特别有益类型定义结构页{//from linux-2.4.0-test2 structlist_head list；//2,4 struct address_space*映射；//1,2 unsignedlong index；//1,2 structpage*next_hash；//1,2 atomic_t计数；//1,1+1个无符号长标志；//1,2结构列表\u头lru；//2,4等待队列头等待；//5,10结构页**pprev_散列；//1,2 struct buffer_head*buffers；//1,2个无符号长虚拟；//1,2 struct zone_struct*zone；//1,2}mem_map_t；//18*4==72 x86//36*4==144 Alpha</p><p>   On a 32-bit Pentium, the size of mem_map_t is 72 bytes. It was40 bytes in 2.2.16. Since the array allocation code usessizeof(mem_map_t) to align the array, the base is aligned incorrectlyas well. In any case MAP_ALIGN() can be replaced withL1_CACHE_ALIGN() which uses simpler code:</p><p>在32位奔腾上，mem_map_t的大小为72字节。在2.2.16中是40字节。由于阵列分配代码使用SSIZEOF（mem_map___t）来对齐阵列，因此基座对齐不正确。在任何情况下，MAP_ALIGN（）都可以替换为L1_CACHE_ALIGN（），它使用更简单的代码：</p><p>  #define MAP_ALIGN(x) ((((x) % sizeof(mem_map_t)) ==0)           \     ? (x) : ((x) + sizeof(mem_map_t) - ((x) %sizeof(mem_map_t))))  lmem_map = (struct page *)(PAGE_OFFSET +    MAP_ALIGN((unsigned long)lmem_map - PAGE_OFFSET));  #define L1_CACHE_ALIGN(x)(((x)+(L1_CACHE_BYTES-1))               \     &amp;~(L1_CACHE_BYTES-1))  lmem_map = (struct page*) L1_CACHE_ALIGN((unsigned long)lmem_map);</p><p>#定义映射对齐（x）（（（x）%sizeof（mem_MAP_t））=0）\？（x） ：（（x）+sizeof（mem_map_t）-（x）%sizeof（mem_map_t）））lmem_map=（结构页面*）（页面偏移+贴图对齐（（无符号长）lmem_贴图-页面偏移）#定义一级缓存对齐（x）（（x）+（一级缓存字节-1））\&amp~（一级缓存字节-1））lmem_映射=（结构页*）一级缓存对齐（（无符号长）lmem_映射）；</p><p>   On a 64-bit Alpha, a long is 8 bytes with an 8 byte alignmentand sizeof(mem_map_t) is 144 bytes. The flags field doesn&#39;t need tobe a long, it should be an int. Since atomic_t is also an int and thetwo fields are adjacent, they would pack into a single long word. Thepage wait queue head used to be a pointer. Changing it back wouldsave enough to allow cache aligning both 32-bit and 64-bitversions.</p><p>在64位Alpha上，long是8字节，带有8字节对齐，sizeof（mem_map__t）是144字节。flags字段没有&#39；t不需要是长的，它应该是一个int。因为原子_t也是一个int，而且两个字段相邻，所以它们会组合成一个长单词。Page wait队列头过去是一个指针。将其更改回原来的版本将节省足够的内存，以允许缓存对齐32位和64位版本。</p><p>   It is possible to target and conditionally compile for aparticular processor. Linux has an include file,&lt;asm-i386/cache.h&gt;, defining the L1 cache line size,L1_CACHE_BYTES, for the x86 architecture family. The slab allocator[Bonwick94], which allocates small objects from memory pages, usesL1_CACHE_BYTES when a client requests a cache aligned object with theSLAB_HWCACHE_ALIGN flag.</p><p>可以针对特定的处理器进行有条件的编译。Linux有一个包含文件&lt；asm-i386/高速缓存。h&gt；，定义x86体系结构系列的一级缓存线大小，即一级缓存字节。slab分配器[Bonwick94]从内存页分配小对象，当客户机请求带有Lab_HWCACHE_ALIGN标志的缓存对齐对象时，它使用1_CACHE_字节。</p><p>  /*  * include/asm-i386/cache.h  */ #ifndef __ARCH_I386_CACHE_H #define __ARCH_I386_CACHE_H /* bytes per L1 cache line */ #if    CPU==586 || CPU==686 #define       L1_CACHE_BYTES  32 #else #define       L1_CACHE_BYTES  16 #endif #endif</p><p>/**包括/asm-i386/缓存。h*/#如果CPU==586 | CPU==686#定义一级缓存字节32#否则#定义一级缓存字节16#endif#endif#</p><p>   If someone got a Red Hat kernel conservatively compiledtargeting the 486, then it assumed 16 byte cache lines. It was alsowrong for the Athlon. This has been fixed in 2.4 by defining andusing the kernel configuration macro CONFIG_X86_L1_CACHE_BYTES in&lt;linux/autoconf.h&gt;.</p><p>如果有人得到了一个以486为目标的、经过保守编译的Red Hat内核，那么它就假定有16字节的缓存线。这对雅典人来说也是一件好事。在2.4中，通过在&lt；linux/autoconf。h&gt；。</p><p> If you must assume one cache line size when laying out the fieldsinside of structs intended for portable software, use 32 byte cachelines. For example, mem_map_t could use this. Notice that 32 bytealigned cache lines are also 16 byte aligned. The PowerPC 601nominally has a 64 byte cache line but it really has two connected 32byte cache lines. The Sparc64 has a 32 byte L1 and a 64 byte L2 cacheline. It is much easier to think of all systems as having 32 bytecache lines and enumerate the exceptions, if any. Alpha and Sparc64have 32 byte cache lines but the Athlon and Itanium, the exceptionsthat proves the rule, have 64 byte cache lines. And the IBM S/390 G6has a 256K L1 cache with 128 byte cache lines.</p><p>如果在设计用于便携软件的结构的fieldsinside时必须假定一个缓存线大小，请使用32字节缓存线。例如，mem_map_t可以使用这个。请注意，32字节对齐的缓存线也是16字节对齐的。PowerPC 601名义上有一个64字节的缓存线，但实际上有两个连接的32字节缓存线。Sparc64有一个32字节的L1和一个64字节的L2缓存线。将所有系统都视为具有32个字节缓存线并枚举异常（如果有）要容易得多。Alpha和Sparc64有32字节的缓存线，但Athlon和安腾（证明这一规则的例外）有64字节的缓存线。IBM S/390 G6有一个256K的一级缓存，带有128字节的缓存线。</p><p> On the vast majority of processors, 32 byte cache lines is the rightthing to do. And most importantly, if you have addressed and avoidedthe footprint and worst case thrashing scenarios in the 32 byte case,you will have avoided them for the other cases.</p><p>在绝大多数处理器上，32字节缓存线是正确的选择。最重要的是，如果在32字节的情况下解决并避免了足迹和最坏情况下的颠簸场景，那么在其他情况下就可以避免它们。</p><p>   Linux represents each process with a task_struct which isallocated two 4K pages. The task list is a list of the task_struct&#39;sof all existing processes. The runqueue is a list of thetask_struct&#39;s of all runnable processes. Each time the schedulerneeds to find another process to run, it searches the entire runqueuefor the most deserving process.</p><p>Linux用分配了两个4K页面的task_结构表示每个进程。任务列表是任务结构的列表&#39；sof所有现有流程。runqueue是任务结构的列表&#39；这是所有可运行进程的一部分。每次调度程序需要查找另一个要运行的进程时，它都会在整个运行队列中搜索最值得运行的进程。</p><p> Some folks at IBM [Bryant00] noticed that if there were a couple ofthousand threads that scheduling took a significant percentage of theavailable CPU time. On a uniprocessor machine with a couple ofthousand native Java threads, just the scheduler alone was taking upmore than 25% of the available CPU. This gets worse on a sharedmemory SMP machine because memory bus contention goes up. Thisdoesn&#39;t scale.</p><p>IBM[Bryant00]的一些人注意到，若有几个线程，调度占用了相当大的可用CPU时间。在一台具有数百个本地Java线程的单处理器机器上，仅调度程序就占用了超过25%的可用CPU。这在sharedmemory SMP机器上变得更糟，因为内存总线争用增加。这不是&#39；t刻度。</p><p> It turned out that the goodness() routine in the scheduler referencedseveral different cache lines in the task_struct. After reorganizingtask_struct, goodness() now references only a single cache line andthe CPU cycle count was reduced from 179 cycles to 115 cycles. Thisis still a lot.</p><p>事实证明，调度器中的goodness（）例程引用了task_结构中的几个不同缓存线。在重新组织任务结构之后，goodness（）现在只引用一条缓存线，CPU周期计数从179个周期减少到115个周期。这仍然很多。</p><p> Here is the important cache line, the Linux scheduling loop and thegoodness() routine. The scheduler loop iterates through the entirerunqueue, evaluates each process with goodness() and finds the bestprocess to run next.</p><p>下面是重要的缓存线、Linux调度循环和thegoodness（）例程。调度器循环遍历entirerunqueue，用goodness（）计算每个进程，并找到下一个要运行的最佳进程。</p><p>  struct task_struct {     ...    long             counter;          // critical 2cd cache line    long              priority;     unsigned long    policy;     struct mm_struct *mm, *active_mm;    int               has_cpu;    int               processor;     struct list_headrun_list;          //only first long word     ... };  tmp = runqueue_head.next; while (tmp != &amp;runqueue_head) {     p = list_entry(tmp, struct task_struct,run_list);     if (can_schedule(p)){               // running on another CPU         int weight = goodness(p,this_cpu, prev-&gt;active_mm);         if (weight &gt; c)             c= weight, next = p;     }     tmp = tmp-&gt;next; }  #define PROC_CHANGE_PENALTY  15        // processor affinity  static inline int goodness(struct task_struct *p,     int this_cpu, struct mm_struct *this_mm) {     int weight;     if (p-&gt;policy != SCHED_OTHER) {         weight = 1000 +p-&gt;rt_priority; // realtime processes         goto out;     }     weight = p-&gt;counter;     if (!weight)         gotoout;                         // no quanta left #ifdef __SMP__     if (p-&gt;processor == this_cpu)         weight +=PROC_CHANGE_PENALTY;  // processor affinity #endif     if (p-&gt;mm ==this_mm)                // same thread class         weight +=1;                     // ascurrent?     weight += p-&gt;priority; out:     return weight; }</p><p>结构任务{…long counter；//关键2cd缓存线长优先级；无符号长策略；结构mm_struct*mm，*active_mm；int有_cpu；int处理器；结构列表_headrun_lisT//只有第一个长单词…}；tmp=运行队列头。下一个while（tmp！=&amp；runqueue_head）{p=list_entry（tmp，struct task_struct，run_list）；if（can_schedule（p））{//在另一个CPU上运行int weight=goodness（p，this_CPU，prev-&gt；active_mm）；if（weight&gt；c）c=weight，next=p；}tmp=tmp-&gt；下一步；}#定义进程更改惩罚15//处理器关联静态内联int goodness（struct task_struct*p，int this_cpu，struct mm_struct*this_mm）{int weight；如果（p-&gt；policy！=SCHED_OTHER）{weight=1000+p-&gt；rt_priority；//实时进程退出；}重量=p-&gt；柜台如果（！重量）掉出来；//没有剩余的量子#ifdef _usmp _; if（p-&gt；处理器==此cpu）权重+=程序更改U惩罚；//处理器关联性#endif（p-&gt；mm==this_-mm）//相同线程类权重+=1；//电流？重量+=p-&gt；优先事项out：返回权重；}</p><p>   A long runqueue is certainly not the common case even forheavily loaded servers. This is because event driven programsessentially self schedule with poll(). The contrasting style,threading, is preferred by Java, Apache and TUX. It is ironic thatpoll() also had scalability problems, and on other Unix systems aswell [Honeyman99]. Also, the Linux 2.4 x86 kernels increase themaximum number of threads past 4000.</p><p>即使对于负载很重的服务器，长运行队列也肯定不是常见的情况。这是因为事件驱动的程序使用poll（）进行自我调度。相比之下，Java、Apache和TUX更喜欢线程化风格。讽刺的是，poll（）也存在可伸缩性问题，在其他Unix系统上也是如此[Honeyman 99]。此外，Linux 2.4 x86内核将最大线程数增加到4000个以上。</p><p> On SMP machines, processes have a scheduling affinity with the lastCPU they ran on. The idea is that some of the working set is still inthe local cache. But the scheduler has a subtle SMP bug. When a CPUhas no processes on the runqueue, the scheduler will assign it arunnable process with an affinity to another CPU. It would be wiserto first dole out more quanta to processes on the runqueue, perhapsonly those with an affinity to that CPU. Even then it may be betterto idle, particularly with a short runqueue.</p><p>在SMP机器上，进程与它们运行的最后一个CPU具有调度关联。这个想法是，一些工作集仍然在本地缓存中。但是调度程序有一个微妙的SMP错误。当一个CPU在运行队列上没有进程时，调度程序将把它分配给一个与另一个CPU有亲缘关系的可命名进程。明智的做法是首先向运行队列上的进程分配更多量子，也许是那些与CPU有关联的进程。即使这样，空闲也可能更好，尤其是在运行队列较短的情况下。</p><p>   Modern CPUs aggressively prefetch instructions but what aboutdata? CPUs don&#39;t prefetch data cache lines, but vectorizing compilersdo and programs can. Depending on the amount of CPU processing percache line, you may need to prefetch more than one cache line ahead.If the prefetch is scheduled sufficiently far in advance, it won&#39;tmatter if the cache line is in memory rather than L2 [Intel99a].</p><p>现代CPU积极地预取指令，但数据呢？CPU不&#39；t预取数据缓存线，但矢量化编译器和程序可以。根据CPU对缓存线的处理量，可能需要提前预取多条缓存线。如果预回迁提前了足够长的时间，它就赢了&#39；t判断缓存线是否在内存中，而不是L2[Intel99a]。</p><p> Typically prefetching is used in multimedia kernels and matrixoperations where the prefetched address can be easily calculated.Algorithms operating on data structures can use prefetch as well. Thesame methods apply except that the prefetched address will follow alink rather than an address calculation. Prefetching for datastructures is important since memory bandwidth is increasing fasterthan latency is decreasing. Traversing a data structure is morelikely to suffer from a latency problem. Often only a few fields in astructure are used whereas with multimedia usually every bit isexamined.</p><p>通常，预取用于多媒体内核和矩阵操作，其中预取地址可以轻松计算。在数据结构上运行的算法也可以使用预取。除了预取地址将遵循alink而不是地址计算之外，其他方法也适用。数据结构的预取非常重要，因为内存带宽的增加比延迟的减少更快。遍历数据结构更容易出现延迟问题。通常只使用结构中的几个字段，而使用多媒体时，通常会检查每个字段。</p><p>   If a prefetch instruction can be scheduled 20-25 or soinstructions before the cache line will be used, the fetch cancompletely overlap instruction execution. The exact prefetchscheduling distance is a characteristic of the processor and memory.Superscalar processors execute more than one instruction at atime.</p><p>如果一条预取指令可以在使用缓存线之前调度20-25次或SOI指令，则取数可以完全重叠指令执行。精确的预取调度距离是处理器和内存的一个特征。超标量处理器一次执行多条指令。</p><p>   If an algorithm is traversing a data structure likely to be inL2, and it can schedule a prefetch 6-10 instructions before the cacheline will be used, the fetch can completely overlap instructionexecution.</p><p>如果算法正在遍历可能是inL2的数据结构，并且可以在使用缓存线之前安排预取6-10条指令，则取数可以完全与指令执行重叠。</p><p> The Linux scheduler loop is a good candidate for cache lineprefetching from L2 because goodness() is short and after the IBMpatch, it only touches a single cache line.</p><p>Linux调度程序循环是从二级缓存线预取的一个很好的候选者，因为goodness（）很短，在IBMpatch之后，它只触及一条缓存线。</p><p> Here is a prefetching version of the scheduler. It overlaps theprefetch of the next cache line from L2 during the execution ofgoodness().</p><p>这是调度程序的预取版本。在goodness（）的执行过程中，它与二级缓存线的预取重叠。</p><p>  tmp = runqueue_head.next; while (tmp != &amp;runqueue_head) {     p = list_entry(tmp, struct task_struct,run_list);     tmp = tmp-&gt;next;    CacheLine_Prefetch(tmp-&gt;next);      //movl xx(%ebx),%eax     if (can_schedule(p)) {         int weight = goodness(p,this_cpu, prev-&gt;active_mm);         if (weight &gt; c)             c= weight, next = p;     } }</p><p>tmp=运行队列头。下一个while（tmp！=&amp；runqueue_head）{p=list_entry（tmp，struct task_struct，run_list）；tmp=tmp-&gt；next；CacheLine_Prefetch（tmp-&gt；next）//movl xx（%ebx），%eax if（can_schedule（p））{int weight=goods（p，this_cpu，prev-&gt；active_mm）；if（weight&gt；c）c=重量，next=p；    } }</p><p>   By the wa</p><p>华盛顿</p><p>......</p><p>......</p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/缓存/">#缓存</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/编程/">#编程</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/cache/">#cache</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/谷歌/">#谷歌</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy;2012-2021 diglog.com </div></div></body></html>