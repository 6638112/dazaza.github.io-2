<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>我们应该如何批评研究？ How Should We Critique Research?</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">How Should We Critique Research?<br/>我们应该如何批评研究？ </h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2021-04-16 23:40:49</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2021/4/b0767bca52ca00a8aeda4e8148f7abca.png"><img src="http://img2.diglog.com/img/2021/4/b0767bca52ca00a8aeda4e8148f7abca.png" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>Scientific and statistical research must be read with a critical eye to understand how credible the claims are. The Reproducibility Crisis and the growth of meta-science have demonstrated that much research is of low quality and often false. But there are so many possible things any given study could be criticized for, falling short of an unobtainable ideal, that it becomes unclear which possible criticism is important, and they may degenerate into mere rhetoric. How do we separate fatal flaws from unfortunate caveats from specious quibbling?</p><p>必须用批判性注意读取科学和统计研究，以了解索赔的可靠性。再现性危机和Meta-Science的增长表明，许多研究质量低，通常是假的。但是，有许多可能的研究可能被批评的任何可能的事情都批评，缺乏不可接受的理想，即不明确的是哪种可能的批评是重要的，他们可能会变得更加简而言之。我们如何将致命的缺陷与不幸的警告分开来自尊严的Quibing？</p><p> I offer a pragmatic criterion: what makes a criticism important is how much it could change a result if corrected and how much that would then change our decisions or actions: to what extent it is a “difference which makes a difference”. This is why issues of research fraud, causal inference, or biases yielding overestimates are universally important, because a ‘causal’ effect turning out to be zero effect or overestimated by a factor will change almost all decisions based on such research; while on the other hand, other issues like measurement error or distributional assumptions, which are equally common, are often  not important as they typically yield much smaller changes in conclusions, and hence decisions.</p><p> 我提供了务实的标准：是什么构成批评的重要性是如果纠正以及更改我们的决定或行动，它可以改变多少，这将如何改变我们的决定或行动：这是一个“差异有所不同”的程度。这就是为什么研究欺诈，因果推断或偏见产生高估的原因是普遍重要的，因为“因因素”的“因果”效应被归零效应或过度归因于因素将根据此类研究改变几乎所有决定;另一方面，虽然测量误差或分布假设等其他问题通常不重要，因为它们通常在结论中通常产生更小的变化，因此决定。</p><p> If we regularly ask whether a criticism would make this kind of difference, it will be clearer which ones are important criticisms, and which ones risk being rhetorical distractions and obstructing meaningful evaluation of research.</p><p> 如果我们经常询问批评是否会产生这种差异，那么它将更清楚，哪些是重要的批评，其中风险是修辞分心和阻碍有意义的研究评估。</p><p> Learning statistics is great. If you want to read and understand scientific papers in general, there’s little better to learn than statistics because  everything these days touches on statistical issues and draws on increasingly powerful statistical methods and large datasets, whether flashy like machine learning or mundane like geneticists drawing on biobanks of millions of people, and if you don’t have at least some grasp of statistics, you will be increasingly left out of scientific and technological progress and unable to meaningfully discuss their application to society, so you must have a good grounding in statistics if you are at all interested in these topics—or so I want to say. The problem is… learning statistics can be dangerous.</p><p> 学习统计数据很棒。如果您想一般阅读和理解科学论文，比统计数据更好地学习，因为这些天的一切都涉及统计问题，并借鉴越来越强大的统计方法和大型数据集，无论是诸如机器学习还是世俗的遗传学家等遗传学家数百万人，如果你没有至少对统计数据掌握，你将越来越多地遗漏科学和技术进步，并且无法将他们的申请与社会有意义地讨论，所以如果你必须在统计数据上有很好的基础您对这些主题感兴趣 - 或者我想说。问题是...学习统计可能是危险的。</p><p> Like learning some formal logic or about cognitive biases, statistics seems like the sort of thing one might say “A little learning is a dangerous thing /  Drink deep, or taste not the Pierian spring /  There shallow draughts intoxicate the brain, /  And drinking largely sobers us again.”</p><p> 比如学习一些正式的逻辑或关于认知偏见，统计看起来可能会说“一点学习是危险的东西/饮酒深刻，或者味道不是彼得安春天/有浅薄的草稿醉酒，主要喝酒再次索布我们。“</p><p> When you first learn some formal logic and about fallacies, it’s hard to not use the shiny new hammer to go around playing ‘fallacy bingo’ (to mix metaphors): “aha! that is an  ad hominem, my good sir, and a logically invalid objection.” The problem, of course, is that many fallacies are perfectly good as a matter of inductive logic:  ad hominems are often highly relevant (eg if the person is being bribed). A rigorous insistence on formal syllogisms will at best waste a lot of time, and at worst becomes a tool for self-delusion by selective application of rigor.</p><p> 当你第一次学习一些正式的逻辑和关于谬误时，很难不使用闪亮的新锤子来播放“秋季宾果”（混合隐喻）：“AHA！这是一个广告主页，我的好先生，以及逻辑上无效的反对意见。“当然，问题是，随着归纳逻辑的问题严格坚持正式的三段论将以最好的浪费大量的时间，并且在最糟糕的是通过选择性地应用严格的自我妄想工具。</p><p> Similarly, cognitive biases are hard to use effectively (because they are informative priors in some cases, and in common harmful cases, one will have already learned better), but are easy to abuse—it’s always easiest to see how someone  else is sadly falling prey to confirmation bias.</p><p> 同样，认知偏差很难有效使用（因为它们是某些情况下的信息前瞻，并且在普通有害的情况下，人们已经学会了更好），但很容易滥用 - 它总是最容易看出别人悲伤的伤害猎物确认偏见。 </p><p> So, what do we mean by statistical criticism? what makes a good or bad statistical objection?</p><p>那么，我们的统计批评是什么意思？是什么，做出了好或坏的统计反对意见？</p><p> “Here I should like to say: a wheel that can be turned though nothing else moves with it, is not part of the mechanism.”</p><p> “在这里，我想说：一个可以转动的轮子，但没有别的东西，这不是机制的一部分。”</p><p> It can’t just be that a criticism is boring and provokes eye-rolling—someone who in every genetics discussion from ~2000–2010 harped on statistical power &amp; polygenicity and stated that all these exciting new candidate-gene &amp; gene-environment interaction results were so much hogwash and the entire literature garbage would have been deeply irritating to read, wear out their welcome fast, and have been  absolutely right⁠. (Or for nutrition research, or for social psychology, or for…) As provoking as it may be to read yet another person sloganize “correlation ≠ causation” or “yeah, in mice!”, unfortunately, for much research  that is all that should ever be said about it, no matter how much we weary of it.</p><p> 它不能只是一种批评是无聊的，引起眼球的恐惧 - 从〜2000-2010竖立在统计权力＆amp上的每一个遗传讨论中的人;多种因素，并陈述了所有这些令人兴奋的新候选基因＆amp;基因 - 环境互动结果是如此多的婆婆，整个文学垃圾是深感令人深感令人沮丧的，磨掉他们的欢迎快，并绝对是正确的。 （或用于营养研究，或社会心理学，或......）作为挑衅，因为它可能是读取另一个人黄黄色“相关性≠的因果关系”或“是的，在老鼠中！”，不幸的是，对于所有这一切的研究不管我们厌倦了多少，都应该说出来。</p><p> It can’t be that some assumption is violated (or unproven or unprovable), or that some aspect of the real world is left out, because all statistical models are massively abstract, gross simplifications. Because it is  always possible to identify some issue of inappropriate assumption of normality, or some autocorrelation which is not modeled, or some nonlinear term not included, or prior information left out, or data lacking in some respect. Checklists and preregistrations and other techniques can help improve the quality considerably, but will never solve this problem. Short of tautological analysis of a computer simulation, there is not and never has been a perfect statistical analysis, and if there was, it would be too complicated for anyone to understand (which is a criticism as well). All of our models are false, but some may be useful, and a good statistical analysis is merely ‘good enough’.</p><p> 不能违反（或未经证实或无法移动）的一些假设，或者现实世界的某些方面被遗漏了，因为所有统计模型都是大规模的摘要，毛额简化。因为始终可以识别一些不恰当的正常假设的问题，或者没有建模的一些自相关，或者一些不包括的非线性术语，或遗漏的现有信息，或者在某种方面缺乏数据。清单和预先记录和其他技术可以有助于提高质量，但永远不会解决这个问题。缺乏对计算机模拟的TaItolorical分析，没有并且从未成为一个完美的统计分析，如果有的话，任何人都要理解（这是一种批评）将过于复杂。我们所有的型号都是假的，但有些可能有用，并且良好的统计分析仅仅是“足够好”。</p><p> It can’t be that results “replicate” or not. Replicability doesn’t say much other than if further data were collected the same way, the results would stay the same. While a result which doesn’t replicate is of questionable value at best (it most likely wasn’t real to begin with  3), a result being replicable is no guarantee of quality either. One may have a consistent   process, but replicable garbage is still garbage. To collect more data may be to simply more precisely estimate the process’s systematic error and biases. (No matter how many published homeopathy papers you can find showing homeopathy works, it doesn’t.)</p><p> 它不能是结果“复制”。重复性并没有说出除了同样的方式收集进一步的数据，结果将保持不变。虽然最佳复制的结果是值得怀疑的值（它很可能是不是真实的，但是以3开始），结果是可复制的结果无法保证质量。一个可能有一致的过程，但可复制的垃圾仍然是垃圾。要收集更多数据，可以简单地更精确地估计过程的系统错误和偏差。 （无论您如何发表的顺势疗法论文，您都可以找到同种疗法，它没有。）</p><p> It certainly has little to do with  p-values, either in a study or in its replications (because nothing of interest has to do with  p-values); if we correct an error and change a specific  p-value from  p = 0.05 to  p = 0.06, so what? ( “Surely, God loves the 0.06 nearly as much as the 0.05…”) Posterior probabilities, while meaningful and important, also are no criterion: is it important if a study has a posterior probability of a parameter being greater than zero of 95% rather than 94%? Or &gt;99%? Or &gt;50%? If a criticism, when corrected, reduces a posterior probability from 99% to 90%, is that what we mean by an important criticism? Probably (ahem) not.</p><p> 它肯定与在研究中或复制中的p值几乎没有（因为没有兴趣与p值有关）;如果我们纠正错误并从p = 0.05从p = 0.06更改特定的p值，那么是什么？ （“肯定，上帝喜欢0.06几乎和0.05 ......”）后验概率，而有意义和重要，也没有标准：如果一个研究的参数的后验概率大于95％而不是94％？或＆gt; 99％？或＆gt; 50％？如果批评，在纠正时，将后续概率从99％降至90％，这是我们的意思是一个重要的批评？可能（咳咳）没有。</p><p> It also doesn’t have to do with any increase or decrease in effect sizes. If a study makes some errors which means that it produces an effect size twice as large as it should, this might be absolutely damning or it might be largely irrelevant. Perhaps the uncertainty was at least that large so no one took the point-estimate at face-value to begin with, or everyone understood the potential for errors and understood the point-estimate was an upper bound. Or perhaps the effect is so large that overestimation by a factor of  10 wouldn’t be a problem.</p><p> 它还不必与效果大小的任何增加或减少有关。如果一项研究产生一些错误，这意味着它会产生两倍大的效果大小，因为它应该是绝对达到的，或者可能很大程度上无关紧要。也许不确定性至少是大大的所以没有人在面值开始估计，以便开始，或者每个人都理解错误的可能性，并理解这一点是一个上限。或许效果如此之大，以至于超过10倍的估计不会是一个问题。 </p><p> It usually doesn’t have to do with predictive power (whether quantified as R 2 or   etc); sheer prediction is the goal of a subset of research (although if one could show that a particular choice led to a lower predictive score, that would be a good critique), and in many contexts, the best model is not particularly predictive at all, and a model being  too predictive is a red flag.</p><p>它通常与预测力量不一定（无论是否量化为R 2 OR）;纯粹的预测是研究子集的目标（尽管如果人们可以表明一个特定的选择导致更低的预测得分，那将是一个良好的批评），并且在许多情况下，最好的模型根本不是特别预测的，并且模型过于预测性是红旗。</p><p> “The statistician is no longer an alchemist expected to produce gold from any worthless material offered him. He is more like a chemist capable of assaying exactly how much of value it contains, and capable also of extracting this amount, and no more. In these circumstances, it would be foolish to commend a statistician because his results are precise, or to reprove because they are not. If he is competent in his craft, the value of the result follows solely from the value of the material given him. It contains so much information and no more. His job is only to produce what it contains…Immensely laborious calculations on inferior data may increase the yield from 95 to 100 per cent. A gain of 5 per cent, of perhaps a small total. A competent overhauling of the process of collection, or of the experimental design, may often increase the yield ten or twelve fold, for the same cost in time and labour. …To consult the statistician after an experiment is finished is often merely to ask him to conduct a  post mortem examination. He can perhaps say what the experiment died of.”</p><p> “统计名不再是一个预期的炼金术士，预计将从任何毫无价值的材料中生产金子。他更像是一种化学家，能够确切地测定它含有多少价值，也能够提取这个量，而且没有更多。在这种情况下，赞扬统计名人是愚蠢的，因为他的结果精确，或者责备，因为他们不是。如果他在他的工艺中能够称职，那么结果的价值就是仅仅从给予他的材料的价值。它包含了这么多信息，不再是。他的工作只是制作它所含的东西......对劣等数据的艰巨计算可能会增加95％至100％的产量。增长5％，也许是少量的。在收集过程中或实验设计的过程中，可能往往增加产量十或十二倍，以相同的时间和劳动力。 ......在实验结束后咨询统计学家通常只是要求他进行验尸检查。他也许可以说实验死于什么。“</p><p>  Well, if a draft of a study was found and the claims were based on a statistically-significant effect in one variable, but in the final published version, it omits that variable and talks only about a different variable, one would wonder. Discovering that authors of a study had been paid millions of dollars by a company benefiting from the study results would seriously shake one’s confidence in the results. If a correlation didn’t exist at all when we compared siblings within a family, or better yet, identical twins, or if the correlation didn’t exist in other datasets, or other countries, then regardless of how strongly supported it is in that one dataset, it would be a concern. If a fancy new machine learning model outperformed   by 2%, but turned out to not be using a heldout sample properly and actually performed the same, doubtless ML researchers would be less impressed. If someone showed an   reached the opposite effect size to a correlational analysis, that would strike most people as important. If a major new cancer drug was being touted as being as effective as the usual chemotherapy with fewer side-effects in the latest trial, and one sees that both were being compared to a null hypothesis of zero effect and the point-estimate for the new drug was lower than the usual chemotherapy, would patients want to use it? If a psychology experiment had different results with a passive control group and an active control group, or a surgery’s results depend on whether the clinical trial used blinding, certainly an issue. And if data was fabricated entirely, that would certainly be worth mentioning.</p><p>  嗯，如果发现了一项研究的草案，并且索赔基于一个变量的统计上显着的效果，但在最终发布的版本中，它省略了该变量并仅谈论不同的变量，一个人会想知道。发现一项研究的作者通过从研究结果受益的公司获得了数百万美元，这将严重震撼一个人对结果的信心。如果在我们在家庭内比较兄弟姐妹，或者更好的尚未相同的双胞胎，或者在其他数据集或其他国家/地区不存在相关性，那么如果在其他国家/地区的相关性，则不存在相关性，那么无论它有多强烈支持一个数据集，这将是一个问题。如果一个花哨的新机器学习模型表现出2％，但原来不正确地使用挖掘样品并实际执行相同，但无疑的ML研究人员将不那么印象。如果有人表明达到相反的效果规模，以与相关的分析达成相反的效果，那将使大多数人变得重要。如果在最新试验中吹捧了一个主要的新癌症药物作为通常的副作用的常量效果有效，并且看到两者都与零效应的零效果和新的点估计相比药物低于常用化疗，患者是否想要使用它？如果心理学实验与被动对照组和活性对照组有不同的结果，或者手术的结果取决于临床试验是否致盲，当然是一个问题。如果数据完全制作，那么这肯定值得一提。</p><p> These are all inherently different going by some of the conventional views outlined above. So what do they have in common that makes them good criticisms?</p><p> 这些传统观点都是本质上的本质上的不同。那么它们有什么共同之处，使他们成为良好的批评？</p><p> “Results are only valuable when the amount by which they probably differ from the truth is so small as to be insignificant for the purposes of the experiment. What the odds should be depends:”</p><p> “结果只有当他们可能与真相不同的金额有价值，这对于实验的目的而言是如此之小。赔率应该取决于：“</p><p> “On the degree of accuracy which the nature of the experiment allows, and”</p><p> “关于实验性质允许的准确度和”</p><p> ⁠, “The Application of the ‘Law of Error’ to the work of the Brewery”, 1904  4</p><p> ⁠，“在啤酒厂的工作中的应用”，啤酒厂的工作“，1904 4 </p><p> “Moreover, the economic approach seems (if not rejected owing to aristocratic or puritanic taboos) the only device apt to distinguish neatly what is or is not contradictory in the logic of uncertainty (or probability theory). That is the fundamental lesson supplied by   notion of  …probability theory and decision theory are but two versions (theoretical and practical) of the study of the same subject: uncertainty.”</p><p>“此外，经济方法似乎（如果不受贵族或清教徒的禁忌拒绝）唯一的设备才能在不确定（或概率理论）逻辑中易于区分或不矛盾。这是......概率理论和决策理论所提供的基本课程是同一主题研究的两个版本（理论和实用）：不确定。“</p><p> But what I think they share in common is this decision-theoretic justification which unifies criticisms (and would unify  statistical pedagogy too):</p><p> 但我认为他们共同分享的是这种决定理论的理由，统一批评（并将统一统计教育学）：</p><p> The importance of a statistical criticism is the probability that it would change a hypothetical decision based on that research.</p><p> 统计批判的重要性是它将改变基于该研究的假设决策的可能性。</p><p> I would assert that  p-values are not posterior probabilities are not effect sizes are not utilities are not profits are not decisions. Dichotomies come from decisions. All analyses are ultimately decision analyses: our beliefs and analyses may be continuous, but our actions are discrete.</p><p> 我会断言，P值不是后验概率不是效果大小不是公用事业不是利润不是决策。二分法来自决定。所有分析最终是决策分析：我们的信念和分析可能是连续的，但我们的行为是离散的。</p><p> When we critique a study, the standard we grope towards is one which ultimately terminates in real-world actions and decision-making, a standard which is inherently context-dependent, admits of no bright lines, and depends on the use and motivation for research, grounded in what is the right thing to do.  5</p><p> 当我们批评研究时，我们遵循的标准是最终终止于现实世界的行动和决策，这是一个固有的上下文依赖的标准，承认没有明亮的线条，并取决于研究的使用和动机，接地是正确的事情。 5.</p><p>  It doesn’t have anything to do with attaining some arbitrary level of “significance” or being “well-powered” or having a certain  k in a meta-analysis for estimating heterogeneity, or even any particular posterior probability, or effect size threshold; it doesn’t have anything to do with violating a particular assumption, unless, by violating that assumption, the model is not ‘good enough’ and would lead to bad choices; and it is loosely tied to replication (because if a result doesn’t replicate in the future situations in which actions will be taken, it’s not useful for planning) but not defined by it (as a result could replicate fine while still being useless).</p><p>  对于获得一些任意级别的“意义”或“良好的”或在良好的ks中具有某种k，以估计异质性，甚至任何特定的后阈值，或效应尺寸阈值;与违反特定假设没有任何关系，除非违反这种假设，否则模型不是“足够好”，并会导致糟糕的选择;它被松散地绑定到复制（因为如果结果在将在将采取行动的未来情况下复制，因此它没有用规划），但没有由它定义（结果可以在仍未无用时复制很好） 。</p><p> The importance of many of these criticisms can be made much more intuitive by asking what the research is for and how it would affect a downstream decision. We don’t need to do a formal decision analysis going all the way from data through a Bayesian analysis to utilities and a causal model to compare (although this would be useful to do and might be necessary in edge cases), an informal consideration can be a good start, as one can intuitively guess at the downstream effects.</p><p> 许多这些批评的重要性可以通过询问研究是什么以及如何影响下游决定来更加直观。我们不需要通过贝叶斯分析到公用事业的分析以及对比较的因果模型一直进行正式的决策分析（尽管这将是有用的，并且在边缘案件中可能是必要的），但可以是一个非正式的考虑是一个很好的开始，因为人们可以直观地猜测下游效果。 </p><p> I think we can meaningfully apply this criterion even to ‘pure’ research questions where it is unclear how the research would ever be applied, specifically. We know a great deal about epistemology and scientific methodology and what practices tend to lead to reliable knowledge. (When people argue in favor of pure research because of its history of spinoffs like cryptography from number theory, that very argument implies that the spinoffs aren’t  that unpredictable &amp; is a successful pragmatic defense. The fact that our evolved curiosity can be useful is surely no accident.)</p><p>我认为我们也可以有意义地应用这个标准，即使是“纯粹”的研究问题，尚不清楚如何应用研究，具体而言。我们对认识论和科学方法论有很大的了解以及哪些实践往往会导致可靠的知识。 （当人们争论纯粹的研究时，因为它的旋转史如加密学的历史，所以非常论证意味着疏散不是那种不可预测的＆amp;是一个成功的务实防御。我们进化的好奇心是有用的事实肯定没有意外。）</p><p> For example, even without a specific purpose in mind for some research, we can see why forging fraudulent data is the worst possible criticism: because there is no decision whatsoever which is made better by using faked data. Many assumptions or shortcuts will work in some cases, but there is no case where fake data, which is uncorrelated with reality, works; even in the case where the fake data is scrupulously forged to exactly replicate the best understanding of reality  6⁠, it damages decision-making by overstating the amount of evidence, leading to overconfidence and underexploration.</p><p> 例如，即使没有针对某些研究的特定目的，我们也可以看到为什么伪造欺诈性数据是可能的最批评：因为没有任何决定，通过使用伪造的数据来更好地实现。许多假设或快捷方式将在某些情况下工作，但在某些情况下，没有假数据，这与现实不相关，工作;即使在伪造的数据被限制为完全复制对现实的最佳了解的情况下，它也夸大了夸大证据的决策，导致过度频繁和曝光率。</p><p> Similarly, careless data collection and measurement error. Microbiologists couldn’t know about   in advance, before it was discovered by comparing odd entries in   databases, and it’s a good example of how pure research can lead to tremendous gains. But how could you discover  anything from   databases if they are incomplete, full of mislabeled/ contaminated samples, or the sequencing was done sloppily &amp; the sequences largely random garbage? If you’re studying ‘cancer cells’ and they are a mislabeled cell line &amp; actually liver cells, how could that possibly add to knowledge about cancer?</p><p> 同样，粗心的数据收集和测量误差。在通过比较数据库中的奇数条目发现之前，微生物学家无法提前了解，并且是纯粹研究如何导致巨大收益的一个很好的例子。但是，如果它们是不完整的，充满误标记/污染的样品，或者差不多，你怎么能发现来自数据库的任何东西，或者排序是邋ily＆amp的测序;序列很大程度上是随机垃圾？如果您正在研究“癌细胞”，它们是误标记的细胞系＆amp;实际上肝细胞，可能会增加癌症的知识吗？</p><p> Or consider the placebo effect. If you learned that a particular study’s result was driven entirely by a placebo effect and that using blinding would yield a null, I can safely predict that—regardless of field or topic or anything else—you will almost always be badly disappointed. If a study measures just a placebo effect (specifically, demand or expectancy effects), this is damning, because the placebo effect is already known to be universally applicable (so showing that it happened again is not interesting) through a narrow psychological causal mechanism which fades out over time &amp; doesn’t affect hard endpoints (like mortality), while it doesn’t affect the countless causal mechanisms which placebo-biased studies  seem to be manipulating (and whose manipulation would in fact be useful both immediately and for building theories). If, say,   except through the placebo effect, why would we want to use them? There are  some exceptions where we would be indifferent after learning a result was just a placebo effect (chronic pain treatment? mild influenza?), but not many.</p><p> 或考虑安慰剂效应。如果您了解到，特定的研究结果完全由安慰剂效应驱动，并且使用盲目会产生空，我可以安全地预测 - 无论现场或哪个主题或其他任何东西 - 你几乎总是非常失望。如果一项研究措施只是安慰剂效应（具体而言，需求或期望效应），这是诅咒的，因为通过狭窄的心理因果机制，安慰剂效应已被称为普遍适用（因此表明它再次发生并不有趣）随着时间的推移而消失;不会影响硬端点（如死亡率），而它不会影响安慰剂偏置的研究似乎操纵的无数因果机制（其操纵实际上是立即和建筑理论有用）。如果说，除了通过安慰剂效应，我们为什么要使用它们？在学习后，我们会在难以置信的情况下才有一些例外情况只是安慰剂效应（慢性疼痛治疗？轻度流感？），但不多。</p><p> How about non-replicability? The simplest explanation for the Replicability Crisis in psychology is that most of the results aren’t real and were random noise,  p-hacked into publications. The most charitable interpretation made by apologists is that the effects  were real, but they are simply either small or so highly context-dependent on the exact details (the precise location, color of the paper, experimenter, etc) to the point where even collaborating with the original researchers is not guaranteed to replicate successfully an effect. Again, regardless of the specific result, this presents a trilemma which is particularly damaging from a decision-theory point of view:</p><p> 不可复制性怎么样？心理学中可复制性危机的最简单解释是，大多数结果都不是真实的并且是随机噪声，P-hacked进入出版物。辩护者所作的最慈善的解释是，这些效果是真实的，但它们只是缺乏小或如此非常高度的上下文，依赖于确切的细节（纸张，实验者等的精确位置，颜色，实验等）甚至合作使用原始研究人员无法保证成功复制效果。同样，无论具体结果如何，这都提出了一种Treilmma，它与决策理论的观点特别损害：</p><p> they are much smaller than reported (and thus much less useful for any kind of application or theory-building),</p><p> 它们远小于报道（因此对任何类型的应用或理论建设有用的不太有用），</p><p> or they are so fragile and in any future context almost as likely to be some other effect, in even the opposite direction, that their average effect is effectively zero (and thus useless).</p><p> 或者它们如此脆弱，在任何未来的上下文中，几乎可能是一些其他效果，甚至相反的方向，它们的平均效果有效零（并且因此无用）。 </p><p> Decisions precede beliefs. Our ontology and our epistemology flows from our decision theory, not vice-versa. This may appear to be logically backwards, but that is the situation we are in, as evolved embodied beings thinking &amp; acting under uncertainty: like  Otto Neurath’s  —there is nowhere we can ‘step aside’ and construct all belief and knowledge up from scratch and logical metaphysics, instead, we examine and repair our raft as we stand on it, piece by piece. The naturalistic answer to the skeptic (like  ) is that our beliefs are not unreliable because they are empirical or evolved or ultimately temporally begin in trial-and-error but they are reliable  because they have been gradually evolved to pragmatically be correct for decision-making, and  due to the constraints of evolution⁠, developed reliable knowledge of the world and methods of science. (An example of reversing the flow would be the Deutsch-Wallace attempt to found  the Born   on decision theory; earlier, statisticians such as  ⁠,  ⁠,  ⁠,  ⁠,   &amp;   etc showed that much of statistics could be grounded in decision-making instead of vice-versa, demonstrated by the subjective probability school and devices like the   enforcing  ⁠.)</p><p>决定在信仰之前。我们的本体论和我们的认识论从我们的决策理论中流动，而不是反之亦然。这可能似乎是逻辑向后，但这是我们所在的情况，因为所体现的生物思维＆amp;在不确定性下行事：就像奥托尼卫生的 - 这无处可去，我们可以从划痕和逻辑形而上学构建所有信仰和知识，而是我们在我们站立时检查和修复我们的筏子，逐一的作品。对怀疑论者（比如）的自然主义答案是，我们的信仰并不可靠，因为它们是经验的或进化的或者最终在审判和错误中开始，但它们是可靠的，因为它们已被逐步发展以务实地对决策进行务实正确而被争论，并且由于进化的约束，开发了对世界的可靠知识和科学方法。 （逆转流程的一个例子将是Deutsch-Wallace试图在决策理论上发现出生;之前，统计学家如⁠，⁠，⁠，⁠，＆amp;等表明，大部分统计数据都可以在决策中被接地而不是反之亦然，由主观概率学校和依照⁠。）</p><p> “A good rule of thumb might be, ‘If I added a zero to this number, would the sentence containing it mean something different to me?’ If the answer is ‘no’, maybe the number has no business being in the sentence in the first place.”</p><p> “一个好的拇指规则可能是，”如果我向这个号码添加了一个零，那句话会意味着与我不同吗？“如果答案是'否'，也许这个数字也没有业务在句子中没有业务第一个地方。“</p><p>  A critique of  assuming correlation = causation is a good one, because correlation is usually not causation, and going from an implicit ~100% certainty that it is to a more realistic 25% or less, would change many decisions as that observation alone reduces the expected value by &gt;75%, which is a big enough penalty to eliminate many appealing-sounding things.</p><p>  假设相关性=因果关系是一个好的，因为相关性通常不是因果关系，并且从隐含的〜100％确定，它是一个更现实的25％或更少，可以改变许多决定，因为单独的观察可以减少这种观察预期价值＆gt; 75％，这是一种足够的惩罚，消除了许多吸引人的发言。</p><p> Because causal effects are such a central topic, any methodological errors which affect inference of correlation rather than causation are important errors.</p><p> 由于因果效应是如此的核心主题，任何影响相关性引起的方法错误，而不是因果关系都是重要的错误。</p><p> A critique of  distributional assumptions (such as observing that a variable isn’t so much normal as Student’s  t-distributed) isn’t  usually an important one, because the change in the posterior distribution of any key variable will be minimal, and could change only decisions which are on a knife’s-edge to begin with (and thus, of little value).</p><p> 一种批评的分布假设（例如观察变量并不是如此，因为学生的T分布式不那么正常）通常是重要的，因为任何关键变量的后部分布的变化都会很小，并且可能会改变只有在刀刃上的决定，开始（并且因此，几乎没有价值）。</p><p> There are exceptions here, and in some areas, this can be critical. Distribution-wise, using a normal instead of a log-normal is often minor since they are so similar in the bulk of their distribution… unless we are talking about their  tails, like in an   context (common in any kind of selection or extremes analysis, such as employment or athletics or  media or natural disasters), where the more extreme points out on the tail are the important thing; in which case, using a normal will lead to wild underestimates of how far out those outliers will be, which could be of great practical importance</p><p> 这里有异常，在某些区域，这可能是至关重要的。分布明智，使用正常而不是逻辑正常通常很小，因为它们在其分发的大部分中如此相似......除非我们谈论他们的尾巴，就像在一个上下文中一样（在任何类型的选择或极端分析中常见，例如就业或田径或媒体或自然灾害），在尾巴上更加极端的指向是重要的;在这种情况下，使用正常会导致狂放的低估这些异常值的距离是多少，这可能具有很大的实际重要性</p><p> On the other hand, treating a Li</p><p> 另一方面，治疗李 </p><p>......</p><p>...... </p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://www.gwern.net/Research-criticism">https://www.gwern.net/Research-criticism</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/批评/">#批评</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/critique/">#critique</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/研究/">#研究</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/分享/">#分享</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy;2012-2021 diglog.com </div></div></body></html>