<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>一种激进的新技术让人工智能在几乎没有数据的情况下学习</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">一种激进的新技术让人工智能在几乎没有数据的情况下学习</h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2020-10-19 03:55:41</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2020/10/eeec9a4b1344d33d99a0a14e66d4ae43.jpg"><img src="http://img2.diglog.com/img/2020/10/eeec9a4b1344d33d99a0a14e66d4ae43.jpg" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>Machine learning typically requires tons of examples. To get an AI model to recognize a horse, you need to show it thousands of images of horses. This is what makes the technology computationally expensive—and very different from human learning. A child often needs to see just a few examples of an object, or even only one, before being able to recognize it for life.</p><p>机器学习通常需要大量的例子。要让人工智能模型识别一匹马，你需要向它展示数以千计的马的图像。这就是这项技术在计算上昂贵的原因-而且与人类学习有很大的不同。孩子通常只需要看到几个物体的例子，甚至只有一个，才能终生识别它。</p><p>  In fact, children sometimes don’t need  any examples to identify something. Shown photos of a horse and a rhino, and told a unicorn is something in between, they can recognize the mythical creature in a picture book the first time they see it.</p><p>事实上，孩子们有时不需要任何例子来识别东西。他们展示了一匹马和一头犀牛的照片，并告诉他们独角兽介于两者之间，他们可以在第一次看到图画书中的神话生物时认出它。</p><p>    Now  a  new paper from the University of Waterloo in Ontario suggests that AI models should also be able to do this—a process the researchers call “less than one”-shot, or LO-shot, learning. In other words, an AI model should be able to accurately recognize  more objects than the number of examples it was trained on. That could be a big deal for a field that has grown increasingly expensive and inaccessible as the data sets used become ever larger.</p><p>现在，安大略省滑铁卢大学的一篇新论文提出，人工智能模型也应该能够做到这一点-研究人员称这一过程“不到一次”-拍摄，或Lo-shot，学习。换句话说，人工智能模型应该能够准确识别比它所训练的样本数量更多的对象。对于一个随着使用的数据集变得越来越大而变得越来越昂贵和难以进入的领域来说，这可能是一个大问题。</p><p>    The researchers first demonstrated this idea while experimenting with the popular computer-vision data set known as  MNIST. MNIST, which contains 60,000 training images of handwritten digits from 0 to 9, is often used to test out new ideas in the field.</p><p>研究人员在实验流行的计算机视觉数据集MNIST时首次演示了这一想法。MNIST包含从0到9的6万个手写数字的训练图像，经常用于在该领域测试新想法。</p><p>  In  a previous paper, MIT researchers had introduced a technique to “distill” giant data sets into tiny ones, and as a proof of concept, they had compressed MNIST down to only 10 images. The images weren’t selected from the original data set but carefully engineered and optimized to contain an equivalent amount of information to the full set. As a result, when trained exclusively on the 10 images, an AI model could achieve nearly the same accuracy as one trained on all MNIST’s images.</p><p>在之前的一篇论文中，麻省理工学院的研究人员介绍了一种技术，将巨大的数据集“提炼”成微小的数据集，作为概念的证明，他们将MNIST压缩到只有10张图像。这些图像不是从原始数据集中挑选出来的，而是经过精心设计和优化的，以包含与全套相同的信息量。因此，当只对这10张图像进行训练时，人工智能模型可以达到几乎与对所有MNIST图像进行训练的准确度相同的精度。</p><p>      The Waterloo researchers wanted to take the distillation process further. If it’s possible to shrink 60,000 images down to 10, why not squeeze them into five? The trick, they realized, was to create images that blend multiple digits together and then feed them into an AI model with hybrid, or “soft,” labels. (Think back to a horse and rhino having partial features of a unicorn.)</p><p>滑铁卢的研究人员希望进一步推进蒸馏过程。如果可以将60,000张图片缩小到10张，为什么不把它们压缩成5张呢？他们意识到，诀窍是创建将多个数字混合在一起的图像，然后将它们输入到带有混合或“软”标签的人工智能模型中。(回想一下具有独角兽部分特征的马和犀牛。)。</p><p>  “If you think about the digit 3, it kind of also looks like the digit 8 but nothing like the digit 7,” says Ilia Sucholutsky, a PhD student at Waterloo and lead author of the paper. “Soft labels try to capture these shared features. So instead of telling the machine, ‘This image is the digit 3,’ we say, ‘This image is 60% the digit 3, 30% the digit 8, and 10% the digit 0.’”</p><p>滑铁卢大学博士生、这篇论文的主要作者伊利亚·苏库鲁茨基(Ilia Sucholutsky)说：“如果你想一想数字3，它看起来也有点像数字8，但与数字7一点也不像。”“软标签试图捕捉这些共享功能。因此，我们不会告诉机器，‘这个图像是数字3’，而是说，‘这个图像是数字3的60%，数字8的30%，数字0的10%。’“。</p><p>    Once the researchers successfully used soft labels to achieve LO-shot learning on MNIST, they began to wonder how far this idea could actually go. Is there a limit to the number of categories you can teach an AI model to identify from a tiny number of examples?</p><p>一旦研究人员成功地使用软标签在MNIST上实现了Lo-shot学习，他们就开始怀疑这个想法实际上能走多远。你可以教一个人工智能模型从极少的例子中识别的类别有没有限制？</p><p>  Surprisingly, the answer seems to be no. With carefully engineered soft labels, even two examples could theoretically encode any number of categories. “With two points, you can separate a thousand classes or 10,000 classes or a million classes,” Sucholutsky says.</p><p>令人惊讶的是，答案似乎是否定的。通过精心设计的软标签，理论上即使是两个示例也可以对任意数量的类别进行编码。Sucholutsky说：“有了两个点，你就可以把一千个班级、一万个班级或者一百万个班级分开。”</p><p>    This is what the researchers demonstrate in their latest paper, through a purely mathematical exploration. They play out the concept with one of the simplest machine-learning algorithms, known as k-nearest neighbors (kNN), which classifies objects using a graphical approach.</p><p>这是研究人员在他们的最新论文中通过纯粹的数学探索证明的。他们用一种最简单的机器学习算法来实现这一概念，称为k近邻(KNN)，这种算法使用图形方法对对象进行分类。</p><p>  To understand how kNN works, take the task of classifying fruits as an example. If you want to train a kNN model to understand the difference between apples and oranges, you must first select the features you want to use to represent each fruit. Perhaps you choose color and weight, so for each apple and orange, you feed the kNN one data point with the fruit’s color as its x-value and weight as its y-value. The kNN algorithm then plots all the data points on a 2D chart and draws a boundary line straight down the middle between the apples and the oranges. At this point the plot is split neatly into two classes, and the algorithm can now decide whether new data points represent one or the other based on which side of the line they fall on.</p><p>要了解KNN是如何工作的，请以水果分类任务为例。如果要训练KNN模型以理解苹果和橙子之间的区别，则必须首先选择要用来表示每个水果的特征。也许您选择颜色和重量，因此对于每个苹果和橙子，您用水果的颜色作为其x值，将重量作为其y值，向knn提供一个数据点。然后，KNN算法将所有数据点绘制在2D图表上，并在苹果和橙子之间沿中间垂直绘制一条边界线。在这一点上，曲线图被整齐地分成两类，算法现在可以根据新数据点位于直线的哪一侧来决定它们代表的是其中一个还是另一个。</p><p>  To explore LO-shot learning with the kNN algorithm, the researchers created a series of tiny synthetic data sets and carefully engineered their soft labels. Then they let the kNN plot the boundary lines it was seeing and found it successfully split the plot up into more classes than data points. The researchers also had a high degree of control over where the boundary lines fell. Using various tweaks to the soft labels, they could get the kNN algorithm to draw precise patterns in the shape of flowers.</p><p>为了探索使用KNN算法的Lo-shot学习，研究人员创建了一系列微小的合成数据集，并仔细设计了它们的软标签。然后，他们让KNN绘制它看到的边界线，并发现它成功地将曲线图分成了比数据点更多的类。研究人员还高度控制了边界线落在哪里。通过对软标签进行各种调整，他们可以得到KNN算法来绘制精确的花朵形状图案。</p><p>    Of course, these theoretical explorations have some limits. While the idea of LO-shot learning should transfer to more complex algorithms, the task of engineering the soft-labeled examples grows substantially harder. The kNN algorithm is interpretable and visual, making it possible for humans to design the labels; neural networks are complicated and impenetrable, meaning the same may not be true. Data distillation, which works for designing soft-labeled examples for neural networks, also has a major disadvantage: it requires you to start with a giant data set in order to shrink it down to something more efficient.</p><p>当然，这些理论探索也有一定的局限性。虽然Lo-shot学习的想法应该转移到更复杂的算法上，但设计软标记示例的任务变得更加困难。KNN算法是可解释和可视的，使得人类可以设计标签；神经网络复杂且难以穿透，这意味着同样的情况可能不是真的。为神经网络设计软标签示例的数据蒸馏也有一个主要缺点：它要求您从一个巨大的数据集开始，以便将其缩减为更有效的数据集。</p><p>  Sucholutsky says he’s now working on figuring out other ways to engineer these tiny synthetic data sets—whether that means designing them by hand or with another algorithm. Despite these additional research challenges, however, the paper provides the theoretical foundations for LO-shot learning. “The conclusion is depending on what kind of data sets you have, you can probably get massive efficiency gains,” he says.</p><p>Sucholutsky说，他现在正致力于找出其他方法来设计这些微小的合成数据集-无论这是指手工设计还是用另一种算法设计。然而，尽管存在这些额外的研究挑战，本文还是为Lo-shot学习提供了理论基础。“结论是，根据你拥有的数据集的类型，你可能会获得巨大的效率提升，”他说。</p><p>  This is what most interests Tongzhou Wang, an MIT PhD student who led the earlier research on data distillation. “The paper builds upon a really novel and important goal: learning powerful models from small data sets,” he says of Sucholutsky’s contribution.</p><p>这是最让通州王感兴趣的，他是麻省理工学院的博士生，领导了早期关于数据蒸馏的研究。“这篇论文建立在一个非常新颖和重要的目标之上：从小数据集中学习强大的模型，”他在谈到苏库卢茨基的贡献时说。</p><p>  Ryan Khurana, a researcher at the Montreal AI Ethics Institute, echoes this sentiment: “Most significantly, ‘less than one’-shot learning would radically reduce data requirements for getting a functioning model built.” This could make AI more accessible to companies and industries that have thus far been hampered by the field’s data requirements. It could also improve data privacy, because less information would have to be extracted from individuals to train useful models.</p><p>蒙特利尔人工智能伦理研究所的研究员瑞安·库拉纳(Ryan Khurana)呼应了这一观点：“最重要的是，‘少于一次’的学习将从根本上降低建立功能模型所需的数据需求。”这可能会使人工智能更容易被到目前为止受到该领域数据要求阻碍的公司和行业使用。它还可以改善数据隐私，因为训练有用的模型需要从个人那里提取更少的信息。</p><p>  Sucholutsky emphasizes that the research is still early, but he is excited. Every time he begins presenting his paper to fellow researchers, their initial reaction is to say that the idea is impossible, he says. When they suddenly realize it isn’t, it opens up a whole new world.</p><p>Sucholutsky强调，这项研究还为时过早，但他很兴奋。他说，每次他开始向其他研究人员展示他的论文时，他们的第一反应是说这个想法是不可能的。当他们突然意识到事实并非如此时，它打开了一个全新的世界。</p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://www.technologyreview.com/2020/10/16/1010566/ai-machine-learning-with-tiny-data/">https://www.technologyreview.com/2020/10/16/1010566/ai-machine-learning-with-tiny-data/</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/人工智能/">#人工智能</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/数据/">#数据</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/technique/">#technique</a></button></div></div><div class="shadow p-3 mb-5 bg-white rounded clearfix"><div class="container"><div class="row"><div class="col-sm"><div><a target="_blank" href="/story/1029566.html"><img src="http://img2.diglog.com/img/2020/10/thumb_a25834e671f1317b78cd89cfeee6cb6d.png" class="img-fluid" onerror="this.style.display='none'"></a></div><div class="item_title"><a target="_blank" href="/story/1029566.html">看看“神经符号人工智能”，它结合了深度神经网络技术和“优秀的老式人工智能”，其支持者和批评者都发表了评论</a></div><span class="my_story_list_date">2020-10-18 14:18</span></div><div class="col-sm"><div><a target="_blank" href="/story/1029464.html"><img src="http://img2.diglog.com/img/2020/10/thumb_a0638e4eefdd1ad8da1fb70e0320c216.jpeg" class="img-fluid" onerror="this.style.display='none'"></a></div><div class="item_title"><a target="_blank" href="/story/1029464.html">人工智能编程的范式</a></div><span class="my_story_list_date">2020-10-18 0:10</span></div><div class="col-sm"><div><a target="_blank" href="/story/1029432.html"><img src="http://img2.diglog.com/img/2020/10/thumb_5dd9aac1c9652bd8460827272517f9d9.jpg" class="img-fluid" onerror="this.style.display='none'"></a></div><div class="item_title"><a target="_blank" href="/story/1029432.html">巴尔多之门3号开发者建造了一个测试人工智能。然后，他们试图击败它</a></div><span class="my_story_list_date">2020-10-17 19:37</span></div><div class="col-sm"><div><a target="_blank" href="/story/1029115.html"><img src="http://img2.diglog.com/img/2020/10/thumb_bb097cbc0a9dbcd8ea6b781154f90aa1.png" class="img-fluid" onerror="this.style.display='none'"></a></div><div class="item_title"><a target="_blank" href="/story/1029115.html">
自大流行以来，谷歌的对话式人工智能Duplex已经更新了3M+的企业列表</a></div><span class="my_story_list_date">2020-10-16 4:25</span></div></div></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/美国/">#美国</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/谷歌/">#谷歌</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/linux/">#linux</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/程序/">#程序</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy; 2020 diglog.com </div></div></body></html>