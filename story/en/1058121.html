<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>书评：“一千个大脑”由杰夫霍金斯 Book Review: “A Thousand Brains” by Jeff Hawkins</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">Book Review: “A Thousand Brains” by Jeff Hawkins<br/>书评：“一千个大脑”由杰夫霍金斯 </h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2021-04-14 00:38:43</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2021/4/923c2d73f240b076cddc957ba0581219.png"><img src="http://img2.diglog.com/img/2021/4/923c2d73f240b076cddc957ba0581219.png" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>Jeff Hawkins gets full credit for getting me first interested in the idea that neuroscience might lead to artificial general intelligence—an idea which gradually turned into an all-consuming hobby, and more recently a new job. I&#39;m not alone in finding him inspiring. Andrew Ng claimed   here that Hawkins helped convince him, as a young professor, that a simple scaled-up learning algorithm could reach Artificial General Intelligence (AGI). (Ironically, Hawkins scoffs at the deep neural nets built by Ng and others—Hawkins would say: &#34;Yes yes, a simple scaled-up learning algorithm can reach AGI, but not  that learning algorithm!!&#34;)</p><p>杰夫·霍金斯获得了对神经科学可能导致人为一般情报的想法充分信誉 - 这是一个逐渐变成了繁殖的爱好的想法，最近是一项新工作。我并不孤单地找到他的鼓舞人心。 Andrew Ng在这里声称霍金斯帮助他说服了他作为一个年轻的教授，这是一个简单的缩放学习算法可以达到人为的一般情报（AGI）。 （讽刺地，讽刺地，由NG和其他人建造的霍金斯嘲笑在NG和其他人 - 霍金斯愿意：＆＃34;是的，一个简单的缩放学习算法可以达到AGI，但不是那个学习算法!!＆＃34;）</p><p> Hawkins&#39;s last book was  On Intelligence in 2004. What&#39;s he been up to since then? Well, if you don&#39;t want to spend the time reading his journal articles or  watching his research meetings on YouTube, good news for you—his new book,  A Thousand Brains, is out! There’s a lot of fascinating stuff here. I&#39;m going to pick and choose a couple topics that I find especially interesting and important, but do read the book for much more that I&#39;m not mentioning.</p><p> 霍金斯＆＃39;最后一本书在2004年是智力。从那时起，他一直在做什么？好吧，如果你不想花时间阅读他的日记文章或观看他对YouTube的研究会议，请为你的好消息 - 他的新书，一千个大脑，出了！这里有很多迷人的东西。我要选择一对夫妇，我发现了特别有趣，重要的话题，但是更多地阅读这本书。更多的是我没有提到。</p><p>  Many expert neuroscientists think that the brain is horrifically complicated, and we are centuries away from understanding it well enough to build AGI (i.e., computer systems that have the same kind of common-sense and flexible understanding of the world and ability to solve problems that humans do). Not Jeff Hawkins! He thinks we  can understand the brain well enough to copy its principles into an AGI. And he doesn&#39;t think that goal is centuries away. He thinks we&#39;re most of the way there! In   an interview last year he guessed that we’re within 20 years of finishing the job.</p><p>  许多专家的神经科学家认为大脑是恐怖复杂的，我们几个世纪以来，从理解它足以建立AGI（即具有同样的常识和灵活理解世界的计算机系统和解决问题的能力人类。不是杰夫霍金斯！他认为我们能够理解大脑，足以将其原则复制到AGI中。他并不认为这个目标是几个世纪的距离。他认为我们在那里的大部分方式！去年在一次面试中，他猜到了我们在完成工作的20年内。</p><p> The people arguing that the brain is horrifically complicated seem at first glance to have a strong case. The brain has a whopping          10     11 neurons with          10     14 synapses, packed full of intricate structure.   One study found 180 distinct areas within the cerebral cortex. Neuroscience students pour over huge stacks of flashcards with terms like “striatum”, “habenula”, “stria medullaris”, “fregula”, and &#34;interpeduncular nucleus&#34;. (Quiz: Which of those are real brain regions, and which are types of pasta?) Every year we get another 50,000 or so new neuroscience papers dumped into our ever-deepening ocean of knowledge about the brain, with no end in sight.</p><p> 争论大脑在恐怖复杂的人乍一看乍一看似乎有一个强有力的案例。大脑具有高达10个11神经元，具有10个突触1014个突触，充满了复杂结构。一项研究发现了180个脑皮质内的不同区域。神经科学学生用“纹状体”，“哈伯拉斯”，“斯特拉米兰”，“弗雷拉”，“弗雷拉”和＃34;脑干核＆＃34;。 （测验：其中哪些是真正的大脑地区，哪种类型的意大利面？）每年我们得到另外50,000左右的新神经科学论文倾倒在我们无与伦比的大脑中的知识中，没有结束。</p><p> So the brain is indeed horrifically complicated. Right? Well, Jeff Hawkins and like-minded thinkers have a rebuttal, and it comes in two parts:</p><p> 所以大脑确实是恐怖复杂的。正确的？嗯，杰夫霍金斯和思想思想家有反驳，它有两部分：</p><p> 1. The horrific complexity of the “old brain” doesn’t count, because we don’t need it for AGI</p><p> 1.“老大脑”的可怕复杂性不计数，因为我们不需要它为AGI</p><p> According to Hawkins, much of the brain—including a disproportionate share of the brain&#39;s horrific complexity, like the interpeduncular nucleus I mentioned— just doesn’t count. Yes it’s complicated. But we don’t care, because understanding it is not necessary for building AGI. In fact, understanding it is not even  helpful for building AGI!</p><p> 根据霍金斯的说法，大部分大脑 - 包括脑​​大脑的不成比例的份额和恐怖复杂性，就像我提到的脑干核一样 - 只是不计数。是的，它很复杂。但我们不在乎，因为了解它不是建立AGI所必需的。事实上，了解它甚至没有帮助建立AGI！ </p><p> I’m talking here about the distinction between what Hawkins calls  “old brain vs new brain”. The “new brain” is the mammalian neocortex, a wrinkly sheet on that is especially enlarged in humans, wrapping around the outside of the human brain, about 2.5 mm thick and the size of a large dinner napkin (if you unwrinkled it). The “old brain” is everything else in the brain, which (says Hawkins) is more similar between mammals, reptiles, and so on.</p><p>我在这里谈论霍金斯叫“老大脑与新大脑”之间的区别。 “新大脑”是哺乳动物Neocortex，一个皱纹的表格，在人类外，缠绕在人类大脑的外面，约2.5毫米厚，大小的大型晚餐餐巾（如果你解开它）。 “老大脑”是大脑中的一切，（霍金斯）在哺乳动物，爬行动物等方面更相似。</p><p> “The neocortex is the organ of intelligence,” writes Hawkins. “Almost all the capabilities we think of as intelligence—such as vision, language, music, math, science, and engineering—are created by the neocortex. When we think about something, it is mostly the neocortex doing the thinking…. If we want to understand intelligence, then we have to understand what the neocortex does and how it does it. An animal doesn’t need a neocortex to live a complex life. A crocodile’s brain is roughly equivalent to our brain, but without a proper neocortex. A crocodile has sophisticated behaviors, cares for its young, and knows how to navigate its environment...but nothing close to human intelligence.”</p><p> “Neocortex是智慧的器官，”霍金斯写道。 “几乎所有的能力都认为是智力 - 例如视觉，语言，音乐，数学，科学和工程 - 是由Neocortex创建的。当我们思考某些事情时，它主要是新科的思考......如果我们想了解智能，那么我们必须了解Neocortex的表现以及它是如何实现的。动物不需要neocortex来过一个复杂的生活。鳄鱼的大脑大致相当于我们的大脑，但没有适当的新皮质。鳄鱼有精致的行为，关心它的年轻人，并知道如何导航其环境......但是没有任何接近人类智慧。“</p><p> I think Hawkins&#39;s  new brain / old brain discussion is bound to drive neuroscientist readers nuts. See, for example, the paper   Your Brain Is Not An Onion With A Tiny Reptile Inside for this perspective, or see the current widespread dismissal of   “triune brain theory”. The mammalian neocortex is in fact closely related to the “pallium” in other animals, particularly the well-developed pallium in birds and reptiles (including, yes, crocodiles!). One researcher (Tegan McCaslin) attempted a   head-to-head comparison between bird pallium and primate neocortex, and found that there was no obvious difference in intelligence, when you hold the number of neurons fixed. A   recent   paper found suggestive evidence of similar neuron-level circuitry between the bird pallium and mammalian neocortex. Granted, the neurons have a different spatial arrangement in the bird pallium vs the mammal neocortex. But it’s the neuron types and connectivity that define the algorithm, not the spatial arrangement.   Paul Cisek traces the origin of the pallium all the way back to the earliest proto-brains. The human neocortex indeed massively expanded relative to chimpanzees, but then again, so did the “old brain” human cerebellum and thalamus.</p><p> 我认为霍金斯＆＃39;新的大脑/旧大脑讨论必然会驾驶神经科学家读者坚果。看，例如，你的大脑不是一个洋葱，里面有一个微小的爬行动物，或者看到目前的普遍解雇“三月大脑理论”。哺乳动物Neocortex实际上与其他动物中的“钯”密切相关，特别是鸟类和爬行动物的良好的钯（包括，是的鳄鱼！）。一名研究员（Tegan McCaslin）试图在鸟类钯和灵长类动物的新毒素之间进行头脑比较，发现智力没有明显的差异，当你固定的神经元数量时。最近的一篇论文发现了鸟类钯和哺乳动物Neocortex之间类似神经元电路的暗示证据。授予，神经元在鸟类钯中具有不同的空间布置，Vs哺乳动物Neocortex。但它是定义算法的神经元类型和连接，而不是空间布置。保罗·凯斯克将钯的原点一直追溯到最早的原型脑中。人类新科查确实相对于黑猩猩，但再次，“老脑”人体小脑和丘脑也是如此。</p><p> And what’s more (these angry neuroscientists would likely continue), it’s not like the neocortex works by itself. The “old brain” thalamus has just as much a claim to be involved in human intelligence, language, music, and so on as the neocortex does, and likewise with the “old brain” basal ganglia, cerebellum, and hippocampus.</p><p> 更重要的是（这些愤怒的神经科学家可能会继续），它不像新科奇自我工作。 “老大脑”丘脑占据了人类智慧，语言，音乐等的声称，因为新科的表现形式，同样与“老脑”基底神经节，小脑和海马。</p><p> OK. All this is true. But I’m going to stick my neck out and say that Hawkins is  “correct in spirit” on this issue. And I’ve tried (e.g.   here) to stake out a more careful and defensible claim along the same lines.</p><p> 好的。这一切都是真的。但我要把我的脖子伸出来说，霍金斯在这个问题上是“正确的精神”。我已经尝试过（例如，这里）掌握沿着同一条线更加谨慎和可靠的索赔。</p><p> My version goes: The mammal brain has a  “neocortex subsystem” (and likewise the bird and lizard brain has a  “pallium subsystem”). This  subsystem implements a learning algorithm that starts from scratch (analogous to random weights—so it’s utterly useless to the organism at birth), but helps the organism more and more over time, as it learns. This subsystem involves the neocortex (or pallium), as well as the hippocampus, thalamus, and I would also include at least some parts of the basal ganglia and cerebellum. But definitely not the brainstem, for example. This subsystem is not particularly “new” or peculiar to mammals, and I figure that some super-primitive version of this subsystem goes  way back, maybe helping lampreys navigate their environment and remember where there&#39;s often food, or whatever. But the subsystem  is unusually large and well-developed in humans, and it  is the home of human intelligence, and it does  primarily revolve around the activities of the neocortex / pallium.</p><p> 我的版本：哺乳动物大脑有一个“Neocortex子系统”（同样地鸟和蜥蜴大脑有一个“钯子系统”）。该子系统实现了一种从头开始的学习算法（类似于随机权重 - 所以它在出生时对生物体完全没用），但是在它学习时，越来越多地帮助生物体。该子系统涉及Neocortex（或钯），以及海马，丘脑，我还包括基础神经节和小脑的至少一些部分。例如，绝对不是脑干。这个子系统并不是哺乳动物的特别“新”，而且我认为这个子系统的一些超原始版本的回归，也许有助于Lampreys导航他们的环境并记住其中的地方＆＃39;常见的地方，或者是什么食物，或者常吃的地方。但是，子系统在人类中异常大而且很好地发展，它是人类智慧的家园，它主要围绕着Neocortex / Pallium的活动。</p><p> So far as I can tell, my version keeps all the good ideas of Hawkins (and like-minded thinkers) intact, while avoiding the problematic parts. I&#39;m open to feedback, of course.</p><p> 到目前为止，我的版本可以保持霍金斯（和志同道合的思想家）的所有好主意，同时避免有问题的部分。当然，我打开反馈意见。 </p><p> 2. The horrific complexity of the neocortex is in the learned content, not the learning algorithm</p><p>2. Neocortex的可怕复杂性在学习内容中，而不是学习算法</p><p> The second reason that making brain-like AGI is easier than it looks, according to Hawkins, is that “the neocortex looks similar everywhere”. He writes, &#34;The complex circuitry of the neocortex looks remarkably alike in visual regions, language regions, and touch regions, [and even] across species.... There are differences. For example, some regions of the neocortex have more of certain cells and less of others, and there are some regions that have an extra cell type not found elsewhere...But overall, the variations between regions are relatively small compared to the similarities.&#34;</p><p> 根据霍金斯的说法，使大脑的AGI的第二种原因比它看起来更容易看起来“Neocortex看起来很相似”。他写道，＆＃34; Neocortex的复杂电路看起来非常相似，横跨物种，[甚至]，[甚至]。存在差异。例如，Neocortex的一些区域具有更多的细胞和其他细胞，并且有一些区域在其他地方没有发现额外的细胞类型......但总体而言，与相似性相比，区域之间的变化相对较小。 ＆＃34;</p><p> How is it possible for one type of circuit to do so many things? Because it’s a learning algorithm! Different parts of the neocortex receive different types of data, and correspondingly learn different types of patterns as they develop.</p><p> 一种类型的电路如何做这么多的事情？因为它是一种学习算法！ Neocortex的不同部分接收不同类型的数据，并相应地了解不同类型的模式。</p><p> Think of the   OpenAI Microscope visualizations of different neurons in a deep neural net. There’s so much complexity! But no human needed to design that complexity; it was automatically discovered by the learning algorithm. The learning algorithm itself is comparatively simple—gradient descent and so on.</p><p> 想想在深神经网络中不同神经元的开放显微镜可视化。有这么多的复杂性！但没有人需要设计复杂性;它被学习算法自动发现。学习算法本身是相对简单的梯度下降等。</p><p> By the same token, a cognitive psychologist could easily spend her entire career diving into the intricacies of how an adult neocortex processes phonemes. But on Hawkins&#39;s view, we can build brain-like AGI without doing any of that hard work. We just need to find the learning algorithm, and let &#39;er rip, and it will construct the phoneme-processing machinery on its own.</p><p> 通过同样的令牌，认知心理学家可以很容易地将整个职业生涯潜入成人Neocortex流程的复杂性。但在霍金斯和＃39;我们可以在不做任何努力工作的情况下建立大脑的AGI。我们只需要找到学习算法，让＆＃39; er RIP，它将自己构建音素加工机械。</p><p> Hawkins offers various pieces of evidence that the neocortex runs a single, massively-parallel, legible learning algorithm. First, as above, &#34;the detailed circuits seen everywhere in the neocortex are remarkably similar”. Second, “the major expansion of the modern human neocortex relative to our hominid ancestors occurred rapidly in evolutionary time, just a few million years. This is probably not enough time for multiple new complex capabilities to be discovered by evolution, but it is plenty of time for evolution to make more copies of the same thing.” Third is plasticity—for example how blind people use their visual cortex for other purposes. Fourth, “our brains did not evolve to program computers or make ice cream.&#34;</p><p> 霍金斯提供了各种证据，即Neocortex运行单一，大规模平行，清晰易读的学习算法。首先，如上所述，＆＃34; Neocortex中的各处看到的详细电路非常相似“。其次，“现代人类新皮质相对于我们的同源祖先的主要扩张发生在进化时间，即在进化时间内，截至几百万年。这可能是一种待进化发现多个新的复杂能力的时间，但进化是有足够的时间来制作更多的副本。“第三是可塑性 - 例如，盲人如何对其他目的使用他们的视觉皮质。第四，“我们的大脑并未演变为程序计算机或制作冰淇淋。＆＃34;</p><p> There&#39;s a lot more evidence for and against, beyond what Hawkins talks about. (For example,  here&#39;s a very clever argument in favor that I saw just a few days ago.) I’ve written about cortical uniformity previously (  here,   here), and plan to do a more thorough and careful job in the future. For now I’ll just say that this is certainly a hypothesis worth taking seriously, and even if it’s not  universally accepted in neuroscience, Hawkins is by no means the only one who believes it.</p><p> 在霍金斯谈论的情况下，有很多证据和反对。 （例如，这里＆＃39;非常聪明的论点，有利的是，我在几天前看到了。）我以前写过皮质均匀性（这里，这里），并计划在这里做出更彻底和仔细的工作未来。现在，我只是说这肯定是一个值得认真的假设，即使它在神经科学中没有普遍接受，霍金斯也不是唯一一个相信它的人。 </p><p> 3. Put them together, and you get a vision for brain-like AGI on the horizon</p><p>3.把它们放在一起，你在地平线上获得脑的脑电图</p><p> So if indeed we can get AGI by reverse-engineering just the neocortex (and its “helper” organs like the thalamus and hippocampus), and if the neocortex is a relatively simple, human-legible, learning algorithm, then all of the sudden it doesn’t sound so crazy for Hawkins to say that brain-like AGI is feasible, and not centuries away, but rather already starting to crystallize into view on the horizon. I found this vision intriguing when I first heard it, and after quite a bit more research and exposure to other perspectives, I still more-or-less buy into it (although as I mentioned, I&#39;m not done studying it).</p><p> 因此，如果我们确实可以通过逆向工程获得AGI，只需Neocortex（以及它的“辅助者”器官，如丘脑和海马），如果Neocortex是一个相对简单，人类清晰，学习算法，那么所有的突然间对于霍金斯来说，霍金斯听起来很疯狂，说大脑 - 类似的AGI是可行的，而不是几个世纪以来，而是已经开始在地平线上结晶。我发现这个愿景有趣当我第一次听到它，并且经过相当多的研究和接触到其他观点，我还是更加或更少的购买（虽然我提到的那样，我没有完成学习它） 。</p><p> By the way, an interesting aspect of cortical uniformity is that it&#39;s a giant puzzle piece into which we need to (and haven’t yet) fit every other aspect of human nature and psychology. There should be whole books written on this. Instead,  nothing. For example, I have all sorts of social instincts—guilt, the desire to be popular, etc. How exactly does that work? The neocortex knows whether or not I’m popular, but it doesn’t care, because (on this view) it’s just a generic learning algorithm. The old brain cares very much whether I&#39;m popular, but it’s too stupid to understand the world, so how would it know whether I’m popular or not? I’ve casually speculated on this a bit (e.g.   here) but it seems like a gaping hole in our understanding of the brain, and you won’t find any answers in Hawkins’s book … or anywhere else as far as I know! I encourage anyone reading this to try to figure it out, or tell me if you know the answer. Thesis topic anyone?</p><p> 顺便说一下，皮质均匀性的一个有趣的方面是它＆＃39;我们需要（尚未）的巨大拼图件（尚未）符合人性和心理学的其他方面。应该有完整的书写。相反，没有。例如，我有各种各样的社会本能 - 内疚，欲望是流行的等等。这是怎么做的？ Neocortex知道我是否受欢迎，但它不在乎，因为（在这个视图上）只是一种通用学习算法。老大脑非常关心我是否流行了很多，但了解世界太愚蠢了，所以它如何了解我是否受欢迎？我在这一点上随便推测（例如，这里），但在我们对大脑的理解中看起来似乎是一个巨大的洞，你不会在霍金斯书中找到任何答案......或者据我所知，其他任何地方我鼓励任何人阅读这个才能试图弄清楚，或者告诉我你是否知道答案。论文主题有人？</p><p>  For everything I&#39;ve written so far, I could have written essentially the same thing about Hawkins’s 2004 book. That&#39;s not new, although it remains as important and under-discussed as ever.</p><p>  对于我到目前为止写的一切，我本可以写的是霍金斯2004年的书的基本相同。这并不是新的，尽管它仍然与以往一样重要和讨论。</p><p> A big  new part of the book is that Hawkins and collaborators now have more refined ideas about exactly what learning algorithm the neocortex is running. (Hint: it’s  not a deep convolutional neural net trained by backpropagation. Hawkins  hates those!)</p><p> 这本书的一个很大的新部分是霍金斯和合作者现在拥有更精致的想法，了解neocortex正在运行的何种学习算法。 （提示：它不是由BackPropagation培训的深卷大神经网络。霍金斯讨厌那些！）</p><p> This is a big and important section of the book. I’m going to skip it. My excuse is:   I wrote a summary of an interview he did a while back, and that post covered more-or-less similar ground. That said, this book describes it better, including a new and helpful (albeit still a bit sketchy) discussion of learning abstract concepts.</p><p> 这是这本书的重要和​​重要部分。我要跳过它。我的借口是：我写了一段面试的摘要，他做了一段时间后，那个帖子涵盖了更多或更不相似的地面。也就是说，这本书描述了它更好，包括一个新的和助人（虽然有点粗略）对学习抽象概念的讨论。</p><p> To be clear, in case you&#39;re wondering, Hawkins does not have a complete ready-to-code algorithm for how the neocortex works. He claims to have a framework including essential ingredients that need to be present. But many details are yet to be filled in.</p><p> 为了清楚，万一你＆＃39;重新想象，霍金斯没有一个完整的准备代码算法，了解Neocortex如何工作。他声称有一个框架，包括需要存在的基本成分。但许多细节尚未填补。 </p><p>  Some people (cf.   Stuart Russell&#39;s book) are concerned that the development of AGI poses a substantial risk of catastrophic accidents, up to and including human extinction. They therefore urge research into how to ensure that AIs robustly do what humans want them to do—just as Enrico Fermi invented  nuclear reactor control rods  before he built the first nuclear reactor.</p><p>有些人（CF.Stuart Russell＆＃39;书）担心AGI的发展构成了灾难性事故的大量风险，达到和包括人为灭绝。因此，他们敦促研究如何确保AIS强大地做人类希望他们做的事情 - 就像Enrico Fermi发明了核反应堆控制杆，在他建造了第一核反应堆之前。</p><p> Jeff Hawkins is having none of it. “When I read about these concerns,” he says, “I feel that the arguments are being made without any understanding of what intelligence is.”</p><p> 杰夫霍金斯没有任何东西。 “当我读到这些问题时，”他说，“我觉得在没有任何理解情报的情况下正在做出的论点。”</p><p> Well, I’m more-or-less fully on board with Hawkins’s underlying framework for thinking about the brain and neocortex and intelligence. And I  do think that developing a neocortex-like AGI poses a serious risk of catastrophic accidents, up to and including human extinction, if we don’t spend some time and effort developing new good ideas analogous to Fermi’s brilliant invention of control rods.</p><p> 好吧，我和霍金斯的潜在框架思考大脑和新科的底板，我更加有或更少。如果我们不花一些时间和努力，开发一种灾难性事故的灾难性事故风险，造成灾难性事故的严重风险，即使我们不花一些时间和努力为Fermi的控制杆的优秀发明制定新的好思想。</p><p> So I guess I’m in an unusually good position to make this case!</p><p> 所以我想我处于一个异常的良好位置来制作这种情况！</p><p>  I’ll start by summarizing Hawkins’s argument that neocortex-like AGI does  not pose an existential threat of catastrophic accidents. Here are what I take to be his main and best arguments:</p><p>  我将首先总结霍金斯的论点，即新科查类似的AGI不会造成灾难性事故的存在威胁。以下是我认为是他的主要和最好的论点：</p><p>  Asimov’s three laws of robotics were proposed in the context of science-fiction novels and don’t necessarily apply to all forms of machine intelligence. But in any product design, there are safeguards that are worth considering. They can be quite simple. For example, my car has a built-in safety system to avoid accidents. Normally, the car follows my orders, which I communicate via the accelerator and brake pedals. However, if the car detects an obstacle that I am going to hit, it will ignore my orders and apply the brakes. You could say the car is following Asimov’s first and second laws, or you could say that the engineers who designed my car built in some safety features. Intelligent machines will also have built-in behaviors for safety.</p><p>  在科幻小说中提出了Asimov的三个机器人法律，并不一定适用于所有形式的机器智能。但在任何产品设计中，都有值得考虑的保障措施。它们可以很简单。例如，我的汽车有内置安全系统，以避免事故。通常，汽车跟随我的订单，我通过加速器和制动踏板进行通信。但是，如果汽车检测到我要击中的障碍，它将忽略我的订单并应用刹车。你可以说这辆车跟随Asimov的第一和第二种法律，或者你可以说设计了我的汽车的工程师，建在一些安全功能。智能机器也将有内置的行为安全。</p><p> Second, Hawkins says that goals and motivations are separate from intelligence. The neocortex makes a map of the world, he says. You can use a map to do good or ill, but “a map has no motivations on its own. A map will not desire to go someplace, nor will it spontaneously develop goals or ambitions. The same is true for the neocortex.”</p><p> 其次，霍金斯表示，目标和动机与智力分开。他说，Neocortex是世界上的地图。您可以使用地图做好事或生病，但“一张地图没有自己的动机。地图不会渴望走出一些地方，也不会自发地发展目标或野心。 Neocortex也是如此。“ </p><p> Third, Hawkins has specific disagreements with the idea of “goal misalignment”. He correctly describes what that is: “This threat supposedly arises when an intelligent machine pursues a goal that is harmful to humans  and we can’t stop it. It is sometimes referred to as the “Sorcerer’s Apprentice” problem…. The concern is that an intelligent machine might similarly do what we ask it to do, but when we ask the machine to stop, it sees that as an obstacle to completing the first request. The machine goes to any length to pursue the first goal….</p><p>第三，霍金斯对“目标错位”的想法具有特定的分歧。他正确地描述了这是什么：“当一个智能化机器追求对人类有害的目标时，这种威胁应该出现，我们无法阻止它。有时被称为“巫师的学徒”问题......关注的是，一个智能机器可能类似地做我们要求它做的事情，但是当我们要求机器停止时，它认为作为完成第一个请求的障碍。机器追求任何长度来追求第一个目标......</p><p>  The goal-misalignment threat depends on two improbabilities: first, although the intelligent machine accepts our first request, it ignores subsequent requests, and second, the intelligent machine is capable of commandeering sufficient resources to prevent all human efforts to stop it…. Intelligence is the ability to learn a model of the world. Like a map, the model can tell you how to achieve something, but on its own it has no goals or drives. We, the designers of intelligent machines, have to go out of our way to design in motivations. Why would we design a machine that accepts our first request but ignores all others after that?...The second requirement of the goal-misalignment risk is that an intelligent machine can commandeer the Earth’s resources to pursue its goals, or in other ways prevent us from stopping it...To do so would require the machine to be in control of the vast majority of the world’s communications, production, and transportation…. A possible way for an intelligent machine to prevent us from stopping it is blackmail. For example, if we put an intelligent machine in charge of nuclear weapons, then the machine could say “If you try to stop me, I will blow us all up.”... We have similar concerns with humans. This is why no single human or entity can control the entire internet and why we require multiple people to launch a nuclear missile.”</p><p>  目标错位威胁取决于两个可变性：首先，虽然智能机器接受我们的第一个请求，但它忽略了后续请求，而其次，智能机器能够征长足够的资源来防止所有人类努力阻止所有努力阻止它......智力是学习世界模特的能力。就像地图一样，模型可以告诉你如何实现某些东西，但是它自己没有目标或驱动器。我们是智能机器的设计师，必须竭尽全力在动机中设计。为什么我们将设计一台接受我们的第一个请求的机器，但在此之后忽略所有其他机器？......智能机器的第二个要求是智能机器可以征长地球资源，以追求其目标，或以其他方式预防我们从阻止它......这样做会要求机器控制绝大多数世界的通信，生产和运输......智能机器可以防止我们停止它是勒索的可能方法。例如，如果我们把智能机器放在负责核武器，那么机器可以说“如果你试图阻止我，我会把我们全力吹。”......我们与人类相似。这就是为什么没有单一人或实体可以控制整个互联网以及为什么我们需要多个人推出核导弹。“</p><p>  Now I don’t think any of these arguments are particularly unreasonable. The common thread as I see it is, what Hawkins writes is the  start of a plausible idea to avoid catastrophic AGI accidents. But when you think about those ideas a bit more carefully, and try to work out the details, it starts to seem much harder, and less like a slam-dunk and more like an open problem which might or might not even be solvable.</p><p>  现在我认为任何这些论点都不是特别不合理的。常见的线程在我看到的是，霍金斯写的是避免灾难性的AGI事故的合理想法的开始。但是当你想到那些更仔细的想法时，并尝试解决细节，它开始似乎更难，而且就像一个猛烈的扣篮，更像是一个可能或可能甚至无法解决的打开问题。</p><p>  Hawkins writes that goals and motivations are separate from intelligence. Yes! I’m totally on board with that. As stated above, I think that the neocortex (along with the thalamus etc.) is running a general-purpose learning algorithm, and the brainstem etc. is nudging it to hatch and execute plans that involve reproducing and winning allies, and nudging it to  not hatch and execute plans that involve falling off cliffs and getting eaten by lions.</p><p>  霍金斯写道，目标和动机与智力分开。是的！我完全在船上。如上所述，我认为Neocortex（以及丘脑等）正在运行通用学习算法，并且脑干等旨在孵化并执行涉及再现和获胜盟友的计划，并努力不孵化并执行涉及悬崖和狮子吃掉的计划。</p><p> By the same token, we want and expect our intelligent machines to have goals. As Hawkins says, “We wouldn’t want to send a team of robotic construction workers to Mars, only to find them lying around in the sunlight all day”! So how does that work? Here&#39;s Hawkins:</p><p> 通过同样的令牌，我们想要并期望我们的智能机器有目标。正如霍金斯所说，“我们不想向火星派一个机器人建筑工人团队，只发现他们整天躺在阳光下”！那么这是怎么做的？在这里＆＃39;霍金斯：</p><p> To get a sense of how this works, imagine older brain areas conversing with the neocortex. Old brain says, “I am hungry. I want food.” The neocortex responds, “I looked for food and found two places nearby that had food in the past. To reach one food location, we follow a river. To reach the other, we cross an open field where some tigers live.” The neocortex says these things calmly and without value. However, the older brain area associates tigers with danger. Upon hearing the word “tiger,” the old brain jumps into action. It releases [cortisol]... and neuromodulators…in essence, telling the neocortex “Whatever you were just thinking, DON’T do that.”</p><p> 为了了解这项工作的感觉，想象较旧的脑区与Neocortex交谈。老大脑说，“我饿了。我要食物。” Neocortex回应，“我寻找食物，在过去附近有两个地方发现了两个地方。达到一个食物，我们沿着一条河流。要到达另一个老虎队的开放领域。“ Neocortex在冷静地说出这些东西，没有价值。然而，旧的大脑区域将老虎与危险联系起来。听到“老虎”这个词后，旧的大脑跳进了行动。它释放[皮质醇] ......和神经调节者......实质上，告诉Neocortex“无论你只是想着，都不这样做。”</p><p> When I put that description into a diagram, I wind up with something like this:</p><p> 当我将该描述放入图表时，我结束了这样的东西： </p><p>  The neocortex proposes ideas, and the Judge (in the &#34;old brain&#34;) judges those ideas to be good or bad.</p><p>Neocortex提出了想​​法和法官（在＆＃34;老脑和＃34;）判断这些想法是好的或坏的。</p><p> This is a good start. I can certainly imagine building an intelligent goal-seeking machine along these lines. But  the devil is in the details! Specifically:  Exactly what algorithm do we put into the “Judge” box? Let&#39;s think it through.</p><p> 这是一个很好的开始。我肯定可以想象沿着这些线构建智能射击机。但是魔鬼是细节！特别是：我们究竟是什么算法，我们进入了“判断”框？让＆＃39;思考它。</p><p> First things first, we should not generally expect the “Judge” to be an intelligent machine that understands the world. Otherwise,  that neocortex-like machine would need  its own motivation, and we’re right back to where we started! So I’m going to suppose that the Judge box will house a relatively simple algorithm written by humans. So exactly what do you put in there to make the robot want to build the infrastructure for a Mars colony? That&#39;s an open question.</p><p> 首先，首先，我们通常不应该期望“判断”成为一个了解世界的智能机器。否则，那种类似的机器需要自己的动机，我们就回到了我们开始的地方！所以我将假设法官盒子将容纳一种相对简单的人类算法。那么你完全放在那里，让机器人想要为火星殖民地建立基础设施？那个打开的问题，＆＃39;</p><p> Second, given that the Judge box is relatively stupid, it needs to do a lot of memorization of the form  “this meaningless pattern of neocortical activity is good, and this meaningless pattern of neocortical activity is bad”, without having a  clue what those patterns actually mean. Why? Because otherwise the neocortex would have an aw</p><p> 第二，鉴于法官盒比较愚蠢，需要做很多记忆的形式“这种毫无义的新皮肤活动模式是好的，这种毫无意义的新皮肤活动模式是坏的”，没有有线索那些模式实际上是卑鄙的。为什么？因为否则Neocortex会有一个aw</p><p>......</p><p>...... </p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://www.lesswrong.com/posts/ixZLTmFfnKRbaStA5/book-review-a-thousand-brains-by-jeff-hawkins">https://www.lesswrong.com/posts/ixZLTmFfnKRbaStA5/book-review-a-thousand-brains-by-jeff-hawkins</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/书评/">#书评</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/review/">#review</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/霍金斯/">#霍金斯</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/分享/">#分享</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy;2012-2021 diglog.com </div></div></body></html>