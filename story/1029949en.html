<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>基于GPU的Moana Motunui渲染器</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">基于GPU的Moana Motunui渲染器</h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2020-10-20 10:59:07</div><div class="page_narrow text-break page_content"><p>Disney Animation’s Moana island dataset is a production-scale scene with memory requirements that make it challenging to render. This post summarizes some of those challenges, and describes how the  GPU-Motunui project is able to efficiently render the scene on a consumer-grade GPU with less than 8GB of memory.  Click here to skip ahead to the results.</p><p>迪士尼动画的莫阿纳岛数据集是一个生产规模的场景，具有内存要求，这使得渲染具有挑战性。这篇文章总结了其中的一些挑战，并描述了GPU-Motunui项目如何能够在内存不到8 GB的消费级GPU上高效地渲染场景。单击此处跳至结果。</p><p>  In 2018, Disney Animation released the Moana island dataset to the rendering research community. Compared to traditional research scenes, the scale of the Moana island scene is massive: the scene contains 90 million quad primitives, 5 million curves, and more than 28 million instances. All told, the island consists of over 15 billion primitives, weighing in at just under 30GB of geometry files.</p><p>2018年，迪士尼动画向渲染研究界发布了莫阿纳岛数据集。与传统的研究场景相比，莫阿纳岛场景的规模是巨大的：该场景包含9000万个四边形基本体、500万条曲线和2800多万个实例。总而言之，该岛由超过150亿个基本体组成，几何文件的重量略低于30 GB。</p><p> The shots included with the dataset are beautiful, and showcase the amazing imagery that can be created by combining the best artists in the world with path tracing techniques and modern hardware. Here are two reference images, rendered with Disney’s proprietary Hyperion renderer:</p><p>数据集包含的照片很漂亮，展示了通过将世界上最好的艺术家与路径跟踪技术和现代硬件相结合可以创建的令人惊叹的图像。以下是使用迪士尼专有的Hyperion渲染器渲染的两个参考图像：</p><p>    The goal of the GPU-Motunui project is to render all the Moana shots efficiently and accurately on a consumer-grade graphics card. There are two main challenges to accomplishing this with the Moana dataset. First, with a typical graphics card having only 8GB of memory, an out-of-core rendering solution is required to handle the large amounts of geometry. Second, the scene’s textures are provided in the Ptex format, and Ptex doesn’t have a publicly available CUDA implementation. This project currently only solves the first problem, and Ptex texture lookup is done on the CPU (although conveniently its cost is fully hidden by being computed concurrently with GPU shadow ray tracing).</p><p>GPU-Motunui项目的目标是在消费级显卡上高效而准确地渲染所有Moana镜头。使用Moana数据集实现这一点有两个主要挑战。首先，对于只有8 GB内存的典型图形卡，需要内核外渲染解决方案来处理大量几何体。其次，场景的纹理是以Ptex格式提供的，并且Ptex没有公开可用的CUDA实现。这个项目目前只解决了第一个问题，Ptex纹理查找是在CPU上完成的(尽管方便的话，它的成本是完全隐藏的，因为它与GPU阴影光线跟踪并行计算)。</p><p> The Hyperion reference images are impossible to match exactly; for example the varying brown and green colors along the palm tree fronds in the palmsCam shot are not provided in the dataset. Other features of the scene are possible to render but out of my initial scope, notably subdivision surfaces and their displacement maps, and a full Disney BSDF implementation.</p><p>Hyperion参考图像不可能精确匹配；例如，数据集中没有提供PalmsCam拍摄的棕榈树叶子沿线变化的棕色和绿色。场景的其他功能也可以渲染，但超出了我最初的范围，特别是细分曲面及其置换贴图，以及完整的迪士尼BSDF实现。</p><p>  All ray tracing operations are run through Nvidia’s OptiX 7 API. This means GPU-Motunui gets the full benefits of available RT cores and a world-class BVH implementation. The following sections describe how GPU-Motunui maps dataset assets to OptiX data structures, and how GPU-Motunui’s out-of-core rendering solution works.</p><p>所有光线跟踪操作均通过NVIDIA的OptiX 7 API运行。这意味着GPU-Motunui充分利用了可用的RT内核和世界级的BVH实现。以下各节介绍GPU-Motunui如何将数据集资源映射到OptiX数据结构，以及GPU-Motunui的内核外渲染解决方案如何工作。</p><p>  The Moana scene makes widespread use of multi-level instancing. In OptiX, this requires a three-level hierarchy of acceleration structures to manage: two levels of IASs, and a base level of GASs (Instance Acceleration Structures and Geometry Acceleration Structures, respectively). GPU-Motunui makes use of OptiX’s AS compaction and relocation APIs to further reduce memory usage.</p><p>Moana场景广泛使用多级实例化。在OptiX中，这需要管理三个级别的加速结构层次：两个级别的IAS和一个基本级别的GASS(分别为实例加速结构和几何体加速结构)。GPU-Motunui利用OptiX的AS压缩和重定位API进一步减少内存使用。</p><p> The isHibiscus element makes a good example of how a typical element in the scene is organized and built. The tree is assembled from a base model in one Wavefront .obj file (containing the trunk and branches), and four primitives: one flower and three leaf models (each with their own .obj file).</p><p>IsHibiscus元素很好地说明了场景中的典型元素是如何组织和构建的。树由一个Wavefront.obj文件(包含树干和分支)中的基础模型和四个基本体组成：一个花和三个叶模型(每个模型都有自己的.obj文件)。</p><p>  In OptiX, each of these models has an associated GAS, and each GAS can be subdivided into multiple build inputs. Build inputs are used to map sections of the model to information needed at shading time by indexing into OptiX’s shader binding table. These GASs form the bottom level of the hierarchy.</p><p>在OptiX中，这些型号中的每一个都有关联的气体，并且每个气体可以细分为多个构建输入。构建输入用于通过索引到OptiX的着色器绑定表，将模型的各部分映射到着色时所需的信息。这些GAs形成了层次结构的最低级别。</p><p> Next, an IAS is used to build the full isHibiscus element. This IAS is in the middle level of the hierarchy. The figure below shows each primitive’s instances in isolation, and combined to make the full element:</p><p>接下来，使用IAS构建完整的isHibiscus元素。此IAS位于层次结构的中间级别。下图单独显示了每个基本体的实例，并将其组合成完整的元素：</p><p>  Finally, a second IAS is built to track all of the element’s instances present in the scene. This second IAS is the top level of the instance hierarchy.</p><p>最后，构建第二个IAS来跟踪场景中存在的所有元素实例。第二个IAS是实例层次结构的顶级。</p><p>  Although the isHibiscus element has a typical structure, there are some more complicated elements included in the dataset. The isCoral element, for example, has different base geometry and instanced primitives for each of its element instances, but the underlying primitive geometries are shared across all the element instances.</p><p>虽然isHibiscus元素具有典型的结构，但数据集中还包括一些更复杂的元素。例如，isCoral元素的每个Element实例都有不同的基本几何体和实例化基本体，但所有Element实例共享底层基本体几何体。</p><p> The Moana GAS and IASs alone require 18.5 GB, well past the memory budget of my 8GB RTX 2070. Because OptiX has no native support for out-of-core rendering, the traditional OptiX pipeline had to be put aside for a custom-made solution.</p><p>仅Moana GAS和IASS就需要18.5 GB，远远超出了我的8 GB RTX2070的内存预算。因为OptiX没有对内核外渲染的本机支持，所以传统的OptiX管道不得不搁置一边，以供定制的解决方案使用。</p><p>  To solve the out-of-core rendering problem, GPU-Motunui divides the scene’s geometry into different sections, and ray traces each separately, while tracking the closest hit. Replacing a traditional device trace call with a host loop comes with many design consequences to the renderer, from asset loading to the core path tracing loop that sends rays through the scene.</p><p>为了解决外置渲染问题，GPU-Motunui将场景的几何体划分为不同的部分，光线分别跟踪每个部分，同时跟踪最近的命中。使用主机循环替换传统设备跟踪调用会给渲染器带来许多设计后果，从资源加载到通过场景发送光线的核心路径跟踪循环。</p><p> Before rendering, the asset loading process allocates a large chunk of GPU memory (currently 6.7GB). A custom allocator is implemented that manages this block of memory. It is responsible for allocating two types of memory: output and temporary. Output memory is allocated from the left of the block, and is used for OptiX structures. Temporary memory is managed on a stack from the right end of the memory block. Managing the temporary memory this way ensures that the output structures are always tightly packed.</p><p>在渲染之前，资源加载过程会分配一大块GPU内存(当前为6.7 GB)。实现了管理该内存块的自定义分配器。它负责分配两种类型的内存：输出内存和临时内存。输出内存从块的左侧分配，用于OptiX结构。从内存块的右端开始在堆栈上管理临时内存。以这种方式管理临时内存可确保输出结构始终紧密打包。</p><p> After elements are processed into their accelerator structures on the GPU, their used memory is snapshotted onto the host, and the allocator is cleared. The process is repeated until all of the scene’s geometry is processed, resulting in the host managing a list of GPU memory snapshots. The figure below shows an example layout of GPU memory that could be snapshotted:</p><p>在GPU上将元素处理成它们的加速器结构之后，将它们使用的内存快照到主机上，并清除分配器。重复该过程，直到处理完场景的所有几何体，导致主机管理GPU内存快照列表。下图显示了可以拍摄快照的GPU内存布局示例：</p><p>  As mentioned above, when it comes time to ray trace, each snapshot is processed in a loop. This means a call to  cudaMemcpy and  optixLaunch for each snapshot. A global buffer is maintained that indicates the depth of the current closest intersection. This value is used as the  tmax parameter for the CUDA kernel’s call to  optixTrace, and a successful intersection will update the depth buffer for the next launch.</p><p>如上所述，当涉及光线跟踪时，每个快照都是在循环中处理的。这意味着为每个快照调用cudaMemcpy和optixLaunch。维护指示当前最近交叉点深度的全局缓冲区。该值用作CUDA内核调用optixTrace的tmax参数，成功的交集将为下次启动更新深度缓冲区。</p><p> In a traditional OptiX path tracer, the entire render loop can run in device code inside a single call to  optixLaunch; i.e., a successful intersection will lead to more BSDF and shadow rays being traced in the same kernel launch. Because GPU-Motunui’s design mandates multiple launches for tracing each path segment, the render loop is pulled out into host code. While this potentially diminishes OptiX’s ability to efficiently schedule program execution, it also opens up opportunties for optimization, such as running Ptex texture lookups on the CPU concurrently with GPU kernels and I/O.</p><p>在传统的OptiX路径跟踪器中，整个呈现循环可以在单个optixLaunch调用内的设备代码中运行；也就是说，成功的交集将导致在同一内核启动中跟踪更多的BSDF和阴影光线。因为GPU-Motunui的设计要求多次启动来跟踪每个路径段，所以渲染循环被拉到主机代码中。虽然这可能会降低OptiX高效调度程序执行的能力，但它也为优化打开了机会，例如在CPU上与GPU内核和I/O并发运行Ptex纹理查找。</p><p>  As with any OptiX application, GPU-Motunui makes use of the shader binding table (SBT). SBT records contain pointers to normal buffers and material attributes. The underlying data for the normal buffers is stored alongside OptiX acceleration structures and included in geometry snapshots. This ensures that GPU memory is never wasted on unreachable normal buffer data.</p><p>与任何OptiX应用程序一样，GPU-Motunui使用着色器绑定表(SBT)。SBT记录包含指向正常缓冲区和材料属性的指针。正常缓冲区的底层数据与OptiX加速结构一起存储，并包含在几何体快照中。这确保了GPU内存永远不会浪费在无法访问的正常缓冲区数据上。</p><p>  Included below are GPU-Motunui renders of the six scenes included in the dataset. shotCam is the slowest to render at 18.2 seconds per sample at 1024x429 resolution, and took just over five hours total for the final image. All shots are 1024spp, capped at a maximum of five bounces, and were run on an Nvidia RTX 2070.</p><p>以下是数据集中包含的六个场景的GPU-Motunui渲染。在分辨率为1024x429的情况下，ShotCam的渲染速度最慢，每个采样的渲染时间为18.2秒，最终图像总共花费了5个小时多一点的时间。所有镜头均为1024spp，最多5次反弹，并在NVIDIA RTX 2070上运行。</p><p>         The initial implementation of the renderer required 42.6 seconds per 1spp on the shotCam scene. A few optimizations combined to make significant reductions in rendering time, cutting each pass down to 18.2 seconds (a 57.3% reduction).</p><p>在shotCam场景中，渲染器的初始实现需要每1spp 42.6秒。几个优化组合在一起显著缩短了渲染时间，将每个过程缩短到18.2秒(减少了57.3%)。</p><p>  Tracing shadow rays on the GPU in parallel with Ptex lookups on the CPU cut rendering time by 23.4%. It was disappointing to be forced to do texture lookups on the CPU, but the time savings make up for it.</p><p>跟踪GPU上的阴影光线与CPU上的Ptex查找并行，可将渲染时间缩短23.4%。被迫在CPU上执行纹理查找令人失望，但节省的时间弥补了这一点。</p><p>  Parallelizing the Ptex lookups and using multiple Ptex caches eliminated texture lookups as a bottleneck to the system; shadow ray casting time fully dominates the texture lookup. Empirically, spawning two threads per core (totaling 12 on an Intel i7-8700K) and sharing three Ptex caches comfortably reduced the texture lookup time beneath the shadow ray budget. This improved the time savings to a 33.9% reduction over the baseline.</p><p>并行Ptex查找和使用多个Ptex缓存消除了纹理查找对系统的瓶颈；阴影光线投射时间完全控制了纹理查找。根据经验，每个内核产生两个线程(在Inteli7-8700K上总共12个线程)并共享三个Ptex缓存可以轻松地减少阴影光线预算下的纹理查找时间。这使得节省的时间比基线减少了33.9%。</p><p>  The acceleration structure snapshots are all saved to pinned host memory. Switching from normal to pinned host memory increased the transfer throughput from 7.73 GB/s to 11.84 GB/s, cutting the baseline render time by 19.5%.</p><p>加速结构快照全部保存到固定的主机内存。从普通主机内存切换到固定主机内存将传输吞吐量从7.73 GB/s提高到11.84 GB/s，将基准渲染时间缩短了19.5%。</p><p>  Getting this scene running on my RTX 2070 card was a very fun and rewarding project, but there are still many improvements to be made:</p><p>让这个场景在我的RTX 2070卡上运行是一个非常有趣和有意义的项目，但仍然有很多需要改进的地方：</p><p> Experimenting with how various research results hold up on production scenes (e.g., testing select path guiding techniques)</p><p>试验各种研究结果在生产场景中的应用情况(例如，测试选择路径引导技术)。</p><p>  Brent Burley and Dylan Lacewell.  Ptex: Per-face Texture Mapping for Production Rendering. Computer Graphics Forum (Proceedings of Eurographics Symposium on Rendering 2008), 27(4), June 2008.</p><p>布伦特·伯利和迪伦·莱斯韦尔。Ptex：产品级渲染的每面纹理贴图。计算机图形论坛(2008年欧洲图形渲染研讨会论文集)，27(4)，2008年6月。</p><p>  Brent Burley.  Physically Based Shading at Disney. In ACM SIGGRAPH 2012 Course Notes: Practical Physically-Based Shading in Film and Game Production, August 2012.</p><p>布伦特·伯利。迪士尼的基于物理的明暗处理。参见ACM SIGGRAPH 2012课程笔记：电影和游戏制作中实用的基于物理的着色，2012年8月。</p><p>  Brent Burley.  Extending the Disney BRDF to a BSDF with Integrated Subsurface Scattering. In ACM SIGGRAPH 2015 Course Notes: Physically Based Shading in Theory and Practice, August 2015.</p><p>布伦特·伯利。将迪斯尼BRDF扩展到具有集成次表面散射的BSDF。见ACM SIGGRAPH 2015课程笔记：理论和实践中的基于物理的着色，2015年8月。</p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://www.render-blog.com/2020/10/03/gpu-motunui/">https://www.render-blog.com/2020/10/03/gpu-motunui/</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/moana/">#moana</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/motunui/">#motunui</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/渲染/">#渲染</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/美国/">#美国</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/谷歌/">#谷歌</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/linux/">#linux</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/程序/">#程序</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy; 2020 diglog.com </div></div></body></html>