<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>将张量核引入标准Fortran</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">将张量核引入标准Fortran</h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2020-08-16 02:40:50</div><div class="story_img_container"><a href="http://img.diglog.com/img/2020/8/ae498ee1be3d062ecb117388ba2409c8.png"><img src="http://img.diglog.com/img/2020/8/ae498ee1be3d062ecb117388ba2409c8.png" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>调优的数学库是从您的HPC系统中提取终极性能的一种简单可靠的方法。但是，对于寿命长的应用程序或需要在各种平台上运行的应用程序，为每个供应商或库版本改编库调用可能是维护的噩梦。</p><p>可以自动生成对调优数学库的调用的编译器为您提供了两全其美：简单的可移植性和终极性能。在这篇文章中，我将向您展示如何在GPU上无缝加速许多标准Fortran数组内部函数和语言构造。Nvfortran编译器通过将Fortran语句映射到NVIDIA cuTENSOR库中的可用函数来自动实现此加速。NVIDIA cuTENSOR库是一种首创的GPU加速张量线性代数库，提供张量压缩、缩减和元素级运算。</p><p>下面是标准的Fortran数组内部函数如何映射到GPU加速的数学库。在最简单的级别上，只需要两条Fortran语句就可以利用cuTENSOR库提供的出色性能：</p><p>使用cutensorex预定义模块的第一条语句包括重载Fortran内部过程、数组表达式和重载赋值形式的cuTENSOR库接口。接口被写入以仅映射位于GPU设备存储器中的数组。在这篇文章的后面，我将从openacc和CUDA Fortran程序员的角度讨论这意味着什么。在定义了这些接口之后，包含matmul()内部调用的第二个语句将自动映射到cuTENSOR函数调用。</p><p>这些接口通过识别和匹配几个可以映射到单个cuTENSOR内核调用的常用模式来实现延迟执行。在所有情况下，都会调用多个cuTENSOR函数来设置cuTENSOR需要的句柄、描述符数据结构和工作缓冲区。</p><p>但是，GPU上只启动了一个内核。出于性能原因，映射整个语句(包括对左侧数组的赋值)非常重要。您不希望编译器为右侧操作的输入或结果(中间或最终)创建临时数组，这在Fortran中很常见。</p><p>CuTENSOR库包含一般的排列和压缩操作。排列的结果可以任选地通过基本函数进行运算，并且可以任选地缩放。</p><p>Nvfortran编译器可以识别各种Fortran转换内部函数和与常规数组语法结合使用的基本内部函数，并将其映射到cuTENSOR功能。以下是一些比较直白的翻译：</p><p>D=转置(A)d=func(转置(A))d=alpha*func(转置(A)和d=RESHAPE(a，Shape=[...])d=RESHAPE(a，Shape=[...]，order=[...])d=func(RESHAPE(a，...))d=alpha*FUNC(RESHAPE(a，...))d=spend(a，dim=k，ncopy=n)d=func(a，d，...)d=func(a，dim=k，ncopy=n)d=func(a，dm=k，ncopy=n)d=func(a，dim=k，ncopy=n。</p><p>Matmul()的输入也可以在cuTENSOR中进行置换，并且结果可以缩放和累加。这会导致几种可能的组合，例如以下语句：</p><p>C=matmul(a，b)c=c+matmul(a，b)c=c-matmul(a，b)c=c+α*matmul(a，b)d=α*matmul(a，b)+β*c=matmul(转置(A)，b)c=matmul(重塑(a，形状=[...]，顺序=[...])，b)c=matmul(a，转置(b。</p><p>当您使用cutensorex模块中包含的随机数生成功能时，利用cuTENSOR和NVIDIA张量核心与下面的代码示例一样简单：</p><p>程序主程序使用cutensorex*整数，参数：：ni=5120，nj=5120，nk=5120，nx=10%.real(8)，allocatable，Dimension(：，：)：：a，b，d*；**调用CPU_TIME(T1)**Do NT=1，nTimes*d=d+matmul(a，b)*END：**调用CPU_TIME(T2)*Floops=2.0*ni*nj*nk*Floops=flops*nTimes*Print*，&#34；Times&#34；，T2，T1，T2-T1*Floops=2.0*ni*Nj*nk*，&#34；；&#34；，T2，T1，T2-T1*t2*nk*fops=#34；，t2，t1，t2-t1.。，flops/(t2-t1)/1.e9结束程序。</p><p>Matmul()内部调用被映射到尽可能无缝使用张量核的cuTENSOR调用。</p><p>当我前面提到cutensorex接口只将GPU设备数组上的操作映射到cuTENSOR调用时，您可能会问这个程序是如何使用cuTENSOR的。答案在于程序是如何编译的：</p><p>在这里，我将该程序编译为openacc程序，并利用openacc托管内存模式，在该模式下，所有可分配的数组都分配在CUDA统一内存中。通过添加-cuda(也支持CUDA Fortran扩展)，这些数组实质上是CUDA Fortran管理的数组。CUDA Fortran通用接口匹配的一条规则是，当主机和设备接口都存在时，优先使用设备接口作为托管的实际参数。</p><p>当声明、分配和使用在同一程序单元中时，nvfortran编译器提供了一些快捷方式。通常，最好使用openacc指令指示编译器传递设备地址，如下面的代码示例所示：</p><p>！$acc HOST_DATA USE_DEVICE(a，b，d)$acc end HOST_DATA NT=1，n乘以$acc END HOST_DATA！$acc end host_data=d+matmul(a，b)！$acc end host_data。</p><p>对于CUDA Fortran用户来说，cutensorex模块和Fortran转换内部函数成为获得高性能和完全可移植代码的快速途径。使用！@CUF语句添加代码行，这些代码行由nvfortran CUDA Fortran编译器解释和编译，或被标准Fortran编译器作为注释忽略：</p><p>Program Main！@CUF Use cutensorex！@CUF Use cudafor个整数，参数：：ni=5120，nj=5120，nk=5120，nTimes=10。实数(8)，可分配，维度(：，：)：：a，b，d！@CUF Attributes(Device)：：a，b，d*分配(a(ni，nk)，b(nk，nj)，d。新泽西州))可以调用RANDOM_NUMBER(A)；可以调用RANDOM_NUMBER(B)；可以调用RANDOM_NUMBER(B)，可以调用RANDOM_NUMBER(B)。CUTESOR_TIME(T1)=1，n×FLOPS DO NT=1，nTimes_TIME=d+matmul(a，b)；*END_DO将调用CPU_TIME(T2)**FLOPS=2.0*ni*nj*nk*Floops=flops*nTimes*fprint*，&#34；Times&#34；，t2，t2；。，flops/(t2-t1)/1.e9结束程序。</p><p>在第6行，我用device属性声明了数组，这会将它们放在GPU设备内存中。但是，也可以使用Managed属性声明它们。可以使用以下命令编译和链接此程序：</p><p>下面来看一下性能，从前面示例中使用的实数(8)(双精度)数据开始。您可以通过以下几种方式测量矩阵乘法性能：</p><p>要获得最佳的线程化CPU性能，请使用基本线性代数子程序(BLAS)库例程DGEMM。对于前面的操作，等效的DGEMM调用是以下命令：</p><p>要了解调优后的库可以通过简单的实现提供什么，请使用下面的openacc循环结构在GPU上运行。循环结构不使用特殊的平铺或硬件指令。</p><p>。</p><p>表1显示了在基于双插槽AMD EPYC 7742罗马CPU的服务器的一个NUMA节点、单个NVIDIA V100和单个NVIDIA A100 GPU上实现的实际(8)性能。</p><p>您不仅可以在V100和A100 GPU上使用matmul()内部函数实现自动GPU加速，而且在A100上，matmul()到cuTENSOR调用的映射可以让您自动使用FP64张量核。</p><p>可以使用实数(4)(单精度)数据并调用SGEMM而不是DGEMM来执行相同的运行集。此外，CUDA 11.0cuTENSOR Fortran包装器可以利用A100 TF32数据类型和张量核心。表2显示了这些运行的性能。</p><p>为什么要止步于此呢？Nvfortran编译器支持使用REAL(2)数据类型的16位浮点格式(FP16)。您可以在前面的测试中更改数组的类型，也可以以半精度运行计时。</p><p>在V100上引入了半精度数据的张量核运算，然后在A100 GPU上进行了扩展，以支持TF32和全双精度DP64张量核。虽然nvfortran在V100和A100上支持REAL(2)和张量内核，但它还不支持在CPU上完全和优化的REAL(2)，标准的BLAS库也不支持。在这种情况下，比较GPU加速版本的性能才有意义(表3)。</p><p>虽然A100的性能令人印象深刻，代码完全可移植，但它明显低于TF32和FP16的峰值。有固定的开销：在每次调用时，您都要创建和销毁cuTENSOR张量描述符，并创建收缩计划。您还必须查询和管理收缩中使用的工作空间需求，这最终可能会调用cudaMalloc和cudaFree。如果FP64的开销为5-10%，那么对于这种规模的问题，TF32的开销接近25%，FP16的开销约为35%。</p><p>对于需要终极性能的开发人员，nvfortran确实在Fortran cutensor模块(也在HPC SDK中提供)中直接支持到C cuTENSOR API的Fortran接口。您可以自己管理张量描述符、计划和工作区。</p><p>在这篇文章中，我展示了一些简单的程序，以及可以在GPU上自动加速的Fortran内部调用和代码模式的类型。他们甚至可以通过cuTENSOR自动利用张量芯。使用几乎完全符合Fortran标准且完全可移植到其他编译器和系统的程序，您可以在NVIDIA GPU上实现矩阵乘法、矩阵转置、基本数组内部运算以及数组语法的多种组合的近乎峰值的性能。</p><p>无法预测使用这些新功能可能会做什么或实现什么。我期待看到您的反馈和结果。NVIDIA继续添加更多功能，使您能够使用标准Fortran结构以最高性能编程NVIDIA GPU。</p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://developer.nvidia.com/blog/bringing-tensor-cores-to-standard-fortran/">https://developer.nvidia.com/blog/bringing-tensor-cores-to-standard-fortran/</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/标准/">#标准</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/tensor/">#tensor</a></button></div></div><div class="shadow p-3 mb-5 bg-white rounded clearfix"><div class="container"><div class="row"><div class="col-sm"><div><a target="_blank" href="/story/1011512.html"><img src="http://img.diglog.com/img/2020/7/thumb_f0efa62e13080e5ad7f604977747ca82.jpg" class="img-fluid" onerror="this.style.display='none'"></a></div><div class="item_title"><a target="_blank" href="/story/1011512.html">我们从未谈论过的最大特权：美丽</a></div><span class="my_story_list_date">2020-7-13 22:59</span></div><div class="col-sm"><div><a target="_blank" href="/story/1008488.html"><img src="http://img.diglog.com/img/2020/6/thumb_59abf42ca20f04d1c852861e4c803fcf.png" class="img-fluid" onerror="this.style.display='none'"></a></div><div class="item_title"><a target="_blank" href="/story/1008488.html">新的标准交易</a></div><span class="my_story_list_date">2020-6-27 2:42</span></div><div class="col-sm"><div><a target="_blank" href="/story/1006519.html"><img src="http://img.diglog.com/img/2020/6/thumb_8fe935ad6b0c4274a735804803b46b70.png" class="img-fluid" onerror="this.style.display='none'"></a></div><div class="item_title"><a target="_blank" href="/story/1006519.html">单芯片标准光纤超高密度光数据传输</a></div><span class="my_story_list_date">2020-6-14 18:16</span></div><div class="col-sm"><div><a target="_blank" href="/story/1005166.html"><img src="http://img.diglog.com/img/2020/6/thumb_94dd12c91b6437b5f9f49f56b2249eba.jpeg" class="img-fluid" onerror="this.style.display='none'"></a></div><div class="item_title"><a target="_blank" href="/story/1005166.html">一本用C代码写的图画书</a></div><span class="my_story_list_date">2020-6-5 0:57</span></div></div></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/谷歌/">#谷歌</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy;2012-2021 diglog.com </div></div></body></html>