<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>为什么苹果的M1芯片这么快？Why is Apple's M1 chip so fast?</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">Why is Apple's M1 chip so fast?<br/>为什么苹果的M1芯片这么快？</h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2020-12-01 03:57:31</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2020/12/24b0344a1a724e383b636e3be71813ed.jpeg"><img src="http://img2.diglog.com/img/2020/12/24b0344a1a724e383b636e3be71813ed.jpeg" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>Real world experience with the new M1 Macs have started ticking in. They are fast. Real fast. But why? What is the magic?</p><p>新型M1 Mac的真实世界体验已经开始流行。它们的运行速度很快。真快。但为什么？什么是魔术？</p><p>   On Youtube I watched a Mac user who had bought an iMac last year. It was maxed out with 40 GB of RAM costing him about $4000. He watched in disbelief how his hyper expensive iMac was being demolished by his new M1 Mac Mini, which he had paid a measly $700 for.</p><p>   在YouTube上，我看到一位Mac用户去年购买了iMac。它已用完40 GB的RAM，花了他大约4000美元。他难以置信地看着自己的超贵iMac被他的新M1 Mac Mini拆毁了，他为此花了700美元。</p><p> In real world test after test, the M1 Macs are not merely inching past top of the line Intel Macs, they are destroying them. In disbelief people have started asking how on earth this is possible?</p><p> 在现实世界中的一次又一次的测试中，M1 Macs不仅超越了顶级的Intel Macs，而且还在摧毁它们。人们开始难以置信地开始问这到底是怎么可能的？</p><p> If you are   one of those people, you have come to the right place. Here I plan to break it down into digestible pieces exactly what it is that Apple has done with the M1. Specifically the questions I think a lot of people have are:</p><p> 如果您是其中之一，那么您来对地方了。在这里，我计划将其分解为易于消化的部分，就像苹果公司对M1所做的一样。具体来说，我认为很多人有以下问题：</p><p> How easy will it be for the competition such as Intel and AMD to pull the same technical tricks?</p><p> 像英特尔和AMD这样的竞争对手采用相同的技术技巧有多容易？</p><p> Sure you could try to Google this, but if you try to learn what Apple has done beyond the superficial explanations, you will quickly get buried in highly technical jargon such as M1 using very wide instruction decoders, enormous re-order buffer (ROB) etc. Unless you are a CPU hardware geek, a lot of this will simply be gobbledegook.</p><p> 当然，您可以尝试使用Google，但如果您尝试了解苹果公司所做的工作，除了肤浅的解释，您将很快陷入技术高度专业的术语中，例如使用非常宽的指令解码器，巨大的重排序缓冲区（ROB）等的M1除非您是CPU硬件极客，否则很多都是gobbledegook。</p><p> To get the most out of this story I advice reading my earlier piece:  RISC and CISC mean in 2020? There I explain what a microprocessor (CPU) is as well various important concepts such as:</p><p> 为了充分利用这个故事，我建议阅读我的前一篇文章：RISC和CISC意味着2020年？在这里，我解释什么是微处理器（CPU）以及各种重要概念，例如：</p><p>  But if you are impatient, I will do a quick version of the material you need to understand to grasp my explanation of the M1 chip.</p><p>但是，如果您不耐烦，我将简要介绍您需要理解的材料，以帮助我理解M1芯片。</p><p>  Normally when speaking of chips from Intel and AMD we talk about central processing units (CPUs) or microprocessors. As you can read more about in my  RISC vs CISC story, these pull in instructions from memory. Then each instruction is typically carried out in sequence.</p><p>  通常，当谈到英特尔和AMD的芯片时，我们谈论的是中央处理器（CPU）或微处理器。正如您可以在我的RISC vs CISC故事中了解的更多信息一样，这些信息从内存中提取指令。然后，通常按顺序执行每个指令。</p><p>  A CPU at its most basic level is a device with a number of named memory cells called registers and a number of computational units called arithmetic logic units (ALU). The ALUs perform things like addition, subtraction and other basic math operations. However these are only connected to the CPU registers. If you want to add up two numbers, you have to get those two numbers from memory and into two registers in the CPU.</p><p>  一个最基本的CPU是一种设备，它具有许多称为寄存器的命名存储单元和许多称为算术逻辑单元（ALU）的计算单元。 ALU执行加法，减法和其他基本数学运算之类的操作。但是，这些仅连接到CPU寄存器。如果要相加两个数字，则必须从内存中获得这两个数字并放入CPU的两个寄存器中。</p><p> Here are some examples of typical instructions that a RISC CPU as found on the M1 carries out.</p><p> 这是M1上的RISC CPU执行的一些典型指令示例。</p><p>  Here  r1 and  r2 are the registers I talked about. Modern RISC CPUs cannot do operations on numbers which are not in a register like this. E.g. it cannot add two numbers residing in RAM in two different locations. Instead it has to pull these two numbers into a separate register. That is what we do in this simple example. We pull in the number at memory location 150 in the RAM and put it into register  r1 in the CPU. Next we put the contents of address 200 into register  r1. Only then can the numbers be added with the  add r1, r2 instruction.</p><p>  这里的r1和r2是我所讨论的寄存器。现代RISC CPU无法对不在寄存器中的数字进行这样的操作。例如。它不能在两个不同位置的RAM中添加两个数字。相反，它必须将这两个数字放入单独的寄存器中。这就是我们在此简单示例中所做的。我们在RAM中的存储器位置150提取数字，并将其放入CPU的寄存器r1中。接下来，我们将地址200的内容放入寄存器r1中。只有这样，数字才可以用add r1，r2指令相加。</p><p>  The concept of registers is old. E.g. on this old mechanical calculator, the  register is what holds the numbers you are adding. Likely the origin for the word  cash register. The register is where you registered input numbers.</p><p>  寄存器的概念是古老的。例如。在这个旧的机械计算器上，寄存器是保存您要添加的数字的函数。收银机一词的起源。寄存器是您注册输入数字的地方。</p><p>   The M1 is not a CPU, it is a whole system of multiple chips put into one large silicon package. The CPU is just one of these chips.</p><p>   M1不是CPU，它是将多个芯片放入一个大的硅封装中的整个系统。 CPU只是这些芯片之一。</p><p> Basically the M1 is one whole computer onto a chip. The M1 contains CPU, Graphical Processing Unit (GPU), memory, input and output controllers and many more things making up a whole computer. This is what we call a System on a Chip (SoC).</p><p>M1基本上是一台完整的计算机集成到芯片上。 M1包含CPU，图形处理单元（GPU），内存，输入和输出控制器以及构成一台整体计算机的许多其他功能。这就是我们所说的片上系统（SoC）。</p><p>  Today if you buy a chip whether from Intel or AMD, you actually get what amounts to  multiple microprocessors in one package. In the past computers would have multiple physically separate chips on the motherboard of the computer.</p><p>  今天，如果您从Intel或AMD购买芯片，实际上可以在一个封装中获得相当于多个微处理器的数量。过去，计算机的主板上会在物理上具有多个单独的芯片。</p><p>  However because we are able to put so many transistors on a silicon die today, companies such as Intel and AMD began putting multiple microprocessors onto one chip. Today we refer to these chips as CPU cores. One core is basically a full independent chip which can read instructions from memory and perform calculations.</p><p>  但是，由于今天我们能够在硅芯片上放置如此多的晶体管，因此英特尔和AMD等公司开始将多个微处理器集成到一个芯片上。今天，我们将这些芯片称为CPU内核。一个核心基本上是一个完全独立的芯片，可以从内存中读取指令并执行计算。</p><p>  This has for a long time been the name of the game in terms of increasing performance: Just add more general purpose CPU cores. But there is a disturbance in the force. There is one player in the CPU market which is deviating from this trend.</p><p>  长期以来，就提高性能而言，这一直是游戏的名称：只需添加更多通用CPU内核即可。但是部队受到了干扰。 CPU市场中有一个参与者偏离了这一趋势。</p><p>  Instead of adding ever more general purpose CPU cores, Apple has followed another strategy: They have started adding ever more specialized chips doing a few specialized tasks. The benefit of this is that specialized chips tend to be able to perform their tasks significantly faster using much less electric current than a general purpose CPU core.</p><p>  苹果没有添加更多的通用CPU内核，而是采取了另一种策略：他们开始添加更多的专用芯片来完成一些特殊的任务。这样做的好处是，专用芯片趋于使用比通用CPU内核少得多的电流来显着更快地执行其任务。</p><p> This is not entirely new knowledge. For many years already specialized chips such as the graphical processing units (GPUs) have been sitting in Nvidia and AMD graphics cards performing operations related to graphics much faster than general purpose CPUs.</p><p> 这不是全新的知识。多年来，已经在Nvidia和AMD图形卡中安装了诸如图形处理单元（GPU）之类的专用芯片，它们执行与图形相关的操作要比通用CPU快得多。</p><p> What Apple has done is simply to take a more radical shift towards this direction. Rather than just having general purpose cores and memory, the M1 contains a wide variety of specialized chips:</p><p> 苹果公司所做的只是简单地朝这个方向做出更根本的转变。 M1不仅具有通用内核和存储器，还包含各种各样的专用芯片：</p><p> Central Processing Unit (CPU) — The “brains” of the SoC. Runs most of the code of the operating system and you apps.</p><p>中央处理器（CPU）-SoC的“大脑”。运行操作系统和应用程序的大多数代码。</p><p> Graphics Processing Unit (GPU) — Handles graphics-related tasks, such as visualizing an app’s user interface and 2D/3D gaming.</p><p> 图形处理单元（GPU）-处理与图形相关的任务，例如可视化应用程序的用户界面和2D / 3D游戏。</p><p> Image Processing Unit (ISP) — Can be used to speed up common tasks done by image processing aplications.</p><p> 图像处理单元（ISP）-可用于加快图像处理应用程序完成的常见任务。</p><p> Digital Signal Processor (DSP) — Handles more mathematically intensive functions than a CPU. Includes decompressing music files.</p><p> 数字信号处理器（DSP）-处理比CPU更复杂的数学功能。包括解压缩音乐文件。</p><p> Neural Processing Unit (NPU) — Used in high-end smartphones to accelerate machine learning (AI) tasks. These include voice recognition and camera processing.</p><p> 神经处理单元（NPU）—用于高端智能手机，以加速机器学习（AI）任务。这些包括语音识别和相机处理。</p><p> This is part of the reason why a lot of people working on images and video editing with the M1 Macs are seeing such speed improvements. A lot of the tasks they do, can run directly on specialized hardware. That is what allows a cheap M1 Mac Mini to encode a large video file, without breaking sweat while an expensive iMac has all its fans going full blast and still cannot keep up.</p><p> 这就是为什么许多使用M1 Mac进行图像和视频编辑的人看到这种速度提高的原因之一。他们执行的许多任务可以直接在专用硬件上运行。这样一来，廉价的M1 Mac Mini就能编码大型视频文件，而又不会汗流while背，而昂贵的iMac却让所有粉丝全力以赴，但仍无法跟上潮流。</p><p>  Unified memory may confuse you. How is it different from shared memory? And wasn’t sharing video memory with main memory a terrible idea in the past giving low performance? Yes, shared memory was indeed bad. The reason was that the CPU and GPU had to take turns accessing the memory. Sharing it meant contention to use the databus. Basically the GPUs and CPUs had to take turns using a narrow pipe to push or pull data through.</p><p>  统一内存可能会使您感到困惑。与共享内存有何不同？过去，将视频内存与主内存共享不是一个糟糕的主意，导致性能降低吗？是的，共享内存确实不好。原因是CPU和GPU必须轮流访问内存。共享意味着要争用数据总线。基本上，GPU和CPU必须轮流使用狭窄的管道来推动或拉动数据。</p><p> That is not the case with Unified memory. In Unified memory the GPU cores and CPU cores can access memory at the same time. Thus in this case there is no overhead in sharing memory. In addition the CPU and GPU can tell each other about where some memory is located. Previously the CPU would have to copy data from its area of the main memory to the area used by the GPU. With unified memory, it is more like saying “Hey Mr. GPU, I got 30 MB of polygon data starting at memory location 2430.” The GPU can then start using that memory without doing any copying.</p><p>统一内存不是这种情况。在统一内存中，GPU内核和CPU内核可以同时访问内存。因此，在这种情况下，共享内存没有开销。另外，CPU和GPU可以相互告知一些内存的位置。以前，CPU必须将数据从其主内存区域复制到GPU使用的区域。使用统一的内存，它更像是说“嘿，GPU先生，我从内存位置2430开始获得30 MB的多边形数据。”然后，GPU可以开始使用该内存，而无需进行任何复制。</p><p> That means you can significant performance gains by the fact that all the various special co-processors on the M1 can rapidly exchange information with each other by using the same memory pool.</p><p> 这意味着，M1上的所有各种特殊协处理器都可以使用同一内存池彼此快速交换信息，因此可以显着提高性能。</p><p>   If what Apple is doing is so smart, why are not everybody doing it? To some extent they are. Other ARM chip makers are increasingly putting in specialized hardware.</p><p>   如果苹果公司正在做的事情如此聪明，为什么不是每个人都这样做呢？在某种程度上，它们是。其他ARM芯片制造商越来越多地投入专用硬件。</p><p> AMD has also started putting stronger GPUs on some of their chips and moving gradually towards some form of SoC with the accelerated processing units (APU) which are basically CPU cores and GPU cores placed on the same silicon die.</p><p> AMD还开始在其某些芯片上安装功能更强大的GPU，并逐步采用加速处理单元（APU）向某种形式的SoC迈进，这些处理器基本上是CPU内核和GPU内核位于同一硅芯片上。</p><p>  Yet there are important reasons why they cannot do this. An SoC is something naturally the computer maker such as Dell and HP make, since an SoC is essentially a whole computer on a chip. This works fine for ARM, because a company such as Dell or HP would simply license ARM intellectual property and buy various IP for other chips possibly from ARM to add whatever specialized hardware they think their SoC should have. Then they ship the specs over over to a semiconductor foundry such as  GlobalFoundries or  TSMC, which manufactures chips for AMD and Apple today.</p><p>  然而，有重要的原因使他们无法做到这一点。 SoC本质上是Dell和HP等计算机制造商生产的产品，因为SoC本质上是芯片上的整个计算机。这对于ARM来说效果很好，因为诸如Dell或HP之类的公司将简单地许可ARM知识产权，并可能从ARM购买其他芯片的各种IP，以添加他们认为自己的SoC应该具有的任何专用硬件。然后，他们将规格发送给GlobalFoundries或TSMC等半导体代工厂，后者今天为AMD和Apple生产芯片。</p><p>  Here we get a big problem with the Intel and AMD business model. Their business models are based on selling general purpose CPUs, which people just slot in on a large PC motherboard. Thus computer makers can simply buy motherboards, memory, CPUs and graphics cards from different vendors and integrate them to one solution.</p><p>  在这里，我们遇到了Intel和AMD业务模型的大问题。他们的商业模式基于销售通用CPU，而人们只是将其插入大型PC主板中。因此，计算机制造商只需从不同的供应商那里购买主板，内存，CPU和图形卡，然后将它们集成到一个解决方案中即可。</p><p> But we are quickly moving away from that world. In the new SoC world you don’t assemble physical components from different vendors. Instead you assemble IP (intellectual property) from different vendors. You buy the design for graphics cards, CPUs, modems, IO controllers and other things from different vendors and use that to design a SoC in-house. Then you get a foundry to manufacture this.</p><p> 但是我们正在迅速远离那个世界。在新的SoC世界中，您无需组装来自不同供应商的物理组件。相反，您需要组装来自不同供应商的IP（知识产权）。您从不同的供应商那里购买了图形卡，CPU，调制解调器，IO控制器和其他产品的设计，并将其用于内部设计SoC。然后，您将得到一个铸造厂来制造它。</p><p> Now you got a big problem, because neither Intel, AMD or Nvidia are going to license their intellectual property to Dell or HP for them to make an SoC for their machines.</p><p>现在您遇到了一个大问题，因为英特尔，AMD或Nvidia都不会将其知识产权许可给戴尔或惠普，让他们为自己的机器制造SoC。</p><p> Sure Intel and AMD may simply begin to sell whole finished SoCs. But what are these to contain? PC makers may have different ideas of what they should contain. You potentially get a conflict between Intel, AMD, Microsoft and PC makers about what sort of specialized chips should be included because these will need software support.</p><p> 当然，英特尔和AMD可能只是开始销售完整的SoC。但是这些包含什么？ PC制造商可能对它们包含的内容有不同的想法。英特尔，AMD，微软和PC制造商之间可能会出现关于应包含哪种专用芯片的冲突，因为这些芯片需要软件支持。</p><p> For Apple this is simple. They control the whole widget. They give you e.g. the Core ML library for developers to write  machine learning stuff. Whether Core ML runs on Apple’s CPU or the Neural Engine is an implementation detail developers don’t have to care about.</p><p> 对于苹果公司来说，这很简单。他们控制整个小部件。他们给你例如核心ML库，供开发人员编写机器学习内容。 Core ML是在Apple的CPU上运行还是在Neural Engine上运行，是开发人员无需关心的实现细节。</p><p>  So heterogenous computing is part of the reason but not the sole reason. The fast general purpose CPU cores on the M1, called Firestorm are genuinely fast. This is a major deviation from ARM CPU cores in the past which tended to be very weak compared to AMD and Intel cores.</p><p>  因此，异构计算是原因的一部分，而不是唯一的原因。 M1上称为Firestorm的快速通用CPU内核确实非常快。与过去的ARM CPU内核相比，这是一个重大偏差，与AMD和Intel内核相比，ARM CPU内核通常非常弱。</p><p> Firestorm in contrast beats most Intel cores and almost beats the fastest AMD Ryzen cores. Conventional wisdom said that was not going to happen.</p><p> 相比之下，Firestorm击败了大多数Intel内核，几乎击败了最快的AMD Ryzen内核。传统观点认为这不会发生。</p><p> Before talking about what makes Firestorm fast it helps to understand what the core idea of making a fast CPU is really about.</p><p> 在讨论使Firestorm快速运行的原因之前，先要了解使快速CPU成为核心思想的真正意义。</p><p>   Back in the 80s, it was easy. Just increase the clock frequency and the instructions would finish faster. Every clock cycle is when the computer does something. But this  something can be quite little. Thus an instruction may require multiple clock cycles to finis because it is made up of several smaller tasks.</p><p>   上世纪80年代，这很容易。只要增加时钟频率，指令就会更快地完成。每个时钟周期都是计算机执行某项操作的时间。但是，这可能很少。因此，一条指令可能由多个较小的任务组成，因此可能需要多个时钟周期才能完成操作。</p><p> However today increasing the clock frequency is next to impossible. That is the whole “End of Moore’s Law” that people have been harping on for over a decade now.</p><p>但是，如今几乎不可能提高时钟频率。这就是人们十多年来一直在努力的整个“摩尔定律的终结”。</p><p>   There are two approaches to this. One is to add more CPU cores. From the point of view of a software developer it is like adding  threads. Every CPU core is like a hardware thread. If you don’t know what a thread is, then you can think of it as the process of carrying out a task. With two cores, a CPU can carry out two separate tasks concurrently: two threads. The tasks could be described as two separate programs stores in memory or it could actually be the same program performed twice. Each thread needs some book-keeping, such as  where in sequence of program instructions the thread is currently at. Each thread may store temporary results which should be kept separate.</p><p>   有两种方法。一种是添加更多的CPU内核。从软件开发人员的角度来看，这就像添加线程。每个CPU内核都像一个硬件线程。如果您不知道线程是什么，则可以将其视为执行任务的过程。一个CPU具有两个内核，可以同时执行两个单独的任务：两个线程。这些任务可以描述为两个单独的程序存储在内存中，或者实际上可以是同一程序执行两次。每个线程都需要进行一些记账，例如该线程当前在程序指令序列中的位置。每个线程可以存储临时结果，应将其分开保存。</p><p> In principle a processor can have just one core and run multiple threads. In this case it simply halts one thread and stores current progress before switching to another. Later it switches back. This doesn’t bring much of a performance enhancement and is only used when a thread may frequently halt to wait for input from user, data from a slow network connection etc. These may be called software threads. Hardware threads means you have actual extra physical hardware such as extra cores at your disposal to speed up things.</p><p> 原则上，处理器只能具有一个内核并运行多个线程。在这种情况下，它只是暂停一个线程并存储当前进程，然后再切换到另一线程。稍后它将切换回去。这不会带来太多的性能提升，仅在线程可能经常停止等待用户输入，网络连接速度慢等数据时使用。这些可以称为软件线程。硬件线程意味着您可以使用实际的额外物理硬件（例如额外的内核）来加快处理速度。</p><p>  The problem with this is that the developer has to write code to take advantage of this. Some tasks such as sever software is easy to write like this. You can imagine processing each connecting user separate. These tasks are so independent from each other that having lots of cores is an excellent choice for servers especially cloud based services.</p><p>  问题在于，开发人员必须编写代码才能利用这一点。这样的一些任务（例如服务器软件）很容易编写。您可以想象分别处理每个连接用户。这些任务彼此独立，以至于拥有大量内核是服务器（尤其是基于云的服务）的绝佳选择。</p><p>  That is the reason why you see ARM CPUs makers such as Ampere making CPUs such as the  Altra Max which has a crazy 128 cores. This chip is specifically made for the cloud. You don’t need crazy single core performance because in the cloud it is all about having as many threads as possible per watt to handle as many concurrent users as possible.</p><p>  这就是为什么您会看到诸如Ampere之类的ARM CPU制造商生产诸如具有疯狂的128核的Altra Max之类的CPU的原因。该芯片是专门为云计算的。您不需要疯狂的单核性能，因为在云中，每瓦特具有尽可能多的线程来处理尽可能多的并发用户。</p><p> Apple in contrast is in the complete opposite end of the spectrum. Apple makes single user devices. Lots of threads is not an advantage. Their devices are used for gaming, video editing, development etc. They want desktops with beautiful responsive graphics and animations.</p><p> 相比之下，苹果则处于另一端。苹果生产单用户设备。大量线程不是优势。他们的设备用于游戏，视频编辑，开发等。他们希望台式机具有精美的响应图形和动画。</p><p> Desktop software is generally not made to utilize lots of cores. E.g. computer game will likely benefit from 8 cores, but something like 128 cores would be a total waste. Instead you would want fewer but more powerful cores.</p><p> 桌面软件通常不会利用很多内核。例如。电脑游戏可能会受益于8核，但是像128核这样的东西将完全浪费。相反，您将需要更少但更强大的内核。</p><p>  So here is the interesting thing,  Out-of-Order execution is a way to execute more instructions in parallel but without exposing that capability as multiple threads. Developers don’t have to code their software specifically to take advantage of it. Seen from the developer’s perspective it just looks like each core runs faster.</p><p>因此，这很有趣，乱序执行是一种并行执行更多指令但不将该功能作为多个线程公开的方式。开发人员无需专门编码其软件即可利用它。从开发人员的角度来看，似乎每个内核的运行速度都更快。</p><p> To understand how this works, you need to understand some things about memory. Asking for data in one particular memory location is slow. But there is not difference in delay getting 1 byte compared to getting say 128 bytes. Data is sent across what we call a databus. You can think of it as a road or pipe between memory and different parts of the CPU where data gets pushed through. In reality it is of course just some copper tracks conducting electricity. If the databus is wide enough you can just get multiple bytes at the same time.</p><p> 要了解其工作原理，您需要了解一些有关内存的知识。在一个特定的内存位置中请求数据很慢。但是与说128个字节相比，延迟获得1个字节没有什么区别。数据通过我们所谓的数据总线发送。您可以将其视为内存与数据被推送通过的CPU不同部分之间的一条通道或管道。实际上，当然只有一些铜轨可以导电。如果数据总线足够宽，则可以同时获取多个字节。</p><p> Thus CPUs get a whole chunk of instructions at a time to execute. But they are written to be executed one after the other. Modern microprocessors do what we call Out-of-Order (OoO) execution.</p><p> 因此，CPU一次执行一整条指令。但是它们被编写为一个接一个地执行。现代微处理器执行我们所谓的无序（OoO）执行。</p><p> That means they are able to analyze a buffer of instructions quickly and see which ones depend on on which. Look at the simple example below:</p><p> 这意味着他们能够快速分析指令缓冲区，并查看哪些指令取决于哪个指令。看下面的简单例子：</p><p> 01: mul r1, r2, r3 // r1 ← r2 × r3 02: add r4, r1, 5 // r4 ← r1 + 5 03: add r6, r2, 1 // r6 ← r2 + 1</p><p> 01：mul r1，r2，r3 // r1←r2×r3 02：加r4，r1，5 // r4←r1 + 5 03：加r6，r2，1 // r6←r2 + 1</p><p> Multiplication tends to be a slow process. So say it takes multiple clock cycles to perform. The second instruction will simply have to wait because its calculation depends on knowing the result that gets put into the  r1 register.</p><p> 乘法往往是一个缓慢的过程。可以这么说，它需要多个时钟周期来执行。第二条指令仅需等待，因为其计算取决于知道放入r1寄存器的结果。</p><p> However the third instruction at line  03 doesn’t depend on calculations from previous instructions. Hence an Out-of-Order processor can begin calculating this instruction in parallel.</p><p> 但是，第03行的第三条指令并不取决于先前指令的计算结果。因此，乱序处理器可以开始并行计算此指令。</p><p> However more realistically we are talking about hundreds of instructions. The CPU is able to figure out all the dependencies between these instructions.</p><p>但实际上，我们正在谈论数百条指令。 CPU能够找出这些指令之间的所有依赖关系。</p><p> It analysis the instructions by looking at the inputs to each instruction. Does the inputs depend on output from one or more other instructions? By input and output we mean registers containing results from previous calculations.</p><p> 它通过查看每个指令的输入来分析指令。输入是否取决于一个或多个其他指令的输出？输入和输出是指包含以前计算结果的寄存器。</p><p> E.g. the  add r4, r1, 5 instruction depends on input from  r1 which is produced by  mul r1, r2, r3 . We can chain together these relationships into long elaborate graphs which the CPU can work through. The nodes are the instructions and the edges are the registers connecting them.</p><p> 例如。加法r4，r1、5指令取决于mul r1，r2，r3产生的来自r1的输入。我们可以将这些关系链接在一起，成为CPU可以处理的详细图形。节点是指令，边是连接它们的寄存器。</p><p> The CPU can analyze such a graph of nodes and determine which instructions it can perform in parallel and where it needs to wait for the results from multiple dependent calculations before carrying on.</p><p> CPU可以分析这样的节点图，并确定它可以并行执行哪些指令，以及在继续执行之前需要在哪里等待多个相关计算的结果。</p><p> Many instructions will finnish early but we cannot make their results official. We cannot commit them, otherwise we supply the result in the wrong order. To the rest of the world it has to look as if the instructions where carried out in the same sequence as they where issued.</p><p> 许多说明会尽早完成，但我们无法将其结果正式化。我们无法提交它们，否则我们将以错误的顺序提供结果。在世界其他地方，必须仿佛按照说明的发布顺序执行说明。</p><p> Like a stack, the CPU will keep popping done instructions from the top, until hitting an instruction which is not done.</p><p> 像堆栈一样，CPU将从顶部一直弹出完成的指令，直到命中未完成的指令。</p><p> We are not quite done with this explanation, but this gives you a bit of a clue. Basically you can have parallelism that the programmer must know or the kind which the CPU fakes to look as if everything is single thread. However behind the scenes it is doing Out-of-Order black magic.</p><p> 我们对这个解释还不够，但这给了您一些线索。基本上，您可以具有程序员必须知道的并行性，或者CPU伪造的类型看起来像一切都是单线程。但是在幕后，它正在执行乱序黑魔法。</p><p> It is the superior Out-of-Order execution which is making the Firestorm cores on the M1 kick ass and take names. It is in fact much stronger than anything from Intel or AMD. Likely stronger than from anybody else in the mainstream market.</p><p>出色的乱序执行功能使M1踢屁股上的Firestorm核心发挥了重要作用。实际上，它比Intel或AMD的任何产品都要强大。可能比主流市场上的任何其他产品都要强大。</p><p>  In my explanation of Out-of-Order execution (OoO) I skipped some important details, which needs to be covered. Otherwise it is not possible to understand why Apple is ahead of the game and Intel and AMD may not be able to catch up.</p><p>  在我对无序执行（OoO）的解释中，我跳过了一些重要的细节，需要覆盖这些细节。否则，无法理解为什么苹果领先于游戏，而英特尔和AMD可能无法追赶。</p><p> The big “scratchpad” I talked about is actually called the  Re-Order Buffer (ROB), and it doesn’t contain normal machine code instructions. Not the ones that the CPU fetches from memory to execute. These are the instructions in the CPU Instruction Set Architecture (ISA). That is the kind of instructions that we call x86, ARM, PowerPC etc.</p><p> 我所说的大“便签本”实际上称为“重排序缓冲区（ROB）”，它不包含正常的机器代码指令。不是CPU从内存中获取要执行的内容。这些是CPU指令集体系结构（ISA）中的指令。这就是我们称为x86，ARM，PowerPC等的指令。</p><p> However internally the CPU works on an entirely different instruction-set invisible to the programmer. We call these micro-operations (micro-ops or μops). The ROB is full of these micro-ops.</p><p> 但是，在内部，CPU会使用程序员无法看到的完全不同的指令集。我们称这些微操作（微操作或微操作）。 ROB充满了这些微型操作。</p><p> These are much more practical to work with for all the magic a CPU does to make stuff run in parallel. The reason is that micro-ops are very wide (contain a lot of bits) and can contain all sorts of meta-information. You cannot add that kind of information to an ARM or x86 instruction as it would:</p><p> 对于CPU可以并行运行的所有魔术，使用这些实用得多。原因是微操作非常广泛（包含很多位），并且可以包含各种元信息。您不能像这样将此类信息添加到ARM或x86指令中：</p><p> Expose details about  how the CPU works, whether it has an OoO unit, has register renaming and many other details.</p><p> 公开有关CPU工作方式的详细信息，无论它是否具有OoO单元，是否具有寄存器重命名以及许多其他详细信息。</p><p> A lot of the meta information only makes sense in context of our current execution.</p><p> 许多元信息仅在当前执行情况下才有意义。</p><p> You can think of this as when writing a program. You have a public API that needs to be stable and everybody use. That is the ARM, x86, PowerPC, MIPS etc instruction-sets. The micro-ops are basically the private APIs that are used to implement the public ones.</p><p>您可以将其视为编写程序时。您有一个公共API，需要保持稳定并供所有人使用。那就是ARM，x86，PowerPC，MIPS等指令集。微型操作基本上是用于实现公共API的专用API。</p><p> Also micro-ops are usually easier to work with for the CPU. Why? Because they each do one simple limited task. Regular ISA instructions can be more complex causing a bunch of stuff to happen and thus actually translate to multiple micro-ops.</p><p> 通常，微操作通常更容易用于CPU。为什么？因为他们每个人都完成一项简单的有限任务。常规的ISA指令可能更复杂，从而导致大量事情发生，从而实际上转化为多个微操作。</p><p> For CISC CPUs there is usually no alternative but to use micro-ops otherwise the large complex CISC instructions would make pipelines and OoO next to impossible to achieve.</p><p> 对于CISC CPU，通常只有使用微操作，否则别无选择，否则大型复杂的CISC指令会使流水线和OoO几乎无法实现。</p><p> RISC CPUs have a choice. So e.g. smaller ARM CPUs don’t use micro-ops at all. But that also means they cannot do things such as OoO.</p><p> RISC CPU可以选择。所以较小的ARM CPU根本不使用微操作。但这也意味着他们无法做诸如OoO之类的事情。</p><p>  But you wonder why does any of this matter? Why is this detail important to know to understand why Apple has the upper hand on AMD and Intel?</p><p>  但是您想知道为什么这有什么关系吗？为什么要了解为什么Apple在AMD和Intel上占上风呢？</p><p> It is because the ability to run fast depends on how quickly you can fill up the ROB with micro-ops and with how many. The more quickly you fill it up and the larger it is the more opportunities you are given to pick instructions you can execute in parallel and thus improve performance.</p><p> 这是因为快速运行的能力取决于您可以用微操作填充ROB的速度以及有多少操作。您填写得越快，它就越大，您就有更多机会选择可以并行执行的指令，从而提高性能。</p><p> Machine code instructions are chopped into micro-ops by what we call an instruction decoder. If we have more decoders we can chop up more instructions in parallel and thus fill up the ROB faster.</p><p> 机器代码指令被我们称为指令解码器的指令切成微指令。如果我们有更多的解码器，我们可以并行切分更多的指令，从而更快地填充ROB。</p><p> And this is where we see the huge differences. The biggest baddest Intel and AMD microprocessor cores have 4 decoders, which means they can decode 4 instructions in parallel spitting out micro-ops.</p><p>这就是我们看到巨大差异的地方。最糟糕的英特尔和AMD微处理器内核具有4个解码器，这意味着它们可以并行解码4条指令，从而吐出微指令。</p><p> But Apple has a crazy 8 decoders. Not only that but the ROB is something like 3x larger. You can basically hold 3x as many instructions. No other mainstream chip maker has that many decoders in their CPUs.</p><p> 但是苹果公​​司有疯狂的8个解码器。不仅如此，ROB大约大3倍。您基本上可以容纳3倍的指令。没有其他主流芯片制造商的CPU拥有如此多的解码器。</p><p>  This is where we finally see the revenge of RISC, and where the fact that the M1 Firestorm core has an ARM R</p><p>  这是我们最终看到RISC报仇的地方，也是M1 Firestorm内核具有ARM R的事实</p><p>......</p><p>......</p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/芯片/">#芯片</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/m1/">#m1</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/cpu/">#cpu</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/分享/">#分享</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy; 2020 diglog.com </div></div></body></html>