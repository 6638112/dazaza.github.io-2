<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>与PostgreSQL相比，redis在存储一个巨大的json时有多少钱？ How much faster is Redis at storing a blob of JSON compared to PostgreSQL?</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">How much faster is Redis at storing a blob of JSON compared to PostgreSQL?<br/>与PostgreSQL相比，redis在存储一个巨大的json时有多少钱？ </h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2021-04-18 18:24:11</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2021/4/6e4cd427a8a13a7b65bdfc474779ca1f.png"><img src="http://img2.diglog.com/img/2021/4/6e4cd427a8a13a7b65bdfc474779ca1f.png" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>In  Song Search when you&#39;ve found a song, it loads some affiliate links to Amazon.com. (In case you&#39;re curious it&#39;s earning me lower double-digit dollars per month). To avoid overloading the Amazon Affiliate Product API, after I&#39;ve queried their API, I store that result in my own database along with some metadata. Then, the next time someone views that song page, it can read from my local database. With me so far?</p><p>在歌曲搜索时＆＃39找到一首歌曲，它加载了一些与Amazon.com的联盟链接。 （如果您＆＃39;令人叹息的＆＃39;每月降低两位数美元）。在i＆＃39之后，避免过载亚马逊联盟产品API，我询问了他们的API，我将其存储在我自己的数据库中以及一些元数据。然后，下次某人查看歌曲页面时，它可以从我本地数据库中读取。到目前为止和我在一起？</p><p>  The other caveat is that you can&#39;t store these lookups locally too long since prices change and/or results change. So if my own stored result is older than a couple of hundred days, I delete it and fetch from the network again. My current implementation uses PostgreSQL (via the Django ORM) to store this stuff. The model looks like this:</p><p>  另一种警告是，您可以在价格变化和/或结果变化时当地闲长地存储这些查找。因此，如果我自己的存储结果超过几百天，则我将再次删除并再次获取网络。我目前的实现使用PostgreSQL（通过Django Orm）来存储此内容。该模型如下所示：</p><p> class  AmazonAffiliateLookup ( models . Model ,  TotalCountMixin ):  song  =  models . ForeignKey ( Song ,  on_delete = models . CASCADE )  matches  =  JSONField ( null = True )  search_index  =  models . CharField ( max_length = 100 ,  null = True )  lookup_seconds  =  models . FloatField ( null = True )  created  =  models . DateTimeField ( auto_now_add = True ,  db_index = True )  modified  =  models . DateTimeField ( auto_now = True )</p><p> Class Amazonaffiliatelookup（模型。模型，TotalCountmixin）：歌曲=模型。 FookEyKey（歌曲，ON_DELETE =模型。级联）匹配= jsonfield（null = true）search_index =模型。 charfield（max_length = 100，null = true）lookup_seconds =模型。 floatfield（null = true）创建=模型。 DateTimefield（auto_now_add = true，db_index = true）修改=模型。 DateTimefield（auto_now = true）</p><p>  Then, I thought, why not use Redis for this. Then I can use Redis&#39;s &#34;natural&#34; expiration by simply setting as expiry time when I store it and then I don&#39;t have to worry about cleaning up old stuff at all.</p><p>  然后，我想，为什么不使用redis这一点。然后我可以使用redis＆＃39; s＆＃34;自然＆＃34;只需将其存放到到期时间即可到期到期，然后我不必担心清理旧的东西。</p><p> The way I&#39;m using Redis in this project is as a/the cache backend and I have it configured like this:</p><p> I＆＃39; m在这个项目中使用redis的方式是a / the cache后端，我已如下配置：</p><p> CACHES  =  {  &#34;default&#34; :  {  &#34;BACKEND&#34; :  &#34;django_redis.cache.RedisCache&#34; ,  &#34;LOCATION&#34; :  REDIS_URL ,  &#34;TIMEOUT&#34; :  config ( &#34;CACHE_TIMEOUT&#34; ,  500 ),  &#34;KEY_PREFIX&#34; :  config ( &#34;CACHE_KEY_PREFIX&#34; ,  &#34;&#34; ),  &#34;OPTIONS&#34; :  {  &#34;COMPRESSOR&#34; :  &#34;django_redis.compressors.zlib.ZlibCompressor&#34; ,  &#34;SERIALIZER&#34; :  &#34;django_redis.serializers.msgpack.MSGPackSerializer&#34; ,  },  } }</p><p> 缓存= {＆＃34;默认和＃34; ：{＆＃34;后端＆＃34; ：＆＃34; django_redis.cache.rediscache＆＃34; ，＆＃34;位置＆＃34; ：Redis_URL，＆＃34;超时＆＃34; ：配置（＆＃34; cache_timeout＆＃34;，500），＆＃34; key_prefix＆＃34; ：config（＆＃34; cache_key_prefix＆＃34;，＆＃34;＆＃34;），＆＃34;选项＆＃34; ：{＆＃34;压缩机＆＃34; ：＆＃34; django_redis.com压缩机.zlib.zlibcramper＆＃34; ，＆＃34;序列化器＆＃34; ：＆＃34; django_redis.serializers.msgpack.msgpackserializer＆＃34; ，}，}}</p><p>  Perhaps unrealistic but I&#39;m doing all this testing here on my MacBook Pro. The connection to Postgres (version 11.4) and Redis (3.2.1) are both on  localhost.</p><p>  也许不现实但是我在我的MacBook Pro上做了所有这些测试。与postgres（版本11.4）和redis（3.2.1）的连接均在localhost上。 </p><p>  The reads are the most important because hopefully, they happen 10x more than writes as several people can benefit from previous saves.</p><p>读取是最重要的，因为希望他们发生了10倍，而是几个人可以从以前的保存中受益。</p><p> I changed my code so that it would do a read from both databases and if it was found in both, write down their time in a log file which I&#39;ll later summarize. Results are as follows:</p><p> 我更改了我的代码，以便它可以从两个数据库中读取，如果它在两者中都发现，请在我＆＃39; ll后来汇总的日志文件中写下他们的时间。结果如下：</p><p>  It means, when focussing on the median,  Redis is 16 times faster than PostgreSQL at  reading these JSON blobs.</p><p>  这意味着，当聚焦在中位数时，Redis比在阅读这些JSON Blob时比PostgreSQL快16倍。</p><p>  The writes are less important but due to the synchronous nature of my Django, the unlucky user who triggers a look up that I didn&#39;t have, will have to wait for the write before the XHR request can be completed. However, when this happens, the remote network call to the Amazon Product API is bound to be much slower. Results are as follows:</p><p>  写作不太重要，但由于我的Django的同步性，触发了一个触发我在＆＃39; t具有的瞬间触发，在XHR请求完成之前必须等待写入。但是，当发生这种情况时，对Amazon产品API的远程网络调用必然会慢得多。结果如下：</p><p>  It means, when focussing on the median,  Redis is 20 times faster than PostgreSQL at  writing these JSON blobs.</p><p>  这意味着，当聚焦在中位数时，Redis在写这些JSON Blob时比PostgreSQL快20倍。</p><p>  First of all, I&#39;m still a PostgreSQL fan-boy and have no intention of ceasing that. These times are made up of much more than just the individual databases. For example, the PostgreSQL speeds depend on the Django ORM code that makes the SQL and sends the query and then turns it into the model instance. I don&#39;t know what the proportions are between that and the actual bytes-from-PG&#39;s-disk times. But I&#39;m not sure I care either. The tooling around the database is inevitable mostly and it&#39;s what matters to users.</p><p>  首先，我仍然是一个PostgreSQL粉丝男孩，无意停止这一点。这些时间比只有个别数据库更多地组成。例如，PostgreSQL速度取决于使SQL的Django orm代码依赖于django orm代码并发送查询，然后将其转换为模型实例。我不知道该比例与实际字节 - 从PG＆＃39; S磁盘时间之间的比例。但我不确定我也不确定。数据库周围的工具是不可避免的，它是对用户的重要事项。</p><p> Both Redis and PostgreSQL are persistent and survive server restarts and crashes etc. And you get so many more &#34;batch related&#34; features with PostgreSQL if you need them, such as being able to get a list of the last 10 rows added for some post-processing batch job.</p><p> redis和postgresql都是持久和生存的服务器重启和崩溃等，你得到了这么多＆＃34;批量相关＆＃34;具有PostgreSQL的功能如果您需要它们，例如能够获取为某些后处理批处理作业添加的最后10行列表。 </p><p> I&#39;m currently using Django&#39;s cache framework, with Redis as its backend, and it&#39;s a cache framework. It&#39;s not meant to be a persistent database. I like the idea that if I really have to I can just flush the cache and although detrimental to performance (temporarily) it shouldn&#39;t be a disaster. So I think what I&#39;ll do is store these JSON blobs in  both databases. Yes, it means roughly 6GB of SSD storage but it also potentially means loading a LOT more into RAM on my limited server. That extra RAM usage pretty much sums of this whole blog post;  of course it&#39;s faster if you can rely on RAM instead of disk. Now I just need to figure out how RAM I can afford myself for this piece and whether it&#39;s worth it.</p><p>我目前使用django＆＃39; s缓存框架，用redis作为它的后端，它是一个缓存框架。它并不意味着是一个持久的数据库。我喜欢这个想法，如果我真的不得不冲洗缓存，虽然对性能有害（暂时）它应该是灾难。所以我认为i＆＃39; ll do在两个数据库中都存储这些json blob。是的，它意味着大约6GB的SSD存储，但它也可能意味着在我的有限服务器上加载更多。额外的RAM使用这一整个博客文章的总和;当然它＆＃39; s更快，如果您可以依赖RAM而不是磁盘。现在我只需要弄清楚我为这件作用的RAM如何以及它是否值得。</p><p>  I experimented with an optimization of NOT turning the Django ORM query into a model instance for each record. Instead, I did this:</p><p>  我尝试了未经将Django ORM查询转换为每个记录的模型实例。相反，我这样做了：</p><p> +from dataclasses import dataclass +@dataclass +class _Lookup: + modified: datetime.datetime + matches: list... +base_qs = base_qs.values_list(&#34;modified&#34;, &#34;matches&#34;) -lookup = base_qs.get(song__id=song_id) +lookup_tuple = base_qs.get(song__id=song_id) +lookup = _Lookup(*lookup_tuple)print(lookup.modified)</p><p> +从Dataclasses导入DataClass + @ Dataclass +类_Lookup：+修改：DateTime.DateTeme +匹配：list ... + base_qs = base_qs.values_list（＆＃34;修改和＃34;＆＃34; matches＆＃34;） -lookup = base_qs.get（song__id = song_id）+ lookup_tuple = base_qs.get（song__id = song_id）+查找= _lookup（* lookup_tuple）打印（查找.modified）</p><p> Basically, let the SQL driver&#39;s &#34;raw Python&#34; content come through the Django ORM. The old difference between PostgreSQL and Redis was 16x. The  new difference was 14x instead.</p><p> 基本上，让SQL驱动程序＆＃39; s＆＃34;生蟒和＃34;内容通过django orm。 PostgreSQL和Redis之间的旧区别为16倍。新的差异是14倍。</p><p>    Arakel     Did you prewarm the table in PG? Did you use indexes? Which type of indexes? Did you tune up your db? You cant simply compare base configuration performance of in-memory db and PG. You will need some careful configuration and then most probably you&#39;ll get much better results.</p><p>    Arakel你是否在pg中掌握了桌子？你使用索引吗？哪种类型的索引？你有没有调整你的数据库？您不能简单地比较内存内存DB和PG的基本配置性能。你需要一些仔细的配置，然后是你最有可能＆＃39; ll获得更好的结果。</p><p> Peter Bengtsson     The Redis isn&#39;t perfectly configured either. Maybe if PG was better configured, the difference would be 14x instead of 16x.  They aren&#39;t both apples. It&#39;s two different databases with their individual strengths and weaknesses. But you can use them for very similar applications, so it helps to be fully aware of their characteristics.</p><p> Peter Bengtsson Redis ISN＆＃39; t完全配置。也许如果PG更好地配置，则差异将是14倍而不是16倍。他们ann＆＃39; t两者苹果。它＆＃39;两个不同的数据库，具有各个优势和劣势。但是您可以将它们用于非常相似的应用程序，因此它有助于充分了解其特征。</p><p> Łukasz Biały     Wouldn&#39;t it make sense to optimize caching in psql first (3gb db is something psql could keep in mem all the time easily) and then measure the ORM overhead + drop ORM on the hot path and replace it with plain sql DAO? You essentially *could* get a huge perf boost without increasing your data layer complexity I think.</p><p> Łukaszbiaływorln＆＃39; t它在psql中优化缓存DAO？基本上你*可以*在不增加我认为的数据层复杂性的情况下，可以获得巨大的perf升压。 </p><p> Peter Bengtsson     The whole database is about 35GB. That one table, with the JSON blobs, is about 3GB.  But, I can think of some simple optimizations I could do, which is to use the ORM to make the SQL for me, but to not dress it up in and an ORM model instance.</p><p>Peter Bengtsson整个数据库约为35GB。那个表格，带有JSON Blob的表约为3GB。但是，我可以想到我可以做的一些简单优化，这是使用orm来为我制作sql，但不要打扮它和orm模型实例。</p><p>  Serge     Even though Regis can be persistent, you can still lose data on crash. It does not flush data immediately on the disk on writes. Keep that in mind.</p><p>  Serge即使REGIS可能是持久的，你仍然可以在崩溃上丢失数据。它不会在写入时立即刷新数据。记在脑子里。</p><p> Peter Bengtsson     Definitely a feather in PG&#39;s hat. And much the reason why I&#39;m nervous about *relying* on Redis as a persistent store. I&#39;m more and more inclined to use Redis as a caching layer.</p><p> Peter Bengtsson绝对是PG＆＃39; S帽子的羽毛。以及我对依赖的商店依赖*依赖*依赖*的原因。我越来越倾向于使用Redis作为缓存层。</p><p> Kyle Harrison     I mean, the thing is that postgre is storing this data to disk, and reading and writing to disk. In other words a Persistent Datastore. Meaning data will survive a reboot of the service. Redis is a pure memory storage, it reads and writes nothing to disk. In other words it&#39;s a Volatile Datadstore. Meaning data will not survive a reboot of the service.  They serve two entirely different purposes. Redis is purely a cache server. So it stands to reason that of course it&#39;s going to be insanely fast at what it does.  But hey, want something even faster? Check out KeyDB. It&#39;s a fork of redis and I believe drop in compatible. But it uses Multithreading to do the work, where Redis stubbornly stays single thread.</p><p> 凯尔哈里森我的意思是，Postgre是将此数据存储到磁盘，并读写到磁盘。换句话说，一个持久的数据存储。含义数据将在重启服务重新启动。 Redis是纯粹的内存存储，它读取并写入磁盘。换句话说，它＆＃39; s一个易失利的数据。意味着数据不会在重启服务中存活。他们为两种完全不同的目的服务。 redis纯粹是缓存服务器。所以它受到它当然是它＆＃39; s将疯狂地快速迅速。但嘿，想要更快的东西吗？检查keydB。它＆＃39;叉子的叉子，我相信兼容。但它使用多线程来完成工作，其中redis顽固地停留单线。</p><p>  Kyle Harrison     The default Snapshotting is hardly ideal for what one would call &#34;persistent&#34;. One shouldn&#39;t be storing mission critical data in a cache server in hopes it&#39;ll survive. Data in stores like Redis and especially memcached should be considered and are volatile at all times. All Redis does differently from Memcached is ocassionally (and conditionally) dump whats in it into a single file for backup. Really, if you need your key to survive and don&#39;t care about performance as much, stick to your regular database solution, it will absolutely be safer there.</p><p>  Kyle Harrison默认的快照对于一个人呼叫和＃34的默认的快照非常理想。一个应该在高速缓存服务器中存储关键任务数据，希望它＆＃39; ll存活。应该考虑Redis和尤其是Memcached等商店中的数据，并且始终是挥发性的。所有redis都与memcached不同，是由memcached（有条件地）转储它中的一个文件备份。真的，如果你需要你的钥匙来生存和不要关心性能，坚持常规数据库解决方案，它将绝对在那里更安全。</p><p> Tom Dyson     &gt; Redis is a pure memory storage, it reads and writes nothing to disk. In other words it&#39;s a Volatile Datadstore. Meaning data will not survive a reboot of the service  This is straightforwardly wrong. See  https://redis.io/topics/persistence.  &gt; The default Snapshotting is hardly ideal for what one would call &#34;persistent&#34;.  So... don&#39;t use the default snapshotting.</p><p> 汤姆敦森＆gt; Redis是纯粹的内存存储，它读取并写入磁盘。换句话说，它＆＃39; s一个易失利的数据。意味着数据不会在重启服务中存活这是直截了当的。请参阅https://redis.io/topics/persistence。 ＆gt;默认的快照对人们称之为呼叫＆＃34;持久性的快照。所以......不要使用默认的快照。</p><p> Kyle Harrison     &gt; So... don&#39;t use the default snapshotting.  and you propose as to................ what? AOF? The thing that on the same page you linked too describes it as buggy and unreliable? Because that&#39;s the only other option for Redis here. Persistance is simply not Redis&#39; strength, plain and simple.  It&#39;s a cache server. Treat it like one and everyone will be happy. Stop trying to use it like Mongo.</p><p> 凯尔哈里森＆gt;所以......不要使用默认的快照。你建议................什么？ AOF？在同一页面上链接的东西也将其描述为越野车和不可靠？因为那个＆＃39;这里是redis的唯一选择。持久性根本不是redis＆＃39;力量，简单，简单。它＆＃39; s一个缓存服务器。像一个人一样对待它，每个人都会很开心。不要试图像蒙古一样使用它。 </p><p> Christian     I don&#39;t know why you&#39;re saying on the page it says buggy and unreliable &gt;&gt;&gt; it does not say that. In fact, it is say the opposite saying it&#39;s &#34;more durable&#34; than snapshotting. I also, disagree with your persistence is simply not Redis&#39;s strength. What kind of app are you building? A financial records banking application? No? I didn&#39;t think so. Most data is ephemeral transient type data. I.e. A setting click on one part of the app to the next. State type storage. Once the user leaves or is no longer of use in the service bye bye. It&#39;s data that&#39;s no important but the need for speed is paramount for a good user experience. Then, in this use case, Redis is very persistent with the above listed options of RDB or AOF. If you&#39;re trying to run a financial records application with need for accurate data stores then yes Redis wouldn&#39;t be persistent enough for that in a qualifying sense.</p><p>基督徒我不知道为什么你＆＃39;在页面上说，越野车和不可靠，＆gt;＆gt;它没有这么说。事实上，它说它相反说它＆＃39; s＆＃34;更耐用的＆＃34;比快照。我也是，不同意你的坚持只是不是重新的＆＃39;力量。你建造什么样的应用程序？金融记录银行申请？不？我没有这么认为和＃39。大多数数据是短暂的瞬态型数据。 IE。设置点击应用程序的一个部分到下一个。状态类型存储。一旦用户离开或不再在服务再见中使用。它＆＃39; s的数据＆＃39; s没有重要，但需要速度的需求对于良好的用户体验至关重要。然后，在此用例中，Redis与上面列出的RDB或AOF选项非常持久。如果您尝试运行财务记录应用程序，则需要准确的数据商店，那么是Redis WORNN＆＃39; T在符合条件的意义上足够持久。</p><p> Neil Goldman     You said yourself the redis is not properly configured. It takes a decent amount of work to properly configure redis to be durable. Otherwise it is not.</p><p> Neil Goldman你对自己说了Redis没有正确配置。正确配置REDIS需要一个不错的工作量，以持久。否则它不是。</p><p> Kyle Harrison     You know, I simply can&#39;t think of a scenario where I&#39;d even want Redis to be &#34;durable&#34;. It&#39;s a great server to spin up and immediately start storing serialized values into. Building into the application layer the reliance on refreshing that key when expired or missing.  For everything else I would care about if lost to a restart, I&#39;d store in a normal database that properly respects ACID transactions.  Can someone spoon feed me some scenarios where having _redis_ persistence is actually a desireable thing? what&#39;s the point of sacrificing the speed (what it&#39;s good at) for AOF mode, especially if it&#39;s unreliable enough for Redis&#39; docs to make note of anyways?</p><p> 凯尔哈里森你知道，我只想想到一个情景我＆＃39; d甚至希望redis＆＃34;持久和＃34;它＆＃39;是一个很好的服务器，并立即开始将序列化值存储到。建立进入应用程序层的依赖于过期或丢失时刷新该键。对于其他一切，我将关心的是，如果丢失到重启，我会在正常数据库中丢失，可以在正确尊重酸事务。有人勺子可以喂我一些情景，其中_redis_持久性实际上是一个希望的东西吗？什么＆＃39;对于牺牲速度（它＆＃39; s擅长）的角度，特别是如果它＆＃39;对于Redis＆＃39的不可靠;文档要记笔记吗？</p><p> Peter Bengtsson     Yeah, it&#39;s rare if you use Redis generally as a caching pattern.  The one case would be if the Redis is flushed (corrupt restart, or FLUSHALL command) and it causes a stampeding herd on the backend that the cache is supposed to protect. For example, a lot of web apps use something like Redis to store use session cookie values (e.g.  https://docs.djangoproject.com/en/2.2/ref/settings/#std:setting-SESSION_ENGINE in Django) and losing the cache would sign everyone out which would suck. But even there, there are choices, such as the `cached_db` option in Django which *writes* to both, but then mostly *reads* from the cache.</p><p> Peter Bengtsson是的，它＆＃39;如果你用redis一般用作缓存模式。如果redis被刷新（损坏重启或flulall命令），则将是一个案例，并且它会导致缓存应该保护的后端冲压群。例如，许多Web应用程序使用Redis等内容来存储使用会话cookie值（例如https://docs.djangoproject.com/en/2/ref/settings/#std:setting-session_engine）并失去了缓存会签署每个人都会吮吸。但即使在那里，也有选择，例如Django中的“缓存_db`选项，其中*写入*两者，但是大多数*从缓存中读取*。</p><p> Neil Goldman     I&#39;m not saying whether or not you want to use Redis durably, just that if you&#39;re comparing Postgres vs Redis and not properly configuring Redis to be durable, it&#39;s not a very valid comparison. Likewise, I can&#39;t think of a situation where I&#39;d prefer Postgres acting as an in-memory cache vs Redis.</p><p> Neil Goldman I＆＃39;嗯不是说你是否想久经地使用REDIS，就像你＆＃39;重新比较postgres与REDIS，没有正确地配置REDIS要持久，它不是一个非常有效的比较。同样，我可以＆＃39想到我＆＃39; d更喜欢作为内存中的postgres作为内存中缓存的情况vs redis。</p><p> Christian     Again, they do not make note of any concerning bug with actual usage of AOF but rather a specific command not seen anywhere in production or reported usage?</p><p> 基督徒再次，他们没有注意到任何关于AOF的实际使用情况的错误，而是在生产或报告的使用中没有看到的特定命令？</p><p> Marco Ceppi     This simply isn&#39;t true. Redid can flush memory to disk and boot with that disk image. We use Redis and psql for persistent data stores without much issue. Writing to disk is an async process and typically doesn&#39;t disrupt performance unless it&#39;s a very large data set.</p><p> Marco Ceppi这简直就是＆＃39; t真实。 RedID可以将内存刷新到磁盘并使用该磁盘映像启动。我们在没有太多问题的情况下使用redis和psql进行持久数据存储。写入磁盘是异步过程，通常不会破坏性能，除非它和＃39; s非常大的数据集。 </p><p>  Kyle Harrison     lol, sadly no. Wouldn&#39;t that be hilarious though? We&#39;ve exchanged tweets though! Super chill guy</p><p>凯尔哈里森哈哈，可悲的是。虽然是热闹的事情吗？我们＆＃39;虽然交换了推文！超级寒冷的家伙</p><p> Aaron     Are the two databases both filled to the same size? There might be a scale difference if Postgres is looking through logs more data. And also the indexing that is done. Straight speed has tons of context.</p><p> 亚伦是两个数据库，填充到相同的大小？如果Postgres通过日志查看更多数据，则可能存在比例差异。还有所做的索引。直速有大量的上下文。</p><p> Peter Bengtsson     No, they were not. PG had about 3GB worth of data. The Redis was only a couple of hundred megabytes.  Lookup by primary key is always indexed.</p><p> Peter Bengtsson不，他们不是。 PG有大约3GB的数据。 redis只有几百兆字节。主键查找始终索引。</p><p>   Ozz Nixon     Ridiculous Comparison!  REDIS is RAM based... PG or most every other SQL server is DISK based.</p><p>   OZZ尼克松荒谬的比较！ Redis是基于RAM ... PG或大多数其他SQL Server是基于磁盘的。</p><p> Peter Bengtsson     Not really. Redis is disk persistent too. Nothing is lost of your turn it off and restart the server.</p><p> 彼得·孟斯森不是真的。 Redis也是磁盘持久性。您将关闭并重新启动服务器的内容丢失了。</p><p> Ozz Nixon     Redis transactions are not fully ACID compliant ( Atomicity, Consistency, Isolation, and Durability). If ACID transactions are expected, Redis is not the perfect fit and should not be used. An RDBMS or another database system should be used in those scenarios. Feb 25, 2019  Just because REDIS can &#34;Flush to disk&#34; in the background - does not make it an RDBMS system. This technique is how they can say &#34;Disk persistent&#34;... but, if you add to the DB and pull the power - at the exact moment the data parser acknowledges the add - REDIS will lose the data period. This is now to say REDIS sucks, just that you are comparing a RAM DB vs a DISK DB.</p><p> OZZ nixon Redis Transactions不完全酸符（原子性，一致性，隔离和耐用性）。如果预期酸性交易，则Redis并不完美合适，不应使用。应在这些方案中使用RDBMS或其他数据库系统。 2019年2月25日，因为redis can＆＃34;刷新到磁盘＆＃34;在后台 - 不会使其成为RDBMS系统。这种技术是他们如何说出＆＃34;磁盘持久和＃34;但是，如果你添加到DB并拉动电源 - 请在数据解析器确认添加 -  redis将丢失数据期。现在是Redis Sucks，只是你比较RAM DB VS磁盘DB。</p><p> Konstantin Gredeskoul     Seems not entirely appropriate to be comparing an in-memory only database (redis) to a proper transactional database, which with the default configuration requires to fscync and actually acknowledge the data is written to disk (you can change those settings btw).  They ate both fantastic tools, but just as I wouldn’t use PostgreSQL as a cache, I probably wouldn’t use redis as a transactional RDBMS.</p><p> Konstantin Gredeskoul似乎没有完全适合将内存中的数据库（REDIS）进行比较到适当的事务数据库，其中默认配置需要FSCYNC并实际确认将数据写入磁盘（您可以更改这些设置BTW）。他们吃了两个梦幻般的工具，但就像我不使用PostgreSQL作为缓存一样，我可能不会将Redis用作事务性RDBMS。 </p><p> Peter Bengtsson     fsync is only applicable when it comes to writes.  I&#39;m not using PostgreSQL as a cache. It&#39;s being used in a pretty persistent way.</p><p>Peter Bengtsson FSYNC仅适用于写作。我没有使用PostgreSQL作为缓存。它＆＃39; s以非常持久的方式使用。</p><p> Morris de Oryx     An in-memory cache *should* be faster, and such tools absolutely have a place. A tool such as Redis can make an unusable system great, under the right conditions. It would be cool if Postgres added in-memory tables in V13 or V14.  In this case, unless the work is compounded in a loop, even the slowest times are *imperceptible* to a human being:   https://www.nngroup.com/articles/response-times-3-important-limits/  Put another way, some of your results are &#34;20x faster&#34; to a computer and imperceptibly different to a person.</p><p> Morris de Oryx内存中缓存*应该更快，而且这些工具绝对有一个地方。 Redis等工具可以在正确的条件下制作不可用的系统。如果Postgres在V13或V14中添加的存储表中添加了存储器，则会很酷。在这种情况下，除非作品在循环中复合，否则即使是最慢的时间是*难以察觉的*，方式，你的一些结果是＆＃34; 20x更快＆＃34;到计算机，不知不觉地不同于一个人。</p><p> Peter Bengtsson     The numbers add up and it&#39;s nice to eliminate slow things that add up when the application actually does a little bit more that just that one call.</p><p> Peter Bengtsson数字加起来，它很高兴消除应用程序实际上更多的时候加起来的慢的东西，只要一个电话。</p><p> Denique De Nique     The problem with your response is that human perception isn&#39;t the only factor. Another thing to consider is the cost at scale of grinding away for an extra 10x or 20x the time. A lot of infrastructure, particularly cloud infrastructure, is sensitive to this. So you can save a considerable amount of money by saving 20x the computation even if it isn&#39;t always happening in a loop.</p><p> Denique de Nique你的反应问题是人类感知是唯一的因素。另一件需要考虑的是磨削额外10倍或20倍的成本。很多基础设施，特别是云基础设施，对此很敏感。所以即使它是NOSN＆＃39，你也可以通过节省20x计算来节省大量资金。</p><p> Konstantin Gredeskoul     You can always add an in-memory file system and mount some postgresql tables on that partition if you wanted to test in memory speed of postgresql.  Or you could enable delayed_commit, and batch many transactions into a single fsync every 10 seconds.  Then the numbers will be closer to Redis.</p><p> Konstantin Gredeskoul您可以随时添加内存内文件系统，并在该分区上安装一些PostgreSQL表，如果您想测试PostgreSQL的内存速度。或者您可以启用Delayed_commit，每10秒批量批量为单个FSYNC。然后数字将更靠近redis。</p><p> Konstantin Gredeskoul     One additional point about relying on Redis for high performance writes: while postgresql supports concurrent writes via many simultaneous connections and resolves any conflicts that may arise, Redis is single-threaded and can only process a single command per server instance at a time. Therefore redis will peak at some high number of OPS and then fall over, blocking all operations.</p><p> Konstantin Gredeskoul关于依赖Redis的额外点，用于通过许多同步连接支持并发写作并解决可能出现的任何冲突，而Redis是单线程，只能一次处理每个服务器实例的单个命令。因此，REDIS将在一些大量的OPS上达到峰值，然后掉线，阻止所有操作。</p><p> Peter Bengtsson     Excellent point. That&#39;s the kinda of thoughts that are important. Both databases can do the job. They have their different pros and cons. This particular blog post focussed a lot on just one of those: speed.</p><p> 彼得腾科逊的优秀点。那些重要的思想和＃39;两个数据库都可以完成这项工作。他们有不同的利弊。这个特殊的博客文章仅仅在其中一个人聚焦了很多：速度。 </p><p> Joseph Locke     I feel like finishing a write before piping off a response to the user is an unfortunate way of handling things.</p><p>Joseph Locke我觉得在管道向用户响应之前完成写作是一种不幸的方式处理事情。</p><p> Matteo Pasquini     Ok, djago+whathever db just works. Postresql is behind db,(ok, I&#39;m a fan!!) there are features that django simply cannot manage. Seeking for performances in postresql I&#39;d use triggered partitioning, triggered retention policies and fine indexing with index space on dedicated ssd ... Well dba stuffs :) About consistency, streaming replica, django that exploit switch on r/wand switchover failure. About &#39;in memory tables&#39; PG has, as many others, prepared transactions, I&#39;ve found great benefits with tables over 1Tb (Pg 9.3, not partitioned) ...can Redis do that..? Gess it need Tbs of Ram.. Cheers.</p><p> Matteo pasquini好的，djago +是什么db工作。 postresql是db的背后，（好的，我＆＃39; m一个粉丝!!）有一个功能Django根本无法管理。寻求PostresQL I＆＃39中的表演。关于＆＃39;在记忆表＆＃39中; PG有，以及其他其他人，准备的交易，我＆＃39;在1TB上的表格找到了很大的好处（PG 9.3，没有分区）......可以redis做到这一点..？它需要TB的RAM ..欢呼声。</p><p>  Peter Bengtsson     The cryptic thing is that there actually isn&#39;t JSON on the Redis side. It&#39;s a dict. And my Redis serializer, in the Redis driver, is msgpack.</p><p>  Peter Bengtsson神秘的事情是，实际上是RediS侧的＆＃39; T JSON。它＆＃39;是的一个问题。和我的Redis Serializer，在Redis驱动程序中是msgpack。</p><p> Anonymous     Dude, you should ask antirez, the creator of redis. Let me explain: when redis persistence is like postgresql, it has same speed or slower (writing).  http://oldblog.antirez.com/post/redis-persistence-demystified.html</p><p> 匿名家伙，你应该向Redis的创造者询问Antirez。让我解释：当Redis持久性就像PostgreSQL时，它具有相同的速度或更慢（写作）。 http://oldblog.antirez.com/post/redis-persistence-demystified.html.</p><p> Anonymous     Typo: &#34;tl;dr; Redis is 16 times faster and reading these JSON blobs.*&#34; -&gt; &#34;tl;dr; Redis is 16 times faster at reading these JSON blobs.*&#34;</p><p> 匿名错字：＆＃34; tl;博士; Redis是速度快16倍并阅读这些json blobs。*＆＃34; - ＆gt; ＆＃34; tl;博士;阅读这些json blobs的速度速度快16倍。*＆＃34;</p><p>  anon     I&#39;d be interested if you could try sqlite3 which gets rid of all the interprocess traffic since it is loaded into the python process.</p><p>  如果您可以尝试SQLite3，则对此感兴趣，因为它可以摆脱所有进程流量，因为它被加载到Python进程中。</p><p> Peter Bengtsson     Oh yes that would be neat. But does that mean that if you use sqlite3 that its entire memory is loaded into each uwsgi Python process (aka. worker)?</p><p> Peter Bengtsson哦，是的，这将是整洁的。但这是否意味着如果您使用SQLite3，其整个内存将加载到每个UWSGI Python进程（AKA。工作人员）？ </p><p> Anonymous     This seems like an apples and oranges comparison. You&#39;re using the JSONB type in postgres, which allows you to index and query specific fields in the blob, and your testing doesn&#39;t seem to be doing that at all. A fairer comparison would be to use postgres&#39; text type, or a separate comparison that does query for specific fields with both.</p><p>匿名这似乎是苹果和橘子比较。您＆＃39;重新使用Postgres中的JSONB类型，允许您在BLOB中索引和查询特定字段，您的测试似乎正在这样做。更公平的比较是使用Postgres＆＃39;文本类型，或单独的比较，用于使用两者查询特定字段。</p><p> Peter Bengtsson     Yes, it is apples and oranges but they are both things you can use for a juicy and healthy snack. You don&#39;t have to turn the apple into an orange (or the other way around) but it&#39;s about understanding the pros and cons of the apples and the pros and cons of the oranges. Then, equipped with that you can make informed decisions.</p><p> Peter Bengtsson是的，它是苹果和橘子，但它们都是你可以用来用于多汁和健康的零食。你不必把苹果变成橙色（或其他方式），而是关于了解苹果的利弊和橘子的利弊。然后，配备了您可以做出明智的决策。</p><p>  Anonymous     One other thing to keep in mind is that in most configurations I have seen the connection to postgres is encrypted, while the ones to Redis arn&#39;t. while most of the difference here is likely due to RAM vs DISK read/writes. some maybe due to the overhead of TLS connections.</p><p>  匿名识别的是要记住的，在大多数配置中，我已经看到与postgres的连接是加密的，而那些对Redis Arn＆＃39; t。虽然以下大多数差异可能是由于RAM VS磁盘读/写入。有些可能是由于TLS连接的开销。</p><p> tyler neely     This article is missing a ton of crucial details for a real storage decision. Redis has a particularly wasteful storage approach because it rewrites everything periodically. Postgres and many other systems are able to avoid moving old data as frequently.  What about persistence guarantees? What about replication requirements? What about backup effort? The list goes on and on. &#34;Faster&#34; means different things when you&#39;re talking about workloads that require low latency vs workloads that require high throughput.  A network-attached kv skips a lot of the work that an actual database performs. Maybe that&#39;s work that you really don&#39;t need, but maybe you&#39;ll learn after an outage that you wish you had it.  There is no </p><p> 泰勒Neely本文缺少真实储存决策的一大约一个重要的细节。 Redis具有特别浪费的存储方法，因为它定期重写所有内容。 Postgres和许多其他系统能够避免经常移动旧数据。持久性担保怎么样？复制要求怎么样？备份努力怎么样？列表继续和打开。 ＆＃34;更快＆＃34;意味着当您谈论需要低延迟的工作负载与需要高吞吐量的工作负载，意味着不同的东西。连接的KV跳过了很多实际数据库执行的工作。也许那个＆＃39;你真正不需要的工作，但是也许你＆＃39; ll学习后你希望你有它。没有</p><p>......</p><p>...... </p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://www.peterbe.com/plog/redis-vs-postgres-blob-of-json">https://www.peterbe.com/plog/redis-vs-postgres-blob-of-json</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/相比/">#相比</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/redis/">#redis</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/分享/">#分享</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy;2012-2021 diglog.com </div></div></body></html>