<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Openai的最先进的机器视觉AI被手写笔记所迷惑 OpenAI's State-of-the-Art Machine Vision AI Fooled By Handwritten Notes</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">OpenAI's State-of-the-Art Machine Vision AI Fooled By Handwritten Notes<br/>Openai的最先进的机器视觉AI被手写笔记所迷惑 </h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2021-03-10 22:55:13</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2021/3/d77bb259a9a2aa0653c0aa1b20aedc3e.jpg"><img src="http://img2.diglog.com/img/2021/3/d77bb259a9a2aa0653c0aa1b20aedc3e.jpg" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>Researchers from machine learning lab OpenAI have  discovered that their state-of-the-art computer vision system can be deceived by tools no more sophisticated than a pen and a pad. As illustrated in the image above, simply writing down the name of an object and sticking it on another can be enough to trick the software into misidentifying what it sees.</p><p>机器学习实验室Openai的研究人员发现他们的最先进的计算机视觉系统可以通过比笔和垫更复杂的工具欺骗。如上面的图像中所示，只需写下对象的名称并将其粘贴在另一个物体上即可欺骗软件误认它所看到的内容。</p><p> “We refer to these attacks as  typographic  attacks,” write OpenAI’s researchers in a  blog post. “By exploiting the model’s ability to read text robustly, we find that even photographs of hand-written text can often fool the model.” They note that such attacks are similar to  “adversarial images” that can fool commercial machine vision systems, but far simpler to produce.</p><p> “我们将这些攻击称为印刷攻击，”在博客文章中写下Openai的研究人员。 “通过利用模型的读取文本的能力强大，我们发现甚至可以愚弄手写文本的照片甚至可以愚弄模型。”他们注意到，这种攻击类似于可以欺骗商业机器视觉系统的“对抗性图像”，但更简单地生产。</p><p>  Adversarial images present a real danger for systems that rely on machine vision. Researchers have shown, for example, that they can trick the software in Tesla’s self-driving cars to  change lanes without warning simply by placing certain stickers on the road. Such attacks are a serious threat for a variety of AI applications, from the medical to the military.</p><p>  对抗性图像为依赖机器视觉的系统提供了一个真正的危险。例如，研究人员已经表明，他们可以在特斯拉的自动驾驶汽车中欺骗软件，以改变车道，只需将某些贴纸放在道路上即可。这种攻击是对各种AI应用的严重威胁，来自医疗到军队。</p><p> But the danger posed by this specific attack is, at least for now, nothing to worry about. The OpenAI software in question is an experimental system named CLIP that isn’t deployed in any commercial product. Indeed, the very nature of CLIP’s unusual machine learning architecture created the weakness that enables this attack to succeed.</p><p> 但这种特定攻击所带来的危险是至少现在，没有什么可担心的。讨论的Openai软件是一个名为Clip的实验系统，该系统未在任何商业产品中部署。实际上，剪辑不寻常的机器学习架构的本质创造了使这次攻击成功的弱点。</p><p>   CLIP is intended to explore how AI systems might learn to identify objects without close supervision by training on huge databases of image and text pairs. In this case, OpenAI used some 400 million image-text pairs scraped from the internet to train CLIP, which was  unveiled in January.</p><p>   剪辑旨在探索AI系统如何通过在庞大的图像和文本对数据库上培训来识别无需密切监督的对象。在这种情况下，Openai使用了从互联网上刮掉的大约4亿的图像文本对，以培训剪辑，在1月份亮相。</p><p> This month, OpenAI researchers published a new paper describing how they’d opened up CLIP to see how it performs. They discovered what they’re calling “multimodal neurons” — individual components in the machine learning network that respond not only to images of objects but also sketches, cartoons, and associated text. One of the reasons this is exciting is that it seems to mirror how the human brain reacts to stimuli, where single brain cells have been observed  responding to abstract concepts rather than specific examples. OpenAI’s research suggests it may be possible for AI systems to internalize such knowledge the same way humans do.</p><p> 本月，Openai研究人员发表了一篇新论文，描述了他们打开的剪辑，了解它的表现。他们发现他们称之为“多模式神经元” - 机器学习网络中的各个组件不仅响应对象的图像，还响应草图，漫画和相关文本。令人兴奋的原因之一是，它似乎镜像人脑如何对刺激作出反应，其中观察到单一脑细胞的响应抽象概念而不是具体的例子。 Openai的研究表明，AI系统可能会使人类所做的方式内化这些知识。</p><p> In the future, this could lead to more sophisticated vision systems, but right now, such approaches are in their infancy. While any human being can tell you the difference between an apple and a piece of paper with the word “apple” written on it, software like CLIP can’t. The same ability that allows the program to link words and images at an abstract level creates this unique weakness, which OpenAI describes as the “fallacy of abstraction.”</p><p> 在未来，这可能导致更复杂的视觉系统，但现在，这种方法在他们的初期。虽然任何人都可以告诉你苹果和一张纸之间的区别，但用“苹果”一词写在它上，软件就像剪辑一样。相同的能力，允许程序在抽象级别链接单词和图像创造了这种独特的弱点，该oppai描述为“抽象的谬误”。 </p><p>   Another example given by the lab is the neuron in CLIP that identifies piggy banks. This component not only responds to pictures of piggy banks but strings of dollar signs, too. As in the example above, that means you can fool CLIP into identifying a chainsaw as a piggy bank if you overlay it with “$$$” strings, as if it were half-price at your local hardware store.</p><p>实验室给出的另一个例子是剪辑中的神经元，标识存钱罐。此组件不仅响应Piggy Banks的图片，而且也是美元符号的串。如上面的例子，这意味着您可以愚弄剪辑将电锯识别为存钱罐，如果您使用“$$$”字符串覆盖，仿佛它是当地五金店的半价。</p><p> The researchers also found that CLIP’s multimodal neurons encoded exactly the sort of biases you might expect to find when sourcing your data from the internet. They note that the neuron for “Middle East” is also associated with terrorism and discovered “a neuron that fires for both dark-skinned people and gorillas.” This replicates an infamous error in Google’s  image recognition system, which tagged Black people as gorillas. It’s yet another example of just how different machine intelligence is to that of humans’ — and why pulling apart the former to understand how it works is necessary before we trust our lives to AI.</p><p> 研究人员还发现，剪辑的多模式神经元编码了您可能期望在从Internet获取数据时找到的那种偏差。他们注意到“中东”的神经元也与恐怖主义有关，并发现了为深色皮肤和大猩猩发射的神经元。“这复制了谷歌的图像识别系统中的臭名昭着错误，将黑人作为大猩猩标记为大猩猩。这是一个不同的机器智能对人类的另一个例子 - 以及为什么拉开前者，了解在我们信任我们的生活之前是必要的。 </p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://www.theverge.com/2021/3/8/22319173/openai-machine-vision-adversarial-typographic-attacka-clip-multimodal-neuron">https://www.theverge.com/2021/3/8/22319173/openai-machine-vision-adversarial-typographic-attacka-clip-multimodal-neuron</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/视觉/">#视觉</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/state/">#state</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/系统/">#系统</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/谷歌/">#谷歌</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy; 2020 diglog.com </div></div></body></html>