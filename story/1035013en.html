<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>WARP：改进了Firefox 83中的JavaScript性能</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">WARP：改进了Firefox 83中的JavaScript性能</h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2020-11-14 09:01:22</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2020/11/c3aa51b392e66b73c5cc441f2f873219.png"><img src="http://img2.diglog.com/img/2020/11/c3aa51b392e66b73c5cc441f2f873219.png" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>We have enabled Warp, a significant update to  SpiderMonkey, by default in Firefox 83. SpiderMonkey is the JavaScript engine used in the Firefox web browser.</p><p>默认情况下，我们在Firefox 83中启用了Warp，这是对SpiderMonkey的一个重大更新。SpiderMonkey是Firefox Web浏览器中使用的JavaScript引擎。</p><p> With Warp (also called WarpBuilder) we’re making big changes to our  JIT (just-in-time) compilers, resulting in improved responsiveness, faster page loads and better memory usage. The new architecture is also more maintainable and unlocks additional SpiderMonkey improvements.</p><p>通过Warp(也称为WarpBuilder)，我们对JIT(Just-in-Time)编译器进行了重大改变，从而提高了响应速度，加快了页面加载速度，提高了内存使用率。新的架构也更易于维护，并开启了对SpiderMonkey的额外改进。</p><p>    The first step when running JavaScript is to parse the source code into   bytecode, a lower-level representation. Bytecode can be executed immediately using an interpreter or can be compiled to native code by a just-in-time (JIT) compiler. Modern JavaScript engines have multiple tiered execution engines.</p><p>运行JavaScript的第一步是将源代码解析为字节码，这是一种较低级别的表示。字节码可以使用解释器立即执行，也可以由实时(JIT)编译器编译成本机代码。现代的JavaScript引擎有多层执行引擎。</p><p>  Interpreters and baseline JITs have fast compilation times, perform only basic code optimizations (typically based on  Inline Caches), and collect profiling data.</p><p>解释器和基线JIT的编译速度很快，只执行基本的代码优化(通常基于内联缓存)，并收集性能分析数据。</p><p> The  Optimizing JIT performs advanced compiler optimizations but has slower compilation times and uses more memory, so is only used for functions that are warm (called many times).</p><p>优化JIT执行高级的编译器优化，但编译时间较慢且使用更多内存，因此仅用于热(多次调用)函数。</p><p> The optimizing JIT makes assumptions based on the profiling data collected by the other tiers. If these assumptions turn out to be wrong, the optimized code is discarded. When this happens the function resumes execution in the baseline tiers and has to warm-up again (this is called a  bailout).</p><p>优化JIT根据其他层收集的性能分析数据进行假设。如果这些假设被证明是错误的，那么优化后的代码将被丢弃。当发生这种情况时，该函数将在基准层中恢复执行，并且必须再次预热(这称为紧急情况)。</p><p>   Our previous optimizing JIT, Ion, used two very different systems for gathering profiling information to guide JIT optimizations. The first is Type Inference (TI), which collects global information about the types of objects used in the JS code. The second is CacheIR, a simple linear bytecode format used by the Baseline Interpreter and the Baseline JIT as the fundamental optimization primitive. Ion mostly relied on TI, but occasionally used CacheIR information when TI data was unavailable.</p><p>我们之前的JIT优化Ion使用了两个截然不同的系统来收集性能分析信息来指导JIT优化。第一种是类型推断(TI)，它收集有关JS代码中使用的对象类型的全局信息。第二种是CacheIR，这是一种简单的线性字节码格式，由基线解释器和基线JIT用作基本的优化原语。ION主要依靠TI，但在TI数据不可用时，偶尔也会使用CacheIR信息。</p><p> With Warp, we’ve changed our optimizing JIT to rely solely on CacheIR data collected by the baseline tiers. Here’s what this looks like:</p><p>使用Warp，我们已将优化JIT更改为仅依赖基线层收集的CacheIR数据。这看起来是这样的：</p><p> There’s a lot of information here, but the thing to note is that we’ve replaced the IonBuilder frontend (outlined in red) with the simpler WarpBuilder frontend (outlined in green). IonBuilder and WarpBuilder both produce Ion MIR, an  intermediate representation used by the optimizing JIT backend.</p><p>这里有很多信息，但需要注意的是，我们已经用更简单的WarpBuilder前端(用绿色标出)替换了IonBuilder前端(用红色标出)。IonBuilder和WarpBuilder都会生成Ion Mir，这是优化JIT后端使用的中间表示形式。</p><p> Where IonBuilder used TI data gathered from the whole engine to generate MIR, WarpBuilder generates MIR using the same CacheIR that the Baseline Interpreter and Baseline JIT use to generate Inline Caches (ICs). As we’ll see below, the tighter integration between Warp and the lower tiers has several advantages.</p><p>IonBuilder使用从整个引擎收集的TI数据来生成MIR，而WarpBuilder使用基线解释器和基线JIT用来生成内联缓存(IC)的相同CacheIR来生成MIR。正如我们将在下面看到的，Warp和较低层之间更紧密的集成有几个优点。</p><p>    The  Baseline Interpreter and Baseline JIT use two Inline Caches for this function: one for the property access ( o.x), and one for the subtraction. That’s because we can’t optimize this function without knowing the types of  o and  o.x.</p><p>基线解释器和基线JIT对此函数使用两个内联缓存：一个用于属性访问(o.x)，另一个用于减法。这是因为在不知道o和o.x的类型的情况下，我们无法优化该函数。</p><p> The IC for the property access,  o.x, will be invoked with the value of  o. It can then attach an IC stub (a small piece of machine code) to optimize this operation. In SpiderMonkey this works by first generating CacheIR (a simple linear bytecode format, you could think of it as an optimization recipe). For example, if  o is an object and  x is a simple data property, we generate this:</p><p>将使用o值调用属性访问IC o.x。然后，它可以附加一个IC存根(一小段机器代码)来优化此操作。在SpiderMonkey中，这是通过首先生成CacheIR(一种简单的线性字节码格式，您可以将其视为优化配方)来实现的。例如，如果o是一个对象，而x是一个简单的数据属性，我们将生成以下代码：</p><p>  Here we first guard the input ( o) is an object, then we guard on the object’s shape (which determines the object’s properties and layout), and then we load the value of  o.x from the object’s slots.</p><p>在这里，我们首先保护输入(O)是一个对象，然后保护对象的形状(它决定对象的属性和布局)，然后从对象的槽加载o.x的值。</p><p> Note that the shape and the property’s index in the slots array are stored in a separate data section, not baked into the CacheIR or IC code itself. The CacheIR refers to the offsets of these fields with  shapeOffset and  offsetOffset. This allows many different IC stubs to share the same generated code, reducing compilation overhead.</p><p>请注意，插槽数组中的形状和属性索引存储在单独的数据部分中，而不是烘焙到CacheIR或IC代码本身。CacheIR用shapeOffset和OffsetOffset表示这些字段的偏移量。这允许许多不同的IC存根共享相同的生成代码，从而减少编译开销。</p><p> The IC then compiles this CacheIR snippet to machine code. Now, the Baseline Interpreter and Baseline JIT can execute this operation quickly without calling into C++ code.</p><p>然后，IC将此CacheIR片段编译为机器码。现在，基线解释器和基线JIT可以快速执行此操作，而无需调用C++代码。</p><p> The subtraction IC works the same way. If  o.x is an int32 value, the subtraction IC will be invoked with two int32 values and the IC will generate the following CacheIR to optimize that case:</p><p>减法IC的工作原理与此相同。如果o.x是int32值，则将使用两个int32值调用减法IC，并且IC将生成以下CacheIR以优化该情况：</p><p>  This means we first guard the left-hand side is an int32 value, then we guard the right-hand side is an int32 value, and we can then perform the int32 subtraction and return the result from the IC stub to the function.</p><p>这意味着我们首先保护左侧是int32值，然后保护右侧是int32值，然后我们可以执行int32减法，并将IC存根的结果返回给函数。</p><p> The CacheIR instructions capture everything we need to do to optimize an operation. We have a few hundred CacheIR instructions, defined in  a YAML file. These are the building blocks for our JIT optimization pipeline.</p><p>CacheIR指令捕获了我们优化操作所需的所有操作。我们有几百条CacheIR指令，定义在一个YAML文件中。这些是我们的JIT优化管道的构建块。</p><p>  If a JS function gets called many times, we want to compile it with the optimizing compiler. With Warp there are three steps:</p><p>如果一个JS函数被多次调用，我们希望使用优化编译器对其进行编译。使用扭曲有三个步骤：</p><p> WarpOracle: runs on the main thread, creates a snapshot that includes the Baseline CacheIR data.</p><p>WarpOracle：在主线程上运行，创建包含基准CacheIR数据的快照。</p><p> The WarpOracle phase runs on the main thread and is very fast. The actual MIR building can be done on a background thread. This is an improvement over IonBuilder, where we had to do MIR building on the main thread because it relied on a lot of global data structures for Type Inference.</p><p>WarpOracle阶段在主线程上运行，速度非常快。实际的和平号构建可以在后台线程上完成。这是对IonBuilder的改进，在IonBuilder中，我们必须在主线程上构建MIR，因为它依赖于许多全局数据结构来进行类型推断。</p><p> WarpBuilder has a  transpiler to transpile CacheIR to MIR. This is a very mechanical process: for each CacheIR instruction, it just generates the corresponding MIR instruction(s).</p><p>WarpBuilder有一个转换器，可以将CacheIR转换为MIR。这是一个非常机械的过程：对于每条CacheIR指令，它只生成相应的MIR指令。</p><p> Putting this all together we get the following picture (click for a larger version):    We’re very excited about this design: when we make changes to the CacheIR instructions, it automatically affects all of our JIT tiers (see the blue arrows in the picture above). Warp is simply  weaving together the function’s bytecode and CacheIR instructions into a single MIR graph.</p><p>把这些放在一起，我们会得到下面的图片(点击查看更大的版本)：我们对这个设计非常兴奋：当我们更改CacheIR指令时，它会自动影响我们的所有JIT层(参见上图中的蓝色箭头)。WARP只是将函数的字节码和CacheIR指令编织到一个MIR图中。</p><p> Our old MIR builder (IonBuilder) had a lot of complicated code that we don’t need in WarpBuilder because all the JS semantics are captured by the CacheIR data we also need for ICs.</p><p>我们的旧MIR构建器(IonBuilder)有很多我们在WarpBuilder中不需要的复杂代码，因为所有的JS语义都被我们也需要用于IC的CacheIR数据捕获了。</p><p>  Optimizing JavaScript JITs are able to inline JavaScript functions into the caller. With Warp we are taking this a step further: Warp is also able to  specialize inlined functions based on the call site.</p><p>优化的JavaScript JIT能够将JavaScript函数内联到调用方。有了Warp，我们就更进一步了：Warp还能够根据调用点专门化内联函数。</p><p>   This function may be called from multiple places, each passing a different shape of object or different types for  o.x. In this case, the inline caches will have polymorphic CacheIR IC stubs, even if each of the callers only passes a single type. If we inline the function in Warp, we won’t be able to optimize it as well as we want.</p><p>此函数可以从多个位置调用，每个位置都传递不同形状的对象或o.x的不同类型。在这种情况下，内联缓存将具有多态CacheIR IC存根，即使每个调用方只传递一个类型。如果我们在Warp中内联函数，我们将不能像我们想要的那样优化它。</p><p> To solve this problem, we introduced a novel optimization called  Trial Inlining. Every function has an ICScript, which stores the CacheIR and IC data for that function. Before we Warp-compile a function, we scan the Baseline ICs in that function to search for calls to inlinable functions. For each inlinable call site, we create a new ICScript for the callee function. Whenever we call the inlining candidate, instead of using the default ICScript for the callee, we pass in the new specialized ICScript. This means that the Baseline Interpreter, Baseline JIT, and Warp will now collect and use information specialized for that call site.</p><p>为了解决这个问题，我们引入了一种名为试验内联的新优化方法。每个函数都有一个ICScript，用于存储该函数的CacheIR和IC数据。在我们对一个函数进行扭曲编译之前，我们会扫描该函数中的基线IC，以搜索对可内联函数的调用。对于每个可链接的调用点，我们为被调用者函数创建一个新的ICScript。每当我们调用内联候选对象时，我们都会传入新的专用ICScript，而不是使用被调用者的默认ICScript。这意味着Baseline解释器、Baseline JIT和Warp现在将收集和使用该调用点的专用信息。</p><p> Trial inlining is very powerful because it works  recursively. For example, consider the following JS code:</p><p>试用内联非常强大，因为它是递归工作的。例如，考虑以下JS代码：</p><p> function callWithArg(fun, x) { return fun(x);}function test(a) { var b = callWithArg(x =&gt; x + 1, a); var c = callWithArg(x =&gt; x - 1, a); return b + c;}</p><p>函数call WithArg(Fun，x){Return Fun(X)；}函数测试(A){var b=callWithArg(x=&gt；x+1，a)；var c=callWithArg(x=&gt；x-1，a)；return b+c；}。</p><p> When we perform trial inlining for the  test function, we will generate a specialized ICScript for each of the  callWithArg calls. Later on, we attempt recursive trial inlining in those caller-specialized  callWithArg functions, and we can then specialize the  fun call based on the caller. This was not possible in IonBuilder.</p><p>当我们执行测试函数的内联试验时，我们将为每个callWithArg调用生成一个专门的ICScript。稍后，我们尝试在这些调用方专用的callWithArg函数中进行递归尝试内联，然后我们可以根据调用方来专门化有趣的调用。这在IonBuilder中是不可能的。</p><p> When it’s time to Warp-compile the  test function, we have the caller-specialized CacheIR data and can generate optimal code.</p><p>当需要对测试函数进行Warp编译时，我们拥有调用者专用的CacheIR数据，可以生成最佳代码。</p><p> This means we build up the inlining graph  before functions are Warp-compiled, by (recursively) specializing Baseline IC data at call sites. Warp then just inlines based on that without needing its own inlining heuristics.</p><p>这意味着我们在对函数进行WARP编译之前，通过(递归地)专门化调用点的基准IC数据来构建内联图。然后，Warp只需在此基础上进行内联，而不需要自己的内联启发式算法。</p><p>  IonBuilder was able to inline certain built-in functions directly. This is especially useful for things like  Math.abs and  Array.prototype.push, because we can implement them with a few machine instructions and that’s a lot faster than calling the function.</p><p>IonBuilder能够直接内联某些内置函数。这对于像Math.abs和Array.Prototype.ush这样的东西特别有用，因为我们可以用几条机器指令来实现它们，而且这比调用函数要快得多。</p><p> Because Warp is driven by CacheIR, we decided to generate optimized CacheIR for calls to these functions.</p><p>因为Warp是由CacheIR驱动的，所以我们决定为调用这些函数生成优化的CacheIR。</p><p> This means these built-ins are now also properly optimized with IC stubs in our Baseline Interpreter and JIT. The new design leads us to generate the right CacheIR instructions, which then benefits not just Warp but all of our JIT tiers.</p><p>这意味着在我们的基准解释器和JIT中，这些内置的代码现在也通过IC存根进行了适当的优化。新的设计使我们能够生成正确的CacheIR指令，这不仅使Warp受益，而且使我们所有的JIT层都受益。</p><p> For example, let’s look at a  Math.pow call with two int32 arguments. We generate the following CacheIR:</p><p>例如，让我们看看一个带有两个int32参数的Math.pow调用。我们生成以下CacheIR：</p><p> LoadArgumentFixedSlot resultId 1, slotIndex 3GuardToObject inputId 1GuardSpecificFunction funId 1, expectedOffset 0, nargsAndFlagsOffset 8LoadArgumentFixedSlot resultId 2, slotIndex 1LoadArgumentFixedSlot resultId 3, slotIndex 0GuardToInt32 inputId 2GuardToInt32 inputId 3Int32PowResult lhsId 2, rhsId 3ReturnFromIC</p><p>LoadArgumentFixedSlot ResultId 1，SlotIndex 3GuardToObject inputId 1GuardSpecificFunction funId 1，ExptedOffset 0，nargsAndFlagsOffset 8LoadArgumentFixedSlot ResultId 2，slotIndex 1LoadArgumentFixedSlot ResultId 3，slotIndex 0GuardToInt32 inputId 2GuardToInt32 inputId。</p><p> First, we guard that the callee is the built-in  pow function. Then we load the two arguments and guard they are int32 values. Then we perform the  pow operation specialized for two int32 arguments and return the result of that from the IC stub.</p><p>首先，我们确保被调用方是内置的POW函数。然后我们加载这两个参数，并保护它们为int32值。然后，我们执行专用于两个int32参数的幂运算，并从IC存根返回结果。</p><p> Furthermore, the  Int32PowResult CacheIR instruction is also used to optimize the JS  exponentiation operator,  x ** y. For that operator we might generate:</p><p>此外，Int32PowResult CacheIR指令还用于优化JS求幂运算符x**y。对于该运算符，我们可能会生成：</p><p>  When we added Warp  transpiler support for  Int32PowResult, Warp was able to optimize both the exponentiation operator and  Math.pow without additional changes. This is a nice example of CacheIR providing building blocks that can be used for optimizing different operations.</p><p>当我们为Int32PowResult添加Warp转换器支持时，Warp能够在没有额外更改的情况下优化求幂运算符和Math.power。这是CacheIR提供可用于优化不同操作的构建块的一个很好的例子。</p><p>   Warp is faster than Ion on many workloads. The picture below shows a couple examples: we had a 20% improvement on Google Docs load time, and we are about 10-12% faster on the Speedometer benchmark:</p><p>在许多工作负载上，扭曲比离子更快。下面的图片显示了几个例子：我们的Google Docs加载时间提高了20%，速度计基准性能提高了大约10%-12%：</p><p> We’ve seen similar page load and responsiveness improvements on other JS-intensive websites such as Reddit and Netflix. Feedback from Nightly users has been positive as well.</p><p>我们在Reddit和Netflix等其他JS密集型网站上看到了类似的页面加载和响应能力提升。《晚间新闻》用户的反馈也是积极的。</p><p> The improvements are largely because basing Warp on CacheIR lets us remove the code throughout the engine that was required to track the global type inference data used by IonBuilder, resulting in speedups across the engine.</p><p>这些改进很大程度上是因为基于CacheIR的Warp允许我们在整个引擎中删除跟踪IonBuilder使用的全局类型推断数据所需的代码，从而提高整个引擎的速度。</p><p> The old system required all functions to track type information that was only useful in very hot functions. With Warp, the profiling information (CacheIR) used to optimize Warp is also used to speed up code running in the Baseline Interpreter and Baseline JIT.</p><p>旧系统需要所有功能来跟踪类型信息，而这些信息只在非常热门的功能中有用。有了Warp，用来优化Warp的概要信息(CacheIR)也被用来加速在基线解释器和基线JIT中运行的代码。</p><p> Warp is also able to do more work off-thread and requires fewer recompilations (the previous design often overspecialized, resulting in many bailouts).</p><p>Warp还可以在线程外执行更多工作，需要重新编译的次数更少(以前的设计通常过于专门化，导致许多紧急情况)。</p><p>  Warp is currently slower than Ion on certain synthetic JS benchmarks such as Octane and Kraken. This isn’t too surprising because Warp has to compete with almost a decade of optimization work and tuning for those benchmarks specifically.</p><p>目前，在某些合成JS基准(如辛烷和克拉肯)上，WARP比Ion慢。这并不令人惊讶，因为Warp必须与近十年的优化工作竞争，并专门针对这些基准进行调整。</p><p> We believe these benchmarks are not representative of modern JS code (see also the V8 team’s  blog post on this) and the regressions are outweighed by the large speedups and other improvements elsewhere.</p><p>我们认为这些基准测试不能代表现代JS代码(另请参阅V8团队关于此的博客文章)，其他地方的大幅加速和其他改进盖过了这些倒退。</p><p> That said, we will continue to optimize Warp the coming months and we expect to see improvements on all of these workloads going forward.</p><p>这就是说，在接下来的几个月里，我们将继续优化Warp，我们希望在未来看到所有这些工作量的改善。</p><p>  Removing the global type inference data also means we use less memory. For example the picture below shows JS code in Firefox uses 8% less memory when loading a number of websites (tp6):</p><p>删除全局类型推理数据也意味着我们使用更少的内存。例如，下图显示了Firefox中的JS代码在加载多个网站时使用的内存减少了8%(Tp6)：</p><p> We expect this number to improve the coming months as we remove the old code and are able to simplify more data structures.</p><p>我们预计，随着我们移除旧代码并能够简化更多的数据结构，这个数字在接下来的几个月里会有所改善。</p><p>  The type inference data also added a lot of overhead to garbage collection. We noticed some big improvements in our telemetry data for GC sweeping (one of the phases of our GC) when we enabled Warp by default in Firefox Nightly on September 23:</p><p>类型推断数据还为垃圾回收增加了大量开销。9月23日，当我们在Firefox Nighly中默认启用Warp时，我们注意到GC扫描(GC的一个阶段)的遥测数据有了很大的改进：</p><p>  Because WarpBuilder is a lot more mechanical than IonBuilder, we’ve found the code to be much simpler, more compact, more maintainable and less error-prone. By using CacheIR everywhere, we can add new optimizations with much less code. This makes it easier for the team to improve performance and implement new features.</p><p>因为WarpBuilder比IonBuilder机械化得多，所以我们发现代码更简单、更紧凑、更易维护，也更不容易出错。通过到处使用CacheIR，我们可以用更少的代码添加新的优化。这使得团队更容易提高性能和实现新功能。</p><p>  With Warp we have replaced the frontend (the MIR building phase) of the IonMonkey JIT. The next step is removing the old code and architecture. This will likely happen in Firefox 85. We expect additional performance and memory usage improvements from that.</p><p>我们用Warp取代了IonMonkey JIT的前端(和平号建造阶段)。下一步是删除旧的代码和架构。这很可能发生在Firefox 85中。我们预计这会带来额外的性能和内存使用改进。</p><p> We will also continue to incrementally simplify and optimize the backend of the IonMonkey JIT. We believe there’s still a lot of room for improvement for JS-intensive workloads.</p><p>我们还将继续逐步简化和优化IonMonkey JIT的后端。我们认为JS密集型工作负载还有很大的改进空间。</p><p> Finally, because all of our JITs are now based on CacheIR data, we are working on a tool to let us (and web developers) explore the CacheIR data for a JS function. We hope this will help developers understand JS performance better.</p><p>最后，因为我们所有的JIT现在都是基于CacheIR数据的，所以我们正在开发一个工具，让我们(和Web开发人员)为JS函数探索CacheIR数据。我们希望这能帮助开发者更好地理解JS的性能。</p><p>  Most of the work on Warp was done by Caroline Cullen, Iain Ireland, Jan de Mooij, and our amazing contributors André Bargull and Tom Schuster. The rest of the SpiderMonkey team provided us with a lot of feedback and ideas. Christian Holler and Gary Kwong reported various  fuzz bugs.</p><p>《变形金刚》的大部分工作是由卡罗琳·卡伦、伊恩·爱尔兰、简·德·穆伊以及我们令人惊叹的贡献者安德烈·巴尔古尔和汤姆·舒斯特完成的。SpiderMonkey团队的其他成员为我们提供了很多反馈和想法。克里斯蒂安·霍勒(Christian Holler)和加里·光(Gary Kwong</p><p> Thanks to Ted Campbell, Caroline Cullen, Steven DeTar, Matthew Gaudet, Melissa Thermidor, and especially Iain Ireland for their great feedback and suggestions for this post.</p><p>感谢Ted Campbell，Caroline Cullen，Steven DeTar，Matthew Gaudet，Melissa Thermidor，特别是Iain爱尔兰为这篇文章提供了很好的反馈和建议。</p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://hacks.mozilla.org/2020/11/warp-improved-js-performance-in-firefox-83/">https://hacks.mozilla.org/2020/11/warp-improved-js-performance-in-firefox-83/</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/性能/">#性能</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/java/">#java</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/改进/">#改进</a></button></div></div><div class="shadow p-3 mb-5 bg-white rounded clearfix"><div class="container"><div class="row"><div class="col-sm"><div><a target="_blank" href="/story/1034815.html"><img src="http://img2.diglog.com/img/2020/11/thumb_a46c9d7cbefaa795c0e1f17be6540c92.png" class="img-fluid" onerror="this.style.display='none'"></a></div><div class="item_title"><a target="_blank" href="/story/1034815.html">FAST UI Draw是一个提供更高性能画布界面的库</a></div><span class="my_story_list_date">2020-11-13 15:13</span></div><div class="col-sm"><div><a target="_blank" href="/story/1034754.html"><img src="http://img2.diglog.com/img/2020/11/thumb_8c211aac604e1466d518d906fef1d40b.png" class="img-fluid" onerror="this.style.display='none'"></a></div><div class="item_title"><a target="_blank" href="/story/1034754.html">使用Erlang/OTP 22进行性能回归</a></div><span class="my_story_list_date">2020-11-12 20:37</span></div><div class="col-sm"><div><a target="_blank" href="/story/1034750.html"><img src="http://img2.diglog.com/img/2020/11/thumb_531e6f1bdfbafd80056260882331742e.jpeg" class="img-fluid" onerror="this.style.display='none'"></a></div><div class="item_title"><a target="_blank" href="/story/1034750.html">.NET5令人惊叹的性能</a></div><span class="my_story_list_date">2020-11-12 20:15</span></div><div class="col-sm"><div><a target="_blank" href="/story/1034690.html"><img src="http://img2.diglog.com/img/2020/11/thumb_a2dbe46db44265a9c1bc5962ffccfcd7.jpg" class="img-fluid" onerror="this.style.display='none'"></a></div><div class="item_title"><a target="_blank" href="/story/1034690.html">MacBook Air中的Apple Silicon M1芯片性能优于高端16英寸MacBook Pro</a></div><span class="my_story_list_date">2020-11-12 9:11</span></div></div></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/美国/">#美国</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/谷歌/">#谷歌</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/linux/">#linux</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/程序/">#程序</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy; 2020 diglog.com </div></div></body></html>