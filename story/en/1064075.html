<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>近似距离oracles. Approximate Distance Oracles</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">Approximate Distance Oracles<br/>近似距离oracles. </h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2021-06-08 00:20:09</div><div class="page_narrow text-break page_content"><p>“One day Alice came to a fork in the road and saw a Cheshire cat in a tree.  ‘Which road do I take?’ she asked.  ‘Where do you want to go?’ was his response.  ‘I don’t know,’ Alice answered.  ‘Then,’ said the cat, ‘it doesn’t matter.”</p><p>“有一天，爱丽丝来到路上的叉子，在树上看到了柴郡猫。 “我采取哪条路？”她问道。 “你想去哪里？”是他的回应。 “我不知道，”爱丽丝回答道。 “然后，”这只猫说，'没关系。“</p><p> - Lewis Carroll, Alice in Wonderland</p><p>  -  Lewis Carroll，Alice In Wonderland</p><p>   Note: To my knowledge, this is the first non-academic description of Approximate Distance Oracles. Furthermore, this is my first time writing about Graph Theory. Therefore, if you find any mistakes,  please do let me know.</p><p>   注意：到我的知识，这是第一个近似距离畸形的非学术描述。此外，这是我第一次写下图表理论。因此，如果您发现任何错误，请告诉我。</p><p>  Let us assume that we have an undirected graph with strictly positive edge weights. Let us also assume that this graph represents the fictional city -  The Ten Blocks. Here is an aerial view of this city -</p><p>  让我们假设我们有一个具有严格正面重量的无向图。让我们也假设该图表代表虚构城市 - 十个街区。这是这个城市的鸟瞰图 - </p><p>  As  The Ten Blocks&#39; map can be cumbersome to visualize, for the rest of this blog post, we will be working with a simplified version -</p><p>  作为十个街区＆＃39;地图可能会笨重可视化，对于此博客文章的其余部分，我们将使用简化版本 - </p><p>  When we visualize this city as a graph, we notice that it has 10 vertices and 11 edges. Each vertex has a label of the form  Block N, with N being any unique integer (for the rest of this blog post,  we will abbreviate Block N as BN). The  edge weight is the distance between two blocks. For example, the weight of the edge between B1 and B2 is 10. Furthermore, the  length of a path between any two blocks is the sum of all the edge weights connecting that path. For example, the path (B1, B2, B3) has a length of 10+5=15. However, one should note that this is not the only path from B1 to B3. Another path is (B1, B2, B9, B5, B3) which has a path length of 10+50+75+10=145. Certainly a costly one!</p><p>  当我们以图形显示这个城市时，我们注意到它有10个顶点和11个边。每个顶点都有一个表单块n的标签，n个是任何唯一的整数（对于该博客文章的其余部分，我们将缩写为bn的块n）。边缘重量是两个块之间的距离。例如，B1和B2之间的边缘的权重为10.此外，任何两个块之间的路径的长度是连接该路径的所有边缘权重的总和。例如，路径（B1，B2，B3）的长度为10 + 5 = 15。但是，应该注意，这不是B1到B3的唯一路径。另一路径是（B1，B2，B9，B5，B3），其路径长度为10 + 50 + 75 + 10 = 145。当然是一个昂贵的一个！</p><p> A widely studied question about graphs is the  shortest path problem, which is: the problem of finding a path between two vertices (or nodes) in a graph such that the sum of the weights of its constituent edges is minimized.</p><p> 关于图表的广泛研究的问题是最短的路径问题，即：在图中找到两个顶点（或节点）之间的路径的问题，使得其组成边缘的权重的总和最小化。 </p><p>It can be observed visually that the shortest path between B1 and B3 is indeed (B1, B2, B3) with a path length of 10. But how do we  algorithmically find the shortest paths between two vertices? One way is by using  Dijkstra&#39;s algorithm. While a thorough analysis of Dijkstra&#39;s algorithm is beyond the scope of this blog post,  the algorithm mentioned in the Wikipedia page on Dijkstra&#39;s algorithm is an excellent start -  Let the node at which we are starting be called the  initial node. Let the  distance of node  Y be the distance from the  initial node to  Y. Dijkstra&#39;s algorithm will assign some initial distance values and will try to improve them step by step.</p><p>可以在视觉上观察到，B1和B3之间的最短路径确实是（B1，B2，B3），路径长度为10.但是我们如何在两个顶点之间进行算法找到最短路径？一种方法是使用Dijkstra＆＃39; s算法。虽然对Dijkstra＆＃39的彻底分析超出了该博客文章的范围，但在Dijkstra＆＃39; S算法上的维基百科页面中提到的算法是一个很好的开始 - 让我们开始的节点被称为初始节点。让节点y的距离是从初始节点到y. dijkstra＆＃39; s算法将分配一些初始距离值，并将尝试一步一步地改进它们。</p><p>  Mark all nodes unvisited. Create a set of all the unvisited nodes called the  unvisited set.</p><p>  标记所有节点未经许可。创建一组名为“不受检控”集的所有未检测的节点。</p><p>  Assign to every node a tentative distance value: set it to zero for our initial node and to infinity for all other nodes. Set the initial node as current.</p><p>  分配给每个节点暂定距离值：为我们的初始节点设置为零，并为所有其他节点的无穷大。将初始节点设置为当前。</p><p>  For the current node, consider all of its unvisited neighbours and calculate their  tentative distances through the current node. Compare the newly calculated  tentative distance to the current assigned value and assign the smaller one. For example, if the current node  A is marked with a distance of 6, and the edge connecting it with a neighbour  B has length 2, then the distance to  B through  A will be 6 + 2 = 8. If B was previously marked with a distance greater than 8 then change it to 8. Otherwise, the current value will be kept.</p><p>  对于当前节点，请考虑所有未让邻居并通过当前节点计算其暂定距离。将新计算的暂定距离与当前分配的值进行比较并分配较小的距离。例如，如果当前节点A用距离标记为6，并且将其与邻居B连接的边缘具有长度2，则到B到B到B的距离将为6 + 2 = 8.如果B先前标有6 + 2 = 8.然后距离大于8，然后将其更改为8.否则，将保持当前值。</p><p>  When we are done considering all of the unvisited neighbours of the current node, mark the current node as visited and remove it from the  unvisited set. A visited node will never be checked again.</p><p>  当我们完成考虑当前节点的所有未检测的邻居时，将当前节点标记访问并从未检测到的集合中删除它。访问过的节点将再次再次检查。</p><p>  If the destination node has been marked visited (when planning a route between two specific nodes) or if the smallest tentative distance among the nodes in the  unvisited set is infinity (when planning a complete traversal; occurs when there is no connection between the initial node and remaining unvisited nodes), then stop. The algorithm has finished.</p><p>  如果已被标记为访问的目标节点（在规划两个特定节点之间的路由）或者在未检测到的集合中的节点之间的最小暂定距离时（在规划完整的遍历时;在初始节点之间没有连接时发生并剩下不受检测的节点），然后停止。该算法已完成。</p><p>  Otherwise, select the unvisited node that is marked with the smallest tentative distance, set it as the new &#34;current node&#34;, and go back to step 3.</p><p>  否则，选择具有最小暂定距离的未检测的节点，将其设置为新＆＃34;当前节点＆＃34;，然后返回步骤3。 </p><p>  When planning a route, it is actually not necessary to wait until the destination node is &#34;visited&#34; as above: the algorithm can stop once the destination node has the smallest tentative distance among all &#34;unvisited&#34; nodes (and thus could be selected as the next &#34;current&#34;).</p><p>规划路线时，实际上没有必要等到目标节点是＆＃34;访问＆＃34;如上所述：算法一旦目的节点在所有＆＃34之间具有最小的暂定距离，就可以停止;未公开＆＃34;节点（因此可以选择为下一个＆＃34;当前＆＃34;）。</p><p> To visualize the above Dijkstra&#39;s algorithm in practice, here is an example that uses  The Ten Blocks graph -   In a  previous blog post, I described how a variant of Dijkstra&#39;s algorithm called Best-First search (which uses a  heuristic function) can be used for pseudocode-to-code generation. So, it suffices to say that Dijkstra&#39;s algorithm is not the only algorithm to solve the shortest path problem. A curious reader can read about similar algorithms such as the  Bellman-Ford algorithm.</p><p> 为了在实践中可视化上述Dijkstra＆＃39; S算法，这里是一个使用十个块图的示例 - 在先前的博客文章中，我描述了Dijkstra的变种是如何称为最佳首次搜索的算法（使用它启发式功能）可用于伪代码到代码生成。因此，可以说dijkstra＆＃39; s算法不是唯一解决最短路径问题的唯一算法。一个好奇的读者可以读取关于类似算法，例如Bellman-Ford算法。</p><p> The working we described above is part of the  single- pair shortest path problem. This is because, we were primarily interested in the shortest path between one  pair (which in the above example was (B1, B5)). However, Dijkstra&#39;s algorithm can be used for a more general class of problems called  single- source shortest path problems. This variant can be defined as:  A problem in which we have to find shortest paths from a source vertex v to all other vertices in the graph.</p><p> 我们上面描述的工作是单对最短路径问题的一部分。这是因为，我们主要对一对之间的最短路径感兴趣（在上面的例子中是（B1，B5））的最短路径。然而，Dijkstra＆＃39; S算法可用于更常见的问题，称为单源最短路径问题。该变体可以定义为：我们必须从源顶点V到图表中的所有其他顶点找到最短路径的问题。</p><p>Let us assume that in  Figure 3, there was no endpoint. Instead, we want to find the shortest path from B1 to all the other 9 points. In this scenario, as per Dijkstra&#39;s algorithm mentioned above, we stop when we have visited (exactly once) every node in the graph (starting with B1). Here is a step-by-step process of the same -</p><p>让我们假设在图3中，没有端点。相反，我们希望找到B1到所有其他9个点的最短路径。在这种情况下，根据上面提到的算法，当我们访问（完全一度）图中的每个节点时，我们停止（以b1开始）停止。这是一个逐步的过程 - </p><p> Assuming  n is the number of vertices in the graph, Dijkstra&#39;s algorithm requires no more than (n-1) steps, with each step requiring no more than (n-1) comparisons to check if the vertex is not visited before, and no more than (n-1) comparisons to update the labels at each step. All in all, it uses O(n 2) operations for additions and comparisons for the single-source shortest path problem.</p><p> 假设n是图中的顶点的数量，dijkstra＆＃39; s算法不超过（n-1）步骤，每个步骤都需要不超过（n-1）比较来检查是否未访问顶点。 ，并且不超过（n-1）比较在每个步骤中更新标签。总而言之，它使用O（n 2）操作来添加和比较单源最短路径问题。</p><p>  A natural succession to the single-source shortest path problem is the  all-pairs shortest path problem (APSP), which is defined as:  A problem in which we have to find the shortest paths between  every pair of vertices v, v&#39; in the graph.</p><p>  单源最短路径问题的自然继承是全对最短路径问题（APSP），其定义为：我们必须在每对顶点V，V＆＃39之间找到最短路径的问题;在图表中。</p><p>Keeping our previous assumptions valid (the graph is undirected and has positive edge weights), the easiest solution to the above problem would be to run Dijkstra&#39;s algorithm on every vertex in the graph. In doing so, we will obtain the following matrix: As can be observed in Figure 5, the data structure produced is of size O(n 2), an n x n matrix holding the distances. Once this matrix is generated, any future query for the shortest path between two vertices requires O(1) - constant time. However, as we observed, producing such a matrix can take O(n 3) time (breakdown - O(n 2) for the single-source shortest path, which is repeated for n vertices)). Another method to solve the all-pairs shortest-path problem is the  Floyd-Warshall algorithm. The algorithm is as follows:</p><p>保持我们以前的假设有效（图形是无向并具有正的边缘权重），最简单的解决方案是上述问题的方法是在图中的每个顶点上运行Dijkstra＆＃39; s算法。在这样做时，我们将获得以下矩阵：如图5所示，所产生的数据结构是尺寸O（n 2），其保持距离的n x n矩阵。一旦生成此矩阵，两个顶点之间的最短路径的任何未来查询都需要O（1） - 恒定的时间。然而，正如我们所观察到的那样，产生这样的矩阵可以采用O（n 3）时间（用于单源最短路径的单源最短路径的击穿-O（n 2），这被重复为n顶点）。解决全对最短路径问题的另一种方法是弗洛伊德战争算法。该算法如下： </p><p> Wikipedia contains a  step-by-step example of the above algorithm. As can be observed, this algorithm has a time complexity of O(n 3). At this point, a curious reader might be wondering - are the runtime between Floyd-Warshall and Dijkstra-based APSP the same? Here is what  Prof. Steven Skiena had to say in The Algorithm Design Manual (second edition, chapter 6.3 - Shortest Paths):  The Floyd-Warshall all-pairs shortest path runs in O(n 3) time, which is asymptotically no better than n calls to Dijkstra’s algorithm. However, the loops are so tight and the program so short that it runs better in practice. It is notable as one of the rare graph algorithms that work better on adjacency matrices than adjacency lists.</p><p>维基百科包含上述算法的逐步示例。可以观察到，该算法具有O（n 3）的时间复杂度。此时，一个好奇的读者可能会想知道 - 弗洛伊德 - 战争和基于Dijkstra的APSP之间的运行时间相同吗？这是史蒂文斯皮恩的教授在算法设计手册中说（第二版，第6.3章 - 最短路径）：弗洛伊德 - 战争全对最短路径在O（n 3）时间内运行，这渐近地没有比n调用Dijkstra的算法。但是，循环是如此紧张，程序如此之短，即在实践中运行更好。它是值得注意的，作为比邻接列表更好地在邻接矩阵上工作的稀有图算法之一。</p><p>A relevant discussion regarding the above statement is found on StackOverflow -  Time complexity of Floyd Warshall algorithm. A summary of the top answer from  James Lawson is as follows:  The key words here are &#34;in practice&#34;. Remember, asymptotic analysis isn&#39;t perfect. It&#39;s a mathematical abstraction/approximation for performance. When we actually come to run the code, there are many practical factors that it did not take into account. The processor has a complex low-level architecture for fetching and running instructions. .....    It turns out that processors love optimizing nested for loops and multi-dimensional arrays! This is what Skiena is alluding to here. The for loops the array makes the best use of  temporal and spatial locality and works well with low-level processor optimizations. Dijkstra&#39;s algorithm on the other hand doesn&#39;t do this as well and so the processor optimizations don&#39;t work as well. As a result, Dijkstra could indeed be slower in practice.</p><p>关于上述声明的相关讨论是关于弗洛伊德战争算法的堆叠流程时间复杂性。詹姆斯·劳森的最高答案的摘要如下：这里的关键词是＆＃34;在实践中，＆＃34;请记住，渐近分析ISN＆＃39; t完美。它＆＃39;绩效的数学抽象/近似。当我们实际来运行代码时，有许多实际因素它没有考虑到。处理器具有复杂的低级架构，用于获取和运行指令。 .....事实证明，处理器喜欢优化嵌套循环和多维阵列！这是Skiena在这里暗示的。阵列的循环最佳使用时间和空间位置，并适用于低级处理器优化。另一方面，Dijkstra＆＃39; S也是如此，所以处理器优化Don＆＃39; T工作。因此，Dijkstra确实在实践中可能会慢。</p><p> Interesting Story: The history behind the Floyd-Warshall algorithm is as fascinating as the algorithm itself. From Algorithms by Jeff Erickson (chapter 9):  A different formulation of shortest paths that removes this logarithmic factor was proposed twice in 1962, first by Robert Floyd and later independently by Peter Ingerman, both slightly generalizing an algorithm of Stephen Warshall published earlier in the same year. In fact, Warshall’s algorithm was previously discovered by Bernard Roy in 1959, and the underlying recursion pattern was used by Stephen Kleene in 1951. Warshall’s (and Roy’s and Kleene’s) insight was to use a different third parameter in the dynamic programming recurrence.</p><p> 有趣的故事：Floyd-Warshall算法背后的历史与算法本身一样令人着迷。从Jeff Erickson的算法（第9章）：在1962年提出了两次去除这种对数因子的最短路径的不同配方，首先由Robert Floyd和以后独立地由Peter Ingerman独立，略微概括了斯蒂芬马什尔之前发表的斯蒂芬战争算法同年。事实上，Warshall的算法于1959年由Bernard Roy发现，1951年，斯蒂芬克莱琳使用了潜在的递归模式。Warshall（和Roy's和Kleene）的洞察力是在动态编程复发中使用不同的第三个参数。</p><p>Kleene&#39;s algorithm (published in 1956) was used for  converting a deterministic finite automaton into a regular expression. Interestingly, this paper showed that the patterns which are recognizable by the neural nets are precisely the regular expressions. Furthermore, Warshall&#39;s variant was used to efficiently compute the  transitive closures of a relation.</p><p>Kleene＆＃39; S算法（1956年发布）用于将确定性有限自动机转换为正则表达式。有趣的是，本文旨在通过神经网络识别的模式正是正则表达式。此外，Warshall＆＃39; S变型用于有效地计算关系的传递闭合。</p><p> Moreover, Prof. Nodari Sitchinava mentioned  the following fascinating use-cases of the APSP problem:  Unweighted shortest paths are also used in social network analysis to compute the  betweenness centrality of actors. (Weights are usually tie strength rather than cost in SNA.) The more shortest paths between other actors that an actor appears on, the higher the betweenness centrality. This is usually normalized by the number of paths possible. This measure is one estimate of an actor&#39;s potential control of or influence over ties or communication between other actors.</p><p> 此外，Nodari Sitchinava教授提到了APSP问题的以下迷人用例：未加权的最短路径也用于社交网络分析，以计算演员之间的中心中心。 （重量通常是绑定力量而不是SNA中的成本。）演员出现的其他演员之间的最短路径越多，所以中心性越高。这通常由可能的路径数标准化。这项措施是演员的一个估计和在其他演员之间的潜在控制或影响其他演员之间的潜在控制或影响。</p><p>A natural question to ask at this point would be -  how efficient are the above APSP algorithms for any real-world application? Prof. Surender Baswana  in his Randomized Algorithms class mentioned the following regarding the classical APSP algorithms:  Current-state-of-the-art RAM size: 8 GBs   Can&#39;t handle graphs with even 10 5 vertices (with RAM size)</p><p>此时提出的自然问题是 - 以上任何现实世界应用程序的上述APSP算法有多少？ Surender Baswana教授在他的随机算法中提到了关于经典APSP算法的以下内容：当前最先进的RAM大小：8 GBS可以＆＃39; T处理甚至10 5个顶点的图表（带RAM尺寸）</p><p>Do note that according to Google, these lecture slides are from February 2014. Nevertheless, it is surprising to observe such a huge limitation. Mikkel Thorup and Uri Zwick had the following to say in their  Approximate Distance Oracles paper: There are, however, several serious objections to  this. First, a preprocessing time of \(\widetilde{O}(mn)\) may be too long. Second, even if we are willing to wait that long, the \( n \times n \) matrix produced may be too large to store efficiently (typically \( m \ll n^2 \), and then this table is much larger than the network itself).</p><p>请注意，根据谷歌，这些讲座幻灯片是2014年2月。然而，观察如此巨大的限制令人惊讶。 Mikkel Thorup和Urizwick在他们的近似距离令人垂涎欲滴的论文中进行了以下意见：然而，有几个严重的反对意见。首先，\（\ widetilde {o}（mn）\）的预处理时间可能太长。其次，即使我们愿意等待那么长，所产生的\（n \ times n \）矩阵可能太大而无法有效地存储（通常是\（m \ ll n ^ 2 \），然后这个表比较大得多比网络本身）。 </p><p>In the above statement,  this refers to the classical APSP algorithms. Moreover, consistent with the terminology formulated above, n refers to the number of vertices. Furthermore, above, and for the rest of this blog post,  m refers to the number of edges in the graph. The symbol \( \widetilde{O} \) refers to a  variant of the big-O that “ignores” logarithmic factors.</p><p>在上述声明中，这是指经典的APSP算法。此外，与上面配制的术语一致，n是指顶点的数量。此外，上面以及该博客文章的其余部分，M是指图中的边缘的数量。符号\（\ widetilde {o}）指的是“忽略”对数因子的大o的变体。</p><p> The argument Thorup and Zwick provided was the following:  We are given a description of a large network, such as the Internet, or a large road network, such as the US road network. .....   We are not really interested in all distances, we just want the ability to retrieve them quickly, if needed. For example, there are probably many pairs of addresses in the US whose distance is of interest to no one. .....   We show that better solutions exist, if the network is undirected, and if we are willing to settle for approximate distances, instead of exact ones.</p><p> 提供的参数和Zwick提供了以下内容：我们对大型网络进行了描述，例如互联网或大型道路网络，例如美国道路网络。 .....我们对所有距离并不真正感兴趣，我们只需要能够快速检索它们，如果需要。例如，美国可能在美国的距离对没有人感兴趣的许多地址。 .....我们表明如果网络无向，并且如果我们愿意满足于近似距离，而不是确切的，则存在更好的解决方案。</p><p>  With this argument, we turn our attention towards a different class of problems called  all-pairs  approximate shortest path problems. As suggested above, these solutions give an approximation of the shortest path between any pair of vertices. One of the inspirations behind this solution is real-life air/road travel (mentioned in  Prof. Baswana&#39;s slides):  In the above figure, imagine that there are many operational flight paths in India, some of which are - Kanpur-Lucknow, Kanpur-Delhi, and Delhi-Bangalore. Reaching from Kanpur to Lucknow is straightforward, we take a direct flight. However, what if we want to reach from Kanpur to Bangalore? In this case, we first find out the  nearest city from Kanpur with a flight to Bangalore. Let us assume that this city is Delhi. Therefore, instead of creating a shorter route to Bangalore (which comes with its operational expenses), we are traveling to Bangalore via Delhi. As we are selecting the  nearest city (Delhi) with a flight to Bangalore, we are ensuring that the distance will be closest to the shortest path (which in theory is a direct flight to Bangalore) among all the operational paths.</p><p>  通过这个论点，我们将注意力转向不同类别的问题，称为全对近似最短路径问题。如上所述，这些解决方案提供了任何一对顶点之间的最短路径的近似值。这种解决方案背后的一个灵感是现实生活空中/道路旅行（在Baswana＆＃39教授中提到）：在上面的图中，想象着印度有许多操作飞行路径，其中一些是 - 坎普尔-lucknow，坎普尔 - 德里和德里班加罗尔。从坎普尔到勒克瑙到达的是直截了当的，我们直接飞行。但是，如果我们想从坎普尔到班加罗尔到达什么？在这种情况下，我们首先找出来自坎普尔的最近城市，飞往班加罗尔的航班。让我们假设这个城市是德里。因此，而不是创建距离班加罗尔的较短路线（伴随着其运营费用），而是通过德里前往班加罗尔旅行。正如我们选择最近的城市（德里）到班加罗尔的飞行，我们确保距离最近的路径最近（理论上是直接飞往班加罗尔）的所有操作路径。</p><p> To understand this even better, visualize this problem from the perspective of  triangle inequality:  As evident from the above figure, if x gets smaller (which in our example is the distance between Kanpur and the nearest city which connects to Bangalore), the overall distance via this nearest city to the destination will get closer to the shortest path (Kanpur to Bangalore). If one closely observes this example, a neat idea presents itself:  From each vertex, if we store distance information to a small number of vertices, can we still be able to report distance between any pair of vertices?</p><p> 要了解这一点更好，从三角不等式的角度来看待这个问题：从上面的图中明显，如果x变小（在我们的例子中是Kanpur之间的距离和连接到班加罗尔的城市），总距离通过这座最近的城市到目的地将更接近最短的路径（Kanpur到班加罗尔）。如果一个人密切观察这个例子，一个整洁的想法会呈现自己：从每个顶点，如果我们将距离信息存储到少量顶点，我们仍然可以在任何一对顶点之间报告距离吗？</p><p>The above example showed that having distance information on nearby vertices which in turn have distance information of many other vertices is certainly a useful feature. The above blockquote is from Chapter 39 (Randomized Graph Data-Structures for Approximate Shortest Paths) in  Handbook of Data Structures and Applications, 2nd Edition.</p><p>上述示例显示，在附近的顶点上具有距离信息，其又具​​有许多其他顶点的距离信息肯定是一个有用的特征。上述BlockQuote来自第39章（用于近似最短路径的随机图表数据结构），在数据结构和应用程序的手册中，第2版。</p><p> So what did Thorup and Zwick show in their paper on Approximate Distance Oracles? And why is it important? From the same chapter:  Among all the data-structures and algorithms designed for computing all-pairs approximate shortest paths, the approximate distance oracles are unique in the sense that they achieves simultaneous improvement in running time (sub-cubic) as well as space (sub-quadratic), and still answers any approximate distance query in constant time. For any \(k \ge 1\), it takes \(O(kmn^{1/k})\) time to compute (2k − 1)-approximate distance oracle of size \(O(kn^{1+1/k})\) that would answer any (2k − 1)-approximate distance query in O(k) time.</p><p> 那么Thorup和ZWICK在近似距离Oracles上展示了什么？为什么重要？来自同一章节：在设计用于计算全对近似最短路径的所有数据结构和算法中，近似距离oracles在它们的情况下实现了运行时间（子立方）的同时改进以及空间（子二次），仍然在恒定时间内回答任何近似距离查询。对于任何\（k \ ge 1 \），它需要\（o（kmn ^ {1 / k}）\）时间来计算（2k  -  1） - 大小\（O（kn ^ {1+ 1 / k}）\）将在O（k）时间内回答任何（2k-1）的距离查询。</p><p>  To begin, why does the name contain the word  oracle? The literal definition of oracle is &#34;a place at which divine advice or prophecy was sought.&#34; From the original paper&#39;s abstract:  The most impressive feature of our data structure is its constant query time, hence the name “oracle”.</p><p>  首先，为什么这个名称包含Oracle这个词？ Oracle的文字定义是＆＃34;寻求神圣建议或预言的地方。＆＃34;从原始纸张＆＃39; s摘要：我们的数据结构最令人印象深刻的功能是它的常量查询时间，因此名称“Oracle”。 </p><p>Let us start by intuitively understanding the algorithms of a much simpler version known as the  3-approximate distance oracles. Any approximate distance oracle requires two algorithms - a preprocessing/construction algorithm and a distance query algorithm. The preprocessing algorithm constructs the foundation upon which the distance queries can be answered within a constant time. This is similar to the formulation of the matrix in the Floyd-Warshall algorithm. Assume that the  set of vertices we have is labeled as V. For example, in the Ten Blocks city, V = {B1, B2, B3, ..... , B10}. While researching on this topic, the most intuitive preprocessing algorithm I found was that described by  Prof. Baswana and Prof. Sen (chapter 39): Let \(R \subset V\) be a subset of vertices formed by picking each vertex randomly independently with probability \( \gamma \) (the value of \( \gamma \) will be fixed later on).</p><p>通过直观地理解称为3近似距离oracles的更简单版本的算法，让我们开始。任何近似距离Oracle都需要两种算法 - 一种预处理/构建算法和距离查询算法。预处理算法构造在恒定时间内可以在其上应答距离查询的基础。这类似于Floyd-Warshall算法中矩阵的制定。假设我们已有的一组顶点被标记为V.例如，在十个街区城市中，V = {B1，B2，B3，.....，B10}。在研究此主题的同时，找到的最直观的预处理算法是由Baswana和Sen教授所描述的（第39章）：让\（r \ subset v \）是通过随机独立挑选每个顶点来形成的顶点的子集概率\（\ gamma \）（\（\ gamma \）的值将稍后修复）。</p><p>  For each vertex \( u \in V \), store the distances to all the vertices of the sample set R.</p><p>  对于每个顶点\（v \），将距离存储到样本集R的所有顶点。</p><p>  For each vertex \( u \in V \), let \( p(u) \) be the vertex nearest to \( u \) among all the sampled vertices, and let \( S_{u} \) be the set of all thevertices of the graph G that lie closer to u than the vertex \( p(u) \). Store the vertices of set \( S_{u} \) along with their distance from \( u \).</p><p>  对于每个Vertex \（v \），让\（p（u）\）是所有采样顶点中最近的顶点\（u \），并且让\（s_ {u} \）成为集合图表G的所有原装都比顶点\（p（u）\）更靠近U.存储SET \（S_ {U} \）的顶点以及它们的距离\（u \）。</p><p>Before intuitively understanding the algorithm, let&#39;s first see it in action. We start by choosing \( \gamma = n^{-1/2} = 1/\sqrt{n} \). We will later understand why this is the optimal value to choose. Step 1 can be implemented in the following manner: import random, math# Based on the Ten Blocks graphn = 10V = range(1, n+1)gamma = 1/math.sqrt(n)# gamma comes about 0.316R = [vertex for vertex in V if random.choices([True, False], weights=[gamma, 1-gamma])[0]==True]</p><p>在直观地理解算法之前，首先让＆＃39;第一次看到它。我们首先选择\（\ gamma = n ^ { -  1/2} = 1 / \ sqrt {n} \）。我们稍后会理解为什么这是选择的最佳价值。步骤1可以以下列方式实现：基于十个块的导入随机，数学#10V =范围（1，n + 1）伽马= 1 / math.sqrt（n）＃gamma来自大约0.316r = [ Vartex在V中的顶点，如果Aquary.choices（[true，false]，权重= [gamma，1-gamma]）[0] == true]</p><p>Let us assume that after we ran the above code, we obtained  R as [1, 10].</p><p>让我们假设在我们运行上面的代码后，我们获得了[1,10]。</p><p> While the above algorithm is ambiguous about the distance metric in step 2, in reality, we want to store the  shortest distances from all the vertices in V to those in sample set R. These distances can be calculated using Dijkstra&#39;s single- source shortest-path algorithm. However, do note the difference here! We only need to calculate Dijkstra&#39;s algorithm with the subset R as our source vertices (i.e. for our case, we need to perform the algorithm twice, one with source vertex as 1 and another with source vertex as 10). Here is the resulting matrix we are to obtain after step 2:</p><p> 虽然上述算法对步骤2中的距离度量模糊不清，但实际上，我们希望将来自V的所有顶点的最短距离存储在样本集R中的所有顶点。这些距离可以使用Dijkstra＆＃39; s单源最短路径算法。但是，请注意这里的差异！我们只需要使用子集R计算Dijkstra＆＃39; S子集R作为我们的源顶点（即，对于我们的情况，我们需要执行两次算法，其中一个带有源顶点的一个，另一个带有源顶点的另一个源顶点为10）。以下是我们在步骤2之后获得的结果矩阵：</p><p> Observing closely, step 3 has two sub-parts. For each \( u \in V \):  Find \( p(u) \) which is the nearest vertex to \( u \) among all the sampled vertices.</p><p> 密切观察，步骤3有两个子部分。对于每个\（v \）：查找\（p（u）\），它是所有采样顶点中的最近的顶点到\（u \）。 </p><p>  For each vertex u, find \( S_{u} \) which is the set of all the vertices of the graph G that lie closer to u than the vertex \( p(u) \).</p><p>对于每个顶点U，查找\（s_ {u} \），它是图表g的所有顶点的集合，它比顶点\（p（u）\）更近。</p><p> The  sub-part i can be solved simultaneously with step 2. Here is a modified version of the above matrix:   To represent the above-highlighted cells, we create a new terminology called \( \delta(u, p(u)) \). For example, \( \delta(B3, p(B3)) = \delta(B3, B1) \) = 15 and \( \delta(B6, p(B6)) = \delta(B6, B10) \) = 50. Solving the  sub-part ii requires some thinking. We cannot directly apply Dijkstra&#39;s algorithm to every vertex, as that would be the same as solving the classical APSP problem. However, there are two observations to be made here:  We only need to calculate the shortest distances between the pairs of each vertex in \( V \) and \( V\setminus R \). This is to avoid any redundant calculations as we have already found the distances between each vertex in V and set R in step 2.  The symbol \( \setminus \) stands for set-minus and is used in  set-theory to find the relative complement of any set A wrt a set B. For example, if A = {1,2,3,4} and B = {3, 5, 7}, then \( A\setminus B \) = {1, 2, 4}. In our case, \( V\setminus R \) = {2, 3, 4, 5, 6, 7, 8, 9}.</p><p> 可以使用步骤2同时解决子部分。以下是上述矩阵的修改版本：表示上面突出显示的单元格，我们创建一个名为\（\ delta（u，p（u））\的新术语）。例如，\（\ delta（b3，p（b3））= \ delta（b3，b1）\）= 15和\（\ delta（b6，p（b6））= \ delta（b6，b10）\） = 50.解决子部分II需要一些思考。我们不能直接将Dijkstra＆＃39; s算法应用于每个顶点，因为它与解决经典APSP问题相同。然而，这里有两个观察结果：我们只需要计算\（v \）和\（v \ setminus r \）的每个顶点的对之间的最短距离。这是为了避免任何冗余计算，因为我们已经发现了在步骤2中的每个顶点和Set r之间的每个顶点之间的距离。符号\（\ setMinus \）代表Set-minus，用于设定理论以找到相对任何设置WRT A组B的补充。例如，如果a = {1,2,3,4}和b = {3,5,7}，则\（a \ setminus b \）= {1,2 ，4}。在我们的情况下，\（v \ setminus r \）= {2,3,4,5,6,7,8,9}。</p><p>  For any pair \( (u, w) \) where \( u \in V \) and \( w \in V\setminus R \), we can stop computing Dijkstra’s algorithm when that pair&#39;s distance (let this distance be \( \delta(u, w) \)) exceeds the value \( \delta(u, p(u)) \). That is, when \( \delta(u, w) \ge \delta(u, p(u)) \).</p><p>  对于任何对\（（u，w）\）其中\（u \ in v \）和\（在v \ setminus r \中），我们可以在那双的距离时停止计算dijkstra的算法（让此距离是\（\ delta（u，w）\））超过值\（\ delta（u，p（u））\）。也就是说，当\（\ delta（u，w）\ ge \ delta（u，p（u））\）。</p><p> As the above observations were a bit mathematical, let us visualize them with our Ten Blocks graph.   As we can observe in the above figure, we never traversed 7 vertices as traversing them meant that the distance from B3 to that vertex would increase by 15. Let us now visualize the matrix formed after performing the final step 3.   As can be observed from Figure 11, instead of calculating 90 shortest-paths (discarding the starting point calculations), as was the case with classical APSP algorithms like F</p><p> 由于上述观察有点数学，让我们用十个块图来敏感它们。正如我们可以在上图中观察到的那样，我们从未遍历7个顶点，因为它们意味着从B3到该顶点的距离将增加15.让我们现在可视化执行最终步骤3之后形成的矩阵图11，而不是计算90个最短路径（丢弃起始点计算），就像F的经典APSP算法一样</p><p>......</p><p>...... </p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://pncnmnp.github.io/blogs/distance-oracles.html">https://pncnmnp.github.io/blogs/distance-oracles.html</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/oracle/">#oracle</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/距离/">#距离</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/distance/">#distance</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/算法/">#算法</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/谷歌/">#谷歌</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy;2012-2021 diglog.com </div></div></body></html>