<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>使SoAP可以容忍 Making SoA Tollerable</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">Making SoA Tollerable<br/>使SoAP可以容忍 </h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2021-03-01 02:11:29</div><div class="page_narrow text-break page_content"><p>Chandler Caruth (I think - I can&#39;t for the life of me find the reference) said something in a cppcon talk years ago that blew my mind. More or less, 95% of code performance comes from the memory layout and memory access patters of data structures, and 5% comes from clever instruction selection and instruction stream optimization.</p><p>钱德勒·卡鲁斯（Chandler Caruth）（我想-我一辈子都找不到参考文献）在几年前的cppcon演讲中说了一些话，这让我很震惊。或多或少地，95％的代码性能来自数据结构的内存布局和内存访问模式，而5％则来自明智的指令选择和指令流优化。</p><p> That is...terrible news! Instruction selection is now pretty much entirely automated. LLVM goes into my code and goes &#34;ha ha ha foolish human with your integer divide by a constant, clearly you can multiply by this random bit sequence that was proven to be equivalent by a mathematician in the 80s&#34; and my code gets faster. There&#39;s not much I have to worry about on this front.</p><p> 那是...可怕的消息！现在，指令选择几乎是完全自动化的。 LLVM进入我的代码，然后用整数除以一个愚蠢的人，很显然，您可以乘以这个随机位序列，该序列在80年代被数学家证明是等效的。和我的代码变得更快。在这方面，我不必担心。</p><p> The data structures story is so much worse. I say &#34;I&#39;d like to put these bytes here&#34; and the compiler says &#34;very good sir&#34; in sort of a deferential English butler kind of way. I can sense that maybe there&#39;s some judgment and I&#39;ve made bad life choices, but the compiler is  just going to do what I told it. &#34;Lobster Thermidor encrusted in Cool Ranch Doritos, very good sir&#34; and Alfred walks off to leave me in a hell of L2 cache misses of my own design that turn my i-5 into a 486.</p><p> 数据结构的故事要糟糕得多。我说我想把这些字节放在这里然后编译器说“非常好先生”以一种卑鄙的英国男管家的方式。我可以感觉到也许有一些判断，并且我做出了糟糕的选择，但是编译器将按照我的指示去做。 ＆＃34;龙虾·塞米多（Lobster Thermidor）镶嵌在酷牧场多力多滋（Cool Ranch Doritos）中，非常好，先生。然后阿尔弗雷德（Alfred）走开，使我陷入了我自己设计的L2缓存未命中的情况，这使我的i-5变成了486。</p><p> I view this as a fundamental design limitation of C++, one that might someday be fixed with generative meta-programming (that is, when we can program C++ to write our C++, we can program it to take our crappy OOPy-goopy data structures and reorganize them into something the cache likes) but that is the Glorious Future™. For now, the rest of this post is about what we can do about it with today&#39;s C++.</p><p> 我认为这是C ++的一项基本设计局限性，有一天可能会通过生成元编程来解决这一局限性（也就是说，当我们可以对C ++进行编程以编写C ++时，我们可以对其进行编程以采用笨拙的OOPy-goopy数据结构，将它们重新组织成缓存喜欢的东西），但这就是Glorious Future™。现在，本文的其余部分是关于我们今天的C ++可以做什么的。</p><p>  To go faster, we have to keep the CPU busy, which means not waiting for memory. The first step is to use vector and stop using everything else - see the  second half of Chandler&#39;s talk. Basically any data structure where the next thing we need isn&#39;t directly after the thing we just used is bad because the memory might not be in cache.</p><p>  为了更快地运行，我们必须保持CPU繁忙，这意味着不等待内存。第一步是使用vector并停止使用其他所有内容-请参阅Chandler演讲的后半部分。基本上，在我们刚刚使用的东西之后紧接着我们需要下一个东西的任何数据结构都是不好的，因为内存可能不在高速缓存中。</p><p> We experienced this first hand in X-Plane during the port to Vulkan. Once we moved from OpenGL to Vulkan, our CPU time in driver code went way down - 10x less driver time - and all of the remaining CPU time was in our own code. The clear culprit was the culling code, which walks a hierarchical bounding volume tree to decide what to draw.</p><p> 在前往Vulkan的港口期间，我们在X-Plane中亲身体验了这一手。从OpenGL迁移到Vulkan后，驱动程序代码中的CPU时间下降了很多-驱动程序时间减少了10倍-其余所有CPU时间都在我们自己的代码中。罪魁祸首是清除代码，该代码遍历分层的边界体积树来决定要绘制的内容。</p><p> I felt  very clever when I wrote that bounding volume tree in 2005. It has great O(N) properties and lets us discard a lot of data very efficiently. So much winning!</p><p> 当我在2005年编写边界卷树时，我感到非常聪明。它具有出色的O（N）属性，可让我们非常高效地丢弃大量数据。如此多的胜利！ </p><p> But also, it&#39;s a tree. The nodes are almost never consecutive, and a VTune profile is just a sea of cache misses each time we jump nodes. It&#39;s slow because it runs at the speed of main memory.</p><p>而且，它是一棵树。节点几乎从来都不是连续的，并且每当我们跳转节点时，VTune概要文件就是大量的高速缓存未命中。它运行缓慢，因为它以主内存的速度运行。</p><p> We replaced it with a structure that would probably cause you to fail CS 102, algorithms and data structures:</p><p> 我们将其替换为可能会导致CS 102，算法和数据结构失败的结构：</p><p> 1. A bunch of data is kept in an array for a a sub-section of the scenery region.</p><p> 1.一堆数据被保存在一个数组中，用于风景区域的一个子部分。</p><p>  And that&#39;s it. It&#39;s a tree of fixed design of depth two and a virtually infinite node count.</p><p>  就是这样。它是一棵固定设计的树，深度为2，节点数实际上是无限的。</p><p> And it screams. It&#39;s absurdly faster than the tree it replaces, because pretty much every time we have to iterate to our next thing, it&#39;s right there, in cache. The CPU is good at understanding arrays and is going to get the next cache line while we work. Glorious!</p><p> 它尖叫。它比它所替换的树快得多，因为几乎每次我们都必须遍历下一个事物时，它就在缓存中。 CPU擅长理解数组，并且在我们工作时将获得下一个缓存行。辉煌！</p><p> There are problems so big that you still need O(N) analysis, non-linear run-times, etc. If you&#39;re like me and have been doing this for a long time, the mental adjustment is how big N has to be to make that switch. If N is 100, that&#39;s not a big number anymore - put it in an array and blast through it.</p><p> 问题太大了，您仍然需要O（N）分析，非线性运行时间等。如果您像我一样，并且已经进行了很长时间，那么心理上的调整就是N有多大进行切换。如果N为100，则不再是很大的数字-将其放在数组中并对其进行爆炸。</p><p>  So far all we&#39;ve done is replaced every STL container with vector. This is something that&#39;s easy to do for new code, so I would say it should be a style decision - default to vector and don&#39;t pick up sets/maps/lists/whatever unless you have a really, really, really good reason.</p><p>  到目前为止，我们所做的全部工作都是将每个STL容器替换为vector。对于新代码来说，这很容易做到，因此我想这应该是一种样式决定-默认为vector，除非您确实有，否则不要选择set / maps / lists /真的，真的是很好的理由。 </p><p> But it turns out vector&#39;s not that great either. It lines up our objects in a row, but it works on  whole objects. If we have an object with a lot of data, some of which we touch all of the time and some of which we use once on leap years, we waste cache space on the rarely used data. Putting whole objects into an array makes our caches smaller, by filling them up with stuff we aren&#39;t going to use because it happens to be nearby.</p><p>但是事实证明向量也不是那么好。它可以连续排列我们的对象，但可以在整个对象上使用。如果我们有一个包含大量数据的对象，其中一些数据我们一直都在触摸，而某些数据在leap年使用一次，那么我们将在很少使用的数据上浪费缓存空间。将整个对象放到一个数组中可以使我们的缓存更小，因为它们会被填充在我们附近，因为我们不会使用它们。</p><p> Game developers are very familiar with what to do about it - perhaps less so in the C++ community: vector gives us an  array of structures - each object is consecutive and then we get to the next object; what we really want is a  structure of arrays - each  member of the object is consecutive and then we hit the next object.</p><p> 游戏开发人员非常熟悉该怎么做-在C ++社区中可能更少：向量为我们提供了一系列结构-每个对象都是连续的，然后我们进入下一个对象;我们真正想要的是数组的结构-对象的每个成员都是连续的，然后我们命中下一个对象。</p><p> Imagine we have a shape object with a location, a color, a type, and a label. In the structure of arrays world, we store 4 shapes by storing: [(location1, location2, location3, location4), (color 1, color 2, color3, color4), (type 1, type2, type3, type 4), (label 1, label2, label3, label4)].</p><p> 想象我们有一个带有位置，颜色，类型和标签的形状对象。在数组世界的结构中，我们通过存储以下内容来存储4个形状：[[（location1，location2，location3，location4），（color 1，color 2，color3，color4），（type 1，type2，type3，type 4），（标签1，标签2，标签3，标签4）]。</p><p> First, let&#39;s note how much better this is for the cache. When we go looking to see if a shape is on screen, all locations are packed together; every time we skip a shape, the next shape&#39;s location is next in memory. We have wasted no cache or memory bandwidth on thing we won&#39;t draw. If label drawing is turned off, we can ignore that entire block of memory. So much winning!</p><p> 首先，让我们注意这对于缓存有多好。当我们去查看屏幕上是否有形状时，所有位置都挤在一起了。每当我们跳过一个形状时，下一个形状的位置就是内存中的下一个位置。我们不会在不会画的东西上浪费任何缓存或内存带宽。如果标签绘图被关闭，我们可以忽略整个内存块。如此多的胜利！</p><p> Second, let&#39;s note how absolutely miserable this is to maintain in C++. Approximately 100% of our tools for dealing with objects and encapsulations go out the window because we have taken our carefully encapsulated objects, cut out their gooey interiors and spread them all over the place. If you showed this code to an OOP guru they&#39;d tell you you&#39;ve lost your marbles. (Of coarse, SoA isn&#39;t object oriented design, it&#39;s data oriented design. The objects have been minced  on purpose!)</p><p> 其次，让我们注意这在C ++中维护是多么悲惨。我们大约100％的用于处理对象和封装的工具都无法使用，因为我们已经将经过仔细封装的对象拿走了，切掉了它们的粘性内部并将它们散布到整个地方。如果您将此代码显示给OOP专家，他们会告诉您您丢失了弹珠。 （从粗略的角度来说，SoA不是面向对象的设计，而是面向数据的设计。对象是故意切碎的！）</p><p>  So the problem I have been thinking about for a while now is: how do we minimize the maintenance pain of structures of arrays when we have to use them? X-Plane&#39;s user interface isn&#39;t so performance critical that I need to take my polymorphic hierarchy of UI widgets and cut it to bits, but the rendering engine has a bunch of places where moving to SoA is  the optimization to improve performance.</p><p>  因此，我已经思考了一段时间的问题是：当必须使用数组结构时，如何使它们的维护痛苦最小化？ X-Plane的用户界面对性能要求不高，因此我需要采用UI小部件的多态层次结构并将其切成小块，但是渲染引擎在很多地方都需要迁移到SoA以提高性能。</p><p> The least bad C++ I have come up with so far looks something like this:</p><p> 到目前为止，我提出的最差的C ++看起来像这样： </p><p>             You can almost squint at this and say &#34;this is an object with five fields&#34;, and you can almost squint and this and say &#34;this is an array&#34; - it&#39;s both! The trick is that each member field is a base pointer into the first object (of count&#39;s) member field, with the next fields coming consecutively. While all cull_y fields don&#39;t have to follow cull_x in memory, it&#39;s nice if they do - we&#39;d rather not have them on different VM pages, for example.</p><p>您几乎可以斜着眼睛说这是一个有五个字段的对象，而您几乎可以斜着眼睛说这是一个数组。 -两者都有！诀窍是，每个成员字段都是指向第一个对象（计数）成员字段的基本指针，而下一个字段则是连续出现的。尽管所有cull_y字段不必在内存中都跟随cull_x，但如果这样做的话，那就很好了-例如，我们宁愿不在不同的VM页面上使用它们。</p><p> Our SoA struct can both be an array (in that it owns the memory and has the base pointers) but it can also be an iterator - the increment operator increments each of the base pointers. In fact, we can easily build a sub-array by increasing the base pointers and cutting the count, and iteration is just slicing off smaller sub-arrays in place - it&#39;s very cheap.</p><p> 我们的SoA结构既可以是一个数组（因为它拥有内存并具有基本指针），但也可以是迭代器-增量运算符会递增每个基本指针。实际上，我们可以通过增加基本指针并减少计数来轻松构建子阵列，而迭代只是将较小的子阵列切成适当的位置-这非常便宜。</p><p> This turns out to be pretty manageable! We end up writing *iter.cull_x instead of iter-&gt;cull_x, but we more or less get to work with our data as expected.</p><p> 事实证明这很容易管理！我们最终编写了* iter.cull_x而不是iter-＆gt; cull_x，但是我们或多或少开始按预期使用数据。</p><p>  We have one problem left: where did the memory come from to allocate our SoA? We need a helper - something that will &#34;organize&#34; our dynamic memory request and set up our base pointers to the right locations. This code is doing what operator new[] would have done.</p><p>  我们还有一个问题：内存是从哪里分配我们的SoA的？我们需要一个帮手-可以帮助您进行整理的东西。我们的动态内存请求，并设置指向正确位置的基本指针。此代码执行的操作符为new []。</p><p>           Our allocation block helper takes a bunch of requests for arrays of T&#39;s (e.g. arbitrary types) and allocates one big block that allocates them consecutively, filling in dest_ptr to point to each one. When we call detach, the single giant malloc() block is returned to be freed by client code.</p><p>           我们的分配块帮助程序对T数组（例如任意类型）进行一堆请求，并分配一个大块，该大块连续地分配它们，并填充dest_ptr指向每个数组。当我们调用detach时，单个巨型malloc（）块将返回以由客户端代码释放。</p><p> We can feed any number of SoA arrays via a single alloc block, letting us pack an entire structure of arrays of structures into one consecutive memory region. With this tool, &#34;alloc&#34; of an SoA is pretty easy to write.</p><p> 我们可以通过一个分配块提供任意数量的SoA数组，让我们将结构数组的整个结构打包到一个连续的内存区域中。使用此工具，＆＃34; alloc＆＃34; SoA的代码很容易编写。</p><p>            The allocation helper is taking the sting out of memory layout by doing it dynamically at run-time. This is probably fine - the cost of the pointer math is trivial compared to actually going and getting memory from the OS.</p><p>            分配帮助程序通过在运行时动态地进行分配，从而摆脱了内存布局的麻烦。这可能很好-与从操作系统实际获取内存相比，指针数学运算的成本微不足道。 </p><p> When we iterate, we are using memory to find our data members. While there exists some math to find a given member at a given index, we are storing one pointer per member in the iterator instead of one pointer total.</p><p>当我们进行迭代时，我们正在使用内存来查找我们的数据成员。虽然存在一些数学运算可以找到给定索引处的给定成员，但我们在迭代器中为每个成员存储一个指针，而不是总共一个指针。</p><p> One of these structs could be turned into something that looks more like a value type by owning its own memory, etc. but in our applications I have found that several SoAs tend to get grouped together into a bigger &#39;system&#39;, and letting the system own a single block is best. Since we have already opened the Pandora&#39;s box of manually managing our memory, we might as well group things complete and cut down allocator calls while getting better locality.</p><p> 通过拥有自己的内存等，可以将这些结构之一转换为看起来更像值类型的东西，但是在我们的应用程序中，我发现几个SoA倾向于组合在一起成为一个更大的＆system; ，最好让系统拥有一个块。由于我们已经打开了手动管理内存的Pandora框，因此我们不妨将已完成的事情分组并减少分配器调用，同时获得更好的局部性。</p><p>   Someday we&#39;ll have meta-programing, and when we do, it would be amazing to make a &#34;soa_vector&#34; that, given a POD data type, generates something like this:</p><p>   总有一天，我们将进行元编程，当我们这样做时，制作一个＆＃34; soa_vector＆＃34;在给定POD数据类型的情况下，会生成如下内容：</p><p>           I haven&#39;t pursued this in our code because of the annoyance of having to write and maintain the offset-fetch macros by hand, as well as the obfuscation of what the intended data layout really is. I am sure this is possible now with TMP, but the cure would be worse than the disease. But generative meta-programming I think does promise this level of optimized implementation from relatively readable source code.</p><p>           我之所以没有在我们的代码中进行此操作，是因为必须手动编写和维护offset-fetch宏，并且对预期的数据布局的真正含义感到困惑。我敢肯定，现在使用TMP可以做到这一点，但是治愈方法会比疾病更糟糕。但是我认为，生成元编程确实可以从相对可读的源代码中实现这一级别的优化实现。</p><p>  One last note - in my example, I split the X, Y and Z coordinates of my culling volume into their own arrays. Is this a good idea?  If it was a vec3 struct (with x,y,z members) what should we have done?</p><p>  最后一点-在我的示例中，我将剔除体积的X，Y和Z坐标拆分为它们自己的数组。这是一个好主意吗？如果它是vec3结构（带有x，y，z成员），我们应该怎么做？</p><p> The answer is ... it depends? In our real code, X, Y and Z are separate for SIMD friendliness - a nice side effect of separating the coordinates is that we can load four  objects into four lanes of a SIMD register and then perform the math for four objects at once. This is the biggest SIMD win we&#39;ll get - it is extremely cache efficient, we waste no time massaging the data into SIMD format, and we get 100% lane utilization. If you have a chance to go SIMD, separate the fields.</p><p> 答案是……取决于？在我们的实际代码中，X，Y和Z出于SIMD友好性而分开-分离坐标的一个很好的副作用是，我们可以将四个对象加载到SIMD寄存器的四个通道中，然后一次对四个对象执行数学运算。这是我们将获得的最大SIMD胜利-它具有极高的缓存效率，我们不花时间将数据按摩为SIMD格式，并且获得了100％的通道利用率。如果您有机会接受SIMD，请分开字段。</p><p> But this isn&#39;t necessarily best. If we had to make a calculation based on XYZ, together, and we  always use them together and we&#39;re not going to SIMD them, it might make sense to pack them together (e..g so our data went XYZXYZXYZXYZ, etc.). This would mean fetching position would require only one stride in memory and not three. It&#39;s not bad to have things together in cache if we want them together in cache.</p><p> 但这不一定是最好的。如果我们必须一起基于XYZ进行计算，并且我们总是一起使用它们，而又不想对它们进行SIMD，则将它们打包在一起可能是有意义的（例如，我们的数据以XYZXYZXYZXYZ的形式出现，等等。）。这意味着获取位置将只需要在内存中迈出一大步，而不需要三步。如果我们希望将它们一起存储在缓存中，则可以将它们放在一起。 </p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://hacksoflife.blogspot.com/2021/02/making-soa-tollerable.html">https://hacksoflife.blogspot.com/2021/02/making-soa-tollerable.html</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/soap/">#soap</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/soa/">#soa</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/内存/">#内存</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/分享/">#分享</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy; 2020 diglog.com </div></div></body></html>