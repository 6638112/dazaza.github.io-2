<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>基于Python的应用机器学习的线性代数导论</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">基于Python的应用机器学习的线性代数导论</h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2020-11-11 22:41:28</div><div class="page_narrow text-break page_content"><p>Linear algebra is to machine learning as flour to bakery:  every machine learning model is based in linear algebra, as every cake is based in flour. It is not the only ingredient, of course. Machine learning models need vector calculus, probability, and optimization, as cakes need sugar, eggs, and butter. Applied machine learning, like bakery, is essentially about combining these mathematical ingredients in clever ways to create useful (tasty?) models.</p><p>线性代数之于机器学习就像面粉之于面包店：每个机器学习模型都基于线性代数，就像每个蛋糕都基于面粉一样。当然，这不是唯一的配料。机器学习模型需要向量微积分、概率和最优化，就像蛋糕需要糖、鸡蛋和黄油一样。应用机器学习，就像面包店一样，本质上是将这些数学成分以巧妙的方式结合在一起，创造出有用的(好吃的？)。模特们。</p><p> This document contains  introductory level linear algebra notes for applied machine learning. It is meant as a reference rather than a comprehensive review. If you ever get confused by matrix multiplication, don’t remember what was the $L_2$ norm, or the conditions for linear independence, this can serve as a quick reference. It also a good introduction for people that don’t need a deep understanding of linear algebra, but still want to learn about the fundamentals to read about machine learning or to use pre-packaged machine learning solutions. Further, it is a good source for people that learned linear algebra a while ago and need a refresher.</p><p>本文档包含应用机器学习的入门级别线性代数注释。这是一个参考，而不是一个全面的审查。如果你曾经被矩阵乘法弄糊涂了，不要记得什么是$L_2$范数，或者线性无关的条件，这可以作为一个快速参考。对于不需要深入理解线性代数，但仍想了解机器学习基础知识或使用预先打包的机器学习解决方案的人来说，这也是一个很好的介绍。此外，对于刚刚学习了线性代数并需要复习的人来说，这是一个很好的资源。</p><p> These notes are based in a series of (mostly) freely available textbooks, video lectures, and classes I’ve read, watched and taken in the past. If you want to obtain a deeper understanding or to find exercises for each topic, you may want to consult those sources directly.</p><p>这些笔记基于我过去读过、看过和上过的一系列(大部分)免费教科书、视频讲座和课程。如果你想获得更深层次的理解或找到每个主题的练习，你可能想要直接参考这些来源。</p><p>  Linear Algebra Ch. in Deep Learning by Goodfellow, Bengio, and Courville. 1st Ed.  Chapter link.</p><p>线性代数CH.。古德费罗、本吉奥和库维尔著的《深度学习》。第一版。章节链接。</p><p>  Linear Algebra Ch. in Dive into Deep Learning by Zhang, Lipton, Li, And Smola.  Chapter link.</p><p>线性代数CH.。在张、利普顿、李和斯莫拉的《深入学习》一书中。章节链接。</p><p>   I’ve consulted all these resources at one point or another. Pavel Grinfeld’s lectures are my absolute favorites. Salman Khan’s lectures are really good for absolute beginners (they are long though). The famous 3blue1brown series in linear algebra is delightful to watch and to get a solid high-level view of linear algebra.</p><p>我曾在某一时刻咨询过所有这些资源。帕维尔·格林菲尔德(Pavel Grinfeld)的演讲绝对是我的最爱。萨尔曼·汗的讲座对绝对的初学者来说真的很不错(虽然篇幅很长)。著名的线性代数中的3Blue1Brown系列是令人愉快的观看和获得一个坚实的线性代数的高级视图。</p><p> If you have to pic one book, I’d pic  Boyd’s and Vandenberghe’s Intro to applied linear algebra, as it is the most beginner friendly book on linear algebra I’ve encounter. Every aspect of the notation is clearly explained and pretty much all the key content for applied machine learning is covered. The Linear Algebra Chapter in Goodfellow et al is a nice and concise introduction, but it may require some previous exposure to linear algebra concepts. Deisenroth et all book is probably the best and most comprehensive source for linear algebra for machine learning I’ve found, although it assumes that you are good at reading math (and at math more generally). Savov’s book it’s also great for beginners but requires time to digest. Professor Strang lectures are great too but I won’t recommend it for absolute beginners.</p><p>如果你一定要看一本书，我会选博伊德和范登伯格的《应用线性代数导论》，因为这是我见过的最适合初学者阅读的线性代数书籍。这个符号的每一个方面都得到了清楚的解释，几乎所有的应用机器学习的关键内容都被涵盖了。古德费罗等人的《线性代数》一章是一个很好且简明的介绍，但它可能需要先接触一些线性代数概念。Deisenroth等人的书可能是我找到的机器学习线性代数的最好、最全面的来源，尽管它假设你擅长阅读数学(更广泛地说，它是数学方面的)。萨沃夫的书对初学者来说也很棒，但需要时间来消化。斯特朗教授的讲座也很棒，但我不会推荐给纯粹的初学者。</p><p> I’ll do my best to keep notation consistent. Nevertheless, learning to adjust to changing or inconsistent notation is a useful skill, since most authors will use their own preferred notation, and everyone seems to think that its/his/her own notation is better.</p><p>我会尽我最大努力保持记号的一致性。然而，学习适应变化或不一致的符号是一项有用的技能，因为大多数作者都会使用他们自己喜欢的符号，而且每个人似乎都认为自己的符号更好。</p><p> To make everything more dynamic and practical, I’ll introduce bits of Python code to exemplify each mathematical operation (when possible) with  NumPy, which is the facto standard package for scientific computing in Python.</p><p>为了使一切变得更加动态和实用，我将介绍一些Python代码，以便(如果可能)使用NumPy来举例说明每个数学运算，NumPy是在Python中进行科学计算的事实上的标准包。</p><p> Finally, keep in mind this is created by a non-mathematician for (mostly) non-mathematicians. I wrote this as if I were talking to myself or a dear friend, which explains why my writing is sometimes conversational and informal.</p><p>最后，请记住，这是由非数学家为(大多数)非数学家创建的。我写这封信的方式就像是在和我自己或我亲爱的朋友说话，这就解释了为什么我的写作有时是对话式的和非正式的。</p><p> If you find any mistake in notes feel free to reach me out at pcaceres@wisc.edu and to https://pablocaceres.org/ so I can correct the issue.</p><p>如果您在笔记中发现任何错误，请随时联系我：pcaceres@wic.edu和https://pablocaceres.org/，这样我就可以更正这个问题。</p><p>               While writing about linear mappings, I realized the importance of having a basic understanding of a few concepts before approaching the study of linear algebra. If you are like me, you may not have formal mathematical training beyond high school. If so, I encourage you to read this section and spent some time wrapping your head around these concepts before going over the linear algebra content (otherwise, you might prefer to skip this part). I believe that reviewing these concepts is of great help to understand the  notation, which in my experience is one of the main barriers to understand mathematics for nonmathematicians: we are  nonnative speakers, so we are continuously building up our vocabulary. I’ll keep this section very short, as is not the focus of this mini-course.</p><p>在写关于线性映射的文章时，我意识到在学习线性代数之前，对一些概念有一个基本的理解是很重要的。如果你和我一样，你可能不会在高中以后接受过正式的数学训练。如果是这样的话，我鼓励您阅读这一节，并在复习线性代数内容之前花一些时间理解这些概念(否则，您可能更愿意跳过这一部分)。我相信复习这些概念对理解符号有很大的帮助，根据我的经验，这是非数学家理解数学的主要障碍之一：我们不是以英语为母语的人，所以我们在不断增加我们的词汇量。我将这一部分保持简短，因为这不是本迷你课程的重点。</p><p>    Sets are one of the most fundamental concepts in mathematics. They are so fundamental that they are not defined in terms of anything else. On the contrary, other branches of mathematics are defined in terms of sets, including linear algebra. Put simply,  sets are well-defined collections of objects. Such objects are called  elements or members of the set. The crew of a ship, a caravan of camels, and the LA Lakers roster, are all examples of sets. The captain of the ship, the first camel in the caravan, and LeBron James are all examples of “members” or “elements” of their corresponding sets. We denote a set with an upper case italic letter as $\textit{A}$. In the context of linear algebra, we say that a line is a set of points, and the set of all lines in the plane is a set of sets. Similarly, we can say that  vectors are sets of points, and  matrices sets of vectors.</p><p>集合是数学中最基本的概念之一。它们是如此基本，以至于没有用其他任何东西来定义。相反，数学的其他分支是用集合来定义的，包括线性代数。简而言之，集合是定义良好的对象集合。这样的对象称为集合的元素或成员。船上的船员，骆驼大篷车，洛杉矶湖人队的花名册，都是布景的例子。这艘船的船长，大篷车中的第一头骆驼，以及勒布朗·詹姆斯，都是他们相应套装中的“成员”或“元素”的例子。我们将具有大写斜体字母的集合表示为$\textit{A}$。在线性代数的背景下，我们说一条直线是一组点，平面上所有直线的集合是一组集合。类似地，我们可以说向量是点的集合，而矩阵是向量的集合。</p><p>  We build sets using the notion of  belonging. We denote that $a$  belongs (or is an  element or  member of) to $\textit{A}$ with the Greek letter epsilon as:</p><p>我们使用归属感来构建集合。我们用希腊字母epsilon表示$a$属于$\textit{A}$(或者是$\textit{A}$的元素或成员)：</p><p> Another important idea is  inclusion, which allow us to build  subsets. Consider sets $\textit{A}$ and $\textit{B}$. When every element of $\textit{A}$ is an element of $\textit{B}$, we say that $\textit{A}$ is a  subset of $\textit{B}$, or that $\textit{B}$  includes $\textit{A}$. The notation is:</p><p>另一个重要的想法是包含，它允许我们构建子集。考虑集合$\textit{A}$和$\textit{B}$。当$\textit{A}$的每个元素都是$\textit{B}$的元素时，我们说$\textit{A}$是$\textit{B}$的子集，或者说$\textit{B}$包括$\textit{A}$。符号是：</p><p>  Belonging and inclusion are derived from  axion of extension:  two sets are equal if and only if they have the same elements. This axiom may sound trivially obvious but is necessary to make belonging and inclusion rigorous.</p><p>归属和包含源自扩张公理：两个集合相等的充要条件是它们具有相同的元素。这条公理听起来可能不起眼，但却是让归属和包容变得严谨所必需的。</p><p>  In general, anything we assert about the elements of a set results in  generating a subset. In other words, asserting things about sets is a way to manufacture subsets. Take as an example the set of all dogs, that I’ll denote as $\textit{D}$. I can assert now “$d$ is black”. Such an assertion is true for some members of the set of all dogs and false for others. Hence, such a sentence, evaluated for  all member of $\textit{D}$, generates a subset:  the set of all black dogs. This is denoted as:</p><p>一般来说，我们对集合元素的任何断言都会导致生成一个子集。换句话说，断言关于集合的东西是制造子集的一种方式。以所有狗的集合为例，我将其表示为$\textit{D}$。我现在可以断言“$d$是黑色的”。这样的断言对所有狗中的一些成员是正确的，对另一些成员是错误的。因此，这样一个语句(针对$\textit{D}$的所有成员求值)会生成一个子集：所有黑狗的集合。这表示为：</p><p>  The colon ($:$) or vertical bar ($\vert$) read as “such that”. Therefore, we can read the above expression as:  all elements of $d$ in $\textit{D}$ such that $d$ is black. And that’s how we obtain the set $\textit{B}$ from $\textit{A}$.</p><p>冒号($：$)或竖线($\vert$)读作“Tho That”。因此，我们可以将上面的表达式理解为：$\textit{D}$中$d$的所有元素，使得$d$为黑色。这就是我们如何从$\textit{A}$获得集合$\textit{B}$。</p><p> Set generation, as defined before, depends on the  axiom of specification:  to every set $\textit{A}$ and to every condition $\textit{S}(x)$ there corresponds a set $\textit{B}$ whose elements are exactly those elements $a \in \textit{A}$ for which $\textit{S}(x)$ holds.</p><p>如前所述，集合生成依赖于规范的公理：对于每个集合$\textit{A}$和每个条件$\textit{S}(X)$，都有一个集合$\textit{B}$，其元素正是$\textit{A}$中$\textit{S}(X)$成立的元素。</p><p> A condition $\textit{S}(x)$ is any  sentence or  assertion about elements of $\textit{A}$. Valid sentences are either of  belonging or  equality. When we combine belonging and equality assertions with logic operators (not, if, and or, etc), we can build any legal set.</p><p>条件$\textit{S}(X)$是关于$\textit{A}$元素的任何语句或断言。有效的判决要么是归属的，要么是平等的。当我们将归属和相等断言与逻辑运算符(NOT、IF和OR等)结合在一起时，我们可以构建任何合法的集合。</p><p>  Pairs of sets come in two flavors:  unordered and  ordered. We care about pairs of sets as we need them to define a notion of relations and functions (from here I’ll denote sets with lower-case for convenience, but keep in mind we’re still talking about sets).</p><p>成对套装有两种口味：无序的和有序的。我们关心集合对，因为我们需要它们来定义关系和函数的概念(为了方便起见，这里我将用小写表示集合，但请记住，我们仍然在谈论集合)。</p><p> Consider a pair of sets $\textit{x}$ and $\textit{y}$. An  unordered pair is a set whose elements are ${ \textit{x},\textit{y} }$, and ${ \textit{x},\textit{y} } = { \textit{y},\textit{x} } $. Therefore, presentation order does not matter, the set is the same.</p><p>考虑一对集合$\textit{x}$和$\textit{y}$。无序对是元素为${\textit{x}，\textit{y}}$和${\textit{x}，\textit{y}}={\textit{y}，\textit{x}}$的集合。因此，呈现顺序并不重要，集合是相同的。</p><p> In machine learning, we usually do care about presentation order. For this, we need to define an  ordered pair (I’ll introduce this at an intuitive level, to avoid to introduce too many new concepts). An  ordered pair is denoted as $( \textit{x},\textit{y} )$, with $\textit{x}$ as the  first coordinate and $\textit{y}$ as the  second coordinate. A valid ordered pair has the property that $( \textit{x},\textit{y} ) \ne ( \textit{y},\textit{x} )$.</p><p>在机器学习中，我们通常会关心表示顺序。为此，我们需要定义有序对(我将直观地介绍这一点，以避免引入太多新概念)。有序对表示为$(\textit{x}，\textit{y})$，其中$\textit{x}$为第一个坐标，$\textit{y}$为第二个坐标。有效的有序对具有$(\textit{x}，\textit{y})\ne(\textit{y}，\textit{x})$的属性。</p><p>  From ordered pairs, we can derive the idea of  relations among sets or between elements and sets. Relations can be binary, ternary, quaternary, or N-ary. Here we are just concerned with binary relationships. In set theory,  relations are defined as  sets of ordered pairs, and denoted as $\textit{R}$. Hence, we can express the relation between $\textit{x}$ and $\textit{y}$ as:</p><p>从有序对中，我们可以得出集合之间或元素与集合之间关系的概念。关系可以是二元、三元、四元或N元。这里我们只关心二元关系。在集合论中，关系被定义为有序对的集合，并表示为$\textit{R}$。因此，我们可以将$\textit{x}$和$\textit{y}$之间的关系表示为：</p><p> Further, for any $\textit{z} \in \textit{R}$, there exist $\textit{x}$ and $\textit{y}$ such that $\textit{z} = (\textit{x}, \textit{y})$.</p><p>进一步地，对于任何$\textit{z}\在\textit{R}$中，存在$\textit{x}$和$\textit{y}$使得$\textit{z}=(\textit{x}，\textit{y})$。</p><p> From the definition of $\textit{R}$, we can obtain the notions of  domain and  range. The  domain is a set defined as:</p><p>从$\textit{R}$的定义出发，我们可以得到整环和值域的概念。域是定义为：</p><p> This reads as: the values of $\textit{x}$ such that for at least one element of $\textit{y}$, $\textit{x}$ has a relation with $\textit{y}$.</p><p>这是这样的：$\textit{x}$的值使得对于$\textit{y}$的至少一个元素，$\textit{x}$与$\textit{y}$有关系。</p><p>  This reads: the set formed by the values of $\text{y}$ such that at least one element of $\textit{x}$, $\textit{x}$ has a relation with $\textit{y}$.</p><p>这是这样的：由$\text{y}$的值组成的集合，使得$\textit{x}$，$\textit{x}$的至少一个元素与$\textit{y}$有关系。</p><p>  Consider a pair of sets $\textit{X}$ and $\textit{Y}$. We say that a  function from $\textit{X}$ to $\textit{Y}$ is relation such that:</p><p>考虑一对集合$\textit{X}$和$\textit{Y}$。我们说从$\textit{X}$到$\textit{Y}$的函数是这样的关系：</p><p> such that for each $\textit{x} \in \textit{X}$ there is a unique element of $\textit{y} \in \textit{Y}$ with $(\textit{x}, \textit{y}) \in {f}$</p><p>使得对于每个$\textit{x}\在\textit{X}$中存在唯一的元素$\textit{y}\in\textit{Y}$其中$(\textit{x}，\textit{y})\在{f}$中。</p><p> More informally, we say that a function “ transform” or “ maps” or “ sends” $\textit{x}$ onto $\textit{y}$, and for each “ argument” $\textit{x}$ there is a unique value $\textit{y}$ that $\textit{f }$ “ assummes” or “ takes”.</p><p>更非正式地说，我们说一个函数“转换”或“映射”或“发送”$\textit{x}$到$\textit{y}$，并且对于每个“参数”$\textit{x}$，都有一个$\textit{y}$“假设”或“采取”的唯一值。</p><p> We typically denote a relation or function or transformation or mapping from X onto Y as:</p><p>我们通常将从X到Y的关系或函数或变换或映射表示为：</p><p>  The simples way to see the effect of this definition of a function is with a chart. In  Fig. 1, the left-pane shows a valid function, i.e., each value $\textit{f}(\textit{x})$  maps uniquely onto one value of $\textit{y}$. The right-pane is not a function, since each value $\textit{f}(\textit{x})$  maps onto multiple values of $\textit{y}$.</p><p>查看此函数定义的效果的简单方法是使用图表。在图1中，左窗格显示了一个有效函数，即每个值$\textit{f}(\textit{x})$唯一地映射到一个值$\textit{y}$。右窗格不是函数，因为每个值$\textit{f}(\textit{x})$映射到$\textit{y}$的多个值。</p><p>   For $\textit{f}: \textit{X} \rightarrow \textit{Y}$, the  domain of $\textit{f}$ equals to $\textit{X}$, but the  range does not necessarily equals to $\textit{Y}$. Just recall that the  range includes only the elements for which $\textit{Y}$ has a relation with $\textit{X}$.</p><p>对于$\textit{f}：\textit{X}\right tarrow\textit{Y}$，$\textit{f}$的域等于$\textit{X}$，但范围不一定等于$\textit{Y}$。回想一下，该范围只包括$\textit{Y}$与$\textit{X}$有关系的元素。</p><p> The ultimate goal of machine learning is learning functions from data, i.e., transformations or mappings from the  domain onto the  range of a function. This may sound simplistic, but it’s true. The  domain $\textit{X}$ is usually a vector (or set) of  variables or  features mapping onto a vector of  target values. Finally, I want to emphasize that in machine learning the words transformation and mapping are used interchangeably, but both just mean function.</p><p>机器学习的最终目标是从数据中学习函数，即从领域到函数范围的转换或映射。这听起来可能过于简单化了，但这是真的。域$\textit{X}$通常是映射到目标值向量的变量或特征的向量(或集合)。最后，我想强调的是，在机器学习中，单词转换和映射可以互换使用，但两者都只是表示函数。</p><p> This is all I’ll cover about sets and functions. My goals were just to introduce: (1)  the concept of a set, (2)  basic set notation, (3)  how sets are generated, (4)  how sets allow the definition of functions, (5)  the concept of a function. Set theory is a monumental field, but there is no need to learn everything about sets to understand linear algebra. Halmo’s  Naive set theory (not free, but you can find a copy for ~\$8-$10 US) is a fantastic book for people that just need to understand the most fundamental ideas in a relatively informal manner.</p><p>这就是我将介绍的关于集合和函数的全部内容。我的目标只是介绍：(1)集合的概念，(2)基本集合符号，(3)集合是如何生成的，(4)集合如何允许定义函数，(5)函数的概念。集合论是一个不朽的领域，但要理解线性代数，并不需要学习关于集合的所有知识。Halmo天真的集合论(不是免费的，但你可以花8-10美元找到一本)是一本很棒的书，适合那些只需要以相对非正式的方式理解最基本思想的人。</p><p> # Libraries for this section  import  numpy  as  np import  pandas  as  pd import  altair  as  alt alt . themes . enable ( &#39;dark&#39; )</p><p>#这一部分的图书馆将Numpy作为NP导入熊猫作为PD导入Altair作为ALT。主题。启用(暗色)。</p><p>   Linear algebra is the study of vectors. At the most general level, vectors are  ordered finite lists of numbers. Vectors are the most fundamental mathematical object in machine learning. We use them to  represent attributes of entities: age, sex, test scores, etc. We represent vectors by a bold lower-case letter like $\bf{v}$ or as a lower-case letter with an arrow on top like $\vec{v}$.</p><p>线性代数是研究向量的学科。在最一般的层面上，向量是有序的有限数字列表。向量是机器学习中最基本的数学对象。我们使用它们来表示实体的属性：年龄、性别、考试成绩等。我们使用粗体小写字母(如$\bf{v}$)或顶部带有箭头的小写字母(如$\vec{v}$)来表示向量。</p><p> Vectors are a type of mathematical object that can be  added together and/or  multiplied by a number to obtain another object of  the same kind. For instance, if we have a vector $\bf{x} = \text{age}$ and a second vector $\bf{y} = \text{weight}$, we can add them together and obtain a third vector $\bf{z} = x + y$. We can also multiply $2 \times \bf{x}$ to obtain $2\bf{x}$, again, a vector. This is what we mean by  the same kind: the returning object is still a  vector.</p><p>向量是一种数学对象，可以将它们相加和/或乘以一个数字，以获得另一个同类对象。例如，如果我们有一个向量$\bf{x}=\text{age}$和第二个向量$\bf{y}=\text{weight}$，我们可以将它们相加，得到第三个向量$\bf{z}=x+y$。我们还可以将$2\bf{x}$相乘，得到$2\bf{x}$，也就是向量。这就是我们所说的同类：返回的对象仍然是一个向量。</p><p>  Vectors come in three flavors: (1)  geometric vectors, (2)  polynomials, (3) and  elements of $\mathbb{R^n}$ space. We will defined each one next.</p><p>向量有三种形式：(1)几何向量，(2)多项式，(3)和$\mathbb{R^n}$空间的元素。接下来我们将对每一个进行定义。</p><p>  Geometric vectors are oriented segments. Therse are the kind of vectors you probably learned about in high-school physics and geometry. Many linear algebra concepts come from the geometric point of view of vectors: space, plane, distance, etc.</p><p>几何向量是定向线段。这就是你们可能在高中物理和几何中学到的那种向量。许多线性代数概念都来自于向量的几何观点：空间、平面、距离等。</p><p>    A polynomial is an expression like $f(x) = x^2 + y + 1$. This is, a expression adding multiple “terms” (nomials). Polynomials are vectors because they meet the definition of a vector: they can be added together to get another polynomial, and they can be multiplied together to get another polynomial.</p><p>多项式是类似$f(X)=x^2+y+1$的表达式。这是一个添加多个“术语”(名词)的表达式。多项式之所以是向量，是因为它们符合向量的定义：它们可以相加得到另一个多项式，也可以相乘得到另一个多项式。</p><p>     Elements of $\mathbb{R}^n$ are sets of real numbers. This type of representation is arguably the most important for applied machine learning. It is how data is commonly represented in computers to build machine learning models. For instance, a vector in $\mathbb{R}^3$ takes the shape of:</p><p>$\mathbb{R}^n$的元素是实数集。这种类型的表示可以说是应用机器学习中最重要的。这是数据通常在计算机中表示的方式，以构建机器学习模型。例如，$\mathbb{R}^3$中的一个向量的形状为：</p><p>           There are a couple of “special” vectors worth to remember as they will be mentioned frequently on applied linear algebra: (1) zero vector, (2) unit vector, (3) sparse vectors</p><p>有几个“特殊”的向量值得记住，因为它们在应用线性代数中经常被提及：(1)零向量，(2)单位向量，(3)稀疏向量。</p><p> Zero vectors, are vectors composed of zeros, and zeros only. It is common to see this vector denoted as simply $0$, regardless of the dimensionality. Hence, you may see a 3-dimensional or 10-dimensional with all entries equal to 0, refered as “the 0” vector. For instance:</p><p>零矢量是由零和仅由零组成的矢量。通常可以看到这个向量被简单地表示为$0$，而与维度无关。因此，您可能会看到所有条目都等于0的3维或10维，称为“0”向量。例如：</p><p> Unit vectors, are vectors composed of a single element equal to one, and the rest to zero. Unit vectors are important to understand applications like norms. For instance, $\bf{x_1}$, $\bf{x_2}$, and $\bf{x_3}$ are unit vectors:</p><p>单位向量是由单个元素等于1，其余元素等于0组成的向量。单位向量对于理解规范之类的应用非常重要。例如，$\bf{x_1}$、$\bf{x_2}$和$\bf{x_3}$是单位向量：</p><p> Sparse vectors, are vectors with most of its elements equal to zero. We denote the number of nonzero elements of a vector $\bf{x}$ as $nnz(x)$. The sparser possible vector is the zero vector. Sparse vectors are common in machine learning applications and often require some type of method to deal with them effectively.</p><p>稀疏向量是大多数元素等于零的向量。我们将向量$\bf{x}$的非零元素数记为$nnz(X)$。更稀疏的可能向量是零向量。稀疏向量在机器学习应用中很常见，通常需要某种类型的方法来有效地处理它们。</p><p>  Vectors can have any number of dimensions. The most common are the 2-dimensional cartesian plane, and the 3-dimensional space. Vectors in 2 and 3 dimensions are used often for pedgagogical purposes since we can visualize them as geometric vectors. Nevetheless, most problems in machine learning entail more dimensions, sometiome hundreds or thousands of dimensions. The notation for a vector $\bf{x}$ of arbitrary dimensions, $n$ is:</p><p>向量可以有任意多个维度。最常见的是2维笛卡尔平面和3维空间。二维和三维向量经常用于教学目的，因为我们可以把它们形象化成几何向量。然而，机器学习中的大多数问题都涉及到更多的维度，有时甚至是数百或数千个维度。任意维度的向量$\bf{x}$$n$的符号为：</p><p> Vectors dimensions map into  coordinate systems or perpendicular axes. Coordinate systems have an origin at $(0,0,0)$, hence, when we define a vector:</p><p>向量尺寸映射到坐标系或垂直轴。因此，当我们定义一个向量时，坐标系的原点在$(0，0，0)$：</p><p> we are saying: starting from the origin, move 3 units in the 1st perpendicular axis, 2 units in the 2nd perpendicular axis, and 1 unit in the 3rd perpendicular axis. We will see later that when we have a set of perpendicular axes we obtain the basis of a vector space.</p><p>我们是说：从原点开始，在第一个垂直轴上移动3个单位，在第二个垂直轴上移动2个单位，在第三个垂直轴上移动一个单位。我们稍后会看到，当我们有一组垂直轴时，我们就得到了一个向量空间的基。</p><p>     We used vector-vector addition to define vectors without defining vector-vector addition. Vector-vector addition is an element-wise operation, only defined for vectors of the same size (i.e., number of elements). Consider two vectors of the same size, then:</p><p>我们使用向量-向量相加来定义向量，而没有定义向量-向量相加。向量-向量相加是一种基于元素的运算，仅为相同大小(即元素数量)的向量定义。考虑两个大小相同的向量，然后：</p><p>   Adding the zero vector has no effect: $x + 0 = 0 + x = x$</p><p>添加零向量没有任何效果：$x+0=0+x=x$。</p><p> In  NumPy, we add two vectors of the same with the  + operator or the  add method:</p><p>在NumPy中，我们使用+运算符或Add方法将相同的两个向量相加：</p><p>          Right-distributive property for vector addition: $\alpha (\bf{x} + \bf{y}) = \alpha \bf{x} + \alpha \bf{y}$</p><p>向量加法的右分布性质：$\α(\bf{x}+\bf{y})=\α\bf{x}+\α\bf{y}$。</p><p>      There are only two legal operations with vectors in linear algebra:  addition and  multiplication by numbers. When we combine those, we get a  linear combination.</p><p>在线性代数中，只有两种合法的向量运算：加法和乘法。当我们把它们结合起来，我们得到一个线性组合。</p><p>   Another way to express linear combinations you’ll see often is with summation notation. Consider a set of vectors $x_1, …, x_k$ and scalars $\beta_1, …, \beta_k \in \mathbb{R}$, then:</p><p>您经常看到的另一种表示线性组合的方法是使用求和记数法。考虑一组向量$x_1，…。，x_k$和标量$\Beta_1，…。，\beta_k\in\mathbb{R}$，则：</p><p>  Linear combinations are the most fundamental operation in linear algebra. Everything in linear algebra results from linear combinations. For instance, linear regression is a linear combination of vectors.  Fig. 2 shows an example of how adding two geometrical vectors looks like for intuition.</p><p>线性组合是线性代数中最基本的运算。线性代数中的一切都是线性组合的结果。例如，线性回归是向量的线性组合。图2显示了直观地将两个几何向量相加的示例。</p><p>      We covered vector addition and multiplication by scalars. Now I will define vector-vector multiplication, commonly known as a  dot product or  inner product. The dot product of $\bf{x}$ and $\bf{y}$ is defined as:</p><p>我们用标量讲解了向量的加法和乘法。现在我将定义向量-向量乘法，通常称为点积或内积。$\bf{x}$和$\bf{y}$的点积定义为：</p><p> Where the $T$ superscript denotes the transpose of the vector. Transposing a vector just means to “flip” the column vector to a row vector counterclockwise. For instance:</p><p>其中$T$上标表示向量的转置。转置向量只意味着逆时针将列向量“翻转”为行向量。例如：</p><p> Dot products are so important in machine learning, that after a while they become second nature for practitioners.</p><p>点阵产品在机器学习中非常重要，一段时间后，它们就成了从业者的第二天性。</p><p> To multiply two vectors with dimensions (rows=2, cols=1) in  Numpy, we need to transpose the first vector at using the  @ operator:</p><p>要在Numpy中将两个维度(行=2，列=1)的向量相乘，我们需要使用@运算符转置第一个向量：</p><p>      In its more general form, a  vector space, also known as  linear space, is a collection of objects that follow the rules defined for vectors in $\mathbb{R}^n$. We mentioned those rules when we defined vectors: they can be added together and multiplied by scalars, and return vectors of the same type. More colloquially, a vector space is the set of proper vectors and all possible linear combinatios of the vector set. In addition, vector addition and multiplication must follow these eight rules:</p><p>在其更一般的形式中，向量空间也称为线性空间，是遵循$\mathbb{R}^n$中为向量定义的规则的对象的集合。我们在定义向量时提到了这些规则：它们可以加在一起并与标量相乘，并返回相同类型的向量。更通俗地说，向量空间是由真向量和向量集的所有可能的线性组合组成的集合。此外，向量加法和乘法必须遵循以下八条规则：</p><p> $\forall$ $x$ there is a unique vector $x$ such that $x + -x = 0$</p><p>$\对于所有$$x$，存在唯一的向量$x$，使得$x+-x=0$。</p><p> In my experience remembering these properties is not really important, but it’s good to know that such rules exist.</p><p>根据我的经验，记住这些属性并不重要，但知道存在这样的规则是件好事。</p><p>  Consider the vectors $\bf{x}$ and $\bf{y}$ and the scalars $\alpha$ and $\beta$. If we take  all possible linear combinations of $\alpha \bf{x} + \beta \bf{y}$ we would obtain the  span of such vectors. This is easier to grasp when you think about geometric vectors. If our vectors $\bf{x}$ and $\bf{y}$ point into  different directions in the 2-dimensional space, we get that the $span(x,y)$ is equal to  the entire 2-dimensional plane, as shown in the middle-pane in  Fig. 5. Just imagine having an unlimited number of two types of sticks: one pointing vertically, and one pointing horizontally. Now, you can reach any point in the 2-dimensional space by simply combining the necessary number of vertical and horizontal sticks (including taking fractions of sticks).</p><p>考虑向量$\bf{x}$和$\bf{y}$以及标量$\pha$和$\beta$。如果我们取$\α\bf{x}+\β\bf{y}$的所有可能的线性组合，我们就可以得到这些向量的跨度。当你考虑几何向量时，这一点更容易理解。如果我们的向量$\bf{x}$和$\bf{y}$指向2维空间中的不同方向，我们得到$span(x，y)$等于整个2维平面，如图5的中间窗格所示。想象一下有无限数量的两种类型的棍子：一种指向垂直，另一种指向水平。现在，你可以通过简单地组合必要数量的竖直和水平棍子(包括取一些棍子)来到达2维空间中的任何一点。</p><p>   What would happen if the vectors point in the same direction? Now, if you combine them, you just can  span a line, as shown in the left-pane in  Fig. 5. If you have ever heard of the term “multicollinearity”, it’s closely related to this issue: when two variables are “colinear” they are pointing in the same direction, hence they provide redundant information, so can drop one without information loss.</p><p>如果向量指向相同的方向，会发生什么？现在，如果你把它们结合起来，你只需要跨越一条线，如图5的左窗格所示。如果你听说过“多重共线性”这个术语，它与这个问题密切相关：当两个变量“共线”时，它们指向同一个方向，因此它们提供了冗余信息，因此可以在不丢失信息的情况下丢弃一个变量。</p><p> With three vectors pointing into different directions, we can span the entire 3-dimensional space or a  hyper-plane, as in the right-pane of  Fig. 5. Note that the sphere is just meant as a 3-D reference, not as a limit.</p><p>有了三个指向不同方向的矢量，我们就可以跨越整个3维空间或一个超平面，如图5的右窗格所示。请注意，球体只是一个3-D参考，而不是一个限制。</p><p> Four vectors pointing into different directions will span the 4-dimensional space, and so on. From here our geometrical intuition can’t help us. This is an example of how linear algebra can describe the behavior of vectors beyond our basics intuitions.</p><p>指向不同方向的四个向量将跨越4维空间，以此类推。从这里看，我们的几何直觉帮不了我们。这是一个例子，说明了线性代数如何超越我们的基本直觉来描述向量的行为。</p><p>  A  vector subspace (or linear subspace) is a vector space that lies within a larger vector space. These are also known as linear subspaces. Consider a subspace $S$. For a vector to be a valid subspace it has to meet  three conditions:</p><p>向量子空间(或线性子空间)是位于较大向量空间内的向量空间。这些也称为线性子空间。考虑一个子空间$S$。要使一个向量成为有效的子空间，它必须满足三个条件：</p><p>  Intuitively, you can think in closure as being unable to “jump out” from space into another. A pair of vectors laying flat in the 2-dimensional space, can’t, by either addition or multiplication, “jump out” into the 3-dimensional space.</p><p>直觉上，你可以认为闭合是不能从太空“跳出”到另一个太空的。一对平放在2维空间中的向量，无论是通过加法还是乘法，都不能“跳出”到3维空间。</p><p>   Consider the following questions: Is $\bf{x}=\begin{bmatrix} 1 \ 1 \end{bmatrix}</p><p>考虑以下问题：是$\bf{x}=\Begin{bMatrix}1\1\end{bMatrix}。</p><p>......</p><p>.</p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://pabloinsente.github.io/intro-linear-algebra">https://pabloinsente.github.io/intro-linear-algebra</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/python/">#python</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/应用/">#应用</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/linear/">#linear</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/向量/">#向量</a></button></div></div><div class="shadow p-3 mb-5 bg-white rounded clearfix"><div class="container"><div class="row"><div class="col-sm"><div><a target="_blank" href="/story/1034012.html"><img src="http://img2.diglog.com/img/2020/11/thumb_a270829c58d97b90ea892ae979fa861b.jpg" class="img-fluid" onerror="this.style.display='none'"></a></div><div class="item_title"><a target="_blank" href="/story/1034012.html">重头开始的Python并发性(2015)[视频]</a></div><span class="my_story_list_date">2020-11-9 20:56</span></div><div class="col-sm"><div><a target="_blank" href="/story/1033930.html"><img src="http://img2.diglog.com/img/2020/11/thumb_3a1be40609f8294f8c760a1e36d336a5.png" class="img-fluid" onerror="this.style.display='none'"></a></div><div class="item_title"><a target="_blank" href="/story/1033930.html">避免Bash受挫-将Python用于Shell脚本</a></div><span class="my_story_list_date">2020-11-9 4:51</span></div><div class="col-sm"><div><a target="_blank" href="/story/1033316.html"><img src="http://img2.diglog.com/img/2020/11/thumb_21f8be35cef4397449ea9dd55e0aa657.jpg" class="img-fluid" onerror="this.style.display='none'"></a></div><div class="item_title"><a target="_blank" href="/story/1033316.html">Python取代Java成为第二大最受欢迎的编程语言</a></div><span class="my_story_list_date">2020-11-5 20:25</span></div><div class="col-sm"><div><a target="_blank" href="/story/1032893.html"><img src="http://img2.diglog.com/img/2020/11/thumb_64d2ec6863c7815afccdaaa0cf416c51.png" class="img-fluid" onerror="this.style.display='none'"></a></div><div class="item_title"><a target="_blank" href="/story/1032893.html">使用VizTracer可视化Python代码执行</a></div><span class="my_story_list_date">2020-11-3 10:14</span></div></div></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/美国/">#美国</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/谷歌/">#谷歌</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/linux/">#linux</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/程序/">#程序</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy; 2020 diglog.com </div></div></body></html>