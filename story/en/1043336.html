<!doctype html><html lang="zh-hans"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>RISC-V向量指令与ARM和x86 SIMD的比较 RISC-V Vector Instructions vs. ARM and x86 SIMD</title><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link rel="stylesheet" href="/img/css.css?random="><link data-rh="true" rel="icon" href="/img/favicon.ico"/><script data-ad-client="ca-pub-6067137220025946" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5effb96910009800120b8d4d&product=inline-share-buttons" async="async"></script>
<script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "https://hm.baidu.com/hm.js?03c1a0f31299b4a2fbb83c34d6beaac9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script></head><body><div id="my_header"><div class="container"><nav class="navbar navbar-expand-lg"><a class="navbar-brand" href="/"><img alt="diglog" src="/img/logo.v1.gif" class="rounded-sm"></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavAltMarkup"><div class="navbar-nav"></div></div></nav></div></div><div class="container"><div id="my_content"><h1 class="page_narrow">RISC-V Vector Instructions vs. ARM and x86 SIMD<br/>RISC-V向量指令与ARM和x86 SIMD的比较 </h1><div class="row"><div class="col-lg-12 col-12"><div class="my_story_list_item shadow p-3 mb-5 bg-white rounded"><div class="story_page_pub_time page_narrow">2021-01-05 14:10:42</div><div class="story_img_container"><a href="http://img2.diglog.com/img/2021/1/4811dd26a06d13b1d219c524896a13e7.jpeg"><img src="http://img2.diglog.com/img/2021/1/4811dd26a06d13b1d219c524896a13e7.jpeg" class="img-fluid my_story_img" onerror="this.style.display='none'"></a></div><div class="page_narrow text-break page_content"><p>Is old Cray-1 style vector machines coming back? What exactly is the difference between vector instructions and modern SIMD instructions?</p><p>旧的Cray-1型矢量机还会回来吗？向量指令和现代SIMD指令之间到底有什么区别？</p><p>  In the 1980s, super-computers looked like what you see in the image below. The semi-circular shape of a  Cray was synonymous with super computers in the 80s. That was just what a super computer looked like.</p><p>  在1980年代，超级计算机的外观如下图所示。 Cray的半圆形是80年代超级计算机的代名词。那就是一台超级计算机的样子。</p><p>  What does this bygone era of supercomputing have to do with RISC-V? You see, Cray computers where what we call vector processing machines. Something that has long been considered a relic of the past.</p><p>  过去的超级计算时代与RISC-V有什么关系？您会看到Cray计算机，我们称之为矢量处理机。早已被视为过去的遗物。</p><p> Yet RISC-V is bringing Cray style vector processing back, even insisting it should replace SIMD (Single Instruction Multiple Data). Heresy?</p><p> 然而，RISC-V甚至坚持认为它应该替代SIMD（单指令多数据），从而将Cray风格的矢量处理重新带回来。异端？</p><p> Such a bold and different strategy surely needs some explanation. Why are RISC-V designers taking a completely different route from their competitors x86, ARM, MIPS and others?</p><p> 这样大胆而又不同的策略肯定需要一些解释。为什么RISC-V设计师采用与竞争对手x86，ARM，MIPS等完全不同的方法？</p><p> As usual we need a little detour to explain what exactly these technologies are and how they are different. Despite SIMD instructions coming last, I believe it is easier to grasp vector processing instructions by beginning with SIMD.</p><p> 像往常一样，我们需要绕道而行，以解释这些技术究竟是什么以及它们有何不同。尽管SIMD指令排在最后，但我相信从SIMD开始更容易掌握矢量处理指令。</p><p>  Most microprocessors whether x86 or ARM based provide what we call SIMD instructions in the microprocessors. You may have heard of MMX, SSE, AVX-2 and AVX-512. ARM has their own called Advanced SIMD and SVE.</p><p>  无论是基于x86还是基于ARM的大多数微处理器都在微处理器中提供了我们所谓的SIMD指令。您可能听说过MMX，SSE，AVX-2和AVX-512。 ARM有自己的高级SIMD和SVE。 </p><p> What these instructions allow you to do is to apply the same operation to multiple elements. We can contrast this with SISD (Single Instruction Single Data), where an operation is only performed between single elements. The diagram below is a simple illustration of this:</p><p>这些说明允许您执行的操作是将相同的操作应用于多个元素。我们可以将其与SISD（单指令单数据）进行对比，后者仅在单个元素之间执行操作。下图是对此的简单说明：</p><p>  We can write some simple code to illustrate the difference, below is an example of SISD. We can also call it operations on scalars (single values):</p><p>  我们可以编写一些简单的代码来说明差异，以下是SISD的示例。我们也可以称其为标量（单个值）上的操作：</p><p>   [3, 2, 1] + [1, 2, 2] = [4, 4, 3] [3, 2, 1] - [1, 2, 2] = [2, 0, -1]</p><p>   [3，2，1] + [1,2,2] = [4，4，3] [3，2，1]-[1,2,2] = [2，0，-1]</p><p> Let me get more concrete with some pseudo assembly code for doing SISD. In this case we want to add two arrays with two elements each. Each element is a 32 bit integer. One starts at address 14, and the other at address 24:</p><p> 让我更详细地了解一些用于执行SISD的伪汇编代码。在这种情况下，我们要添加两个数组，每个数组包含两个元素。每个元素都是32位整数。一个从地址14开始，另一个从地址24开始：</p><p> load r1, 14 load r2, 24 add r3, r1, r2 ; r3 ← r1 + r2  load r1, 18 load r2, 28 add r4, r1, r2 ; r4 ← r1 + r2</p><p> 负载r1，14负载r2，24加r3，r1，r2; r3←r1 + r2负载r1，18负载r2，28加r4，r1，r2; r4←r1 + r2</p><p>   It is common to prefix vector and SIMD instructions with a  v to separate them from scalar instructions. Conventions varies but this is inspired by ARM, where the  .32 suffix means we are loading in multiple 32-bit values. Assuming our vector registers  v1 and  v2 are 64-bit, then that means two elements are loaded each time.</p><p>   通常在向量和SIMD指令前加上v前缀，以将它们与标量指令分开。约定有所不同，但这是受ARM启发的，后缀.32表示我们正在加载多个32位值。假设向量寄存器v1和v2是64位的，则意味着每次都加载两个元素。</p><p> The  vadd instruction has the  .i32 suffix to indicate that we are adding 32-bit signed integer numbers. We could have used  .u32 to indicate unsigned integers.</p><p> vadd指令的后缀为.i32，表示我们要添加32位带符号整数。我们本可以使用.u32表示无符号整数。 </p><p> Of course this is an entirely unrealistic example, as nobody would use SIMD for that few elements. More realistic we would operate on 16 elements.</p><p>当然，这是一个完全不现实的示例，因为没有人会对这几个元素使用SIMD。更现实的是，我们将对16个元素进行操作。</p><p>  Ok we have a high level description of how SIMD instructions work. But in practical terms how are they handled at the CPU level? What is going on inside a CPU when it performs SIMD instructions?</p><p>  好的，我们对SIMD指令的工作方式进行了高级描述。但是实际上，它们是如何在CPU级别处理的？执行SIMD指令时，CPU内部发生了什么？</p><p>  Don’t worry if you don’t want to bury yourself in my microprocessor article. We will to a short version here skipping some details. Below you see a very simplified diagram of a RISC microprocessor.</p><p>  如果您不想把自己埋在我的微处理器文章中，请不要担心。我们将在此处略过一些版本，以跳过一些详细信息。在下面，您可以看到RISC微处理器的简化图。</p><p>  You can think of the colored bars as pipes for pushing data through to different parts of the CPU. Our main interest here is the blue ones which push the data we operate on as well as instructions through the system. The green pipes are address locations for memory cells.</p><p>  您可以将彩色条视为将数据推入CPU的不同部分的管道。我们在这里的主要兴趣是蓝色的东西，它们推动了我们操作的数据以及通过系统的指令。绿色管道是存储单元的地址位置。</p><p>  In a simple microprocessor you only have one single Arithmetic Logic Unit (ALU). An example of such a processor would be the 6502, used in Commodore 64. The ALU is like the calculator of the CPU. It can add and subtract numbers. It takes two numbers as input, and then add or subtract them and spit the output out at the bottom. Inputs comes from register and output goes back to a register (memory cells with holding numbers you operate on).</p><p>  在一个简单的微处理器中，您只有一个算术逻辑单元（ALU）。这种处理器的一个例子是在Commodore 64中使用的6502。ALU就像CPU的计算器一样。它可以加减数字。它使用两个数字作为输入，然后将它们相加或相减并将输出吐到底部。输入来自寄存器，输出返回到寄存器（具有您要操作的保持编号的内存单元）。</p><p> To turn our CPU into a SIMD executing monster that can chew through dozens of numbers at the same time, we need to make some changes. Below is a simplified example of an upgrade that allows the addition to two numbers at the same time. Please note we are only showing the part related to the registers and ALUs.</p><p> 要将我们的CPU变成可以同时咀嚼数十个数字的执行SIMD的怪物，我们需要进行一些更改。以下是升级的简化示例，该升级允许同时将两个数字相加。请注意，我们仅显示与寄存器和ALU相关的部分。</p><p>  v1,  v2 and  v3 are what we call vector registers. They are chunked into different parts shown as  v1₀ and  v1₁. We can feed each part, or element of the vector, into a separate ALU. This allows us to perform multiple additions at the same time. For a real CPU, we don&#39;t just add one extra ALUs. We add a dozen. Actually we get more crazy. We add a dozen multipliers and other functional units capable of doing all the different operations of a CPU. For very simple CPUs you don&#39;t have multipliers because you can simulate multiplication through repeated additions and shifts (adding and removing digits).</p><p>  v1，v2和v3是我们所谓的向量寄存器。它们被分为不同的部分，分别显示为v1₀和v1₁。我们可以将向量的每个部分或元素输入到单独的ALU中。这使我们可以同时执行多个添加。对于真正的CPU，我们不只是添加一个额外的ALU。我们加一打。实际上，我们变得更加疯狂。我们添加了十二个乘法器和其他功能单元，它们能够执行CPU的所有不同操作。对于非常简单的CPU，您没有乘法器，因为您可以通过重复的加法和移位（加和减数字）来模拟乘法。 </p><p>  So how did these SIMD instructions come about? The need for fast image processing was the starting point. Each pixel in an image is made up of four 8-bit values (RGBA) which needs to be treated as separate numbers. It is slow to add those values separately for millions of pixels. SIMD instructions was an obvious way to boost performance of such tasks.</p><p>那么这些SIMD指令是如何产生的呢？快速图像处理的需求是起点。图像中的每个像素由四个8位值（RGBA）组成，需要将其视为单独的数字。为数百万个像素分别添加这些值很慢。 SIMD指令是提高此类任务性能的明显方法。</p><p>  SIMD is also used inside GPUs as they will add position vectors, multiply matrices. Composite pixel color values etc.</p><p>  SIMD还用于GPU内部，因为它们会添加位置向量，相乘矩阵。复合像素颜色值等</p><p>  It is difficult to parallelize the execution of code. But performing the same operation on multiple elements of data is fairly straight forward when dealing with things such as images, geometry, machine learning and a lot of scientific computing.</p><p>  很难并行执行代码。但是，当处理诸如图像，几何，机器学习和大量科学计算之类的事情时，对数据的多个元素执行相同的操作相当简单。</p><p> SIMD thus gives us a way of easily speeding up these calculations. If you can e.g. add 8 numbers by just executing 1 instruction, then you basically have a 8x speedup. Hence it is not surprising that x86 and ARM microprocessors have piled on a ton of SIMD instructions over the years.</p><p> 因此，SIMD为我们提供了一种轻松加快这些计算速度的方法。如果可以的话只需执行1条指令即可将8个数字相加，则基本上可以实现8倍的加速。因此，多年来x86和ARM微处理器堆积在大量的SIMD指令上就不足为奇了。</p><p> And GPUs basically contain a bucket load of cores doing lots of SIMD computation. This is what has increased graphics performance a lot and why scientific code is increasingly using GPUs.</p><p> GPU基本上包含执行大量SIMD计算的核心存储区。这就是大大提高了图形性能的原因，也是为什么科学代码越来越多地使用GPU的原因。</p><p> But if SIMD is so awesome, why are the RISC-V ditching it and going for Vector processing instead? Or more specifically instead of adding a SIMD instruction-set extension, they are adding a Vector instruction-set extension.</p><p> 但是，如果SIMD如此出色，为什么RISC-V放弃它并进行向量处理呢？更具体地说，他们没有添加SIMD指令集扩展，而是添加了Vector指令集扩展。</p><p>   It is an interesting read, but it gets into a lot more technical depth than I will here. Patterson and Waterman describe the problem:</p><p>   这是一本有趣的文章，但是它比我在这里更深入地介绍了技术。 Patterson和Waterman描述了问题： </p><p> Like an opioid, SIMD starts off innocently enough. An architect partitions the existing 64-bit registers and ALU into many 8-, 16-, or 32-bit pieces and then computes on them in parallel. The opcode supplies the data width and the operation. Data transfers are simply loads and stores of a single 64-bit register. How could anyone be against that?</p><p>就像阿片类药物一样，SIMD的起点足够纯净。架构师将现有的64位寄存器和ALU分为许多8位，16位或32位块，然后对其并行进行计算。操作码提供数据宽度和操作。数据传输只是单个64位寄存器的加载和存储。谁会反对呢？</p><p>  The IA-32 instruction set has grown from 80 to around 1400 instructions since 1978, largely fueled by SIMD.</p><p>  自1978年以来，IA-32指令集已从80条增加到大约1400条，主要是由SIMD推动的。</p><p> For this reason the specifications and manuals for x86 and ARM are enormous. In contrast you can get an overview of all the most important RISC-V instructions on a single double sided sheet of paper. This has implications for those creating the chips in silicon as well as those making assemblers and compilers. Support for SIMD instruction often get added late.</p><p> 因此，x86和ARM的规范和手册非常庞大。相反，您可以在一张双面纸上获得所有最重要的RISC-V指令的概述。这对于那些用硅制造芯片的人以及那些制造汇编器和编译器的人有影响。对SIMD指令的支持通常会在以后添加。</p><p> The designers of RISC-V wants a practical CPU instruction-set which can be used for teaching for a long time. E.g. until RISC-V they used MIPS which stopped being important in the industry long time ago. Academia prefers to not base their teaching on fads and hypes of the industry. Universities emphasize teaching knowledge with long durability. That is why they are more likely to teach to data structures and algorithm rather than say how to use a debugging tool or and IDE.</p><p> RISC-V的设计者希望有一个实用的CPU指令集，该指令集可用于长时间教学。例如。直到RISC-V，他们才使用MIPS，而MIPS在很久以前就不再在业界中占有重要地位。学术界不希望其教学基于行业的时尚和炒作。大学强调教学知识的持久性。这就是为什么他们更愿意讲授数据结构和算法，而不是说如何使用调试工具或IDE。</p><p> Thus SIMD as it has developed is untenable. There are new instructions every few years. Nothing is very durable. Thus Patterson and Waterman argue:</p><p> 因此，SIMD的发展是站不住脚的。每隔几年就会有新的说明。没有什么是非常耐用的。因此，帕特森和沃特曼认为：</p><p> An older and, in our opinion, more elegant alternative to exploit data-level parallelism is vector architectures. Vector computers gather objects from main memory and put them into long, sequential vector registers.</p><p> 向量架构是一种较旧的，更优雅的利用数据级并行性的替代方法。向量计算机从主存储器中收集对象，并将其放入顺序的长向量寄存器中。</p><p>  So the RISC-V designers have created an extension with vector instructions instead of SIMD instructions. But if this is so much better, why did it not happen earlier and why did vector processing fall out of favor in the past?</p><p>  因此，RISC-V设计人员使用矢量指令而不是SIMD指令创建了扩展。但是，如果这样好得多，为什么它没有更早发生，为什么矢量处理在过去就不受欢迎了？ </p><p> Before we can answer any of that, we need to actually understand what vector processing is.</p><p>在回答任何一个问题之前，我们需要实际了解什么是向量处理。</p><p>  The best way of understanding the difference is by looking at some C/C++ code. In SIMD the vector are fixed size and treated as fixed length types like this:</p><p>  理解差异的最好方法是查看一些C / C ++代码。在SIMD中，向量是固定大小的，并被视为固定长度类型，如下所示：</p><p> struct Vec3 {  int x0;  int x1;  int x2; };  struct Vec4 {  int x0;  int x1;  int x2;  int x4; };</p><p> struct Vec3 {int x0;整数x1;整数x2; }; struct Vec4 {int x0;整数x1;整数x2; int x4; };</p><p>  Vec3 vadd3(Vec3 v1, Vec3 v2) {  return Vec3(v1.x0 + v2.x0,  v1.x1 + v2.x1,  v1.x2 + v2.x2); }</p><p>  Vec3 vadd3（Vec3 v1，Vec3 v2）{返回Vec3（v1.x0 + v2.x0，v1.x1 + v2.x1，v1.x2 + v2.x2）; }</p><p> We can think of  Vec3,  Vec4 and  vadd3 as existing in hardware. Developers however want higher level functionality and may compose these operations to create more general purpose functions:</p><p> 我们可以认为Vec3，Vec4和vadd3已存在于硬件中。但是，开发人员需要更高级别的功能，并且可以组合以下操作以创建更多通用功能：</p><p> void vadd(int v1[], int v2[], int n, int v3[]) {  int i = 0;  while (i &lt; n) {  u = Vec3(v1[i], v1[i+1], v1[i+3]);  v = Vec3(v2[i], v2[i+1], v2[i+3]);    w = vadd3(u, v); // Efficient vector operation    v3[i] = w.x0;  v3[i+1] = w.x1;  v3[i+2] = w.x2;   i += 3;  } }</p><p> void vadd（int v1 []，int v2 []，int n，int v3 []）{int i = 0;而（i＆lt; n）{u = Vec3（v1 [i]，v1 [i + 1]，v1 [i + 3]）; v = Vec3（v2 [i]，v2 [i + 1]，v2 [i + 3]）; w = vadd3（u，v）; //有效的向量运算v3 [i] = w.x0; v3 [i + 1] = w.x1; v3 [i + 2] = w.x2;我+ = 3; }}</p><p> You can think of this a bit as pseudo-code. The point to get across is that you can build functionality to process vectors of any length upon functions which processes smaller fixed length vectors.</p><p> 您可以将其视为伪代码。要了解的一点是，您可以在处理较小固定长度向量的函数上构建功能来处理任何长度的向量。 </p><p> Vector processing as was done with old Cray super computers and which essentially is what the RISC-V guys are proposing is to put functions such as  vadd into hardware.</p><p>像使用老式Cray超级计算机一样进行矢量处理，这实际上是RISC-V人士提出的，就是将诸如vadd之类的功能放入硬件中。</p><p>   It means internally we still got SIMD units that operate on some fixed width vectors. However that is not what the assembly programmers sees. Instead just like with  vadd the assembly code instructions are not tied to specific vector lengths. There are special status and control registers (CSR) which the programmer can set to the length of the vector he or she is operating on. This is kind of similar to how  vadd takes the  n argument specifying the length of the vector.</p><p>   这意味着在内部，我们仍然可以在某些固定宽度矢量上运行SIMD单元。但这不是汇编程序员所看到的。相反，就像使用vadd一样，汇编代码指令也不依赖于特定的向量长度。程序员可以将特殊的状态和控制寄存器（CSR）设置为他或她正在操作的向量的长度。这有点类似于vadd如何使用n参数指定向量的长度。</p><p> Instead we got some really long vectors. Significantly longer than the vector registers used by SIMD instructions. It could be hundreds of elements that could fit. It is not practical to create ALUs and multipliers for every one of these elements as we do with SIMD style vector registers.</p><p> 相反，我们得到了一些很长的向量。比SIMD指令使用的向量寄存器长得多。可能有数百个合适的元素。像我们对SIMD样式矢量寄存器所做的那样，为这些元素的每一个创建ALU和乘法器是不切实际的。</p><p>  Instead what happens when the CPU reads a  vadd function is it starts looping over these large registers just like we did in the pseudo code example. Here is a code example:</p><p>  相反，当CPU读取vadd函数时会发生什么，就像我们在伪代码示例中所做的那样，它开始循环访问这些大寄存器。这是一个代码示例：</p><p> vsetlen r1 , 16, 120 ; 120 element vector. Each element 16-bit vload v1, 14 ; Load 120 elements start at address 14 vload v2, 134 ; Load elements starting at address 123 vadd v3, v1, v2 ; Add all 120 elements. vstore v3, 254 ; Store result at address 254</p><p> vsetlen r1，16，120; 120个元素向量。每个元素16位vload v1，14;负载120个元素从地址14开始vload v2，134;从地址123开始的加载元素vadd v3，v1，v2;添加所有120个元素。 vstore v3，254;将结果存储在地址254</p><p> Before performing operations one has to configure the vector processor, by setting the number of elements in a vector and the size and type of each element. In this example I made it simple. We are always dealing with signed integers. But in a real system you have to be able to specify whether you are dealing with floating point number and signed or unsigned integers.</p><p> 在执行操作之前，必须通过设置向量中元素的数量以及每个元素的大小和类型来配置向量处理器。在此示例中，我将其简化。我们一直在处理带符号整数。但是在实际系统中，您必须能够指定要处理的是浮点数以及带符号或无符号整数。</p><p> What  vload does depends on the configuration. In this case we will load 120 elements, each 16-bit wide from memory.</p><p> vload的作用取决于配置。在这种情况下，我们将加载120个元素，每个元素距离内存16位宽。 </p><p> vadd iterates over all 120 elements in both the  v1 and  v2 vector register. Each element is added and result written to register  v3. To better understand how this works, let us talk about about the number of clock cycles involved.</p><p>vadd遍历v1和v2向量寄存器中的所有120个元素。每个元素都会添加，并将结果写入寄存器v3。为了更好地了解它是如何工作的，让我们讨论一下所涉及的时钟周期数。</p><p> A clock cycle is what a microprocessor needs to perform one simple task. It could be one clock cycle to decode an instruction, one to add two numbers. More complex operations such as multiplication could take multiple clock cycles.</p><p> 时钟周期是微处理器执行一项简单任务所需要的。解码指令可能需要一个时钟周期，一个指令要添加两个数字。诸如乘法之类的更复杂的操作可能需要多个时钟周期。</p><p> Say behind the scenes we got four ALUs. Thus we can perform four additions every clock cycle. That means  vadd will require 30 clock cycles to complete:</p><p> 在后台说，我们有四个ALU。因此，我们可以在每个时钟周期执行四个加法运算。这意味着vadd将需要30个时钟周期才能完成：</p><p>  This may not sound great. Why not do the same directly using an assembly program that loops and performs these SIMD instructions directly. Why implement in hardware something that has to be done in an iteration anyway?</p><p>  这听起来可能不太好。为什么不使用直接循环并直接执行这些SIMD指令的汇编程序直接执行相同的操作。为什么要在硬件中实施必须迭代执行的操作？</p><p>  One major benefit is that we need much smaller programs. We don’t need to write programs with multiple loads, comparisons and loops.</p><p>  一个主要的好处是我们需要小得多的程序。我们不需要编写具有多个加载，比较和循环的程序。</p><p> Patterson and Waterman make an example program for comparison in their article:  SIMD Instructions Considered Harmful. Here is their observation of difference in program size:</p><p> Patterson和Waterman在他们的文章“ SIMD指令被认为有害”中提供了一个示例程序进行比较。这是他们对程序大小差异的观察：</p><p> Two-thirds to three-fourths of the code for MIPS-32 MSA and IA-32 AVX2 is SIMD overhead, either to prepare the data for the main SIMD loop or to handle the fringe elements when n is not a multiple of the number of floating-point numbers in a SIMD register.</p><p> MIPS-32 MSA和IA-32 AVX2的代码的三分之二至四分之三是SIMD开销，用于为主SIMD循环准备数据或在n不等于n的倍数时处理边缘元素。 SIMD寄存器中的浮点数。 </p><p> But more importantly with vector instructions you don’t have to keep decoding the same instructions repeatedly. Performing repeated conditional branching etc. In the code examples Patterson and Waterman are using they remark that the SIMD programs require 10 to 20 times more instructions to be executed compared to the RISC-V version using vector instructions.</p><p>但是更重要的是，对于矢量指令，您不必继续重复解码相同的指令。执行重复的条件分支等。在代码示例中，Patterson和Waterman使用它们来表示，与使用矢量指令的RISC-V版本相比，SIMD程序需要执行的指令多10至20倍。</p><p> The reason being that a SIMD loop only process 2 to 4 elements on each iteration. In the vector code, one assumes the hardware supports vector registers with 64 elements. Thus batches of 64 elements are handled on each iteration, cutting down on the number of times one needs to iterate.</p><p> 原因是SIMD循环每次迭代仅处理2到4个元素。在矢量代码中，假定硬件支持具有64个元素的矢量寄存器。因此，每次迭代处理了64个元素的批处理，从而减少了需要迭代的次数。</p><p> The max vector length can be queried at runtime, so one does not need to hardcode 64 element long batch sizes.</p><p> 可以在运行时查询最大向量长度，因此不需要对64个元素的大批量大小进行硬编码。</p><p> Decoding fewer instructions reduce power usage as decoding and fetching consume a fair amount of power.</p><p> 解码较少的指令会减少功耗，因为解码和获取会消耗大量功耗。</p><p> In addition we achieve what all good interface design should strive towards: Hiding implementation details. Why is that important? Look at USB plugs? We love it when USB standard increase performance without physically changing the plug.</p><p> 此外，我们实现了所有好的界面设计应努力实现的目标：隐藏实现细节。为什么这么重要？看看USB插头吗？当USB标准无需物理改变插头即可提高性能时，我们会喜欢它。</p><p>  When chip technology improves you are allowed to use more transistors. You can use this to add more ALUs and multiplier to handle more vector elements in parallel. For CPUs with SIMD instructions that means adding a couple of hundred new instructions for the new vector lengths you can now handle.</p><p>  随着芯片技术的改进，您可以使用更多的晶体管。您可以使用它来添加更多的ALU和乘数，以并行处理更多的矢量元素。对于具有SIMD指令的CPU，这意味着您现在可以处理数百条针对新矢量长度的新指令。</p><p> Programs will have to be recompiled to handle these newly added long vectors to get a performance boost. With the RISC-V approach that is not necessary. The code looks the same. Only thing changing is that  vadd will finish in fewer cycles because it has a larger SIMD unit allowing it to process a larger batch of elements each clock cycle.</p><p> 必须重新编译程序才能处理这些新添加的长向量，以提高性能。使用RISC-V方法是没有必要的。代码看起来一样。唯一的变化是vadd将在更少的周期内完成，因为它具有更大的SIMD单元，从而使其可以在每个时钟周期内处理更大数量的元素。 </p><p>  Here is a piece of the puzzle I don’t think David Patterson have explained that well in his previous writing. Cray vector processing machines basically died out.</p><p>我想大卫·帕特森（David Patterson）在先前的著作中没有很好地解释这是一个难题。克雷矢量处理机基本上已经淘汰了。</p><p>  To understand why, we need to understand tradeoffs. If you want to transport a maximum amount of cargo from A to B, you can basically do it in two ways. Use a racing car to drive fast back and forth with small quantities of cargo.</p><p>  要了解原因，我们需要了解权衡。如果您想将最大数量的货物从A运到B，则基本上可以采用两种方式。使用赛车以少量货物来回快速行驶。</p><p> Or you can use a large slow moving truck which can haul a large amount of cargo but which move slowly.</p><p> 或者，您可以使用大型的缓慢移动的卡车，该卡车可以拖运大量货物但移动缓慢。</p><p>  Most general purpose software is best served by a racing car. General purpose programs are not easily serializable. What data they need depends on instructions executed. There are all sort of conditional branches and random access of memory to take into account. You simply cannot pick up a lot of cargo (data) on each visit to the warehouse (memory) because you don’t know what will be required further down the line.</p><p>  大多数通用软件最好由赛车提供。通用程序不容易序列化。他们需要什么数据取决于执行的指令。有各种各样的条件分支和对内存的随机访问要考虑在内。每次访问仓库（内存）时，您根本无法拿起很多货物（数据），因为您不知道接下来需要做什么。</p><p> Thus general purpose microprocessors tend to have large fast memory caches, so the CPU can quickly get what it needs when it needs it (racing car analogy).</p><p> 因此，通用微处理器往往具有较大的快速内存缓存，因此CPU可以在需要时快速获得所需的信息（与汽车类似）。</p><p> Vector processor in contrast work much like GPUs. They did not deal with general purpose programs. Usually they where used for scientific software such as weather simulations where you need large amounts of data which can be processed in parallel. GPUs likewise can process lots of pixels or coordinates in parallel.</p><p> 相反，矢量处理器的工作方式与GPU非常相似。他们没有处理通用程序。通常，它们用于科学软件，例如天气模拟，您需要大量可以并行处理的数据。 GPU同样可以并行处理大量像素或坐标。</p><p> Thus you don’t need to move fast, because you can pick up huge chunks of data each time. Thus GPUs and Vector machines typically have low clock frequency and small caches. Instead their memory system is setup to fetch a lot of data in parallel. In other words, they move data like a truck moves cargo. A lot at a time, but slowly.</p><p> 因此，您无需快速移动，因为每次都可以拾取大量数据。因此，GPU和矢量机通常具有较低的时钟频率和较小的缓存。相反，他们的内存系统设置为并行获取大量数据。换句话说，它们像卡车一样移动货物来移动数据。一次很多，但是很慢。 </p><p> Vector machines actually have data in pipelines because it is very predictable what the next data needed will be.</p><p>向量机实际上在管道中具有数据，因为可以预测下一个数据是什么。</p><p>  Sure you could up the clock frequency of vector processors and give them fat caches, but what is the point when you got much better choices available? All the transistors you don’t spend on cache you can use to expand ability to process more elements in parallel. Also watt usage and heath doesn’t grow linearly with clock frequency. It grows much faster. Thus to keep thermal budget down it pays to keep clock frequency low.</p><p>  当然，您可以提高矢量处理器的时钟频率，并为它们提供大量的高速缓存，但是，当您获得更多更好的选择时，又有什么意义呢？您不用花在缓存上的所有晶体管，就可以用来扩展并行处理更多元素的能力。而且，瓦特的使用和健康状况不会随时钟频率线性增长。它增长更快。因此，要降低热预算，就必须保持时钟频率较低。</p><p> If you look at the ET-SoC-1 solution from Esperanto Technologies you see all of these tradeoffs taken into consideration. Their SoC is about the same size as Apple’s M1 SoC in terms of number of transistors. Yet a vector processing core require a lot less silicon because we are not aiming for high single thread performance. The M1 Firestorm cores are fat beasts because they ned a lot of transistors to implement Out-of-Order Execution (OoOE), branch prediction, deep pipelines and many other things to get single thread performance to scream.</p><p> 如果查看Esperanto Technologies的ET-SoC-1解决方案，您会发现所有这些折衷考虑在内。就晶体管数量而言，它们的SoC大小与Apple的M1 SoC相同。然而，矢量处理内核所需的硅要少得多，因为我们的目标不是高单线程性能。 M1 Firestorm核心是肥兽，因为它们使用了许多晶体管来实现乱序执行（OoOE），分支预测，深层流水线和许多其他功能，以使单线程性能大跌眼镜。</p><p>  The ET-SoC-1 in contrast can fit over 1000 RISC-V CPU cores implementing the Vector instruction extension. That is because vector processor can be made really tiny:</p><p>  相比之下，ET-SoC-1可以容纳1000个以上实现Vector指令扩展的RISC-V CPU内核。这是因为矢量处理器可以做得非常小：</p><p> They are in order, so you save a lot of silicon by not implementing complex OoOE controller logic.</p><p> 它们是有序的，因此您可以通过不实现复杂的OoOE控制器逻辑来节省大量芯片。</p><p> Thus if you can describe your problem as operations on large vectors, then you can get some crazy performance gains using the same number of transistors by going for a vector machine design.</p><p> 因此，如果您可以将问题描述为对大向量的运算，那么通过进行向量机设计，可以使用相同数量的晶体管获得一些疯狂的性能提升。</p><p>  But here is the kicker: If your program cannot be expressed that way you are in for a world of hurt. Executing regular desktop software which does not operate on large vectors will get terrible performance. Why?</p><p>  但是这里有一个关键点：如果无法以这种方式表示您的程序，那么您就陷入了一个痛苦的世界。执行不能在大向量上运行的常规桌面软件将获得可怕的性能。为什么？ </p><p> Your clock frequency is low. You got no OoOE, and your cache is tiny. Hence every instruction which needs to get some data has to wait a long time. This was the problem for Cray. They where simply not usable for general purpose computing. Due to the rest of the market using more traditional CPUs those got cheaper to make and a lot of the kind of software Cray computer ran could be done well by simply running on multicore machines, using clusters or whatever.</p><p>您的时钟频率低。您没有OoOE，并且您的缓存很小。因此，每个需要获取一些数据的指令都必须等待很长时间。这是克雷的问题。它们根本无法用于通用计算。由于使用其他传统CPU的其他市场价格便宜，而且Cray计算机上运行的许多软件都可以通过在多核计算机上运行，​​使用群集或其他方法来很好地完成。</p><p> When regular computers started to need vector processing, this was for multimedia applications. Image processing and stuff like that. In this case you typically work with small short vectors. Then SIMD instruction was an obvious and simple solution. They are pretty straight forward to setup. Just add some vector registers and operations to work on them. Vector instructions require much more thought and planning. You need ways to setup vector length and element types. Large vectors are impractical to save and restore when switching between programs. And anyway these programs didn’t need long vectors.</p><p> 当常规计算机开始需要矢量处理时，这是用于多媒体应用程序的。图像处理之类的东西。在这种情况下，您通常使用小的短向量。然后，SIMD指令是显而易见的简单解决方案。他们非常直接地进行设置。只需添加一些向量寄存器和操作即可。矢量指令需要更多的思考和计划。您需要设置矢量长度和元素类型的方法。在程序之间切换时，大的向量对于保存和恢复是不切实际的。无论如何，这些程序不需要长向量。</p><p> Thus there was initially no obvious advantage to vector extensions over SIMD. Because vector processing is not great for general purpose computing the ET-SoC-1 developed by Esperanto Technologies e.g. has four fat RISC-V cores, called ET-Maxion, designed for general purpose computing. These are more like the M1 Firestorm cores:</p><p> 因此，与SIMD相比，矢量扩展最初没有明显的优势。由于向量处理对于通用计算而言不是很好，因此世界语技术公司（Esperanto Technologies）开发的ET-SoC-1有四个肥胖的RISC-V内核，称为ET-Maxion，专为通用计算而设计。这些更像是M1 Firestorm核心：</p><p>  These will run the operating system and schedule work tasks to the smaller RISC-V cores (ET-minion) with vector extensions. This might be the type of architectural choices we will see more of: Mixing of different kinds of cores with different strengths.</p><p>  这些将运行操作系统并将工作任务调度到带有矢量扩展的较小的RISC-V内核（ET-minion）。这可能是架构选择的类型，我们将看到更多：混合使用具有不同强度的不同类型的核心。</p><p> General purpose computing cannot really benefit that much for having lots of cores. However for specialized tasks it is much better to use unconventional cores than large cores made for general purpose computing.</p><p> 通用计算不能真正受益于拥有大量内核。但是，对于特殊任务，使用非常规内核要比用于通用计算的大型内核好得多。</p><p>   Thus given a budget of X number of transistors, to speed up these tasks you would better of opting for a vector processor design than adding more large general purpose cores.</p><p>   因此，给定X晶体管数量的预算，要加快这些任务的执行时间，最好选择矢量处理器设计，而不是增加更多的通用内核。</p><p> Thus we are really back to the ar</p><p> 因此，我们真的回到了ar </p><p>......</p><p>...... </p></div><div id="story_share_this"><div class="sharethis-inline-share-buttons"></div></div><div class="text-break sotry_link page_narrow"><a target="_blank" href="https://medium.com/swlh/risc-v-vector-instructions-vs-arm-and-x86-simd-8c9b17963a31">https://medium.com/swlh/risc-v-vector-instructions-vs-arm-and-x86-simd-8c9b17963a31</a></div><div class="story_tags page_narrow"><button type="button" class="btn btn-light my_tag"><a href="/tag/向量指令/">#向量指令</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/vector/">#vector</a></button><button type="button" class="btn btn-light my_tag"><a href="/tag/指令/">#指令</a></button></div></div><div class="my_movie_list_item shadow p-3 mb-5 bg-white rounded"><button type="button" class="btn btn-link my_tag"><a href="/tag/web2.0/">#web2.0</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/google/">#google</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/设计/">#设计</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/创意/">#创意</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/摄影/">#摄影</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/游戏/">#游戏</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/图片/">#图片</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/软件/">#软件</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/视频/">#视频</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/手机/">#手机</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/广告/">#广告</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/iphone/">#iphone</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/网站/">#网站</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/免费/">#免费</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/windows/">#windows</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/下载/">#下载</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/苹果/">#苹果</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/微软/">#微软</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/apple/">#apple</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/firefox/">#firefox</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/blog/">#blog</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/音乐/">#音乐</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/博客/">#博客</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/wordpress/">#wordpress</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/恶搞/">#恶搞</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/qq/">#qq</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/艺术/">#艺术</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/web/">#web</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/工具/">#工具</a></button><button type="button" class="btn btn-link my_tag"><a href="/tag/分享/">#分享</a></button></div></div></div><div id="my_footer"><div class=""><a href="/tags/">tags</a> <a href="/users/">users</a></div>&copy; 2020 diglog.com </div></div></body></html>